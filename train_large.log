----------------------------------------------------------------
Activating environment
Python version used:
Python 3.10.15
Starting training...
NVML Initialized
Driver Version: b'450.80.02'
[2025-03-17 10:48:47,810][__main__][INFO] - Start experiment: exp/default/2025-03-17_10-48-47_
[2025-03-17 10:48:47,836][__main__][INFO] - create datalogger
[2025-03-17 10:48:47,836][__main__][INFO] - Create new model
[2025-03-17 10:48:49,304][models.ncsnpp][DEBUG] - NCSNpp.__init__
[2025-03-17 10:48:49,304][models.ncsnpp][DEBUG] - all_resolutions: [256, 128, 64, 32, 16, 8, 4]
[2025-03-17 10:48:49,307][models.ncsnpp][DEBUG] - num_channels: 6
[2025-03-17 10:48:51,659][__main__][INFO] - start training
NO CHECKPOINT TO RESUME FROM
[2025-03-17 10:48:53,681][model][INFO] - set optim with {'_target_': 'torch.optim.Adam', 'lr': 0.0001, 'weight_decay': 0.0}
┏━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓
┃   ┃ Name        ┃ Type             ┃ Params ┃ Mode  ┃
┡━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩
│ 0 │ model       │ ScoreModelNCSNpp │ 65.9 M │ train │
│ 1 │ loss        │ MSELoss          │      0 │ train │
│ 2 │ si_sdr_loss │ SISDRLoss        │      0 │ train │
└───┴─────────────┴──────────────────┴────────┴───────┘
Trainable params: 65.9 M                                                        
Non-trainable params: 128                                                       
Total params: 65.9 M                                                            
Total estimated model params size (MB): 263                                     
Modules in train mode: 444                                                      
Modules in eval mode: 0                                                         
[2025-03-17 10:50:34,435][model][INFO] - Training step 160 loss 1.2461738586425781
[2025-03-17 10:51:53,255][model][INFO] - Training step 320 loss 0.006489409599453211
[2025-03-17 10:53:16,291][model][INFO] - Training step 480 loss 1.0139460563659668
[2025-03-17 10:54:34,156][model][INFO] - Training step 640 loss 0.2875060737133026
[2025-03-17 10:55:54,772][model][INFO] - Training step 800 loss 0.009184171445667744
[2025-03-17 10:57:15,927][model][INFO] - Training step 960 loss 0.4051564037799835
[2025-03-17 10:58:32,142][model][INFO] - Training step 1120 loss 0.005273769143968821
[2025-03-17 10:59:55,026][model][INFO] - Training step 1280 loss 0.007371074520051479
[2025-03-17 11:01:15,278][model][INFO] - Training step 1440 loss 108.04603576660156
[2025-03-17 11:02:33,579][model][INFO] - Training step 1600 loss 0.0013001123443245888
[2025-03-17 11:03:53,978][model][INFO] - Training step 1760 loss 0.32948899269104004
[2025-03-17 11:05:14,222][model][INFO] - Training step 1920 loss 0.3641066551208496
[2025-03-17 11:06:36,530][model][INFO] - Training step 2080 loss 0.4471643567085266
[2025-03-17 11:07:57,539][model][INFO] - Training step 2240 loss 0.33538973331451416
[2025-03-17 11:09:18,792][model][INFO] - Training step 2400 loss 0.3274137079715729
[2025-03-17 11:10:37,412][model][INFO] - Training step 2560 loss 0.3636816143989563
[2025-03-17 11:11:58,426][model][INFO] - Training step 2720 loss 0.31293004751205444
[2025-03-17 11:13:19,480][model][INFO] - Training step 2880 loss 0.3331720530986786
[2025-03-17 11:14:41,192][model][INFO] - Training step 3040 loss 0.326437771320343
[2025-03-17 11:16:02,743][model][INFO] - Training step 3200 loss 0.2462785840034485
[2025-03-17 11:17:24,805][model][INFO] - Training step 3360 loss 0.2997922897338867
[2025-03-17 11:18:42,202][model][INFO] - Training step 3520 loss 0.25873079895973206
[2025-03-17 11:20:04,865][model][INFO] - Training step 3680 loss 0.0012664982350543141
[2025-03-17 11:21:24,004][model][INFO] - Training step 3840 loss 0.18286141753196716
[2025-03-17 11:22:47,666][model][INFO] - Training step 4000 loss 0.1848963350057602
[2025-03-17 11:24:09,680][model][INFO] - Training step 4160 loss 0.19802024960517883
[2025-03-17 11:25:28,893][model][INFO] - Training step 4320 loss 0.28668415546417236
[2025-03-17 11:26:49,943][model][INFO] - Training step 4480 loss 0.30510425567626953
[2025-03-17 11:28:09,596][model][INFO] - Training step 4640 loss 0.1893472820520401
[2025-03-17 11:29:26,997][model][INFO] - Training step 4800 loss 0.32327142357826233
[2025-03-17 11:30:47,278][model][INFO] - Training step 4960 loss 0.30290576815605164
[2025-03-17 11:32:09,111][model][INFO] - Training step 5120 loss 0.5485382080078125
[2025-03-17 11:33:27,992][model][INFO] - Training step 5280 loss 0.12623371183872223
[2025-03-17 11:34:49,204][model][INFO] - Training step 5440 loss 0.15438470244407654
[2025-03-17 11:36:06,872][model][INFO] - Training step 5600 loss 0.2742757797241211
[2025-03-17 11:37:27,139][model][INFO] - Training step 5760 loss 0.09573175013065338
[2025-03-17 11:38:48,942][model][INFO] - Training step 5920 loss 0.2341449111700058
[2025-03-17 11:40:10,219][model][INFO] - Training step 6080 loss 0.1796310842037201
[2025-03-17 11:41:32,653][model][INFO] - Training step 6240 loss 0.2970295548439026
[2025-03-17 11:42:51,898][model][INFO] - Training step 6400 loss 0.13160035014152527
[2025-03-17 11:44:12,778][model][INFO] - Training step 6560 loss 0.2272290736436844
[2025-03-17 11:45:33,826][model][INFO] - Training step 6720 loss 0.003785516135394573
[2025-03-17 11:46:52,095][model][INFO] - Training step 6880 loss 0.23290064930915833
[2025-03-17 11:48:12,014][model][INFO] - Training step 7040 loss 0.09126898646354675
[2025-03-17 11:49:32,591][model][INFO] - Training step 7200 loss 0.17873156070709229
[2025-03-17 11:50:53,241][model][INFO] - Training step 7360 loss 0.10843020677566528
[2025-03-17 11:52:10,161][model][INFO] - Training step 7520 loss 0.1537591516971588
[2025-03-17 11:53:29,749][model][INFO] - Training step 7680 loss 0.003348561469465494
[2025-03-17 11:54:48,234][model][INFO] - Training step 7840 loss 0.09395803511142731
[2025-03-17 11:56:04,502][model][INFO] - Training step 8000 loss 0.009146117605268955
[2025-03-17 11:57:24,565][model][INFO] - Training step 8160 loss 0.07361940294504166
[2025-03-17 11:58:43,248][model][INFO] - Training step 8320 loss 0.2927003502845764
[2025-03-17 12:00:00,495][model][INFO] - Training step 8480 loss 0.1558087170124054
[2025-03-17 12:01:20,250][model][INFO] - Training step 8640 loss 0.16168266534805298
[2025-03-17 12:02:40,753][model][INFO] - Training step 8800 loss 0.12654604017734528
[2025-03-17 12:03:59,736][model][INFO] - Training step 8960 loss 0.023794930428266525
[2025-03-17 12:05:19,830][model][INFO] - Training step 9120 loss 0.183632493019104
[2025-03-17 12:06:39,875][model][INFO] - Training step 9280 loss 0.11016057431697845
[2025-03-17 12:07:58,030][model][INFO] - Training step 9440 loss 0.07575751096010208
[2025-03-17 12:09:17,173][model][INFO] - Training step 9600 loss 0.10380479693412781
[2025-03-17 12:10:39,248][model][INFO] - Training step 9760 loss 0.07502883672714233
[2025-03-17 12:12:00,555][model][INFO] - Training step 9920 loss 0.45131656527519226
[2025-03-17 12:13:20,299][model][INFO] - Training step 10080 loss 0.01128273457288742
[2025-03-17 12:14:36,133][model][INFO] - Training step 10240 loss 0.06499908864498138
[2025-03-17 12:15:58,166][model][INFO] - Training step 10400 loss 0.07700365036725998
[2025-03-17 12:17:17,485][model][INFO] - Training step 10560 loss 0.0036221188493072987
[2025-03-17 12:18:38,424][model][INFO] - Training step 10720 loss 0.058915477246046066
[2025-03-17 12:19:59,610][model][INFO] - Training step 10880 loss 0.11564401537179947
[2025-03-17 12:21:19,390][model][INFO] - Training step 11040 loss 0.0992400050163269
[2025-03-17 12:22:37,006][model][INFO] - Training step 11200 loss 0.15037646889686584
[2025-03-17 12:23:54,741][model][INFO] - Training step 11360 loss 0.25598713755607605
[2025-03-17 12:25:12,624][model][INFO] - Training step 11520 loss 0.2765955328941345
[2025-03-17 12:26:31,928][model][INFO] - Training step 11680 loss 0.11386112123727798
[2025-03-17 12:27:52,047][model][INFO] - Training step 11840 loss 0.00637500174343586
[2025-03-17 12:29:09,211][model][INFO] - Training step 12000 loss 0.2627931833267212
[2025-03-17 12:30:30,255][model][INFO] - Training step 12160 loss 0.09293808043003082
[2025-03-17 12:31:49,000][model][INFO] - Training step 12320 loss 0.15630969405174255
[2025-03-17 12:33:09,369][model][INFO] - Training step 12480 loss 0.08688659965991974
[2025-03-17 12:34:26,529][model][INFO] - Training step 12640 loss 0.11831174790859222
[2025-03-17 12:35:46,988][model][INFO] - Training step 12800 loss 0.15308593213558197
[2025-03-17 12:37:04,665][model][INFO] - Training step 12960 loss 0.19992229342460632
[2025-03-17 12:38:25,610][model][INFO] - Training step 13120 loss 0.06119022145867348
[2025-03-17 12:39:43,689][model][INFO] - Training step 13280 loss 0.05889085680246353
[2025-03-17 12:41:02,559][model][INFO] - Training step 13440 loss 0.01482787262648344
[2025-03-17 12:42:20,778][model][INFO] - Training step 13600 loss 0.08505722880363464
[2025-03-17 12:43:44,090][model][INFO] - Training step 13760 loss 0.10694652795791626
[2025-03-17 12:45:05,124][model][INFO] - Training step 13920 loss 0.12731732428073883
[2025-03-17 12:46:22,455][model][INFO] - Training step 14080 loss 0.08581703901290894
[2025-03-17 12:47:38,452][model][INFO] - Training step 14240 loss 0.26061317324638367
[2025-03-17 12:48:59,386][model][INFO] - Training step 14400 loss 0.23692777752876282
[2025-03-17 12:50:18,785][model][INFO] - Training step 14560 loss 0.09772695600986481
[2025-03-17 12:51:38,822][model][INFO] - Training step 14720 loss 0.5653331279754639
[2025-03-17 12:52:57,590][model][INFO] - Training step 14880 loss 0.09187527745962143
[2025-03-17 12:54:18,865][model][INFO] - Training step 15040 loss 0.10813476145267487
[2025-03-17 12:55:37,898][model][INFO] - Training step 15200 loss 0.06318051367998123
[2025-03-17 12:56:58,636][model][INFO] - Training step 15360 loss 0.24412253499031067
[2025-03-17 12:58:16,483][model][INFO] - Training step 15520 loss 0.0934201031923294
[2025-03-17 12:59:36,180][model][INFO] - Training step 15680 loss 0.10302484035491943
[2025-03-17 13:00:55,911][model][INFO] - Training step 15840 loss 0.3621414303779602
[2025-03-17 13:02:14,216][model][INFO] - Training step 16000 loss 0.27786847949028015
[2025-03-17 13:03:34,766][model][INFO] - Training step 16160 loss 0.05424370989203453
[2025-03-17 13:04:53,483][model][INFO] - Training step 16320 loss 0.10202495008707047
[2025-03-17 13:06:11,554][model][INFO] - Training step 16480 loss 0.24843713641166687
[2025-03-17 13:07:30,058][model][INFO] - Training step 16640 loss 0.12062319368124008
[2025-03-17 13:08:47,724][model][INFO] - Training step 16800 loss 0.1296679675579071
[2025-03-17 13:10:08,860][model][INFO] - Training step 16960 loss 0.07399623095989227
[2025-03-17 13:11:29,077][model][INFO] - Training step 17120 loss 0.07902278006076813
[2025-03-17 13:12:46,983][model][INFO] - Training step 17280 loss 0.4264684319496155
[2025-03-17 13:14:07,921][model][INFO] - Training step 17440 loss 0.08714260905981064
[2025-03-17 13:15:27,589][model][INFO] - Training step 17600 loss 0.0824788510799408
[2025-03-17 13:16:47,582][model][INFO] - Training step 17760 loss 0.08766776323318481
[2025-03-17 13:18:08,054][model][INFO] - Training step 17920 loss 0.2843879461288452
[2025-03-17 13:19:28,413][model][INFO] - Training step 18080 loss 0.005182292312383652
[2025-03-17 13:20:47,236][model][INFO] - Training step 18240 loss 0.07489049434661865
[2025-03-17 13:22:09,512][model][INFO] - Training step 18400 loss 0.016588516533374786
[2025-03-17 13:23:27,719][model][INFO] - Training step 18560 loss 0.006175711750984192
[2025-03-17 13:24:47,636][model][INFO] - Training step 18720 loss 0.16382049024105072
[2025-03-17 13:26:05,909][model][INFO] - Training step 18880 loss 0.2417420744895935
[2025-03-17 13:27:24,377][model][INFO] - Training step 19040 loss 0.004426229745149612
[2025-03-17 13:28:44,535][model][INFO] - Training step 19200 loss 0.015175905078649521
[2025-03-17 13:30:04,441][model][INFO] - Training step 19360 loss 0.055714160203933716
[2025-03-17 13:31:25,385][model][INFO] - Training step 19520 loss 0.1621890515089035
[2025-03-17 13:32:45,441][model][INFO] - Training step 19680 loss 0.07178550958633423
[2025-03-17 13:34:03,704][model][INFO] - Training step 19840 loss 0.13224589824676514
[2025-03-17 13:35:23,346][model][INFO] - Training step 20000 loss 0.12576903402805328
[2025-03-17 13:36:43,145][model][INFO] - Training step 20160 loss 0.07859440892934799
[2025-03-17 13:38:03,331][model][INFO] - Training step 20320 loss 0.14282667636871338
[2025-03-17 13:39:22,582][model][INFO] - Training step 20480 loss 0.11517339944839478
[2025-03-17 13:40:41,547][model][INFO] - Training step 20640 loss 0.005632850807160139
[2025-03-17 13:42:01,693][model][INFO] - Training step 20800 loss 0.09969636797904968
[2025-03-17 13:43:19,344][model][INFO] - Training step 20960 loss 0.05820795148611069
[2025-03-17 13:44:42,170][model][INFO] - Training step 21120 loss 0.17479291558265686
[2025-03-17 13:46:01,817][model][INFO] - Training step 21280 loss 0.0503852516412735
[2025-03-17 13:47:23,753][model][INFO] - Training step 21440 loss 0.19523954391479492
[2025-03-17 13:48:40,636][model][INFO] - Training step 21600 loss 0.13583040237426758
[2025-03-17 13:50:02,817][model][INFO] - Training step 21760 loss 0.07262986153364182
[2025-03-17 13:51:20,881][model][INFO] - Training step 21920 loss 0.26564279198646545
[2025-03-17 13:52:37,875][model][INFO] - Training step 22080 loss 0.09029269218444824
[2025-03-17 13:53:56,353][model][INFO] - Training step 22240 loss 0.07830992341041565
[2025-03-17 13:55:19,185][model][INFO] - Training step 22400 loss 0.07182706147432327
[2025-03-17 13:56:39,576][model][INFO] - Training step 22560 loss 0.05987180769443512
[2025-03-17 13:57:57,910][model][INFO] - Training step 22720 loss 0.06846778094768524
[2025-03-17 13:59:19,285][model][INFO] - Training step 22880 loss 0.00447081308811903
[2025-03-17 14:00:40,930][model][INFO] - Training step 23040 loss 0.08906348049640656
[2025-03-17 14:02:00,361][model][INFO] - Training step 23200 loss 0.09940718114376068
[2025-03-17 14:03:21,427][model][INFO] - Training step 23360 loss 0.005396188702434301
[2025-03-17 14:04:41,142][model][INFO] - Training step 23520 loss 0.056456904858350754
[2025-03-17 14:05:58,463][model][INFO] - Training step 23680 loss 0.06848938018083572
[2025-03-17 14:07:18,747][model][INFO] - Training step 23840 loss 0.06853902339935303
[2025-03-17 14:08:36,097][model][INFO] - Training step 24000 loss 0.27701014280319214
[2025-03-17 14:09:55,445][model][INFO] - Training step 24160 loss 0.06027722358703613
[2025-03-17 14:11:15,102][model][INFO] - Training step 24320 loss 0.24617332220077515
[2025-03-17 14:12:33,213][model][INFO] - Training step 24480 loss 0.22712016105651855
[2025-03-17 14:13:51,906][model][INFO] - Training step 24640 loss 0.07525696605443954
[2025-03-17 14:15:09,940][model][INFO] - Training step 24800 loss 0.07354778051376343
[2025-03-17 14:16:33,568][model][INFO] - Training step 24960 loss 0.0793314129114151
[2025-03-17 14:17:52,424][model][INFO] - Training step 25120 loss 0.26129311323165894
[2025-03-17 14:19:08,954][model][INFO] - Training step 25280 loss 0.049578867852687836
[2025-03-17 14:20:25,750][model][INFO] - Training step 25440 loss 0.050756920129060745
[2025-03-17 14:21:46,289][model][INFO] - Training step 25600 loss 0.08923330157995224
[2025-03-17 14:23:04,571][model][INFO] - Training step 25760 loss 0.23415711522102356
[2025-03-17 14:24:23,596][model][INFO] - Training step 25920 loss 0.06472162902355194
[2025-03-17 14:25:42,753][model][INFO] - Training step 26080 loss 0.057625509798526764
[2025-03-17 14:27:03,946][model][INFO] - Training step 26240 loss 0.0625847727060318
[2025-03-17 14:28:22,691][model][INFO] - Training step 26400 loss 0.005773274227976799
[2025-03-17 14:29:44,277][model][INFO] - Training step 26560 loss 0.3217886984348297
[2025-03-17 14:31:04,967][model][INFO] - Training step 26720 loss 0.24567747116088867
[2025-03-17 14:32:24,709][model][INFO] - Training step 26880 loss 0.08467699587345123
[2025-03-17 14:33:44,510][model][INFO] - Training step 27040 loss 0.04291801154613495
[2025-03-17 14:35:06,907][model][INFO] - Training step 27200 loss 0.0455140620470047
[2025-03-17 14:36:27,206][model][INFO] - Training step 27360 loss 0.06233377382159233
[2025-03-17 14:37:44,523][model][INFO] - Training step 27520 loss 0.08316992968320847
[2025-03-17 14:39:03,581][model][INFO] - Training step 27680 loss 0.002679641591385007
[2025-03-17 14:40:21,225][model][INFO] - Training step 27840 loss 0.0932859256863594
[2025-03-17 14:41:44,514][model][INFO] - Training step 28000 loss 0.2709958553314209
[2025-03-17 14:43:03,759][model][INFO] - Training step 28160 loss 0.14912712574005127
[2025-03-17 14:44:24,985][model][INFO] - Training step 28320 loss 0.05573422089219093
[2025-03-17 14:45:43,455][model][INFO] - Training step 28480 loss 0.2686654329299927
[2025-03-17 14:47:01,438][model][INFO] - Training step 28640 loss 0.08027619123458862
[2025-03-17 14:48:20,488][model][INFO] - Training step 28800 loss 0.259227991104126
[2025-03-17 14:49:40,937][model][INFO] - Training step 28960 loss 0.007713643368333578
[2025-03-17 14:50:59,771][model][INFO] - Training step 29120 loss 0.10313141345977783
[2025-03-17 14:52:21,888][model][INFO] - Training step 29280 loss 0.08560384809970856
[2025-03-17 14:53:41,614][model][INFO] - Training step 29440 loss 0.27643445134162903
[2025-03-17 14:55:00,268][model][INFO] - Training step 29600 loss 0.008330564945936203
[2025-03-17 14:56:21,157][model][INFO] - Training step 29760 loss 0.2601003646850586
[2025-03-17 14:57:41,331][model][INFO] - Training step 29920 loss 0.07815621793270111
[2025-03-17 14:59:01,335][model][INFO] - Training step 30080 loss 0.07072646915912628
[2025-03-17 15:00:18,622][model][INFO] - Training step 30240 loss 0.06743009388446808
[2025-03-17 15:01:40,962][model][INFO] - Training step 30400 loss 0.14808163046836853
[2025-03-17 15:03:01,058][model][INFO] - Training step 30560 loss 0.19080707430839539
[2025-03-17 15:04:17,281][model][INFO] - Training step 30720 loss 0.04552771896123886
[2025-03-17 15:05:35,070][model][INFO] - Training step 30880 loss 0.05699819326400757
[2025-03-17 15:06:54,098][model][INFO] - Training step 31040 loss 0.24889656901359558
[2025-03-17 15:08:12,257][model][INFO] - Training step 31200 loss 0.05750560760498047
[2025-03-17 15:09:34,531][model][INFO] - Training step 31360 loss 0.09397049993276596
[2025-03-17 15:10:52,913][model][INFO] - Training step 31520 loss 0.11782518029212952
[2025-03-17 15:12:13,806][model][INFO] - Training step 31680 loss 0.12441609799861908
[2025-03-17 15:13:31,218][model][INFO] - Training step 31840 loss 0.08316163718700409
[2025-03-17 15:14:47,159][model][INFO] - Training step 32000 loss 0.06579321622848511
[2025-03-17 15:16:06,616][model][INFO] - Training step 32160 loss 0.17013144493103027
[2025-03-17 15:17:26,060][model][INFO] - Training step 32320 loss 0.052156344056129456
[2025-03-17 15:18:45,586][model][INFO] - Training step 32480 loss 0.27441754937171936
[2025-03-17 15:20:08,691][model][INFO] - Training step 32640 loss 0.07905291020870209
[2025-03-17 15:21:27,738][model][INFO] - Training step 32800 loss 0.2446780800819397
[2025-03-17 15:22:52,713][model][INFO] - Training step 32960 loss 0.10214649140834808
[2025-03-17 15:24:12,587][model][INFO] - Training step 33120 loss 0.06061771512031555
[2025-03-17 15:25:30,619][model][INFO] - Training step 33280 loss 0.11366535723209381
[2025-03-17 15:26:52,643][model][INFO] - Training step 33440 loss 0.07646352052688599
[2025-03-17 15:28:12,476][model][INFO] - Training step 33600 loss 0.26947736740112305
[2025-03-17 15:29:32,341][model][INFO] - Training step 33760 loss 0.25812679529190063
[2025-03-17 15:30:53,267][model][INFO] - Training step 33920 loss 0.11219539493322372
[2025-03-17 15:32:13,824][model][INFO] - Training step 34080 loss 0.0057605872862041
[2025-03-17 15:33:35,133][model][INFO] - Training step 34240 loss 0.15559005737304688
[2025-03-17 15:34:56,761][model][INFO] - Training step 34400 loss 0.006329347379505634
[2025-03-17 15:36:17,322][model][INFO] - Training step 34560 loss 0.23827581107616425
[2025-03-17 15:37:35,882][model][INFO] - Training step 34720 loss 0.07786105573177338
[2025-03-17 15:38:55,126][model][INFO] - Training step 34880 loss 0.061517395079135895
[2025-03-17 15:40:17,596][model][INFO] - Training step 35040 loss 0.061781540513038635
[2025-03-17 15:41:37,044][model][INFO] - Training step 35200 loss 0.1478404402732849
[2025-03-17 15:42:57,059][model][INFO] - Training step 35360 loss 0.17788997292518616
[2025-03-17 15:44:19,748][model][INFO] - Training step 35520 loss 0.011559702455997467
[2025-03-17 15:45:36,950][model][INFO] - Training step 35680 loss 0.16707506775856018
[2025-03-17 15:46:56,257][model][INFO] - Training step 35840 loss 0.037445634603500366
[2025-03-17 15:48:13,141][model][INFO] - Training step 36000 loss 0.07269187271595001
[2025-03-17 15:49:31,147][model][INFO] - Training step 36160 loss 0.08986839652061462
[2025-03-17 15:50:49,387][model][INFO] - Training step 36320 loss 0.040653061121702194
[2025-03-17 15:52:09,697][model][INFO] - Training step 36480 loss 0.04651534557342529
[2025-03-17 15:53:30,817][model][INFO] - Training step 36640 loss 0.05501963943243027
[2025-03-17 15:54:49,116][model][INFO] - Training step 36800 loss 0.27148187160491943
[2025-03-17 15:56:11,737][model][INFO] - Training step 36960 loss 0.2075863927602768
[2025-03-17 15:57:31,792][model][INFO] - Training step 37120 loss 0.2739311456680298
[2025-03-17 15:58:51,590][model][INFO] - Training step 37280 loss 0.05945223569869995
[2025-03-17 16:00:10,426][model][INFO] - Training step 37440 loss 0.08752568066120148
[2025-03-17 16:01:27,456][model][INFO] - Training step 37600 loss 0.08461534231901169
[2025-03-17 16:02:46,575][model][INFO] - Training step 37760 loss 0.04912666976451874
[2025-03-17 16:04:03,460][model][INFO] - Training step 37920 loss 0.0434751957654953
[2025-03-17 16:05:23,254][model][INFO] - Training step 38080 loss 0.06858667731285095
[2025-03-17 16:06:41,938][model][INFO] - Training step 38240 loss 0.04988342523574829
[2025-03-17 16:08:01,192][model][INFO] - Training step 38400 loss 0.07168611884117126
[2025-03-17 16:09:16,963][model][INFO] - Training step 38560 loss 0.25259390473365784
[2025-03-17 16:10:36,877][model][INFO] - Training step 38720 loss 0.26955646276474
[2025-03-17 16:11:56,497][model][INFO] - Training step 38880 loss 0.05131169408559799
[2025-03-17 16:13:14,184][model][INFO] - Training step 39040 loss 0.03852537274360657
[2025-03-17 16:14:34,630][model][INFO] - Training step 39200 loss 0.005340630188584328
[2025-03-17 16:15:54,189][model][INFO] - Training step 39360 loss 0.058031998574733734
[2025-03-17 16:17:13,854][model][INFO] - Training step 39520 loss 0.19392898678779602
[2025-03-17 16:18:31,818][model][INFO] - Training step 39680 loss 0.039576731622219086
[2025-03-17 16:19:51,292][model][INFO] - Training step 39840 loss 0.055916257202625275
[2025-03-17 16:21:13,629][model][INFO] - Training step 40000 loss 0.0662602037191391
[2025-03-17 16:22:34,561][model][INFO] - Training step 40160 loss 0.05754102021455765
[2025-03-17 16:23:53,816][model][INFO] - Training step 40320 loss 0.08747027814388275
[2025-03-17 16:25:15,350][model][INFO] - Training step 40480 loss 0.21371178328990936
[2025-03-17 16:26:34,432][model][INFO] - Training step 40640 loss 0.06755789369344711
[2025-03-17 16:27:51,833][model][INFO] - Training step 40800 loss 0.1555841863155365
[2025-03-17 16:29:09,543][model][INFO] - Training step 40960 loss 0.4148014783859253
[2025-03-17 16:30:30,262][model][INFO] - Training step 41120 loss 0.007391207851469517
[2025-03-17 16:31:52,961][model][INFO] - Training step 41280 loss 0.053572963923215866
[2025-03-17 16:33:09,845][model][INFO] - Training step 41440 loss 0.2781335711479187
[2025-03-17 16:34:28,764][model][INFO] - Training step 41600 loss 0.2523699402809143
[2025-03-17 16:35:51,184][model][INFO] - Training step 41760 loss 0.26762279868125916
[2025-03-17 16:37:10,378][model][INFO] - Training step 41920 loss 0.05808853358030319
[2025-03-17 16:38:28,716][model][INFO] - Training step 42080 loss 0.00433475524187088
[2025-03-17 16:39:44,024][model][INFO] - Training step 42240 loss 0.16169583797454834
[2025-03-17 16:41:02,386][model][INFO] - Training step 42400 loss 0.2576634883880615
[2025-03-17 16:42:22,586][model][INFO] - Training step 42560 loss 0.2343568503856659
[2025-03-17 16:43:42,537][model][INFO] - Training step 42720 loss 0.02880653738975525
[2025-03-17 16:45:00,040][model][INFO] - Training step 42880 loss 0.07301411032676697
[2025-03-17 16:46:20,675][model][INFO] - Training step 43040 loss 0.07057539373636246
[2025-03-17 16:47:38,046][model][INFO] - Training step 43200 loss 0.05378671735525131
[2025-03-17 16:48:58,642][model][INFO] - Training step 43360 loss 0.19386079907417297
[2025-03-17 16:50:19,895][model][INFO] - Training step 43520 loss 0.2782265543937683
[2025-03-17 16:51:41,150][model][INFO] - Training step 43680 loss 0.23088806867599487
[2025-03-17 16:53:02,506][model][INFO] - Training step 43840 loss 0.05866241082549095
[2025-03-17 16:54:21,116][model][INFO] - Training step 44000 loss 0.0719301849603653
[2025-03-17 16:55:40,529][model][INFO] - Training step 44160 loss 0.03837520256638527
[2025-03-17 16:57:00,083][model][INFO] - Training step 44320 loss 0.03795737773180008
[2025-03-17 16:58:20,090][model][INFO] - Training step 44480 loss 0.029881827533245087
[2025-03-17 16:59:38,131][model][INFO] - Training step 44640 loss 0.042269568890333176
[2025-03-17 17:00:58,723][model][INFO] - Training step 44800 loss 0.2659260630607605
[2025-03-17 17:02:15,979][model][INFO] - Training step 44960 loss 0.1077890545129776
[2025-03-17 17:03:37,087][model][INFO] - Training step 45120 loss 0.05771251022815704
[2025-03-17 17:04:59,218][model][INFO] - Training step 45280 loss 0.05623519793152809
[2025-03-17 17:06:20,713][model][INFO] - Training step 45440 loss 0.10514667630195618
[2025-03-17 17:07:42,107][model][INFO] - Training step 45600 loss 0.09696453809738159
[2025-03-17 17:09:03,368][model][INFO] - Training step 45760 loss 0.0536096915602684
[2025-03-17 17:10:24,460][model][INFO] - Training step 45920 loss 0.2548673748970032
[2025-03-17 17:11:44,380][model][INFO] - Training step 46080 loss 0.2273133248090744
[2025-03-17 17:13:00,962][model][INFO] - Training step 46240 loss 0.008191948756575584
[2025-03-17 17:14:25,715][model][INFO] - Training step 46400 loss 0.00549910357221961
[2025-03-17 17:15:39,906][model][INFO] - Training step 46560 loss 0.008749352768063545
[2025-03-17 17:17:00,078][model][INFO] - Training step 46720 loss 0.16568785905838013
[2025-03-17 17:18:18,998][model][INFO] - Training step 46880 loss 0.004281374625861645
[2025-03-17 17:19:37,124][model][INFO] - Training step 47040 loss 0.13781656324863434
[2025-03-17 17:20:56,851][model][INFO] - Training step 47200 loss 0.03499395772814751
[2025-03-17 17:22:15,677][model][INFO] - Training step 47360 loss 0.04458419233560562
[2025-03-17 17:23:37,551][model][INFO] - Training step 47520 loss 0.032621584832668304
[2025-03-17 17:24:57,437][model][INFO] - Training step 47680 loss 0.2679556608200073
[2025-03-17 17:26:14,807][model][INFO] - Training step 47840 loss 0.04210998862981796
[2025-03-17 17:27:35,419][model][INFO] - Training step 48000 loss 0.19907355308532715
[2025-03-17 17:28:55,838][model][INFO] - Training step 48160 loss 0.048130400478839874
[2025-03-17 17:30:14,228][model][INFO] - Training step 48320 loss 0.010824255645275116
[2025-03-17 17:31:34,303][model][INFO] - Training step 48480 loss 0.015183783136308193
[2025-03-17 17:32:55,140][model][INFO] - Training step 48640 loss 0.2558009922504425
[2025-03-17 17:34:17,390][model][INFO] - Training step 48800 loss 0.04204887896776199
[2025-03-17 17:35:37,987][model][INFO] - Training step 48960 loss 0.04234945774078369
[2025-03-17 17:36:58,405][model][INFO] - Training step 49120 loss 0.046234458684921265
[2025-03-17 17:38:19,508][model][INFO] - Training step 49280 loss 0.12103282660245895
[2025-03-17 17:39:41,181][model][INFO] - Training step 49440 loss 0.25919467210769653
[2025-03-17 17:41:00,838][model][INFO] - Training step 49600 loss 0.0031557923648506403
[2025-03-17 17:42:21,717][model][INFO] - Training step 49760 loss 0.017189692705869675
[2025-03-17 17:43:42,523][model][INFO] - Training step 49920 loss 0.036012861877679825
[2025-03-17 17:44:59,312][model][INFO] - Training step 50080 loss 0.2755467891693115
[2025-03-17 17:46:19,891][model][INFO] - Training step 50240 loss 0.09347423166036606
[2025-03-17 17:47:39,047][model][INFO] - Training step 50400 loss 0.07863817363977432
[2025-03-17 17:48:58,240][model][INFO] - Training step 50560 loss 0.042344991117715836
[2025-03-17 17:50:16,365][model][INFO] - Training step 50720 loss 0.05305732786655426
[2025-03-17 17:59:50,761][model][INFO] - Training step 80 loss 0.26214271783828735
[2025-03-17 18:01:09,624][model][INFO] - Training step 240 loss 0.005833810195326805
[2025-03-17 18:02:29,469][model][INFO] - Training step 400 loss 0.24346235394477844
[2025-03-17 18:03:50,965][model][INFO] - Training step 560 loss 0.0471554696559906
[2025-03-17 18:05:13,961][model][INFO] - Training step 720 loss 0.06748379021883011
[2025-03-17 18:06:35,014][model][INFO] - Training step 880 loss 0.2896943688392639
[2025-03-17 18:07:53,035][model][INFO] - Training step 1040 loss 0.02745092660188675
[2025-03-17 18:09:10,346][model][INFO] - Training step 1200 loss 0.11377659440040588
[2025-03-17 18:10:32,009][model][INFO] - Training step 1360 loss 0.06361788511276245
[2025-03-17 18:11:47,049][model][INFO] - Training step 1520 loss 0.08685864508152008
[2025-03-17 18:13:08,383][model][INFO] - Training step 1680 loss 0.17844457924365997
[2025-03-17 18:14:28,686][model][INFO] - Training step 1840 loss 0.10051435232162476
[2025-03-17 18:15:49,173][model][INFO] - Training step 2000 loss 0.0788634717464447
[2025-03-17 18:17:12,659][model][INFO] - Training step 2160 loss 0.0351564921438694
[2025-03-17 18:18:32,228][model][INFO] - Training step 2320 loss 0.05309576541185379
[2025-03-17 18:19:50,634][model][INFO] - Training step 2480 loss 0.260387122631073
[2025-03-17 18:21:08,907][model][INFO] - Training step 2640 loss 0.2660835385322571
[2025-03-17 18:22:29,657][model][INFO] - Training step 2800 loss 0.26156535744667053
[2025-03-17 18:23:51,131][model][INFO] - Training step 2960 loss 0.04665954038500786
[2025-03-17 18:25:09,261][model][INFO] - Training step 3120 loss 0.005355100147426128
[2025-03-17 18:26:26,478][model][INFO] - Training step 3280 loss 0.2469595968723297
[2025-03-17 18:27:46,724][model][INFO] - Training step 3440 loss 0.07859797775745392
[2025-03-17 18:29:05,008][model][INFO] - Training step 3600 loss 0.06040975823998451
[2025-03-17 18:30:28,756][model][INFO] - Training step 3760 loss 0.057247936725616455
[2025-03-17 18:31:47,907][model][INFO] - Training step 3920 loss 0.041021689772605896
[2025-03-17 18:33:09,653][model][INFO] - Training step 4080 loss 0.28051328659057617
[2025-03-17 18:34:30,787][model][INFO] - Training step 4240 loss 0.10403233021497726
[2025-03-17 18:35:49,232][model][INFO] - Training step 4400 loss 0.03279682993888855
[2025-03-17 18:37:11,149][model][INFO] - Training step 4560 loss 0.25821545720100403
[2025-03-17 18:38:33,765][model][INFO] - Training step 4720 loss 0.2567395567893982
[2025-03-17 18:39:53,891][model][INFO] - Training step 4880 loss 0.0462832897901535
[2025-03-17 18:41:13,144][model][INFO] - Training step 5040 loss 0.10499925911426544
[2025-03-17 18:42:30,934][model][INFO] - Training step 5200 loss 0.265627384185791
[2025-03-17 18:43:50,100][model][INFO] - Training step 5360 loss 0.0880277007818222
[2025-03-17 18:45:08,175][model][INFO] - Training step 5520 loss 0.13787293434143066
[2025-03-17 18:46:28,657][model][INFO] - Training step 5680 loss 0.04101208597421646
[2025-03-17 18:47:48,804][model][INFO] - Training step 5840 loss 0.07413406670093536
[2025-03-17 18:49:07,889][model][INFO] - Training step 6000 loss 0.03015591949224472
[2025-03-17 18:50:27,293][model][INFO] - Training step 6160 loss 0.044634439051151276
[2025-03-17 18:51:48,718][model][INFO] - Training step 6320 loss 0.061170510947704315
[2025-03-17 18:53:07,213][model][INFO] - Training step 6480 loss 0.26363956928253174
[2025-03-17 18:54:25,086][model][INFO] - Training step 6640 loss 0.26913982629776
[2025-03-17 18:55:44,709][model][INFO] - Training step 6800 loss 0.03222765028476715
[2025-03-17 18:57:05,310][model][INFO] - Training step 6960 loss 0.26596105098724365
[2025-03-17 18:58:24,526][model][INFO] - Training step 7120 loss 0.07750412076711655
[2025-03-17 18:59:45,717][model][INFO] - Training step 7280 loss 0.05447045713663101
[2025-03-17 19:01:04,220][model][INFO] - Training step 7440 loss 0.004353073425590992
[2025-03-17 19:02:22,803][model][INFO] - Training step 7600 loss 0.2465384602546692
[2025-03-17 19:03:41,679][model][INFO] - Training step 7760 loss 0.25355708599090576
[2025-03-17 19:05:01,669][model][INFO] - Training step 7920 loss 0.04820791631937027
[2025-03-17 19:06:20,646][model][INFO] - Training step 8080 loss 0.05450502783060074
[2025-03-17 19:07:41,106][model][INFO] - Training step 8240 loss 0.1213264912366867
[2025-03-17 19:09:00,258][model][INFO] - Training step 8400 loss 0.14933687448501587
[2025-03-17 19:10:17,376][model][INFO] - Training step 8560 loss 0.06924547255039215
[2025-03-17 19:11:36,972][model][INFO] - Training step 8720 loss 0.19292721152305603
[2025-03-17 19:12:54,675][model][INFO] - Training step 8880 loss 0.042224932461977005
[2025-03-17 19:14:13,065][model][INFO] - Training step 9040 loss 0.05060133337974548
[2025-03-17 19:15:27,857][model][INFO] - Training step 9200 loss 0.05615860968828201
[2025-03-17 19:16:47,427][model][INFO] - Training step 9360 loss 0.08946970850229263
[2025-03-17 19:18:05,686][model][INFO] - Training step 9520 loss 0.03945592790842056
[2025-03-17 19:19:26,773][model][INFO] - Training step 9680 loss 0.10983746498823166
[2025-03-17 19:20:48,379][model][INFO] - Training step 9840 loss 0.10602016746997833
[2025-03-17 19:22:10,319][model][INFO] - Training step 10000 loss 0.13910788297653198
[2025-03-17 19:23:29,761][model][INFO] - Training step 10160 loss 0.03481803834438324
[2025-03-17 19:24:49,403][model][INFO] - Training step 10320 loss 0.041113805025815964
[2025-03-17 19:26:10,437][model][INFO] - Training step 10480 loss 0.0503268837928772
[2025-03-17 19:27:31,435][model][INFO] - Training step 10640 loss 0.25346124172210693
[2025-03-17 19:28:51,345][model][INFO] - Training step 10800 loss 0.06704064458608627
[2025-03-17 19:30:11,126][model][INFO] - Training step 10960 loss 0.25718551874160767
[2025-03-17 19:31:28,714][model][INFO] - Training step 11120 loss 0.26659196615219116
[2025-03-17 19:32:48,107][model][INFO] - Training step 11280 loss 0.16274365782737732
[2025-03-17 19:34:07,228][model][INFO] - Training step 11440 loss 0.07426441460847855
[2025-03-17 19:35:24,638][model][INFO] - Training step 11600 loss 0.03272879123687744
[2025-03-17 19:36:45,935][model][INFO] - Training step 11760 loss 0.25727999210357666
[2025-03-17 19:38:07,205][model][INFO] - Training step 11920 loss 0.25719934701919556
[2025-03-17 19:39:29,805][model][INFO] - Training step 12080 loss 0.07035759836435318
[2025-03-17 19:40:51,279][model][INFO] - Training step 12240 loss 0.10758744925260544
[2025-03-17 19:42:07,858][model][INFO] - Training step 12400 loss 0.0489649772644043
[2025-03-17 19:43:28,660][model][INFO] - Training step 12560 loss 0.006712130270898342
[2025-03-17 19:44:48,160][model][INFO] - Training step 12720 loss 0.07317937910556793
[2025-03-17 19:46:07,845][model][INFO] - Training step 12880 loss 0.011714057996869087
[2025-03-17 19:47:28,660][model][INFO] - Training step 13040 loss 0.23570507764816284
[2025-03-17 19:48:46,125][model][INFO] - Training step 13200 loss 0.3284911513328552
[2025-03-17 19:50:02,768][model][INFO] - Training step 13360 loss 0.2098732441663742
[2025-03-17 19:51:19,679][model][INFO] - Training step 13520 loss 0.15165528655052185
[2025-03-17 19:52:41,065][model][INFO] - Training step 13680 loss 0.03916550427675247
[2025-03-17 19:54:02,004][model][INFO] - Training step 13840 loss 0.0043390486389398575
[2025-03-17 19:55:19,322][model][INFO] - Training step 14000 loss 0.27068284153938293
[2025-03-17 19:56:39,310][model][INFO] - Training step 14160 loss 0.040852807462215424
[2025-03-17 19:58:00,907][model][INFO] - Training step 14320 loss 0.007547704037278891
[2025-03-17 19:59:20,458][model][INFO] - Training step 14480 loss 0.2521924376487732
[2025-03-17 20:00:41,393][model][INFO] - Training step 14640 loss 0.06831426918506622
[2025-03-17 20:02:01,726][model][INFO] - Training step 14800 loss 0.4482293128967285
[2025-03-17 20:03:24,683][model][INFO] - Training step 14960 loss 0.0054560014978051186
[2025-03-17 20:04:45,758][model][INFO] - Training step 15120 loss 0.2877275347709656
[2025-03-17 20:06:05,862][model][INFO] - Training step 15280 loss 0.062066979706287384
[2025-03-17 20:07:27,034][model][INFO] - Training step 15440 loss 0.007626259699463844
[2025-03-17 20:08:44,355][model][INFO] - Training step 15600 loss 0.11154452711343765
[2025-03-17 20:10:03,494][model][INFO] - Training step 15760 loss 0.19354671239852905
[2025-03-17 20:11:22,926][model][INFO] - Training step 15920 loss 0.058474741876125336
[2025-03-17 20:12:42,949][model][INFO] - Training step 16080 loss 0.0031454134732484818
[2025-03-17 20:14:03,235][model][INFO] - Training step 16240 loss 0.009838122874498367
[2025-03-17 20:15:20,239][model][INFO] - Training step 16400 loss 0.0520792081952095
[2025-03-17 20:16:39,830][model][INFO] - Training step 16560 loss 0.25845062732696533
[2025-03-17 20:17:57,193][model][INFO] - Training step 16720 loss 0.11094547063112259
[2025-03-17 20:19:19,192][model][INFO] - Training step 16880 loss 0.039488784968853
[2025-03-17 20:20:41,240][model][INFO] - Training step 17040 loss 0.11997117102146149
[2025-03-17 20:22:02,344][model][INFO] - Training step 17200 loss 0.06843090057373047
[2025-03-17 20:23:19,815][model][INFO] - Training step 17360 loss 0.22525471448898315
[2025-03-17 20:24:39,796][model][INFO] - Training step 17520 loss 0.2654085159301758
[2025-03-17 20:26:01,445][model][INFO] - Training step 17680 loss 0.08695385605096817
[2025-03-17 20:27:17,192][model][INFO] - Training step 17840 loss 0.33334577083587646
[2025-03-17 20:28:36,327][model][INFO] - Training step 18000 loss 0.06015436351299286
[2025-03-17 20:29:56,407][model][INFO] - Training step 18160 loss 0.14043009281158447
[2025-03-17 20:31:20,871][model][INFO] - Training step 18320 loss 0.13199512660503387
[2025-03-17 20:32:42,339][model][INFO] - Training step 18480 loss 0.2823144197463989
[2025-03-17 20:34:04,685][model][INFO] - Training step 18640 loss 0.07050913572311401
[2025-03-17 20:35:24,110][model][INFO] - Training step 18800 loss 0.04971152916550636
[2025-03-17 20:36:45,500][model][INFO] - Training step 18960 loss 0.07150878012180328
[2025-03-17 20:38:03,411][model][INFO] - Training step 19120 loss 0.057226307690143585
[2025-03-17 20:39:19,650][model][INFO] - Training step 19280 loss 0.19945314526557922
[2025-03-17 20:40:36,989][model][INFO] - Training step 19440 loss 0.23902562260627747
[2025-03-17 20:41:58,034][model][INFO] - Training step 19600 loss 0.06999731063842773
[2025-03-17 20:43:16,702][model][INFO] - Training step 19760 loss 0.03872434049844742
[2025-03-17 20:44:38,021][model][INFO] - Training step 19920 loss 0.07206765562295914
[2025-03-17 20:45:57,772][model][INFO] - Training step 20080 loss 0.0624973401427269
[2025-03-17 20:47:17,337][model][INFO] - Training step 20240 loss 0.12220616638660431
[2025-03-17 20:48:38,735][model][INFO] - Training step 20400 loss 0.1521042287349701
[2025-03-17 20:50:02,247][model][INFO] - Training step 20560 loss 0.08722472935914993
[2025-03-17 20:51:36,464][model][INFO] - Training step 20720 loss 0.17380541563034058
[2025-03-17 20:53:11,113][model][INFO] - Training step 20880 loss 0.26526832580566406
[2025-03-17 20:54:31,851][model][INFO] - Training step 21040 loss 0.09461657702922821
[2025-03-17 20:55:50,889][model][INFO] - Training step 21200 loss 0.26494163274765015
[2025-03-17 20:57:12,619][model][INFO] - Training step 21360 loss 0.1059909462928772
[2025-03-17 20:58:30,899][model][INFO] - Training step 21520 loss 0.11609768867492676
[2025-03-17 21:00:01,587][model][INFO] - Training step 21680 loss 0.007848511449992657
[2025-03-17 21:01:18,708][model][INFO] - Training step 21840 loss 0.0044237170368433
[2025-03-17 21:02:40,733][model][INFO] - Training step 22000 loss 0.04829297959804535
[2025-03-17 21:03:59,031][model][INFO] - Training step 22160 loss 0.0522879920899868
[2025-03-17 21:05:19,740][model][INFO] - Training step 22320 loss 0.31591421365737915
[2025-03-17 21:06:40,039][model][INFO] - Training step 22480 loss 0.256621778011322
[2025-03-17 21:07:57,281][model][INFO] - Training step 22640 loss 0.03931797295808792
[2025-03-17 21:09:14,805][model][INFO] - Training step 22800 loss 0.04375039041042328
[2025-03-17 21:10:33,753][model][INFO] - Training step 22960 loss 0.25770920515060425
[2025-03-17 21:11:52,090][model][INFO] - Training step 23120 loss 0.008240006864070892
[2025-03-17 21:13:14,173][model][INFO] - Training step 23280 loss 0.040761832147836685
[2025-03-17 21:14:34,505][model][INFO] - Training step 23440 loss 0.04960358142852783
[2025-03-17 21:15:50,863][model][INFO] - Training step 23600 loss 0.07131221145391464
[2025-03-17 21:17:08,989][model][INFO] - Training step 23760 loss 0.07203704118728638
[2025-03-17 21:18:30,031][model][INFO] - Training step 23920 loss 0.18676260113716125
[2025-03-17 21:19:48,092][model][INFO] - Training step 24080 loss 0.0015836003003641963
[2025-03-17 21:21:05,570][model][INFO] - Training step 24240 loss 0.2609197795391083
[2025-03-17 21:22:26,489][model][INFO] - Training step 24400 loss 0.043789394199848175
[2025-03-17 21:23:46,356][model][INFO] - Training step 24560 loss 0.1657501459121704
[2025-03-17 21:25:04,624][model][INFO] - Training step 24720 loss 0.07225099205970764
[2025-03-17 21:26:26,295][model][INFO] - Training step 24880 loss 0.09322556108236313
[2025-03-17 21:27:43,085][model][INFO] - Training step 25040 loss 0.2530553340911865
[2025-03-17 21:29:02,350][model][INFO] - Training step 25200 loss 0.04885460436344147
[2025-03-17 21:30:21,794][model][INFO] - Training step 25360 loss 0.27900242805480957
[2025-03-17 21:31:41,580][model][INFO] - Training step 25520 loss 0.13737481832504272
[2025-03-17 21:33:01,894][model][INFO] - Training step 25680 loss 0.27069592475891113
[2025-03-17 21:34:19,229][model][INFO] - Training step 25840 loss 0.06863809376955032
[2025-03-17 21:35:39,166][model][INFO] - Training step 26000 loss 0.14771375060081482
[2025-03-17 21:36:58,090][model][INFO] - Training step 26160 loss 0.04230910539627075
[2025-03-17 21:38:19,049][model][INFO] - Training step 26320 loss 0.05002274364233017
[2025-03-17 21:39:39,921][model][INFO] - Training step 26480 loss 0.05321907252073288
[2025-03-17 21:41:01,685][model][INFO] - Training step 26640 loss 0.05261436477303505
[2025-03-17 21:42:21,721][model][INFO] - Training step 26800 loss 0.10622535645961761
[2025-03-17 21:43:41,016][model][INFO] - Training step 26960 loss 0.05916263163089752
[2025-03-17 21:44:59,977][model][INFO] - Training step 27120 loss 0.03680098429322243
[2025-03-17 21:46:19,672][model][INFO] - Training step 27280 loss 0.26076674461364746
[2025-03-17 21:47:39,895][model][INFO] - Training step 27440 loss 0.05345183610916138
[2025-03-17 21:48:59,643][model][INFO] - Training step 27600 loss 0.24154716730117798
[2025-03-17 21:50:20,509][model][INFO] - Training step 27760 loss 0.046361953020095825
[2025-03-17 21:51:39,136][model][INFO] - Training step 27920 loss 0.02522142045199871
[2025-03-17 21:52:59,853][model][INFO] - Training step 28080 loss 0.05076450854539871
[2025-03-17 21:54:17,042][model][INFO] - Training step 28240 loss 0.0703459233045578
[2025-03-17 21:55:33,946][model][INFO] - Training step 28400 loss 0.032589904963970184
[2025-03-17 21:56:54,800][model][INFO] - Training step 28560 loss 0.04279233515262604
[2025-03-17 21:58:12,826][model][INFO] - Training step 28720 loss 0.029508091509342194
[2025-03-17 21:59:31,816][model][INFO] - Training step 28880 loss 0.025926925241947174
[2025-03-17 22:00:52,791][model][INFO] - Training step 29040 loss 0.24707230925559998
[2025-03-17 22:02:15,241][model][INFO] - Training step 29200 loss 0.03141307830810547
[2025-03-17 22:03:38,993][model][INFO] - Training step 29360 loss 0.008082043379545212
[2025-03-17 22:05:01,235][model][INFO] - Training step 29520 loss 0.4024800956249237
[2025-03-17 22:06:21,516][model][INFO] - Training step 29680 loss 0.2489486038684845
[2025-03-17 22:07:42,668][model][INFO] - Training step 29840 loss 0.07104846835136414
[2025-03-17 22:09:01,002][model][INFO] - Training step 30000 loss 0.2170821577310562
[2025-03-17 22:10:18,541][model][INFO] - Training step 30160 loss 0.0916348397731781
[2025-03-17 22:11:39,073][model][INFO] - Training step 30320 loss 0.2371591478586197
[2025-03-17 22:12:57,339][model][INFO] - Training step 30480 loss 0.0768330916762352
[2025-03-17 22:14:14,935][model][INFO] - Training step 30640 loss 0.04497242718935013
[2025-03-17 22:15:31,839][model][INFO] - Training step 30800 loss 0.0059234099462628365
[2025-03-17 22:16:52,490][model][INFO] - Training step 30960 loss 0.08375062048435211
[2025-03-17 22:18:10,826][model][INFO] - Training step 31120 loss 0.054129309952259064
[2025-03-17 22:19:30,413][model][INFO] - Training step 31280 loss 0.11154121160507202
[2025-03-17 22:20:51,855][model][INFO] - Training step 31440 loss 0.2870004177093506
[2025-03-17 22:22:11,204][model][INFO] - Training step 31600 loss 0.04459255933761597
[2025-03-17 22:23:32,485][model][INFO] - Training step 31760 loss 0.07631650567054749
[2025-03-17 22:24:51,606][model][INFO] - Training step 31920 loss 0.17456161975860596
[2025-03-17 22:26:11,212][model][INFO] - Training step 32080 loss 0.22313299775123596
[2025-03-17 22:27:32,925][model][INFO] - Training step 32240 loss 0.004459642805159092
[2025-03-17 22:28:54,977][model][INFO] - Training step 32400 loss 0.05222626030445099
[2025-03-17 22:30:18,464][model][INFO] - Training step 32560 loss 0.06047447770833969
[2025-03-17 22:31:39,152][model][INFO] - Training step 32720 loss 0.039823051542043686
[2025-03-17 22:33:02,298][model][INFO] - Training step 32880 loss 0.010251693427562714
[2025-03-17 22:34:23,638][model][INFO] - Training step 33040 loss 0.2529352307319641
[2025-03-17 22:35:41,199][model][INFO] - Training step 33200 loss 0.2842751741409302
[2025-03-17 22:37:01,923][model][INFO] - Training step 33360 loss 0.03335928916931152
[2025-03-17 22:38:20,761][model][INFO] - Training step 33520 loss 0.12813755869865417
[2025-03-17 22:39:41,290][model][INFO] - Training step 33680 loss 0.26648128032684326
[2025-03-17 22:40:59,445][model][INFO] - Training step 33840 loss 0.03619152680039406
[2025-03-17 22:42:16,260][model][INFO] - Training step 34000 loss 0.10902103781700134
[2025-03-17 22:43:40,810][model][INFO] - Training step 34160 loss 0.00415794039145112
[2025-03-17 22:45:01,753][model][INFO] - Training step 34320 loss 0.045371077954769135
[2025-03-17 22:46:25,757][model][INFO] - Training step 34480 loss 0.2696692943572998
[2025-03-17 22:47:46,539][model][INFO] - Training step 34640 loss 0.10585376620292664
[2025-03-17 22:49:04,152][model][INFO] - Training step 34800 loss 0.08243013173341751
[2025-03-17 22:50:25,560][model][INFO] - Training step 34960 loss 0.05349693447351456
[2025-03-17 22:51:44,063][model][INFO] - Training step 35120 loss 0.05796685069799423
[2025-03-17 22:53:05,518][model][INFO] - Training step 35280 loss 0.039662573486566544
[2025-03-17 22:54:22,996][model][INFO] - Training step 35440 loss 0.030055850744247437
[2025-03-17 22:55:44,222][model][INFO] - Training step 35600 loss 0.06640278548002243
[2025-03-17 22:57:02,714][model][INFO] - Training step 35760 loss 0.038451939821243286
[2025-03-17 22:58:21,345][model][INFO] - Training step 35920 loss 0.05491093918681145
[2025-03-17 22:59:44,378][model][INFO] - Training step 36080 loss 0.07188376784324646
[2025-03-17 23:01:06,053][model][INFO] - Training step 36240 loss 0.0458369106054306
[2025-03-17 23:02:25,421][model][INFO] - Training step 36400 loss 0.06104665622115135
[2025-03-17 23:03:46,128][model][INFO] - Training step 36560 loss 0.05952834337949753
[2025-03-17 23:05:05,118][model][INFO] - Training step 36720 loss 0.020121049135923386
[2025-03-17 23:06:26,672][model][INFO] - Training step 36880 loss 0.2633320391178131
[2025-03-17 23:07:46,009][model][INFO] - Training step 37040 loss 0.03220866248011589
[2025-03-17 23:09:07,676][model][INFO] - Training step 37200 loss 0.10574530810117722
[2025-03-17 23:10:26,155][model][INFO] - Training step 37360 loss 0.01658756099641323
[2025-03-17 23:11:49,130][model][INFO] - Training step 37520 loss 0.01056794635951519
[2025-03-17 23:13:06,179][model][INFO] - Training step 37680 loss 0.25062644481658936
[2025-03-17 23:14:23,902][model][INFO] - Training step 37840 loss 0.2607070803642273
[2025-03-17 23:15:42,910][model][INFO] - Training step 38000 loss 0.2756754159927368
[2025-03-17 23:17:03,794][model][INFO] - Training step 38160 loss 0.039343833923339844
[2025-03-17 23:18:24,850][model][INFO] - Training step 38320 loss 0.05571574345231056
[2025-03-17 23:19:45,640][model][INFO] - Training step 38480 loss 0.26381129026412964
[2025-03-17 23:21:02,649][model][INFO] - Training step 38640 loss 0.04941748082637787
[2025-03-17 23:22:21,896][model][INFO] - Training step 38800 loss 0.02757135033607483
[2025-03-17 23:23:42,489][model][INFO] - Training step 38960 loss 0.047013577073812485
[2025-03-17 23:24:59,280][model][INFO] - Training step 39120 loss 0.038472797721624374
[2025-03-17 23:26:18,310][model][INFO] - Training step 39280 loss 0.06110343709588051
[2025-03-17 23:27:37,316][model][INFO] - Training step 39440 loss 0.05223510414361954
[2025-03-17 23:28:56,615][model][INFO] - Training step 39600 loss 0.04377956688404083
[2025-03-17 23:30:14,391][model][INFO] - Training step 39760 loss 0.049349457025527954
[2025-03-17 23:31:36,485][model][INFO] - Training step 39920 loss 0.0413261316716671
[2025-03-17 23:32:56,049][model][INFO] - Training step 40080 loss 0.003903105854988098
[2025-03-17 23:34:16,553][model][INFO] - Training step 40240 loss 0.05701986327767372
[2025-03-17 23:35:38,489][model][INFO] - Training step 40400 loss 0.04038253799080849
[2025-03-17 23:36:57,404][model][INFO] - Training step 40560 loss 0.04491259902715683
[2025-03-17 23:38:16,147][model][INFO] - Training step 40720 loss 0.05556090176105499
[2025-03-17 23:39:34,902][model][INFO] - Training step 40880 loss 0.03829966485500336
[2025-03-17 23:40:55,784][model][INFO] - Training step 41040 loss 0.005680955946445465
[2025-03-17 23:42:15,812][model][INFO] - Training step 41200 loss 0.046528950333595276
[2025-03-17 23:43:35,830][model][INFO] - Training step 41360 loss 0.03206993266940117
[2025-03-17 23:44:52,929][model][INFO] - Training step 41520 loss 0.08504896610975266
[2025-03-17 23:46:11,752][model][INFO] - Training step 41680 loss 0.1029873788356781
[2025-03-17 23:47:30,111][model][INFO] - Training step 41840 loss 0.02643337845802307
[2025-03-17 23:48:49,445][model][INFO] - Training step 42000 loss 0.008140086196362972
[2025-03-17 23:50:10,459][model][INFO] - Training step 42160 loss 0.013520129024982452
[2025-03-17 23:51:28,972][model][INFO] - Training step 42320 loss 0.08757363259792328
[2025-03-17 23:52:51,600][model][INFO] - Training step 42480 loss 0.09032464027404785
[2025-03-17 23:54:09,606][model][INFO] - Training step 42640 loss 0.03855335712432861
[2025-03-17 23:55:30,172][model][INFO] - Training step 42800 loss 0.2401019036769867
[2025-03-17 23:56:49,315][model][INFO] - Training step 42960 loss 0.31343185901641846
[2025-03-17 23:58:08,808][model][INFO] - Training step 43120 loss 0.005195554345846176
[2025-03-17 23:59:27,680][model][INFO] - Training step 43280 loss 0.24720439314842224
[2025-03-18 00:00:48,639][model][INFO] - Training step 43440 loss 0.05831770598888397
[2025-03-18 00:02:07,343][model][INFO] - Training step 43600 loss 0.0794295072555542
[2025-03-18 00:03:27,173][model][INFO] - Training step 43760 loss 0.04785687103867531
[2025-03-18 00:04:43,489][model][INFO] - Training step 43920 loss 0.062454525381326675
[2025-03-18 00:06:04,277][model][INFO] - Training step 44080 loss 0.06261492520570755
[2025-03-18 00:07:24,237][model][INFO] - Training step 44240 loss 0.05555036664009094
[2025-03-18 00:08:42,426][model][INFO] - Training step 44400 loss 0.25671330094337463
[2025-03-18 00:10:00,815][model][INFO] - Training step 44560 loss 0.14440812170505524
[2025-03-18 00:11:24,615][model][INFO] - Training step 44720 loss 0.012216094881296158
[2025-03-18 00:12:43,043][model][INFO] - Training step 44880 loss 0.08471406996250153
[2025-03-18 00:14:06,485][model][INFO] - Training step 45040 loss 0.04119443893432617
[2025-03-18 00:15:25,625][model][INFO] - Training step 45200 loss 0.006684897001832724
[2025-03-18 00:16:46,232][model][INFO] - Training step 45360 loss 0.055195152759552
[2025-03-18 00:18:08,792][model][INFO] - Training step 45520 loss 0.05263674259185791
[2025-03-18 00:19:29,429][model][INFO] - Training step 45680 loss 0.029219700023531914
[2025-03-18 00:20:53,901][model][INFO] - Training step 45840 loss 0.003732998389750719
[2025-03-18 00:22:12,772][model][INFO] - Training step 46000 loss 0.09491574019193649
[2025-03-18 00:23:37,544][model][INFO] - Training step 46160 loss 0.008065191097557545
[2025-03-18 00:24:55,739][model][INFO] - Training step 46320 loss 0.002380868885666132
[2025-03-18 00:26:16,192][model][INFO] - Training step 46480 loss 0.03364387899637222
[2025-03-18 00:27:35,429][model][INFO] - Training step 46640 loss 0.26740872859954834
[2025-03-18 00:28:56,807][model][INFO] - Training step 46800 loss 0.14575731754302979
[2025-03-18 00:30:16,117][model][INFO] - Training step 46960 loss 0.058460935950279236
[2025-03-18 00:31:33,352][model][INFO] - Training step 47120 loss 0.26846590638160706
[2025-03-18 00:32:55,383][model][INFO] - Training step 47280 loss 0.09190395474433899
[2025-03-18 00:34:14,720][model][INFO] - Training step 47440 loss 0.008548131212592125
[2025-03-18 00:35:34,612][model][INFO] - Training step 47600 loss 0.24478602409362793
[2025-03-18 00:36:55,819][model][INFO] - Training step 47760 loss 0.13324132561683655
[2025-03-18 00:38:16,300][model][INFO] - Training step 47920 loss 0.07445266842842102
[2025-03-18 00:39:35,626][model][INFO] - Training step 48080 loss 0.054056718945503235
[2025-03-18 00:40:53,166][model][INFO] - Training step 48240 loss 0.14765870571136475
[2025-03-18 00:42:12,595][model][INFO] - Training step 48400 loss 0.06636954843997955
[2025-03-18 00:43:33,350][model][INFO] - Training step 48560 loss 0.10774633288383484
[2025-03-18 00:44:54,217][model][INFO] - Training step 48720 loss 0.043022241443395615
[2025-03-18 00:46:14,315][model][INFO] - Training step 48880 loss 0.24550560116767883
[2025-03-18 00:47:30,018][model][INFO] - Training step 49040 loss 0.05043913424015045
[2025-03-18 00:48:50,484][model][INFO] - Training step 49200 loss 0.0040907952934503555
[2025-03-18 00:50:09,120][model][INFO] - Training step 49360 loss 0.013040971010923386
[2025-03-18 00:51:28,968][model][INFO] - Training step 49520 loss 0.12067444622516632
[2025-03-18 00:52:48,576][model][INFO] - Training step 49680 loss 0.024598082527518272
[2025-03-18 00:54:07,428][model][INFO] - Training step 49840 loss 0.2906968295574188
[2025-03-18 00:55:29,241][model][INFO] - Training step 50000 loss 0.06003393977880478
[2025-03-18 00:56:49,637][model][INFO] - Training step 50160 loss 0.2475256323814392
[2025-03-18 00:58:10,861][model][INFO] - Training step 50320 loss 0.0884217768907547
[2025-03-18 00:59:29,981][model][INFO] - Training step 50480 loss 0.057786017656326294
[2025-03-18 01:00:48,579][model][INFO] - Training step 50640 loss 0.2621057629585266
[2025-03-18 01:10:21,142][model][INFO] - Training step 0 loss 0.055248960852622986
[2025-03-18 01:11:40,394][model][INFO] - Training step 160 loss 0.04438968747854233
[2025-03-18 01:12:59,396][model][INFO] - Training step 320 loss 0.14760106801986694
[2025-03-18 01:14:18,792][model][INFO] - Training step 480 loss 0.08351998776197433
[2025-03-18 01:15:39,501][model][INFO] - Training step 640 loss 0.04883731156587601
[2025-03-18 01:17:00,444][model][INFO] - Training step 800 loss 0.04837141931056976
[2025-03-18 01:18:18,667][model][INFO] - Training step 960 loss 0.05092424899339676
[2025-03-18 01:19:38,009][model][INFO] - Training step 1120 loss 0.10842161625623703
[2025-03-18 01:20:57,231][model][INFO] - Training step 1280 loss 0.06816365569829941
[2025-03-18 01:22:17,870][model][INFO] - Training step 1440 loss 0.06159394979476929
[2025-03-18 01:23:38,332][model][INFO] - Training step 1600 loss 0.08317655324935913
[2025-03-18 01:24:58,423][model][INFO] - Training step 1760 loss 0.022580914199352264
[2025-03-18 01:26:16,474][model][INFO] - Training step 1920 loss 0.056416526436805725
[2025-03-18 01:27:34,755][model][INFO] - Training step 2080 loss 0.08872553706169128
[2025-03-18 01:28:57,555][model][INFO] - Training step 2240 loss 0.2917913496494293
[2025-03-18 01:30:16,840][model][INFO] - Training step 2400 loss 0.050695210695266724
[2025-03-18 01:31:36,975][model][INFO] - Training step 2560 loss 0.06581666320562363
[2025-03-18 01:32:55,108][model][INFO] - Training step 2720 loss 0.042474135756492615
[2025-03-18 01:34:13,609][model][INFO] - Training step 2880 loss 0.03183209151029587
[2025-03-18 01:35:32,744][model][INFO] - Training step 3040 loss 0.04059140384197235
[2025-03-18 01:36:51,288][model][INFO] - Training step 3200 loss 0.029375296086072922
[2025-03-18 01:38:12,652][model][INFO] - Training step 3360 loss 0.018355950713157654
[2025-03-18 01:39:29,791][model][INFO] - Training step 3520 loss 0.05847451463341713
[2025-03-18 01:40:48,834][model][INFO] - Training step 3680 loss 0.046974919736385345
[2025-03-18 01:42:05,829][model][INFO] - Training step 3840 loss 0.14839962124824524
[2025-03-18 01:43:27,171][model][INFO] - Training step 4000 loss 0.25730568170547485
[2025-03-18 01:44:50,907][model][INFO] - Training step 4160 loss 0.03204804286360741
[2025-03-18 01:46:10,243][model][INFO] - Training step 4320 loss 0.0899457037448883
[2025-03-18 01:47:28,936][model][INFO] - Training step 4480 loss 0.05354045331478119
[2025-03-18 01:48:47,948][model][INFO] - Training step 4640 loss 0.047955162823200226
[2025-03-18 01:50:05,969][model][INFO] - Training step 4800 loss 0.06723420321941376
[2025-03-18 01:51:26,325][model][INFO] - Training step 4960 loss 0.04722351208329201
[2025-03-18 01:52:48,499][model][INFO] - Training step 5120 loss 0.09674905240535736
[2025-03-18 01:54:06,876][model][INFO] - Training step 5280 loss 0.02545354515314102
[2025-03-18 01:55:24,782][model][INFO] - Training step 5440 loss 0.06851375848054886
[2025-03-18 01:56:43,760][model][INFO] - Training step 5600 loss 0.006019514054059982
[2025-03-18 01:58:07,928][model][INFO] - Training step 5760 loss 0.0608028769493103
[2025-03-18 01:59:26,079][model][INFO] - Training step 5920 loss 0.05385155975818634
[2025-03-18 02:00:45,269][model][INFO] - Training step 6080 loss 0.25400084257125854
[2025-03-18 02:02:06,041][model][INFO] - Training step 6240 loss 0.0056122783571481705
[2025-03-18 02:03:25,009][model][INFO] - Training step 6400 loss 0.27664291858673096
[2025-03-18 02:04:42,018][model][INFO] - Training step 6560 loss 0.04592980071902275
[2025-03-18 02:06:02,927][model][INFO] - Training step 6720 loss 0.019959628582000732
[2025-03-18 02:07:22,565][model][INFO] - Training step 6880 loss 0.06382548809051514
[2025-03-18 02:08:41,509][model][INFO] - Training step 7040 loss 0.035915736109018326
[2025-03-18 02:10:03,798][model][INFO] - Training step 7200 loss 0.19174005091190338
[2025-03-18 02:11:23,744][model][INFO] - Training step 7360 loss 0.13351282477378845
[2025-03-18 02:12:43,129][model][INFO] - Training step 7520 loss 0.0033883380237966776
[2025-03-18 02:14:04,572][model][INFO] - Training step 7680 loss 0.04707887023687363
[2025-03-18 02:15:24,823][model][INFO] - Training step 7840 loss 0.04857911169528961
[2025-03-18 02:16:45,273][model][INFO] - Training step 8000 loss 0.05511132627725601
[2025-03-18 02:18:04,628][model][INFO] - Training step 8160 loss 0.03246724233031273
[2025-03-18 02:19:22,602][model][INFO] - Training step 8320 loss 0.03606829792261124
[2025-03-18 02:20:40,697][model][INFO] - Training step 8480 loss 0.17269417643547058
[2025-03-18 02:21:57,477][model][INFO] - Training step 8640 loss 0.03885781019926071
[2025-03-18 02:23:15,306][model][INFO] - Training step 8800 loss 0.042727433145046234
[2025-03-18 02:24:34,242][model][INFO] - Training step 8960 loss 0.06585671752691269
[2025-03-18 02:25:52,877][model][INFO] - Training step 9120 loss 0.06612379848957062
[2025-03-18 02:27:10,415][model][INFO] - Training step 9280 loss 0.06260357797145844
[2025-03-18 02:28:30,566][model][INFO] - Training step 9440 loss 0.03366445004940033
[2025-03-18 02:29:51,562][model][INFO] - Training step 9600 loss 0.06208069249987602
[2025-03-18 02:31:11,323][model][INFO] - Training step 9760 loss 0.03124939277768135
[2025-03-18 02:32:31,129][model][INFO] - Training step 9920 loss 0.033575013279914856
[2025-03-18 02:33:53,413][model][INFO] - Training step 10080 loss 0.22979594767093658
[2025-03-18 02:35:11,960][model][INFO] - Training step 10240 loss 0.24554051458835602
[2025-03-18 02:36:33,179][model][INFO] - Training step 10400 loss 0.06638160347938538
[2025-03-18 02:37:52,409][model][INFO] - Training step 10560 loss 0.42819827795028687
[2025-03-18 02:39:13,349][model][INFO] - Training step 10720 loss 0.26455000042915344
[2025-03-18 02:40:34,147][model][INFO] - Training step 10880 loss 0.12479349970817566
[2025-03-18 02:41:54,176][model][INFO] - Training step 11040 loss 0.07040451467037201
[2025-03-18 02:43:12,524][model][INFO] - Training step 11200 loss 0.051627762615680695
[2025-03-18 02:44:31,454][model][INFO] - Training step 11360 loss 0.19761589169502258
[2025-03-18 02:45:50,775][model][INFO] - Training step 11520 loss 0.28907281160354614
[2025-03-18 02:47:10,059][model][INFO] - Training step 11680 loss 0.006085987202823162
[2025-03-18 02:48:32,188][model][INFO] - Training step 11840 loss 0.042359478771686554
[2025-03-18 02:49:50,950][model][INFO] - Training step 12000 loss 0.09284092485904694
[2025-03-18 02:51:12,130][model][INFO] - Training step 12160 loss 0.2432442307472229
[2025-03-18 02:52:30,171][model][INFO] - Training step 12320 loss 0.23893848061561584
[2025-03-18 02:53:51,664][model][INFO] - Training step 12480 loss 0.26678019762039185
[2025-03-18 02:55:10,188][model][INFO] - Training step 12640 loss 0.24431735277175903
[2025-03-18 02:56:31,066][model][INFO] - Training step 12800 loss 0.006754683330655098
[2025-03-18 02:57:50,427][model][INFO] - Training step 12960 loss 0.03415616601705551
[2025-03-18 02:59:13,027][model][INFO] - Training step 13120 loss 0.038119569420814514
[2025-03-18 03:00:32,257][model][INFO] - Training step 13280 loss 0.06780967116355896
[2025-03-18 03:01:52,025][model][INFO] - Training step 13440 loss 0.5322180390357971
[2025-03-18 03:03:15,630][model][INFO] - Training step 13600 loss 0.03948267176747322
[2025-03-18 03:04:35,942][model][INFO] - Training step 13760 loss 0.27024608850479126
[2025-03-18 03:05:56,913][model][INFO] - Training step 13920 loss 0.07564699649810791
[2025-03-18 03:07:14,477][model][INFO] - Training step 14080 loss 0.2639576494693756
[2025-03-18 03:08:34,702][model][INFO] - Training step 14240 loss 0.008293421007692814
[2025-03-18 03:09:55,307][model][INFO] - Training step 14400 loss 0.06133146584033966
[2025-03-18 03:11:16,428][model][INFO] - Training step 14560 loss 0.04169340431690216
[2025-03-18 03:12:32,520][model][INFO] - Training step 14720 loss 0.12112990021705627
[2025-03-18 03:13:52,797][model][INFO] - Training step 14880 loss 0.05657206475734711
[2025-03-18 03:15:17,042][model][INFO] - Training step 15040 loss 0.07350458204746246
[2025-03-18 03:16:38,325][model][INFO] - Training step 15200 loss 0.26220080256462097
[2025-03-18 03:17:56,680][model][INFO] - Training step 15360 loss 0.1241244524717331
[2025-03-18 03:19:15,860][model][INFO] - Training step 15520 loss 0.03155898675322533
[2025-03-18 03:20:31,634][model][INFO] - Training step 15680 loss 0.04919172823429108
[2025-03-18 03:21:50,525][model][INFO] - Training step 15840 loss 0.08838344365358353
[2025-03-18 03:23:08,764][model][INFO] - Training step 16000 loss 0.003641607705503702
[2025-03-18 03:24:29,278][model][INFO] - Training step 16160 loss 0.03687091916799545
[2025-03-18 03:25:50,410][model][INFO] - Training step 16320 loss 0.04973225295543671
[2025-03-18 03:27:09,399][model][INFO] - Training step 16480 loss 0.09712713956832886
[2025-03-18 03:28:27,125][model][INFO] - Training step 16640 loss 0.09137357771396637
[2025-03-18 03:29:43,237][model][INFO] - Training step 16800 loss 0.09307015687227249
[2025-03-18 03:31:03,682][model][INFO] - Training step 16960 loss 0.13244053721427917
[2025-03-18 03:32:19,111][model][INFO] - Training step 17120 loss 0.04954158887267113
[2025-03-18 03:33:39,724][model][INFO] - Training step 17280 loss 1.3301787376403809
[2025-03-18 03:34:58,977][model][INFO] - Training step 17440 loss 0.05105406418442726
[2025-03-18 03:36:18,090][model][INFO] - Training step 17600 loss 0.29615822434425354
[2025-03-18 03:37:35,922][model][INFO] - Training step 17760 loss 0.07124333083629608
[2025-03-18 03:38:52,608][model][INFO] - Training step 17920 loss 0.0036455090157687664
[2025-03-18 03:40:10,764][model][INFO] - Training step 18080 loss 0.04373418539762497
[2025-03-18 03:41:28,599][model][INFO] - Training step 18240 loss 0.056717656552791595
[2025-03-18 03:42:46,684][model][INFO] - Training step 18400 loss 0.05037734657526016
[2025-03-18 03:44:08,935][model][INFO] - Training step 18560 loss 0.0043829260393977165
[2025-03-18 03:45:31,668][model][INFO] - Training step 18720 loss 0.006042683497071266
[2025-03-18 03:46:50,249][model][INFO] - Training step 18880 loss 0.2281668335199356
[2025-03-18 03:48:08,392][model][INFO] - Training step 19040 loss 0.051499396562576294
[2025-03-18 03:49:27,300][model][INFO] - Training step 19200 loss 0.2277345061302185
[2025-03-18 03:50:48,070][model][INFO] - Training step 19360 loss 0.04561004787683487
[2025-03-18 03:52:09,037][model][INFO] - Training step 19520 loss 0.03911382704973221
[2025-03-18 03:53:29,783][model][INFO] - Training step 19680 loss 0.16682443022727966
[2025-03-18 03:54:48,456][model][INFO] - Training step 19840 loss 0.0410933755338192
[2025-03-18 03:56:08,868][model][INFO] - Training step 20000 loss 0.06498956680297852
[2025-03-18 03:57:31,679][model][INFO] - Training step 20160 loss 0.017609238624572754
[2025-03-18 03:58:50,140][model][INFO] - Training step 20320 loss 0.17917223274707794
[2025-03-18 04:00:07,324][model][INFO] - Training step 20480 loss 0.09635347127914429
[2025-03-18 04:01:25,179][model][INFO] - Training step 20640 loss 0.14071303606033325
[2025-03-18 04:02:47,210][model][INFO] - Training step 20800 loss 0.25113600492477417
[2025-03-18 04:04:07,496][model][INFO] - Training step 20960 loss 0.039986807852983475
[2025-03-18 04:05:31,352][model][INFO] - Training step 21120 loss 0.5639159083366394
[2025-03-18 04:06:52,590][model][INFO] - Training step 21280 loss 0.05557291954755783
[2025-03-18 04:08:13,002][model][INFO] - Training step 21440 loss 0.08590096235275269
[2025-03-18 04:09:31,378][model][INFO] - Training step 21600 loss 0.06406508386135101
[2025-03-18 04:10:52,197][model][INFO] - Training step 21760 loss 0.049362439662218094
[2025-03-18 04:12:11,882][model][INFO] - Training step 21920 loss 0.03922326862812042
[2025-03-18 04:13:31,029][model][INFO] - Training step 22080 loss 0.258859246969223
[2025-03-18 04:14:51,351][model][INFO] - Training step 22240 loss 0.04563181847333908
[2025-03-18 04:16:13,284][model][INFO] - Training step 22400 loss 0.07198496907949448
[2025-03-18 04:17:33,105][model][INFO] - Training step 22560 loss 0.048389241099357605
[2025-03-18 04:18:52,538][model][INFO] - Training step 22720 loss 0.02877161093056202
[2025-03-18 04:20:11,333][model][INFO] - Training step 22880 loss 0.03925506770610809
[2025-03-18 04:21:31,254][model][INFO] - Training step 23040 loss 0.09833228588104248
[2025-03-18 04:22:51,837][model][INFO] - Training step 23200 loss 0.10632559657096863
[2025-03-18 04:24:13,139][model][INFO] - Training step 23360 loss 0.12496942281723022
[2025-03-18 04:25:34,292][model][INFO] - Training step 23520 loss 0.041405513882637024
[2025-03-18 04:26:55,009][model][INFO] - Training step 23680 loss 0.263199120759964
[2025-03-18 04:28:16,119][model][INFO] - Training step 23840 loss 0.2546491026878357
[2025-03-18 04:29:34,333][model][INFO] - Training step 24000 loss 0.03877202421426773
[2025-03-18 04:30:51,373][model][INFO] - Training step 24160 loss 0.052562959492206573
[2025-03-18 04:32:10,740][model][INFO] - Training step 24320 loss 0.04179751127958298
[2025-03-18 04:33:30,724][model][INFO] - Training step 24480 loss 0.019198808819055557
[2025-03-18 04:34:49,347][model][INFO] - Training step 24640 loss 0.027601437643170357
[2025-03-18 04:36:07,779][model][INFO] - Training step 24800 loss 0.07189485430717468
[2025-03-18 04:37:29,561][model][INFO] - Training step 24960 loss 0.08904743194580078
[2025-03-18 04:38:49,087][model][INFO] - Training step 25120 loss 0.014717462472617626
[2025-03-18 04:40:04,730][model][INFO] - Training step 25280 loss 0.02968158945441246
[2025-03-18 04:41:22,440][model][INFO] - Training step 25440 loss 0.05005941540002823
[2025-03-18 04:42:43,902][model][INFO] - Training step 25600 loss 0.007942542433738708
[2025-03-18 04:43:59,808][model][INFO] - Training step 25760 loss 0.08519153296947479
[2025-03-18 04:45:21,232][model][INFO] - Training step 25920 loss 0.041991159319877625
[2025-03-18 04:46:39,324][model][INFO] - Training step 26080 loss 0.03539278730750084
[2025-03-18 04:47:57,323][model][INFO] - Training step 26240 loss 0.00970830675214529
[2025-03-18 04:49:18,431][model][INFO] - Training step 26400 loss 0.06451573967933655
[2025-03-18 04:50:41,344][model][INFO] - Training step 26560 loss 0.05855053663253784
[2025-03-18 04:52:01,096][model][INFO] - Training step 26720 loss 0.05990872532129288
[2025-03-18 04:53:19,316][model][INFO] - Training step 26880 loss 0.04541650786995888
[2025-03-18 04:54:36,216][model][INFO] - Training step 27040 loss 0.1939401924610138
[2025-03-18 04:55:55,377][model][INFO] - Training step 27200 loss 0.2633640766143799
[2025-03-18 04:57:15,505][model][INFO] - Training step 27360 loss 0.07745419442653656
[2025-03-18 04:58:33,383][model][INFO] - Training step 27520 loss 0.0735168606042862
[2025-03-18 04:59:51,005][model][INFO] - Training step 27680 loss 0.1872280091047287
[2025-03-18 05:01:10,361][model][INFO] - Training step 27840 loss 0.008087798953056335
[2025-03-18 05:02:31,749][model][INFO] - Training step 28000 loss 0.007367752026766539
[2025-03-18 05:03:51,358][model][INFO] - Training step 28160 loss 0.2564789652824402
[2025-03-18 05:05:10,696][model][INFO] - Training step 28320 loss 0.06431078910827637
[2025-03-18 05:06:32,066][model][INFO] - Training step 28480 loss 0.006585904397070408
[2025-03-18 05:07:51,803][model][INFO] - Training step 28640 loss 0.1055455207824707
[2025-03-18 05:09:10,965][model][INFO] - Training step 28800 loss 0.005471114069223404
[2025-03-18 05:10:30,632][model][INFO] - Training step 28960 loss 0.14492331445217133
[2025-03-18 05:11:49,327][model][INFO] - Training step 29120 loss 0.06564696133136749
[2025-03-18 05:13:12,139][model][INFO] - Training step 29280 loss 0.1493791937828064
[2025-03-18 05:14:30,813][model][INFO] - Training step 29440 loss 0.31334975361824036
[2025-03-18 05:15:52,445][model][INFO] - Training step 29600 loss 0.003650275059044361
[2025-03-18 05:17:12,578][model][INFO] - Training step 29760 loss 0.007264601998031139
[2025-03-18 05:18:32,682][model][INFO] - Training step 29920 loss 0.010775112546980381
[2025-03-18 05:19:51,965][model][INFO] - Training step 30080 loss 0.13373950123786926
[2025-03-18 05:21:10,379][model][INFO] - Training step 30240 loss 0.07523255050182343
[2025-03-18 05:22:30,792][model][INFO] - Training step 30400 loss 0.06319054961204529
[2025-03-18 05:23:50,950][model][INFO] - Training step 30560 loss 0.23794052004814148
[2025-03-18 05:25:08,551][model][INFO] - Training step 30720 loss 0.019229628145694733
[2025-03-18 05:26:25,968][model][INFO] - Training step 30880 loss 0.038537438958883286
[2025-03-18 05:27:46,786][model][INFO] - Training step 31040 loss 0.25311219692230225
[2025-03-18 05:29:03,547][model][INFO] - Training step 31200 loss 0.0349004790186882
[2025-03-18 05:30:22,198][model][INFO] - Training step 31360 loss 0.044485412538051605
[2025-03-18 05:31:39,009][model][INFO] - Training step 31520 loss 0.08426470309495926
[2025-03-18 05:32:59,000][model][INFO] - Training step 31680 loss 0.25340425968170166
[2025-03-18 05:34:19,474][model][INFO] - Training step 31840 loss 0.0031400523148477077
[2025-03-18 05:35:41,555][model][INFO] - Training step 32000 loss 0.07138994336128235
[2025-03-18 05:37:00,284][model][INFO] - Training step 32160 loss 0.050829384475946426
[2025-03-18 05:38:23,780][model][INFO] - Training step 32320 loss 0.037968710064888
[2025-03-18 05:39:44,962][model][INFO] - Training step 32480 loss 0.00815132912248373
[2025-03-18 05:41:09,794][model][INFO] - Training step 32640 loss 0.08300820738077164
[2025-03-18 05:42:29,361][model][INFO] - Training step 32800 loss 0.0379633903503418
[2025-03-18 05:43:49,740][model][INFO] - Training step 32960 loss 0.14923560619354248
[2025-03-18 05:45:06,213][model][INFO] - Training step 33120 loss 0.007734481245279312
[2025-03-18 05:46:27,680][model][INFO] - Training step 33280 loss 0.06243175268173218
[2025-03-18 05:47:49,374][model][INFO] - Training step 33440 loss 0.16688619554042816
[2025-03-18 05:49:08,662][model][INFO] - Training step 33600 loss 0.26747238636016846
[2025-03-18 05:50:28,190][model][INFO] - Training step 33760 loss 0.019008053466677666
[2025-03-18 05:51:49,370][model][INFO] - Training step 33920 loss 0.24066516757011414
[2025-03-18 05:53:09,250][model][INFO] - Training step 34080 loss 0.034618258476257324
[2025-03-18 05:54:32,039][model][INFO] - Training step 34240 loss 0.2130751609802246
[2025-03-18 05:55:52,273][model][INFO] - Training step 34400 loss 0.09307878464460373
[2025-03-18 05:57:09,424][model][INFO] - Training step 34560 loss 0.22062340378761292
[2025-03-18 05:58:27,251][model][INFO] - Training step 34720 loss 0.17009660601615906
[2025-03-18 05:59:45,100][model][INFO] - Training step 34880 loss 0.08492903411388397
[2025-03-18 06:01:03,274][model][INFO] - Training step 35040 loss 0.004629544913768768
[2025-03-18 06:02:22,829][model][INFO] - Training step 35200 loss 0.03184553235769272
[2025-03-18 06:03:43,131][model][INFO] - Training step 35360 loss 0.02784777246415615
[2025-03-18 06:05:02,058][model][INFO] - Training step 35520 loss 0.04995688050985336
[2025-03-18 06:06:19,212][model][INFO] - Training step 35680 loss 0.06335005164146423
[2025-03-18 06:07:38,537][model][INFO] - Training step 35840 loss 0.03546484559774399
[2025-03-18 06:08:57,613][model][INFO] - Training step 36000 loss 0.30644142627716064
[2025-03-18 06:10:16,194][model][INFO] - Training step 36160 loss 0.04903433099389076
[2025-03-18 06:11:35,884][model][INFO] - Training step 36320 loss 0.027563683688640594
[2025-03-18 06:12:56,558][model][INFO] - Training step 36480 loss 0.006236562971025705
[2025-03-18 06:14:15,663][model][INFO] - Training step 36640 loss 0.07920613884925842
[2025-03-18 06:15:32,164][model][INFO] - Training step 36800 loss 0.038365550339221954
[2025-03-18 06:16:53,591][model][INFO] - Training step 36960 loss 0.08024309575557709
[2025-03-18 06:18:14,351][model][INFO] - Training step 37120 loss 0.03821583092212677
[2025-03-18 06:19:36,123][model][INFO] - Training step 37280 loss 0.005585194565355778
[2025-03-18 06:20:56,980][model][INFO] - Training step 37440 loss 0.0883922427892685
[2025-03-18 06:22:15,338][model][INFO] - Training step 37600 loss 0.2422754019498825
[2025-03-18 06:23:37,100][model][INFO] - Training step 37760 loss 0.27902665734291077
[2025-03-18 06:24:53,934][model][INFO] - Training step 37920 loss 0.0290544331073761
[2025-03-18 06:26:11,310][model][INFO] - Training step 38080 loss 0.06096435338258743
[2025-03-18 06:27:33,100][model][INFO] - Training step 38240 loss 0.07274633646011353
[2025-03-18 06:28:52,984][model][INFO] - Training step 38400 loss 0.045815348625183105
[2025-03-18 06:30:08,906][model][INFO] - Training step 38560 loss 0.28311559557914734
[2025-03-18 06:31:28,615][model][INFO] - Training step 38720 loss 0.052172183990478516
[2025-03-18 06:32:48,964][model][INFO] - Training step 38880 loss 0.09167686849832535
[2025-03-18 06:34:08,580][model][INFO] - Training step 39040 loss 0.028733065351843834
[2025-03-18 06:35:27,030][model][INFO] - Training step 39200 loss 0.33149755001068115
[2025-03-18 06:36:48,176][model][INFO] - Training step 39360 loss 0.03480469435453415
[2025-03-18 06:38:10,439][model][INFO] - Training step 39520 loss 0.03669093921780586
[2025-03-18 06:39:29,536][model][INFO] - Training step 39680 loss 0.028391942381858826
[2025-03-18 06:40:52,129][model][INFO] - Training step 39840 loss 0.04174325615167618
[2025-03-18 06:42:11,950][model][INFO] - Training step 40000 loss 0.005411350633949041
[2025-03-18 06:43:32,779][model][INFO] - Training step 40160 loss 0.05346972495317459
[2025-03-18 06:44:51,526][model][INFO] - Training step 40320 loss 0.23400282859802246
[2025-03-18 06:46:11,776][model][INFO] - Training step 40480 loss 0.07682403177022934
[2025-03-18 06:47:33,232][model][INFO] - Training step 40640 loss 0.24378611147403717
[2025-03-18 06:48:50,627][model][INFO] - Training step 40800 loss 0.02667645923793316
[2025-03-18 06:50:11,024][model][INFO] - Training step 40960 loss 0.03741566836833954
[2025-03-18 06:51:33,013][model][INFO] - Training step 41120 loss 0.018284082412719727
[2025-03-18 06:52:53,103][model][INFO] - Training step 41280 loss 0.04695391654968262
[2025-03-18 06:54:15,249][model][INFO] - Training step 41440 loss 0.06697472929954529
[2025-03-18 06:55:37,265][model][INFO] - Training step 41600 loss 0.007626279257237911
[2025-03-18 06:56:57,589][model][INFO] - Training step 41760 loss 0.03176774084568024
[2025-03-18 06:58:20,672][model][INFO] - Training step 41920 loss 0.05970576032996178
[2025-03-18 06:59:42,496][model][INFO] - Training step 42080 loss 0.04237540438771248
[2025-03-18 07:01:02,284][model][INFO] - Training step 42240 loss 0.0817621648311615
[2025-03-18 07:02:21,451][model][INFO] - Training step 42400 loss 0.04884178563952446
[2025-03-18 07:03:40,558][model][INFO] - Training step 42560 loss 0.01835070364177227
[2025-03-18 07:04:57,914][model][INFO] - Training step 42720 loss 0.08008153736591339
[2025-03-18 07:06:16,101][model][INFO] - Training step 42880 loss 0.12399314343929291
[2025-03-18 07:07:36,746][model][INFO] - Training step 43040 loss 0.2503903806209564
[2025-03-18 07:08:54,299][model][INFO] - Training step 43200 loss 0.005742982029914856
[2025-03-18 07:10:15,740][model][INFO] - Training step 43360 loss 0.05373573675751686
[2025-03-18 07:11:34,949][model][INFO] - Training step 43520 loss 0.00690618809312582
[2025-03-18 07:12:54,845][model][INFO] - Training step 43680 loss 0.6957380771636963
[2025-03-18 07:14:15,488][model][INFO] - Training step 43840 loss 0.07494434714317322
[2025-03-18 07:15:34,360][model][INFO] - Training step 44000 loss 0.10387670993804932
[2025-03-18 07:16:55,575][model][INFO] - Training step 44160 loss 0.2964412569999695
[2025-03-18 07:18:14,786][model][INFO] - Training step 44320 loss 0.07740722596645355
[2025-03-18 07:19:34,486][model][INFO] - Training step 44480 loss 0.03033110499382019
[2025-03-18 07:20:53,188][model][INFO] - Training step 44640 loss 0.05247122049331665
[2025-03-18 07:22:11,254][model][INFO] - Training step 44800 loss 0.04987621307373047
[2025-03-18 07:23:29,544][model][INFO] - Training step 44960 loss 0.22438019514083862
[2025-03-18 07:24:48,325][model][INFO] - Training step 45120 loss 0.05958398059010506
[2025-03-18 07:26:11,120][model][INFO] - Training step 45280 loss 0.007189897820353508
[2025-03-18 07:27:32,061][model][INFO] - Training step 45440 loss 0.03066086955368519
[2025-03-18 07:28:51,160][model][INFO] - Training step 45600 loss 0.07207494229078293
[2025-03-18 07:30:09,688][model][INFO] - Training step 45760 loss 0.10269083082675934
[2025-03-18 07:31:25,967][model][INFO] - Training step 45920 loss 0.07422482967376709
[2025-03-18 07:32:45,328][model][INFO] - Training step 46080 loss 0.06728200614452362
[2025-03-18 07:34:05,149][model][INFO] - Training step 46240 loss 0.030606240034103394
[2025-03-18 07:35:26,221][model][INFO] - Training step 46400 loss 0.04650377109646797
[2025-03-18 07:36:44,949][model][INFO] - Training step 46560 loss 0.04409283399581909
[2025-03-18 07:38:02,780][model][INFO] - Training step 46720 loss 0.15794003009796143
[2025-03-18 07:39:20,636][model][INFO] - Training step 46880 loss 0.05461912229657173
[2025-03-18 07:40:38,080][model][INFO] - Training step 47040 loss 0.2769598364830017
[2025-03-18 07:41:59,082][model][INFO] - Training step 47200 loss 0.006871662102639675
[2025-03-18 07:43:19,649][model][INFO] - Training step 47360 loss 0.036820150911808014
[2025-03-18 07:44:37,919][model][INFO] - Training step 47520 loss 0.024734992533922195
[2025-03-18 07:45:58,890][model][INFO] - Training step 47680 loss 0.2494123876094818
[2025-03-18 07:47:19,723][model][INFO] - Training step 47840 loss 0.2505657374858856
[2025-03-18 07:48:39,186][model][INFO] - Training step 48000 loss 0.4452705979347229
[2025-03-18 07:50:00,153][model][INFO] - Training step 48160 loss 0.058163948357105255
[2025-03-18 07:51:16,104][model][INFO] - Training step 48320 loss 0.04108665883541107
[2025-03-18 07:52:33,141][model][INFO] - Training step 48480 loss 0.053948599845170975
[2025-03-18 07:53:52,749][model][INFO] - Training step 48640 loss 0.2516520917415619
[2025-03-18 07:55:14,422][model][INFO] - Training step 48800 loss 0.013500150293111801
[2025-03-18 07:56:32,884][model][INFO] - Training step 48960 loss 0.04428219795227051
[2025-03-18 07:57:50,620][model][INFO] - Training step 49120 loss 0.17148593068122864
[2025-03-18 07:59:12,961][model][INFO] - Training step 49280 loss 0.28769105672836304
[2025-03-18 08:00:31,649][model][INFO] - Training step 49440 loss 0.04172254726290703
[2025-03-18 08:01:53,052][model][INFO] - Training step 49600 loss 0.007269526831805706
[2025-03-18 08:03:12,755][model][INFO] - Training step 49760 loss 0.06983645260334015
[2025-03-18 08:04:33,848][model][INFO] - Training step 49920 loss 0.06909254938364029
[2025-03-18 08:05:54,549][model][INFO] - Training step 50080 loss 0.04743269830942154
[2025-03-18 08:07:14,666][model][INFO] - Training step 50240 loss 0.03200230002403259
[2025-03-18 08:08:34,610][model][INFO] - Training step 50400 loss 0.013050475157797337
[2025-03-18 08:09:55,235][model][INFO] - Training step 50560 loss 0.03313938528299332
[2025-03-18 08:11:14,166][model][INFO] - Training step 50720 loss 0.046486444771289825
[2025-03-18 08:20:41,755][model][INFO] - Training step 80 loss 0.08260522782802582
[2025-03-18 08:22:00,337][model][INFO] - Training step 240 loss 0.045032013207674026
[2025-03-18 08:23:21,420][model][INFO] - Training step 400 loss 0.05569729954004288
[2025-03-18 08:24:41,754][model][INFO] - Training step 560 loss 0.05437151715159416
[2025-03-18 08:26:02,503][model][INFO] - Training step 720 loss 0.05815816670656204
[2025-03-18 08:27:26,631][model][INFO] - Training step 880 loss 0.18742942810058594
[2025-03-18 08:28:42,270][model][INFO] - Training step 1040 loss 0.05516096204519272
[2025-03-18 08:29:59,182][model][INFO] - Training step 1200 loss 0.44370949268341064
[2025-03-18 08:31:21,342][model][INFO] - Training step 1360 loss 0.08063933998346329
[2025-03-18 08:32:39,526][model][INFO] - Training step 1520 loss 0.04299396276473999
[2025-03-18 08:34:01,538][model][INFO] - Training step 1680 loss 0.2549360394477844
[2025-03-18 08:35:22,121][model][INFO] - Training step 1840 loss 0.1317899525165558
[2025-03-18 08:36:47,898][model][INFO] - Training step 2000 loss 0.07479511201381683
[2025-03-18 08:38:16,821][model][INFO] - Training step 2160 loss 0.03565337508916855
[2025-03-18 08:39:34,257][model][INFO] - Training step 2320 loss 0.07050567865371704
[2025-03-18 08:41:02,204][model][INFO] - Training step 2480 loss 0.04466649889945984
[2025-03-18 08:42:22,895][model][INFO] - Training step 2640 loss 0.03988321125507355
[2025-03-18 08:43:42,951][model][INFO] - Training step 2800 loss 0.25521060824394226
[2025-03-18 08:45:02,994][model][INFO] - Training step 2960 loss 0.029699601233005524
[2025-03-18 08:46:21,818][model][INFO] - Training step 3120 loss 0.20958998799324036
[2025-03-18 08:47:44,939][model][INFO] - Training step 3280 loss 0.21363908052444458
[2025-03-18 08:49:02,729][model][INFO] - Training step 3440 loss 0.03556168079376221
[2025-03-18 08:50:21,038][model][INFO] - Training step 3600 loss 0.052964262664318085
[2025-03-18 08:51:39,983][model][INFO] - Training step 3760 loss 0.2653007507324219
[2025-03-18 08:53:02,929][model][INFO] - Training step 3920 loss 0.037848569452762604
[2025-03-18 08:54:25,813][model][INFO] - Training step 4080 loss 0.066775381565094
[2025-03-18 08:55:44,854][model][INFO] - Training step 4240 loss 0.08444365859031677
[2025-03-18 08:57:03,050][model][INFO] - Training step 4400 loss 0.254671186208725
[2025-03-18 08:58:25,714][model][INFO] - Training step 4560 loss 0.0036376179195940495
[2025-03-18 08:59:47,643][model][INFO] - Training step 4720 loss 0.25484514236450195
[2025-03-18 09:01:06,952][model][INFO] - Training step 4880 loss 0.018688391894102097
[2025-03-18 09:02:29,735][model][INFO] - Training step 5040 loss 0.29606613516807556
[2025-03-18 09:03:48,842][model][INFO] - Training step 5200 loss 0.030225500464439392
[2025-03-18 09:05:07,813][model][INFO] - Training step 5360 loss 0.16006255149841309
[2025-03-18 09:06:28,103][model][INFO] - Training step 5520 loss 0.011954817920923233
[2025-03-18 09:07:45,327][model][INFO] - Training step 5680 loss 0.042637333273887634
[2025-03-18 09:09:07,545][model][INFO] - Training step 5840 loss 0.10387122631072998
[2025-03-18 09:10:27,729][model][INFO] - Training step 6000 loss 0.007331489585340023
[2025-03-18 09:11:45,468][model][INFO] - Training step 6160 loss 0.032409533858299255
[2025-03-18 09:13:06,880][model][INFO] - Training step 6320 loss 0.06019990146160126
[2025-03-18 09:14:27,846][model][INFO] - Training step 6480 loss 0.04898825287818909
[2025-03-18 09:15:49,052][model][INFO] - Training step 6640 loss 0.1209477037191391
[2025-03-18 09:17:09,658][model][INFO] - Training step 6800 loss 0.02490513026714325
[2025-03-18 09:18:30,588][model][INFO] - Training step 6960 loss 0.06809365749359131
[2025-03-18 09:19:50,516][model][INFO] - Training step 7120 loss 0.052292387932538986
[2025-03-18 09:21:13,563][model][INFO] - Training step 7280 loss 0.03539217263460159
[2025-03-18 09:22:31,905][model][INFO] - Training step 7440 loss 0.005490436684340239
[2025-03-18 09:23:53,264][model][INFO] - Training step 7600 loss 0.05257102847099304
[2025-03-18 09:25:12,687][model][INFO] - Training step 7760 loss 0.03969309478998184
[2025-03-18 09:26:31,081][model][INFO] - Training step 7920 loss 0.00523816654458642
[2025-03-18 09:27:50,020][model][INFO] - Training step 8080 loss 0.04671284928917885
[2025-03-18 09:29:10,705][model][INFO] - Training step 8240 loss 0.007815509103238583
[2025-03-18 09:30:28,417][model][INFO] - Training step 8400 loss 0.06621143966913223
[2025-03-18 09:31:47,378][model][INFO] - Training step 8560 loss 0.03498058021068573
[2025-03-18 09:33:06,892][model][INFO] - Training step 8720 loss 0.16816478967666626
[2025-03-18 09:34:25,540][model][INFO] - Training step 8880 loss 0.040590330958366394
[2025-03-18 09:35:45,169][model][INFO] - Training step 9040 loss 0.008471471257507801
[2025-03-18 09:37:02,489][model][INFO] - Training step 9200 loss 0.006209495011717081
[2025-03-18 09:38:20,653][model][INFO] - Training step 9360 loss 0.19025538861751556
[2025-03-18 09:39:39,767][model][INFO] - Training step 9520 loss 0.041264310479164124
[2025-03-18 09:40:58,089][model][INFO] - Training step 9680 loss 0.0649036094546318
[2025-03-18 09:42:19,739][model][INFO] - Training step 9840 loss 0.11317431181669235
[2025-03-18 09:43:41,258][model][INFO] - Training step 10000 loss 0.02830229140818119
[2025-03-18 09:45:02,112][model][INFO] - Training step 10160 loss 0.03882506489753723
[2025-03-18 09:46:24,089][model][INFO] - Training step 10320 loss 0.098827064037323
[2025-03-18 09:47:44,319][model][INFO] - Training step 10480 loss 0.11962991207838058
[2025-03-18 09:49:05,143][model][INFO] - Training step 10640 loss 0.13213768601417542
[2025-03-18 09:50:22,239][model][INFO] - Training step 10800 loss 0.07288558036088943
[2025-03-18 09:51:44,665][model][INFO] - Training step 10960 loss 0.06807258725166321
[2025-03-18 09:53:02,450][model][INFO] - Training step 11120 loss 0.056393813341856
[2025-03-18 09:54:22,158][model][INFO] - Training step 11280 loss 0.0738464817404747
[2025-03-18 09:55:41,369][model][INFO] - Training step 11440 loss 0.035482391715049744
[2025-03-18 09:57:00,269][model][INFO] - Training step 11600 loss 0.022569170221686363
[2025-03-18 09:58:24,267][model][INFO] - Training step 11760 loss 0.25608059763908386
[2025-03-18 09:59:42,945][model][INFO] - Training step 11920 loss 0.13395816087722778
[2025-03-18 10:01:03,760][model][INFO] - Training step 12080 loss 0.08956985175609589
[2025-03-18 10:02:26,285][model][INFO] - Training step 12240 loss 0.010086970403790474
[2025-03-18 10:03:44,307][model][INFO] - Training step 12400 loss 0.004832704085856676
[2025-03-18 10:05:05,855][model][INFO] - Training step 12560 loss 0.041614383459091187
[2025-03-18 10:06:23,485][model][INFO] - Training step 12720 loss 0.24688905477523804
[2025-03-18 10:07:42,345][model][INFO] - Training step 12880 loss 0.0036322048399597406
[2025-03-18 10:09:01,003][model][INFO] - Training step 13040 loss 0.15292799472808838
[2025-03-18 10:10:21,060][model][INFO] - Training step 13200 loss 0.0450374037027359
[2025-03-18 10:11:40,275][model][INFO] - Training step 13360 loss 0.09148626774549484
[2025-03-18 10:13:00,841][model][INFO] - Training step 13520 loss 0.041054725646972656
[2025-03-18 10:14:22,569][model][INFO] - Training step 13680 loss 0.009609511122107506
[2025-03-18 10:15:43,091][model][INFO] - Training step 13840 loss 0.04924982041120529
[2025-03-18 10:17:03,240][model][INFO] - Training step 14000 loss 0.08107413351535797
[2025-03-18 10:18:23,208][model][INFO] - Training step 14160 loss 0.03651953116059303
[2025-03-18 10:19:40,115][model][INFO] - Training step 14320 loss 0.03898874670267105
[2025-03-18 10:20:56,743][model][INFO] - Training step 14480 loss 0.04615128040313721
[2025-03-18 10:22:18,909][model][INFO] - Training step 14640 loss 0.24676606059074402
[2025-03-18 10:23:37,272][model][INFO] - Training step 14800 loss 0.04905417189002037
[2025-03-18 10:24:57,839][model][INFO] - Training step 14960 loss 0.027524642646312714
[2025-03-18 10:26:20,567][model][INFO] - Training step 15120 loss 0.034084148705005646
[2025-03-18 10:27:38,321][model][INFO] - Training step 15280 loss 0.05901346355676651
[2025-03-18 10:28:58,865][model][INFO] - Training step 15440 loss 0.10375648736953735
[2025-03-18 10:30:16,298][model][INFO] - Training step 15600 loss 0.0889795571565628
[2025-03-18 10:31:35,344][model][INFO] - Training step 15760 loss 0.06449747085571289
[2025-03-18 10:32:55,808][model][INFO] - Training step 15920 loss 0.11633859574794769
[2025-03-18 10:34:13,775][model][INFO] - Training step 16080 loss 0.1437971293926239
[2025-03-18 10:35:33,266][model][INFO] - Training step 16240 loss 0.0789499431848526
[2025-03-18 10:36:53,918][model][INFO] - Training step 16400 loss 0.10877984762191772
[2025-03-18 10:38:14,885][model][INFO] - Training step 16560 loss 0.0988626778125763
[2025-03-18 10:39:30,565][model][INFO] - Training step 16720 loss 0.25524401664733887
[2025-03-18 10:40:49,026][model][INFO] - Training step 16880 loss 0.03664518520236015
[2025-03-18 10:42:10,351][model][INFO] - Training step 17040 loss 0.6083310842514038
[2025-03-18 10:43:28,720][model][INFO] - Training step 17200 loss 0.067281074821949
[2025-03-18 10:44:48,221][model][INFO] - Training step 17360 loss 0.07128900289535522
[2025-03-18 10:46:10,190][model][INFO] - Training step 17520 loss 0.10624869167804718
[2025-03-18 10:47:29,000][model][INFO] - Training step 17680 loss 0.05274537578225136
[2025-03-18 10:48:45,946][model][INFO] - Training step 17840 loss 0.26633208990097046
[2025-03-18 10:50:04,550][model][INFO] - Training step 18000 loss 0.05892512947320938
[2025-03-18 10:51:23,341][model][INFO] - Training step 18160 loss 0.1323554813861847
[2025-03-18 10:52:42,907][model][INFO] - Training step 18320 loss 0.03680106997489929
[2025-03-18 10:54:01,314][model][INFO] - Training step 18480 loss 0.2718472480773926
[2025-03-18 10:55:22,997][model][INFO] - Training step 18640 loss 0.26225361227989197
[2025-03-18 10:56:40,733][model][INFO] - Training step 18800 loss 0.052220702171325684
[2025-03-18 10:58:02,839][model][INFO] - Training step 18960 loss 0.18702396750450134
[2025-03-18 10:59:22,747][model][INFO] - Training step 19120 loss 0.03160726651549339
[2025-03-18 11:00:42,239][model][INFO] - Training step 19280 loss 0.05774958059191704
[2025-03-18 11:01:59,760][model][INFO] - Training step 19440 loss 0.18896055221557617
[2025-03-18 11:03:20,725][model][INFO] - Training step 19600 loss 0.2633345127105713
[2025-03-18 11:04:44,027][model][INFO] - Training step 19760 loss 0.026732226833701134
[2025-03-18 11:06:06,462][model][INFO] - Training step 19920 loss 0.2613052725791931
[2025-03-18 11:07:25,047][model][INFO] - Training step 20080 loss 0.05713380128145218
[2025-03-18 11:08:44,996][model][INFO] - Training step 20240 loss 0.0842331051826477
[2025-03-18 11:10:04,250][model][INFO] - Training step 20400 loss 0.16103866696357727
[2025-03-18 11:11:22,622][model][INFO] - Training step 20560 loss 0.0013908377150073647
[2025-03-18 11:12:41,539][model][INFO] - Training step 20720 loss 0.08858759701251984
[2025-03-18 11:14:01,133][model][INFO] - Training step 20880 loss 0.049776241183280945
[2025-03-18 11:15:20,076][model][INFO] - Training step 21040 loss 0.09081462025642395
[2025-03-18 11:16:41,191][model][INFO] - Training step 21200 loss 0.0032322925981134176
[2025-03-18 11:18:00,988][model][INFO] - Training step 21360 loss 0.24748793244361877
[2025-03-18 11:19:18,833][model][INFO] - Training step 21520 loss 0.019637685269117355
[2025-03-18 11:20:43,406][model][INFO] - Training step 21680 loss 0.006234908476471901
[2025-03-18 11:22:02,002][model][INFO] - Training step 21840 loss 0.03425418585538864
[2025-03-18 11:23:20,876][model][INFO] - Training step 22000 loss 0.19275248050689697
[2025-03-18 11:24:35,910][model][INFO] - Training step 22160 loss 0.04123996943235397
[2025-03-18 11:25:57,383][model][INFO] - Training step 22320 loss 0.08940211683511734
[2025-03-18 11:27:19,791][model][INFO] - Training step 22480 loss 0.07005413621664047
[2025-03-18 11:28:37,878][model][INFO] - Training step 22640 loss 0.028274960815906525
[2025-03-18 11:29:56,488][model][INFO] - Training step 22800 loss 0.009402390569448471
[2025-03-18 11:31:18,360][model][INFO] - Training step 22960 loss 0.005945911165326834
[2025-03-18 11:32:37,036][model][INFO] - Training step 23120 loss 0.007769493851810694
[2025-03-18 11:33:57,119][model][INFO] - Training step 23280 loss 0.04553809016942978
[2025-03-18 11:35:17,804][model][INFO] - Training step 23440 loss 0.069999560713768
[2025-03-18 11:36:37,268][model][INFO] - Training step 23600 loss 0.34657448530197144
[2025-03-18 11:37:55,542][model][INFO] - Training step 23760 loss 0.06504438817501068
[2025-03-18 11:39:17,357][model][INFO] - Training step 23920 loss 0.04957553744316101
[2025-03-18 11:40:39,587][model][INFO] - Training step 24080 loss 0.0651371106505394
[2025-03-18 11:42:00,435][model][INFO] - Training step 24240 loss 0.03673841804265976
[2025-03-18 11:43:21,815][model][INFO] - Training step 24400 loss 0.05186942592263222
[2025-03-18 11:44:42,435][model][INFO] - Training step 24560 loss 0.05108630284667015
[2025-03-18 11:46:00,089][model][INFO] - Training step 24720 loss 0.24854883551597595
[2025-03-18 11:47:22,347][model][INFO] - Training step 24880 loss 0.05527321994304657
[2025-03-18 11:48:42,127][model][INFO] - Training step 25040 loss 0.049139268696308136
[2025-03-18 11:50:04,489][model][INFO] - Training step 25200 loss 0.02856539562344551
[2025-03-18 11:51:23,469][model][INFO] - Training step 25360 loss 0.24218285083770752
[2025-03-18 11:52:46,395][model][INFO] - Training step 25520 loss 0.007413174025714397
[2025-03-18 11:54:08,657][model][INFO] - Training step 25680 loss 0.033354803919792175
[2025-03-18 11:55:28,743][model][INFO] - Training step 25840 loss 0.27201777696609497
[2025-03-18 11:56:51,340][model][INFO] - Training step 26000 loss 0.005489780101925135
[2025-03-18 11:58:12,608][model][INFO] - Training step 26160 loss 0.0402536541223526
[2025-03-18 11:59:34,965][model][INFO] - Training step 26320 loss 0.20259025692939758
[2025-03-18 12:00:54,936][model][INFO] - Training step 26480 loss 0.11833400279283524
[2025-03-18 12:02:13,970][model][INFO] - Training step 26640 loss 0.050184912979602814
[2025-03-18 12:03:33,337][model][INFO] - Training step 26800 loss 0.012622196227312088
[2025-03-18 12:04:52,869][model][INFO] - Training step 26960 loss 0.05209476500749588
[2025-03-18 12:06:14,586][model][INFO] - Training step 27120 loss 0.04614784196019173
[2025-03-18 12:07:32,758][model][INFO] - Training step 27280 loss 0.08549376577138901
[2025-03-18 12:08:53,310][model][INFO] - Training step 27440 loss 0.04869931936264038
[2025-03-18 12:10:11,887][model][INFO] - Training step 27600 loss 0.20436888933181763
[2025-03-18 12:11:31,235][model][INFO] - Training step 27760 loss 0.07349902391433716
[2025-03-18 12:12:48,778][model][INFO] - Training step 27920 loss 0.026124829426407814
[2025-03-18 12:14:08,362][model][INFO] - Training step 28080 loss 0.2594578266143799
[2025-03-18 12:15:27,591][model][INFO] - Training step 28240 loss 0.07941398024559021
[2025-03-18 12:16:48,374][model][INFO] - Training step 28400 loss 0.0712093710899353
[2025-03-18 12:18:10,378][model][INFO] - Training step 28560 loss 0.15032953023910522
[2025-03-18 12:19:27,051][model][INFO] - Training step 28720 loss 0.10138693451881409
[2025-03-18 12:20:45,904][model][INFO] - Training step 28880 loss 0.005184602458029985
[2025-03-18 12:22:05,352][model][INFO] - Training step 29040 loss 0.04546456038951874
[2025-03-18 12:23:26,312][model][INFO] - Training step 29200 loss 0.007458971813321114
[2025-03-18 12:24:45,584][model][INFO] - Training step 29360 loss 0.020188499242067337
[2025-03-18 12:26:06,335][model][INFO] - Training step 29520 loss 0.2645431160926819
[2025-03-18 12:27:28,247][model][INFO] - Training step 29680 loss 0.050184763967990875
[2025-03-18 12:28:45,948][model][INFO] - Training step 29840 loss 0.049196645617485046
[2025-03-18 12:30:09,596][model][INFO] - Training step 30000 loss 0.0959998369216919
[2025-03-18 12:31:27,532][model][INFO] - Training step 30160 loss 0.2524451017379761
[2025-03-18 12:32:46,488][model][INFO] - Training step 30320 loss 0.007669699843972921
[2025-03-18 12:34:06,207][model][INFO] - Training step 30480 loss 0.03320924937725067
[2025-03-18 12:35:21,772][model][INFO] - Training step 30640 loss 0.07384081184864044
[2025-03-18 12:36:39,052][model][INFO] - Training step 30800 loss 0.08936865627765656
[2025-03-18 12:37:58,659][model][INFO] - Training step 30960 loss 0.04062875732779503
[2025-03-18 12:39:17,918][model][INFO] - Training step 31120 loss 0.0648982971906662
[2025-03-18 12:40:34,350][model][INFO] - Training step 31280 loss 0.04656144604086876
[2025-03-18 12:41:52,924][model][INFO] - Training step 31440 loss 0.12929847836494446
[2025-03-18 12:43:11,927][model][INFO] - Training step 31600 loss 0.25619620084762573
[2025-03-18 12:44:29,417][model][INFO] - Training step 31760 loss 0.08569957315921783
[2025-03-18 12:45:50,942][model][INFO] - Training step 31920 loss 0.04488132894039154
[2025-03-18 12:47:08,971][model][INFO] - Training step 32080 loss 0.24630622565746307
[2025-03-18 12:48:28,535][model][INFO] - Training step 32240 loss 0.1718769669532776
[2025-03-18 12:49:48,320][model][INFO] - Training step 32400 loss 0.0050040376372635365
[2025-03-18 12:51:07,766][model][INFO] - Training step 32560 loss 0.05681537091732025
[2025-03-18 12:52:30,710][model][INFO] - Training step 32720 loss 0.03520990163087845
[2025-03-18 12:53:49,824][model][INFO] - Training step 32880 loss 0.05003754422068596
[2025-03-18 12:55:09,960][model][INFO] - Training step 33040 loss 0.22467723488807678
[2025-03-18 12:56:30,856][model][INFO] - Training step 33200 loss 0.006501291878521442
[2025-03-18 12:57:49,470][model][INFO] - Training step 33360 loss 0.024261314421892166
[2025-03-18 12:59:10,599][model][INFO] - Training step 33520 loss 0.2560355067253113
[2025-03-18 13:00:30,022][model][INFO] - Training step 33680 loss 0.01768147200345993
[2025-03-18 13:01:48,788][model][INFO] - Training step 33840 loss 0.051318198442459106
[2025-03-18 13:03:09,187][model][INFO] - Training step 34000 loss 0.006027821451425552
[2025-03-18 13:04:30,490][model][INFO] - Training step 34160 loss 0.0612962543964386
[2025-03-18 13:05:49,438][model][INFO] - Training step 34320 loss 0.029211295768618584
[2025-03-18 13:07:10,950][model][INFO] - Training step 34480 loss 0.008375754579901695
[2025-03-18 13:08:31,417][model][INFO] - Training step 34640 loss 0.24472983181476593
[2025-03-18 13:09:52,657][model][INFO] - Training step 34800 loss 0.04186481609940529
[2025-03-18 13:11:10,834][model][INFO] - Training step 34960 loss 0.11475397646427155
[2025-03-18 13:12:29,482][model][INFO] - Training step 35120 loss 0.015974974259734154
[2025-03-18 13:13:49,267][model][INFO] - Training step 35280 loss 0.03671935573220253
[2025-03-18 13:15:08,993][model][INFO] - Training step 35440 loss 0.022575225681066513
[2025-03-18 13:16:29,099][model][INFO] - Training step 35600 loss 0.07077369093894958
[2025-03-18 13:17:46,177][model][INFO] - Training step 35760 loss 0.04112420976161957
[2025-03-18 13:19:02,862][model][INFO] - Training step 35920 loss 0.052021853625774384
[2025-03-18 13:20:23,417][model][INFO] - Training step 36080 loss 0.05704651027917862
[2025-03-18 13:21:44,032][model][INFO] - Training step 36240 loss 0.03055630996823311
[2025-03-18 13:23:02,971][model][INFO] - Training step 36400 loss 0.26027536392211914
[2025-03-18 13:24:21,760][model][INFO] - Training step 36560 loss 0.04866281896829605
[2025-03-18 13:25:41,356][model][INFO] - Training step 36720 loss 0.014116826467216015
[2025-03-18 13:27:01,404][model][INFO] - Training step 36880 loss 0.0402216874063015
[2025-03-18 13:28:22,213][model][INFO] - Training step 37040 loss 0.008058172650635242
[2025-03-18 13:29:42,146][model][INFO] - Training step 37200 loss 0.040967054665088654
[2025-03-18 13:31:01,023][model][INFO] - Training step 37360 loss 0.23872312903404236
[2025-03-18 13:32:21,047][model][INFO] - Training step 37520 loss 0.021770693361759186
[2025-03-18 13:33:39,262][model][INFO] - Training step 37680 loss 0.007853898219764233
[2025-03-18 13:35:00,086][model][INFO] - Training step 37840 loss 0.15918788313865662
[2025-03-18 13:36:19,602][model][INFO] - Training step 38000 loss 0.01455676183104515
[2025-03-18 13:37:39,677][model][INFO] - Training step 38160 loss 0.03436565399169922
[2025-03-18 13:38:59,844][model][INFO] - Training step 38320 loss 0.2590857446193695
[2025-03-18 13:40:18,108][model][INFO] - Training step 38480 loss 0.05293424427509308
[2025-03-18 13:41:37,835][model][INFO] - Training step 38640 loss 0.046660780906677246
[2025-03-18 13:42:56,392][model][INFO] - Training step 38800 loss 0.0654362365603447
[2025-03-18 13:44:15,592][model][INFO] - Training step 38960 loss 0.14731381833553314
[2025-03-18 13:45:33,715][model][INFO] - Training step 39120 loss 0.03871174901723862
[2025-03-18 13:46:51,878][model][INFO] - Training step 39280 loss 0.053323887288570404
[2025-03-18 13:48:13,241][model][INFO] - Training step 39440 loss 0.17168569564819336
[2025-03-18 13:49:32,009][model][INFO] - Training step 39600 loss 0.03419843316078186
[2025-03-18 13:50:50,932][model][INFO] - Training step 39760 loss 0.04357600212097168
[2025-03-18 13:52:11,722][model][INFO] - Training step 39920 loss 0.07470415532588959
[2025-03-18 13:53:32,461][model][INFO] - Training step 40080 loss 0.020495759323239326
[2025-03-18 13:54:51,849][model][INFO] - Training step 40240 loss 0.03872399404644966
[2025-03-18 13:56:13,021][model][INFO] - Training step 40400 loss 0.06769126653671265
[2025-03-18 13:57:32,276][model][INFO] - Training step 40560 loss 0.06216750293970108
[2025-03-18 13:58:53,086][model][INFO] - Training step 40720 loss 0.25472554564476013
[2025-03-18 14:00:09,817][model][INFO] - Training step 40880 loss 0.2633289694786072
[2025-03-18 14:01:28,152][model][INFO] - Training step 41040 loss 0.061542071402072906
[2025-03-18 14:02:47,684][model][INFO] - Training step 41200 loss 0.024209007620811462
[2025-03-18 14:04:08,781][model][INFO] - Training step 41360 loss 0.04090273380279541
[2025-03-18 14:05:25,278][model][INFO] - Training step 41520 loss 0.04895411431789398
[2025-03-18 14:06:47,223][model][INFO] - Training step 41680 loss 0.1441224366426468
[2025-03-18 14:08:08,344][model][INFO] - Training step 41840 loss 0.022230025380849838
[2025-03-18 14:09:27,921][model][INFO] - Training step 42000 loss 0.256519079208374
[2025-03-18 14:10:48,684][model][INFO] - Training step 42160 loss 0.0661270022392273
[2025-03-18 14:12:07,224][model][INFO] - Training step 42320 loss 0.02543170005083084
[2025-03-18 14:13:27,390][model][INFO] - Training step 42480 loss 0.03439812362194061
[2025-03-18 14:14:47,418][model][INFO] - Training step 42640 loss 0.11898888647556305
[2025-03-18 14:16:06,404][model][INFO] - Training step 42800 loss 0.04634122550487518
[2025-03-18 14:17:25,313][model][INFO] - Training step 42960 loss 0.011303700506687164
[2025-03-18 14:18:43,568][model][INFO] - Training step 43120 loss 0.11133399605751038
[2025-03-18 14:20:02,617][model][INFO] - Training step 43280 loss 0.057621099054813385
[2025-03-18 14:21:24,796][model][INFO] - Training step 43440 loss 0.12259179353713989
[2025-03-18 14:22:45,133][model][INFO] - Training step 43600 loss 0.21730032563209534
[2025-03-18 14:24:07,960][model][INFO] - Training step 43760 loss 0.012283019721508026
[2025-03-18 14:25:29,110][model][INFO] - Training step 43920 loss 0.25487592816352844
[2025-03-18 14:26:47,882][model][INFO] - Training step 44080 loss 0.008102767169475555
[2025-03-18 14:28:12,917][model][INFO] - Training step 44240 loss 0.09700331091880798
[2025-03-18 14:29:30,725][model][INFO] - Training step 44400 loss 0.05852199345827103
[2025-03-18 14:30:52,079][model][INFO] - Training step 44560 loss 0.04605827480554581
[2025-03-18 14:32:12,618][model][INFO] - Training step 44720 loss 0.2528369724750519
[2025-03-18 14:33:29,724][model][INFO] - Training step 44880 loss 0.09824515879154205
[2025-03-18 14:34:52,073][model][INFO] - Training step 45040 loss 0.03193105757236481
[2025-03-18 14:36:10,755][model][INFO] - Training step 45200 loss 0.0399082787334919
[2025-03-18 14:37:33,520][model][INFO] - Training step 45360 loss 0.12129093706607819
[2025-03-18 14:38:53,776][model][INFO] - Training step 45520 loss 0.037163496017456055
[2025-03-18 14:40:15,566][model][INFO] - Training step 45680 loss 0.017324786633253098
[2025-03-18 14:41:37,187][model][INFO] - Training step 45840 loss 0.005066613666713238
[2025-03-18 14:42:56,660][model][INFO] - Training step 46000 loss 0.0507260262966156
[2025-03-18 14:44:16,461][model][INFO] - Training step 46160 loss 0.06484806537628174
[2025-03-18 14:45:37,183][model][INFO] - Training step 46320 loss 0.04233969375491142
[2025-03-18 14:46:56,200][model][INFO] - Training step 46480 loss 0.020312974229454994
[2025-03-18 14:48:16,671][model][INFO] - Training step 46640 loss 0.007696638349443674
[2025-03-18 14:49:38,123][model][INFO] - Training step 46800 loss 0.16445723176002502
[2025-03-18 14:51:02,049][model][INFO] - Training step 46960 loss 0.16458144783973694
[2025-03-18 14:52:20,220][model][INFO] - Training step 47120 loss 0.2705594301223755
[2025-03-18 14:53:45,395][model][INFO] - Training step 47280 loss 0.023685326799750328
[2025-03-18 14:55:06,726][model][INFO] - Training step 47440 loss 0.02080012671649456
[2025-03-18 14:56:28,127][model][INFO] - Training step 47600 loss 0.24629813432693481
[2025-03-18 14:57:47,633][model][INFO] - Training step 47760 loss 0.06539640575647354
[2025-03-18 14:59:08,239][model][INFO] - Training step 47920 loss 0.06879249215126038
[2025-03-18 15:00:29,755][model][INFO] - Training step 48080 loss 0.1907261312007904
[2025-03-18 15:01:48,768][model][INFO] - Training step 48240 loss 0.05983545631170273
[2025-03-18 15:03:06,188][model][INFO] - Training step 48400 loss 0.11911765486001968
[2025-03-18 15:04:24,815][model][INFO] - Training step 48560 loss 0.05744599550962448
[2025-03-18 15:05:45,078][model][INFO] - Training step 48720 loss 0.029188677668571472
[2025-03-18 15:07:06,558][model][INFO] - Training step 48880 loss 0.09759664535522461
[2025-03-18 15:08:26,890][model][INFO] - Training step 49040 loss 0.05987634137272835
[2025-03-18 15:09:45,790][model][INFO] - Training step 49200 loss 0.04201442748308182
[2025-03-18 15:11:04,437][model][INFO] - Training step 49360 loss 0.24614043533802032
[2025-03-18 15:12:26,270][model][INFO] - Training step 49520 loss 0.09278857707977295
[2025-03-18 15:13:46,089][model][INFO] - Training step 49680 loss 0.02171005681157112
[2025-03-18 15:15:08,580][model][INFO] - Training step 49840 loss 0.08156973123550415
[2025-03-18 15:16:33,402][model][INFO] - Training step 50000 loss 0.2717841565608978
[2025-03-18 15:17:52,792][model][INFO] - Training step 50160 loss 0.041634343564510345
[2025-03-18 15:19:14,225][model][INFO] - Training step 50320 loss 0.2527647912502289
[2025-03-18 15:20:32,857][model][INFO] - Training step 50480 loss 0.042542193084955215
[2025-03-18 15:21:49,317][model][INFO] - Training step 50640 loss 0.03665643185377121
[2025-03-18 15:31:23,715][model][INFO] - Training step 0 loss 0.03506934270262718
[2025-03-18 15:32:42,799][model][INFO] - Training step 160 loss 0.023869279772043228
[2025-03-18 15:34:05,521][model][INFO] - Training step 320 loss 0.004898054525256157
[2025-03-18 15:35:23,845][model][INFO] - Training step 480 loss 0.2352602481842041
[2025-03-18 15:36:42,311][model][INFO] - Training step 640 loss 0.25578993558883667
[2025-03-18 15:38:03,200][model][INFO] - Training step 800 loss 0.08383816480636597
[2025-03-18 15:39:25,230][model][INFO] - Training step 960 loss 0.026222430169582367
[2025-03-18 15:40:45,368][model][INFO] - Training step 1120 loss 0.0060725645162165165
[2025-03-18 15:42:06,327][model][INFO] - Training step 1280 loss 0.04588576406240463
[2025-03-18 15:43:24,779][model][INFO] - Training step 1440 loss 0.2971683144569397
[2025-03-18 15:44:42,304][model][INFO] - Training step 1600 loss 0.2640434801578522
[2025-03-18 15:46:01,618][model][INFO] - Training step 1760 loss 0.25621747970581055
[2025-03-18 15:47:19,225][model][INFO] - Training step 1920 loss 0.09242840111255646
[2025-03-18 15:48:36,849][model][INFO] - Training step 2080 loss 0.2717631757259369
[2025-03-18 15:49:55,672][model][INFO] - Training step 2240 loss 0.031676437705755234
[2025-03-18 15:51:14,991][model][INFO] - Training step 2400 loss 0.03815244883298874
[2025-03-18 15:52:31,705][model][INFO] - Training step 2560 loss 0.08547593653202057
[2025-03-18 15:53:50,148][model][INFO] - Training step 2720 loss 0.2570900321006775
[2025-03-18 15:55:09,431][model][INFO] - Training step 2880 loss 0.24706941843032837
[2025-03-18 15:56:28,219][model][INFO] - Training step 3040 loss 0.038300253450870514
[2025-03-18 15:57:47,276][model][INFO] - Training step 3200 loss 0.004586934112012386
[2025-03-18 15:59:04,966][model][INFO] - Training step 3360 loss 0.029434850439429283
[2025-03-18 16:00:22,184][model][INFO] - Training step 3520 loss 0.06706008315086365
[2025-03-18 16:01:43,262][model][INFO] - Training step 3680 loss 0.05893950164318085
[2025-03-18 16:02:59,813][model][INFO] - Training step 3840 loss 0.04060906171798706
[2025-03-18 16:04:19,187][model][INFO] - Training step 4000 loss 0.057245418429374695
[2025-03-18 16:05:40,647][model][INFO] - Training step 4160 loss 0.060268498957157135
[2025-03-18 16:07:00,156][model][INFO] - Training step 4320 loss 0.034143902361392975
[2025-03-18 16:08:22,992][model][INFO] - Training step 4480 loss 0.254319429397583
[2025-03-18 16:09:45,178][model][INFO] - Training step 4640 loss 0.04796864092350006
[2025-03-18 16:11:04,809][model][INFO] - Training step 4800 loss 0.08309856802225113
[2025-03-18 16:12:24,381][model][INFO] - Training step 4960 loss 0.24469643831253052
[2025-03-18 16:13:43,731][model][INFO] - Training step 5120 loss 0.3545039892196655
[2025-03-18 16:15:05,253][model][INFO] - Training step 5280 loss 0.10097675770521164
[2025-03-18 16:16:24,220][model][INFO] - Training step 5440 loss 0.09969708323478699
[2025-03-18 16:17:40,820][model][INFO] - Training step 5600 loss 0.029513053596019745
[2025-03-18 16:18:59,525][model][INFO] - Training step 5760 loss 0.004158742725849152
[2025-03-18 16:20:19,513][model][INFO] - Training step 5920 loss 0.07625417411327362
[2025-03-18 16:21:37,853][model][INFO] - Training step 6080 loss 0.05924912542104721
[2025-03-18 16:22:58,134][model][INFO] - Training step 6240 loss 0.024227041751146317
[2025-03-18 16:24:16,630][model][INFO] - Training step 6400 loss 0.08376749604940414
[2025-03-18 16:25:34,717][model][INFO] - Training step 6560 loss 0.24563293159008026
[2025-03-18 16:26:54,758][model][INFO] - Training step 6720 loss 0.019870776683092117
[2025-03-18 16:28:12,347][model][INFO] - Training step 6880 loss 0.05568089336156845
[2025-03-18 16:29:30,520][model][INFO] - Training step 7040 loss 0.022097572684288025
[2025-03-18 16:30:51,875][model][INFO] - Training step 7200 loss 0.025412745773792267
[2025-03-18 16:32:10,147][model][INFO] - Training step 7360 loss 0.24937297403812408
[2025-03-18 16:33:27,435][model][INFO] - Training step 7520 loss 0.2597663104534149
[2025-03-18 16:34:45,162][model][INFO] - Training step 7680 loss 0.09919469058513641
[2025-03-18 16:36:05,352][model][INFO] - Training step 7840 loss 0.035230524837970734
[2025-03-18 16:37:24,373][model][INFO] - Training step 8000 loss 0.04556315019726753
[2025-03-18 16:38:44,724][model][INFO] - Training step 8160 loss 0.13774219155311584
[2025-03-18 16:40:03,094][model][INFO] - Training step 8320 loss 0.0284053236246109
[2025-03-18 16:41:23,110][model][INFO] - Training step 8480 loss 0.010614749975502491
[2025-03-18 16:42:41,772][model][INFO] - Training step 8640 loss 0.025393016636371613
[2025-03-18 16:43:59,195][model][INFO] - Training step 8800 loss 0.040552232414484024
[2025-03-18 16:45:17,445][model][INFO] - Training step 8960 loss 0.3853136897087097
[2025-03-18 16:46:34,701][model][INFO] - Training step 9120 loss 0.1874130368232727
[2025-03-18 16:47:51,880][model][INFO] - Training step 9280 loss 0.04288991540670395
[2025-03-18 16:49:09,621][model][INFO] - Training step 9440 loss 0.13108594715595245
[2025-03-18 16:50:25,283][model][INFO] - Training step 9600 loss 0.34212207794189453
[2025-03-18 16:51:43,629][model][INFO] - Training step 9760 loss 0.08710549771785736
[2025-03-18 16:53:03,779][model][INFO] - Training step 9920 loss 0.25248855352401733
[2025-03-18 16:54:21,629][model][INFO] - Training step 10080 loss 0.07395486533641815
[2025-03-18 16:55:39,648][model][INFO] - Training step 10240 loss 0.034737326204776764
[2025-03-18 16:56:59,981][model][INFO] - Training step 10400 loss 0.037516359239816666
[2025-03-18 16:58:20,896][model][INFO] - Training step 10560 loss 0.07700608670711517
[2025-03-18 16:59:41,024][model][INFO] - Training step 10720 loss 0.035367656499147415
[2025-03-18 17:01:01,126][model][INFO] - Training step 10880 loss 0.057688355445861816
[2025-03-18 17:02:21,769][model][INFO] - Training step 11040 loss 0.16516324877738953
[2025-03-18 17:03:38,759][model][INFO] - Training step 11200 loss 0.24478113651275635
[2025-03-18 17:04:58,763][model][INFO] - Training step 11360 loss 0.22650504112243652
[2025-03-18 17:06:17,409][model][INFO] - Training step 11520 loss 0.0045450832694768906
[2025-03-18 17:07:35,495][model][INFO] - Training step 11680 loss 0.230130136013031
[2025-03-18 17:08:54,692][model][INFO] - Training step 11840 loss 0.055178940296173096
[2025-03-18 17:10:12,581][model][INFO] - Training step 12000 loss 0.050958771258592606
[2025-03-18 17:11:31,861][model][INFO] - Training step 12160 loss 0.046122319996356964
[2025-03-18 17:12:50,925][model][INFO] - Training step 12320 loss 0.23758649826049805
[2025-03-18 17:14:13,318][model][INFO] - Training step 12480 loss 0.04530167952179909
[2025-03-18 17:15:30,753][model][INFO] - Training step 12640 loss 0.04155372828245163
[2025-03-18 17:16:51,823][model][INFO] - Training step 12800 loss 0.05500242859125137
[2025-03-18 17:18:09,424][model][INFO] - Training step 12960 loss 0.0318668931722641
[2025-03-18 17:19:26,390][model][INFO] - Training step 13120 loss 0.028995253145694733
[2025-03-18 17:20:44,586][model][INFO] - Training step 13280 loss 0.036337047815322876
[2025-03-18 17:22:02,090][model][INFO] - Training step 13440 loss 0.0746007114648819
[2025-03-18 17:23:20,740][model][INFO] - Training step 13600 loss 0.2546992301940918
[2025-03-18 17:24:38,940][model][INFO] - Training step 13760 loss 0.132515087723732
[2025-03-18 17:25:56,493][model][INFO] - Training step 13920 loss 0.07795625925064087
[2025-03-18 17:27:16,179][model][INFO] - Training step 14080 loss 0.08830070495605469
[2025-03-18 17:28:32,435][model][INFO] - Training step 14240 loss 0.11898832023143768
[2025-03-18 17:29:52,187][model][INFO] - Training step 14400 loss 0.039213430136442184
[2025-03-18 17:31:11,195][model][INFO] - Training step 14560 loss 0.06965465098619461
[2025-03-18 17:32:30,469][model][INFO] - Training step 14720 loss 0.03649478778243065
[2025-03-18 17:33:48,022][model][INFO] - Training step 14880 loss 0.046919699758291245
[2025-03-18 17:35:06,577][model][INFO] - Training step 15040 loss 0.06583071500062943
[2025-03-18 17:36:25,589][model][INFO] - Training step 15200 loss 0.03131832182407379
[2025-03-18 17:37:44,589][model][INFO] - Training step 15360 loss 0.01854758709669113
[2025-03-18 17:39:02,485][model][INFO] - Training step 15520 loss 0.029172368347644806
[2025-03-18 17:40:22,549][model][INFO] - Training step 15680 loss 0.2713320255279541
[2025-03-18 17:41:41,534][model][INFO] - Training step 15840 loss 0.26263540983200073
[2025-03-18 17:42:59,092][model][INFO] - Training step 16000 loss 0.004161776974797249
[2025-03-18 17:44:18,069][model][INFO] - Training step 16160 loss 0.025723416358232498
[2025-03-18 17:45:35,171][model][INFO] - Training step 16320 loss 0.05759339779615402
[2025-03-18 17:46:52,018][model][INFO] - Training step 16480 loss 0.026188626885414124
[2025-03-18 17:48:09,367][model][INFO] - Training step 16640 loss 0.0325549952685833
[2025-03-18 17:49:26,386][model][INFO] - Training step 16800 loss 0.04773147404193878
[2025-03-18 17:50:46,663][model][INFO] - Training step 16960 loss 0.017452437430620193
[2025-03-18 17:52:06,136][model][INFO] - Training step 17120 loss 0.005437605082988739
[2025-03-18 17:53:28,496][model][INFO] - Training step 17280 loss 0.06603927910327911
[2025-03-18 17:54:48,097][model][INFO] - Training step 17440 loss 0.050921887159347534
[2025-03-18 17:56:08,551][model][INFO] - Training step 17600 loss 0.14755932986736298
[2025-03-18 17:57:30,020][model][INFO] - Training step 17760 loss 0.043372347950935364
[2025-03-18 17:58:45,566][model][INFO] - Training step 17920 loss 0.08209414780139923
[2025-03-18 18:00:05,467][model][INFO] - Training step 18080 loss 0.04110897332429886
[2025-03-18 18:01:24,026][model][INFO] - Training step 18240 loss 0.048349685966968536
[2025-03-18 18:02:44,292][model][INFO] - Training step 18400 loss 0.26385802030563354
[2025-03-18 18:04:06,787][model][INFO] - Training step 18560 loss 0.039766840636730194
[2025-03-18 18:05:26,884][model][INFO] - Training step 18720 loss 0.0837523490190506
[2025-03-18 18:06:49,022][model][INFO] - Training step 18880 loss 0.03267165273427963
[2025-03-18 18:08:06,895][model][INFO] - Training step 19040 loss 0.05064444988965988
[2025-03-18 18:09:26,610][model][INFO] - Training step 19200 loss 0.05361199378967285
[2025-03-18 18:10:46,064][model][INFO] - Training step 19360 loss 0.060105253010988235
[2025-03-18 18:12:07,905][model][INFO] - Training step 19520 loss 0.06993459165096283
[2025-03-18 18:13:26,908][model][INFO] - Training step 19680 loss 0.2562325596809387
[2025-03-18 18:14:44,875][model][INFO] - Training step 19840 loss 0.03993093967437744
[2025-03-18 18:16:04,523][model][INFO] - Training step 20000 loss 0.004513232968747616
[2025-03-18 18:17:22,687][model][INFO] - Training step 20160 loss 0.06775182485580444
[2025-03-18 18:18:40,859][model][INFO] - Training step 20320 loss 0.0034798276610672474
[2025-03-18 18:20:01,318][model][INFO] - Training step 20480 loss 0.07273826748132706
[2025-03-18 18:21:18,577][model][INFO] - Training step 20640 loss 0.27983778715133667
[2025-03-18 18:22:39,321][model][INFO] - Training step 20800 loss 0.06370548158884048
[2025-03-18 18:23:58,477][model][INFO] - Training step 20960 loss 0.04119720309972763
[2025-03-18 18:25:17,437][model][INFO] - Training step 21120 loss 0.4431800842285156
[2025-03-18 18:26:35,201][model][INFO] - Training step 21280 loss 0.006428839173167944
[2025-03-18 18:27:52,682][model][INFO] - Training step 21440 loss 0.03831687942147255
[2025-03-18 18:29:12,120][model][INFO] - Training step 21600 loss 0.25646066665649414
[2025-03-18 18:30:31,991][model][INFO] - Training step 21760 loss 0.037370868027210236
[2025-03-18 18:31:50,562][model][INFO] - Training step 21920 loss 0.029735364019870758
[2025-03-18 18:33:08,136][model][INFO] - Training step 22080 loss 0.056200459599494934
[2025-03-18 18:34:27,814][model][INFO] - Training step 22240 loss 0.19198273122310638
[2025-03-18 18:35:48,241][model][INFO] - Training step 22400 loss 0.038031380623579025
[2025-03-18 18:37:06,377][model][INFO] - Training step 22560 loss 0.07845483720302582
[2025-03-18 18:38:25,406][model][INFO] - Training step 22720 loss 0.017958050593733788
[2025-03-18 18:39:45,887][model][INFO] - Training step 22880 loss 0.027277983725070953
[2025-03-18 18:41:04,116][model][INFO] - Training step 23040 loss 0.003445124952122569
[2025-03-18 18:42:26,259][model][INFO] - Training step 23200 loss 0.052392005920410156
[2025-03-18 18:43:44,229][model][INFO] - Training step 23360 loss 0.2413094937801361
[2025-03-18 18:45:04,512][model][INFO] - Training step 23520 loss 0.279358446598053
[2025-03-18 18:46:23,155][model][INFO] - Training step 23680 loss 0.04097054898738861
[2025-03-18 18:47:45,366][model][INFO] - Training step 23840 loss 0.030906949192285538
[2025-03-18 18:49:02,645][model][INFO] - Training step 24000 loss 0.009583065286278725
[2025-03-18 18:50:21,390][model][INFO] - Training step 24160 loss 0.06656572222709656
[2025-03-18 18:51:39,904][model][INFO] - Training step 24320 loss 0.2606930732727051
[2025-03-18 18:52:57,060][model][INFO] - Training step 24480 loss 0.005865867715328932
[2025-03-18 18:54:14,670][model][INFO] - Training step 24640 loss 0.039818599820137024
[2025-03-18 18:55:32,634][model][INFO] - Training step 24800 loss 0.26050424575805664
[2025-03-18 18:56:49,839][model][INFO] - Training step 24960 loss 0.07109852135181427
[2025-03-18 18:58:09,454][model][INFO] - Training step 25120 loss 0.1319459229707718
[2025-03-18 18:59:28,036][model][INFO] - Training step 25280 loss 0.03263784199953079
[2025-03-18 19:00:46,464][model][INFO] - Training step 25440 loss 0.03412126004695892
[2025-03-18 19:02:04,272][model][INFO] - Training step 25600 loss 0.13119113445281982
[2025-03-18 19:03:22,936][model][INFO] - Training step 25760 loss 0.0872424840927124
[2025-03-18 19:04:42,881][model][INFO] - Training step 25920 loss 0.1409684419631958
[2025-03-18 19:06:05,146][model][INFO] - Training step 26080 loss 0.055506981909275055
[2025-03-18 19:07:26,050][model][INFO] - Training step 26240 loss 0.25630059838294983
[2025-03-18 19:08:47,020][model][INFO] - Training step 26400 loss 0.01920248009264469
[2025-03-18 19:10:08,415][model][INFO] - Training step 26560 loss 0.022968590259552002
[2025-03-18 19:11:27,993][model][INFO] - Training step 26720 loss 0.02785997837781906
[2025-03-18 19:12:49,081][model][INFO] - Training step 26880 loss 0.24514931440353394
[2025-03-18 19:14:09,874][model][INFO] - Training step 27040 loss 0.036657825112342834
[2025-03-18 19:15:29,998][model][INFO] - Training step 27200 loss 0.03063705936074257
[2025-03-18 19:16:49,468][model][INFO] - Training step 27360 loss 0.046084046363830566
[2025-03-18 19:18:06,335][model][INFO] - Training step 27520 loss 0.045326005667448044
[2025-03-18 19:19:23,934][model][INFO] - Training step 27680 loss 0.03327999264001846
[2025-03-18 19:20:42,664][model][INFO] - Training step 27840 loss 0.08412133157253265
[2025-03-18 19:21:59,818][model][INFO] - Training step 28000 loss 0.2523273825645447
[2025-03-18 19:23:18,775][model][INFO] - Training step 28160 loss 0.03993631526827812
[2025-03-18 19:24:36,940][model][INFO] - Training step 28320 loss 0.240721195936203
[2025-03-18 19:25:56,029][model][INFO] - Training step 28480 loss 0.007596396375447512
[2025-03-18 19:27:16,068][model][INFO] - Training step 28640 loss 0.23942852020263672
[2025-03-18 19:28:31,594][model][INFO] - Training step 28800 loss 0.2510615885257721
[2025-03-18 19:29:52,292][model][INFO] - Training step 28960 loss 0.08096364140510559
[2025-03-18 19:31:10,838][model][INFO] - Training step 29120 loss 0.04876735806465149
[2025-03-18 19:32:31,352][model][INFO] - Training step 29280 loss 0.2771153151988983
[2025-03-18 19:33:48,431][model][INFO] - Training step 29440 loss 0.03365014120936394
[2025-03-18 19:35:06,068][model][INFO] - Training step 29600 loss 0.078057199716568
[2025-03-18 19:36:26,698][model][INFO] - Training step 29760 loss 0.10356840491294861
[2025-03-18 19:37:47,350][model][INFO] - Training step 29920 loss 0.26194509863853455
[2025-03-18 19:39:06,762][model][INFO] - Training step 30080 loss 0.03497173637151718
[2025-03-18 19:40:26,928][model][INFO] - Training step 30240 loss 0.06578649580478668
[2025-03-18 19:41:46,781][model][INFO] - Training step 30400 loss 0.057792261242866516
[2025-03-18 19:43:03,593][model][INFO] - Training step 30560 loss 0.04495598375797272
[2025-03-18 19:44:21,151][model][INFO] - Training step 30720 loss 0.03538709133863449
[2025-03-18 19:45:35,450][model][INFO] - Training step 30880 loss 0.05287061631679535
[2025-03-18 19:46:55,320][model][INFO] - Training step 31040 loss 0.24742290377616882
[2025-03-18 19:48:13,457][model][INFO] - Training step 31200 loss 0.029935862869024277
[2025-03-18 19:49:31,960][model][INFO] - Training step 31360 loss 0.2595610022544861
[2025-03-18 19:50:50,637][model][INFO] - Training step 31520 loss 0.06947927176952362
[2025-03-18 19:52:08,063][model][INFO] - Training step 31680 loss 0.048157863318920135
[2025-03-18 19:53:27,765][model][INFO] - Training step 31840 loss 0.017340844497084618
[2025-03-18 19:54:47,239][model][INFO] - Training step 32000 loss 0.01802729070186615
[2025-03-18 19:56:06,818][model][INFO] - Training step 32160 loss 0.0024058714043349028
[2025-03-18 19:57:27,162][model][INFO] - Training step 32320 loss 0.09868356585502625
[2025-03-18 19:58:47,916][model][INFO] - Training step 32480 loss 0.005877409130334854
[2025-03-18 20:00:10,556][model][INFO] - Training step 32640 loss 0.2691158652305603
[2025-03-18 20:01:29,310][model][INFO] - Training step 32800 loss 0.24706654250621796
[2025-03-18 20:02:50,808][model][INFO] - Training step 32960 loss 0.04031696915626526
[2025-03-18 20:04:07,337][model][INFO] - Training step 33120 loss 0.03233438730239868
[2025-03-18 20:05:28,832][model][INFO] - Training step 33280 loss 0.2516794502735138
[2025-03-18 20:06:46,798][model][INFO] - Training step 33440 loss 0.041963446885347366
[2025-03-18 20:08:04,391][model][INFO] - Training step 33600 loss 0.03478951007127762
[2025-03-18 20:09:23,518][model][INFO] - Training step 33760 loss 0.012019552290439606
[2025-03-18 20:10:42,263][model][INFO] - Training step 33920 loss 0.18177452683448792
[2025-03-18 20:12:02,210][model][INFO] - Training step 34080 loss 0.07635035365819931
[2025-03-18 20:13:20,828][model][INFO] - Training step 34240 loss 0.25010162591934204
[2025-03-18 20:14:40,713][model][INFO] - Training step 34400 loss 0.04889364540576935
[2025-03-18 20:15:57,818][model][INFO] - Training step 34560 loss 0.13130958378314972
[2025-03-18 20:17:15,558][model][INFO] - Training step 34720 loss 0.2870867848396301
[2025-03-18 20:18:33,660][model][INFO] - Training step 34880 loss 0.037976428866386414
[2025-03-18 20:19:54,900][model][INFO] - Training step 35040 loss 0.10126972943544388
[2025-03-18 20:21:14,772][model][INFO] - Training step 35200 loss 0.26221948862075806
[2025-03-18 20:22:32,208][model][INFO] - Training step 35360 loss 0.03148668259382248
[2025-03-18 20:23:53,860][model][INFO] - Training step 35520 loss 0.046141259372234344
[2025-03-18 20:25:12,577][model][INFO] - Training step 35680 loss 0.2601991295814514
[2025-03-18 20:26:31,285][model][INFO] - Training step 35840 loss 0.02480616420507431
[2025-03-18 20:27:50,278][model][INFO] - Training step 36000 loss 0.25124984979629517
[2025-03-18 20:29:09,050][model][INFO] - Training step 36160 loss 0.0559484139084816
[2025-03-18 20:30:29,755][model][INFO] - Training step 36320 loss 0.08226433396339417
[2025-03-18 20:31:50,930][model][INFO] - Training step 36480 loss 0.06067490577697754
[2025-03-18 20:33:11,410][model][INFO] - Training step 36640 loss 0.034884974360466
[2025-03-18 20:34:31,320][model][INFO] - Training step 36800 loss 0.005564739927649498
[2025-03-18 20:35:50,862][model][INFO] - Training step 36960 loss 0.020803336054086685
[2025-03-18 20:37:08,786][model][INFO] - Training step 37120 loss 0.25874626636505127
[2025-03-18 20:38:30,842][model][INFO] - Training step 37280 loss 0.04401516169309616
[2025-03-18 20:39:53,262][model][INFO] - Training step 37440 loss 0.06411993503570557
[2025-03-18 20:41:08,812][model][INFO] - Training step 37600 loss 0.05023812875151634
[2025-03-18 20:42:29,778][model][INFO] - Training step 37760 loss 0.06190808117389679
[2025-03-18 20:43:46,291][model][INFO] - Training step 37920 loss 0.05637248232960701
[2025-03-18 20:45:04,980][model][INFO] - Training step 38080 loss 0.25160014629364014
[2025-03-18 20:46:25,263][model][INFO] - Training step 38240 loss 0.0406295470893383
[2025-03-18 20:47:47,212][model][INFO] - Training step 38400 loss 0.04097753390669823
[2025-03-18 20:49:04,349][model][INFO] - Training step 38560 loss 0.03882572054862976
[2025-03-18 20:50:24,800][model][INFO] - Training step 38720 loss 0.04374702647328377
[2025-03-18 20:51:43,321][model][INFO] - Training step 38880 loss 0.1217721626162529
[2025-03-18 20:53:03,933][model][INFO] - Training step 39040 loss 0.025615641847252846
[2025-03-18 20:54:20,001][model][INFO] - Training step 39200 loss 0.04601367935538292
[2025-03-18 20:55:37,890][model][INFO] - Training step 39360 loss 0.27480167150497437
[2025-03-18 20:56:58,513][model][INFO] - Training step 39520 loss 0.06140842288732529
[2025-03-18 20:58:15,938][model][INFO] - Training step 39680 loss 0.2791556119918823
[2025-03-18 20:59:34,200][model][INFO] - Training step 39840 loss 0.07086646556854248
[2025-03-18 21:00:51,922][model][INFO] - Training step 40000 loss 0.07926593720912933
[2025-03-18 21:02:13,459][model][INFO] - Training step 40160 loss 0.04986919090151787
[2025-03-18 21:03:33,347][model][INFO] - Training step 40320 loss 0.05535474419593811
[2025-03-18 21:04:56,656][model][INFO] - Training step 40480 loss 0.2452799528837204
[2025-03-18 21:06:18,909][model][INFO] - Training step 40640 loss 0.07000237703323364
[2025-03-18 21:07:35,490][model][INFO] - Training step 40800 loss 0.2405032515525818
[2025-03-18 21:08:55,201][model][INFO] - Training step 40960 loss 0.03585211560130119
[2025-03-18 21:10:13,247][model][INFO] - Training step 41120 loss 0.24464720487594604
[2025-03-18 21:11:32,765][model][INFO] - Training step 41280 loss 0.037480320781469345
[2025-03-18 21:12:49,540][model][INFO] - Training step 41440 loss 0.058554016053676605
[2025-03-18 21:14:10,517][model][INFO] - Training step 41600 loss 0.046455759555101395
[2025-03-18 21:15:30,416][model][INFO] - Training step 41760 loss 0.06137653440237045
[2025-03-18 21:16:52,013][model][INFO] - Training step 41920 loss 0.036188606172800064
[2025-03-18 21:18:10,291][model][INFO] - Training step 42080 loss 0.2594949007034302
[2025-03-18 21:19:27,126][model][INFO] - Training step 42240 loss 0.04333266615867615
[2025-03-18 21:20:46,968][model][INFO] - Training step 42400 loss 0.04619305580854416
[2025-03-18 21:22:06,435][model][INFO] - Training step 42560 loss 0.014266105368733406
[2025-03-18 21:23:26,771][model][INFO] - Training step 42720 loss 0.00527977803722024
[2025-03-18 21:24:44,581][model][INFO] - Training step 42880 loss 0.07539373636245728
[2025-03-18 21:26:04,238][model][INFO] - Training step 43040 loss 0.03216582536697388
[2025-03-18 21:27:21,706][model][INFO] - Training step 43200 loss 0.32057780027389526
[2025-03-18 21:28:41,743][model][INFO] - Training step 43360 loss 0.09769324213266373
[2025-03-18 21:30:01,592][model][INFO] - Training step 43520 loss 0.03511694818735123
[2025-03-18 21:31:22,543][model][INFO] - Training step 43680 loss 0.0036123888567090034
[2025-03-18 21:32:41,268][model][INFO] - Training step 43840 loss 0.005436686798930168
[2025-03-18 21:34:01,871][model][INFO] - Training step 44000 loss 0.03979066014289856
[2025-03-18 21:35:22,768][model][INFO] - Training step 44160 loss 0.24726246297359467
[2025-03-18 21:36:43,687][model][INFO] - Training step 44320 loss 0.054089274257421494
[2025-03-18 21:38:01,539][model][INFO] - Training step 44480 loss 0.01451800111681223
[2025-03-18 21:39:22,395][model][INFO] - Training step 44640 loss 0.03081647679209709
[2025-03-18 21:40:40,640][model][INFO] - Training step 44800 loss 0.066155806183815
[2025-03-18 21:41:58,829][model][INFO] - Training step 44960 loss 0.03751513361930847
[2025-03-18 21:43:17,725][model][INFO] - Training step 45120 loss 0.25704777240753174
[2025-03-18 21:44:36,015][model][INFO] - Training step 45280 loss 0.07516657561063766
[2025-03-18 21:45:55,188][model][INFO] - Training step 45440 loss 0.2360152304172516
[2025-03-18 21:47:17,024][model][INFO] - Training step 45600 loss 0.0034361565485596657
[2025-03-18 21:48:37,091][model][INFO] - Training step 45760 loss 0.038842663168907166
[2025-03-18 21:49:54,640][model][INFO] - Training step 45920 loss 0.005662163719534874
[2025-03-18 21:51:12,427][model][INFO] - Training step 46080 loss 0.03652440756559372
[2025-03-18 21:52:31,710][model][INFO] - Training step 46240 loss 0.02422601357102394
[2025-03-18 21:53:51,254][model][INFO] - Training step 46400 loss 0.021264873445034027
[2025-03-18 21:55:10,002][model][INFO] - Training step 46560 loss 0.07116782665252686
[2025-03-18 21:56:30,622][model][INFO] - Training step 46720 loss 0.03534850478172302
[2025-03-18 21:57:48,838][model][INFO] - Training step 46880 loss 0.06818869709968567
[2025-03-18 21:59:08,548][model][INFO] - Training step 47040 loss 0.00156846281606704
[2025-03-18 22:00:24,759][model][INFO] - Training step 47200 loss 0.2777724862098694
[2025-03-18 22:01:42,871][model][INFO] - Training step 47360 loss 0.04312999173998833
[2025-03-18 22:03:02,301][model][INFO] - Training step 47520 loss 0.026456261053681374
[2025-03-18 22:04:22,475][model][INFO] - Training step 47680 loss 0.058452386409044266
[2025-03-18 22:05:43,875][model][INFO] - Training step 47840 loss 0.3049883246421814
[2025-03-18 22:07:02,155][model][INFO] - Training step 48000 loss 0.25837063789367676
[2025-03-18 22:08:21,659][model][INFO] - Training step 48160 loss 0.04283231496810913
[2025-03-18 22:09:38,156][model][INFO] - Training step 48320 loss 0.07771508395671844
[2025-03-18 22:10:55,665][model][INFO] - Training step 48480 loss 0.024702129885554314
[2025-03-18 22:12:15,726][model][INFO] - Training step 48640 loss 0.059405285865068436
[2025-03-18 22:13:36,631][model][INFO] - Training step 48800 loss 0.0038986513391137123
[2025-03-18 22:14:55,017][model][INFO] - Training step 48960 loss 0.04855863004922867
[2025-03-18 22:16:16,920][model][INFO] - Training step 49120 loss 0.02728547528386116
[2025-03-18 22:17:39,131][model][INFO] - Training step 49280 loss 0.0306880921125412
[2025-03-18 22:18:57,182][model][INFO] - Training step 49440 loss 0.01735859550535679
[2025-03-18 22:20:15,021][model][INFO] - Training step 49600 loss 0.10122448205947876
[2025-03-18 22:21:33,598][model][INFO] - Training step 49760 loss 0.01034887321293354
[2025-03-18 22:22:52,477][model][INFO] - Training step 49920 loss 0.04443693906068802
[2025-03-18 22:24:10,607][model][INFO] - Training step 50080 loss 0.0073531921952962875
[2025-03-18 22:25:29,856][model][INFO] - Training step 50240 loss 0.018326347693800926
[2025-03-18 22:26:46,989][model][INFO] - Training step 50400 loss 0.03114844486117363
[2025-03-18 22:28:03,450][model][INFO] - Training step 50560 loss 0.020531538873910904
[2025-03-18 22:29:24,833][model][INFO] - Training step 50720 loss 0.03783155977725983
[2025-03-18 22:38:59,074][model][INFO] - Training step 80 loss 0.09278196096420288
[2025-03-18 22:40:18,811][model][INFO] - Training step 240 loss 0.2554040551185608
[2025-03-18 22:41:38,545][model][INFO] - Training step 400 loss 0.007677100133150816
[2025-03-18 22:42:57,786][model][INFO] - Training step 560 loss 0.07340002059936523
[2025-03-18 22:44:14,827][model][INFO] - Training step 720 loss 0.25150617957115173
[2025-03-18 22:45:32,294][model][INFO] - Training step 880 loss 0.04671351611614227
[2025-03-18 22:46:51,698][model][INFO] - Training step 1040 loss 0.020127948373556137
[2025-03-18 22:48:11,371][model][INFO] - Training step 1200 loss 0.2678500711917877
[2025-03-18 22:49:31,755][model][INFO] - Training step 1360 loss 0.04939929395914078
[2025-03-18 22:50:50,266][model][INFO] - Training step 1520 loss 0.2511710524559021
[2025-03-18 22:52:09,154][model][INFO] - Training step 1680 loss 0.03374486416578293
[2025-03-18 22:53:29,943][model][INFO] - Training step 1840 loss 0.11995145678520203
[2025-03-18 22:54:48,038][model][INFO] - Training step 2000 loss 0.2494611144065857
[2025-03-18 22:56:09,971][model][INFO] - Training step 2160 loss 0.03881523758172989
[2025-03-18 22:57:28,401][model][INFO] - Training step 2320 loss 0.26801377534866333
[2025-03-18 22:58:50,807][model][INFO] - Training step 2480 loss 0.048435620963573456
[2025-03-18 23:00:08,777][model][INFO] - Training step 2640 loss 0.03740886226296425
[2025-03-18 23:01:26,252][model][INFO] - Training step 2800 loss 0.05252164602279663
[2025-03-18 23:02:46,679][model][INFO] - Training step 2960 loss 0.02662612870335579
[2025-03-18 23:04:08,208][model][INFO] - Training step 3120 loss 0.009927126578986645
[2025-03-18 23:05:26,915][model][INFO] - Training step 3280 loss 0.10220115631818771
[2025-03-18 23:06:46,436][model][INFO] - Training step 3440 loss 0.22167134284973145
[2025-03-18 23:08:03,857][model][INFO] - Training step 3600 loss 0.10976454615592957
[2025-03-18 23:09:24,001][model][INFO] - Training step 3760 loss 0.00727491918951273
[2025-03-18 23:10:42,380][model][INFO] - Training step 3920 loss 0.030270973220467567
[2025-03-18 23:12:02,570][model][INFO] - Training step 4080 loss 0.24297940731048584
[2025-03-18 23:13:24,121][model][INFO] - Training step 4240 loss 0.04694490507245064
[2025-03-18 23:14:40,235][model][INFO] - Training step 4400 loss 0.09160555899143219
[2025-03-18 23:15:58,901][model][INFO] - Training step 4560 loss 0.003278218675404787
[2025-03-18 23:17:20,466][model][INFO] - Training step 4720 loss 0.2695830464363098
[2025-03-18 23:18:36,172][model][INFO] - Training step 4880 loss 0.01667201705276966
[2025-03-18 23:19:54,649][model][INFO] - Training step 5040 loss 0.30656880140304565
[2025-03-18 23:21:15,694][model][INFO] - Training step 5200 loss 0.03459100425243378
[2025-03-18 23:22:34,223][model][INFO] - Training step 5360 loss 0.06146608665585518
[2025-03-18 23:23:52,373][model][INFO] - Training step 5520 loss 0.2617253065109253
[2025-03-18 23:25:13,413][model][INFO] - Training step 5680 loss 0.04808615893125534
[2025-03-18 23:26:32,331][model][INFO] - Training step 5840 loss 0.04232751578092575
[2025-03-18 23:27:51,351][model][INFO] - Training step 6000 loss 0.054192185401916504
[2025-03-18 23:29:09,247][model][INFO] - Training step 6160 loss 0.030898399651050568
[2025-03-18 23:30:28,589][model][INFO] - Training step 6320 loss 0.012655166909098625
[2025-03-18 23:31:49,782][model][INFO] - Training step 6480 loss 0.05312742292881012
[2025-03-18 23:33:12,030][model][INFO] - Training step 6640 loss 0.20848675072193146
[2025-03-18 23:34:33,985][model][INFO] - Training step 6800 loss 0.27260822057724
[2025-03-18 23:35:53,999][model][INFO] - Training step 6960 loss 0.2676490843296051
[2025-03-18 23:37:13,628][model][INFO] - Training step 7120 loss 0.06263890117406845
[2025-03-18 23:38:35,059][model][INFO] - Training step 7280 loss 0.038216039538383484
[2025-03-18 23:39:54,879][model][INFO] - Training step 7440 loss 0.04180869460105896
[2025-03-18 23:41:13,433][model][INFO] - Training step 7600 loss 0.09561322629451752
[2025-03-18 23:42:31,515][model][INFO] - Training step 7760 loss 0.06512726843357086
[2025-03-18 23:43:52,507][model][INFO] - Training step 7920 loss 0.004978303797543049
[2025-03-18 23:45:11,773][model][INFO] - Training step 8080 loss 0.04599780589342117
[2025-03-18 23:46:33,723][model][INFO] - Training step 8240 loss 0.030184585601091385
[2025-03-18 23:47:51,603][model][INFO] - Training step 8400 loss 0.050509776920080185
[2025-03-18 23:49:11,190][model][INFO] - Training step 8560 loss 0.03146839141845703
[2025-03-18 23:50:29,887][model][INFO] - Training step 8720 loss 0.2514611482620239
[2025-03-18 23:51:49,099][model][INFO] - Training step 8880 loss 0.047061435878276825
[2025-03-18 23:53:07,067][model][INFO] - Training step 9040 loss 0.059895213693380356
[2025-03-18 23:54:24,782][model][INFO] - Training step 9200 loss 0.008941039443016052
[2025-03-18 23:55:43,806][model][INFO] - Training step 9360 loss 0.10611506551504135
[2025-03-18 23:57:01,875][model][INFO] - Training step 9520 loss 0.02182077430188656
[2025-03-18 23:58:24,493][model][INFO] - Training step 9680 loss 0.08999475836753845
[2025-03-18 23:59:42,030][model][INFO] - Training step 9840 loss 0.24943378567695618
[2025-03-19 00:01:02,971][model][INFO] - Training step 10000 loss 0.06523600965738297
[2025-03-19 00:02:24,336][model][INFO] - Training step 10160 loss 0.028214994817972183
[2025-03-19 00:03:40,368][model][INFO] - Training step 10320 loss 0.04170481115579605
[2025-03-19 00:04:58,424][model][INFO] - Training step 10480 loss 0.038266077637672424
[2025-03-19 00:06:14,881][model][INFO] - Training step 10640 loss 0.008006252348423004
[2025-03-19 00:07:34,043][model][INFO] - Training step 10800 loss 0.08665713667869568
[2025-03-19 00:08:54,050][model][INFO] - Training step 10960 loss 0.16426832973957062
[2025-03-19 00:10:10,177][model][INFO] - Training step 11120 loss 0.03358211740851402
[2025-03-19 00:11:28,568][model][INFO] - Training step 11280 loss 0.05662740767002106
[2025-03-19 00:12:46,009][model][INFO] - Training step 11440 loss 0.03155634179711342
[2025-03-19 00:14:01,763][model][INFO] - Training step 11600 loss 0.021762682124972343
[2025-03-19 00:15:21,307][model][INFO] - Training step 11760 loss 0.0550244078040123
[2025-03-19 00:16:38,728][model][INFO] - Training step 11920 loss 0.0027100369334220886
[2025-03-19 00:17:56,293][model][INFO] - Training step 12080 loss 0.05318234860897064
[2025-03-19 00:19:14,996][model][INFO] - Training step 12240 loss 0.248399555683136
[2025-03-19 00:20:32,369][model][INFO] - Training step 12400 loss 0.06548887491226196
[2025-03-19 00:21:53,330][model][INFO] - Training step 12560 loss 0.035581670701503754
[2025-03-19 00:23:12,655][model][INFO] - Training step 12720 loss 0.0606331005692482
[2025-03-19 00:24:32,239][model][INFO] - Training step 12880 loss 0.23238372802734375
[2025-03-19 00:25:52,872][model][INFO] - Training step 13040 loss 0.004452995490282774
[2025-03-19 00:27:12,032][model][INFO] - Training step 13200 loss 0.04423452168703079
[2025-03-19 00:28:29,710][model][INFO] - Training step 13360 loss 0.06157855689525604
[2025-03-19 00:29:48,205][model][INFO] - Training step 13520 loss 0.010203372687101364
[2025-03-19 00:31:08,762][model][INFO] - Training step 13680 loss 0.009849240072071552
[2025-03-19 00:32:29,414][model][INFO] - Training step 13840 loss 0.05278690904378891
[2025-03-19 00:33:47,343][model][INFO] - Training step 14000 loss 0.04400032386183739
[2025-03-19 00:35:04,372][model][INFO] - Training step 14160 loss 0.03285422921180725
[2025-03-19 00:36:23,981][model][INFO] - Training step 14320 loss 0.032355450093746185
[2025-03-19 00:37:42,990][model][INFO] - Training step 14480 loss 0.025922272354364395
[2025-03-19 00:39:06,499][model][INFO] - Training step 14640 loss 0.23812103271484375
[2025-03-19 00:40:23,789][model][INFO] - Training step 14800 loss 0.051065072417259216
[2025-03-19 00:41:43,899][model][INFO] - Training step 14960 loss 0.18939560651779175
[2025-03-19 00:43:03,651][model][INFO] - Training step 15120 loss 0.05064881592988968
[2025-03-19 00:44:23,250][model][INFO] - Training step 15280 loss 0.0427112802863121
[2025-03-19 00:45:43,360][model][INFO] - Training step 15440 loss 0.2550123929977417
[2025-03-19 00:47:03,540][model][INFO] - Training step 15600 loss 0.08966970443725586
[2025-03-19 00:48:23,158][model][INFO] - Training step 15760 loss 0.31825339794158936
[2025-03-19 00:49:43,525][model][INFO] - Training step 15920 loss 0.0601482167840004
[2025-03-19 00:51:02,711][model][INFO] - Training step 16080 loss 0.0740920901298523
[2025-03-19 00:52:20,733][model][INFO] - Training step 16240 loss 0.05393267422914505
[2025-03-19 00:53:39,985][model][INFO] - Training step 16400 loss 0.06306760013103485
[2025-03-19 00:54:59,943][model][INFO] - Training step 16560 loss 0.08362126350402832
[2025-03-19 00:56:16,863][model][INFO] - Training step 16720 loss 0.09412125498056412
[2025-03-19 00:57:37,283][model][INFO] - Training step 16880 loss 0.052687931805849075
[2025-03-19 00:58:55,200][model][INFO] - Training step 17040 loss 0.09261061251163483
[2025-03-19 01:00:15,906][model][INFO] - Training step 17200 loss 0.2927691340446472
[2025-03-19 01:01:34,383][model][INFO] - Training step 17360 loss 0.09206758439540863
[2025-03-19 01:02:54,704][model][INFO] - Training step 17520 loss 0.04334495961666107
[2025-03-19 01:04:18,083][model][INFO] - Training step 17680 loss 0.2597388029098511
[2025-03-19 01:05:35,310][model][INFO] - Training step 17840 loss 0.044306278228759766
[2025-03-19 01:06:55,722][model][INFO] - Training step 18000 loss 0.20950350165367126
[2025-03-19 01:08:15,327][model][INFO] - Training step 18160 loss 0.0018685837276279926
[2025-03-19 01:09:36,875][model][INFO] - Training step 18320 loss 0.04397903010249138
[2025-03-19 01:10:56,048][model][INFO] - Training step 18480 loss 0.2633667290210724
[2025-03-19 01:12:17,256][model][INFO] - Training step 18640 loss 0.0375681146979332
[2025-03-19 01:13:38,471][model][INFO] - Training step 18800 loss 0.02722661942243576
[2025-03-19 01:14:58,225][model][INFO] - Training step 18960 loss 0.04611783102154732
[2025-03-19 01:16:16,542][model][INFO] - Training step 19120 loss 0.23241554200649261
[2025-03-19 01:17:31,802][model][INFO] - Training step 19280 loss 0.03770837187767029
[2025-03-19 01:18:50,822][model][INFO] - Training step 19440 loss 0.08090418577194214
[2025-03-19 01:20:11,508][model][INFO] - Training step 19600 loss 0.25631606578826904
[2025-03-19 01:21:31,919][model][INFO] - Training step 19760 loss 0.027683347463607788
[2025-03-19 01:22:51,458][model][INFO] - Training step 19920 loss 0.05528520792722702
[2025-03-19 01:24:11,187][model][INFO] - Training step 20080 loss 0.2612321972846985
[2025-03-19 01:25:30,611][model][INFO] - Training step 20240 loss 0.03239040821790695
[2025-03-19 01:26:46,528][model][INFO] - Training step 20400 loss 0.1252056211233139
[2025-03-19 01:28:03,693][model][INFO] - Training step 20560 loss 0.001996934413909912
[2025-03-19 01:29:24,036][model][INFO] - Training step 20720 loss 0.06580446660518646
[2025-03-19 01:30:42,049][model][INFO] - Training step 20880 loss 0.03337801247835159
[2025-03-19 01:32:02,089][model][INFO] - Training step 21040 loss 0.16540654003620148
[2025-03-19 01:33:24,093][model][INFO] - Training step 21200 loss 0.0383652001619339
[2025-03-19 01:34:41,323][model][INFO] - Training step 21360 loss 0.0697631984949112
[2025-03-19 01:35:59,571][model][INFO] - Training step 21520 loss 0.04320140182971954
[2025-03-19 01:37:23,879][model][INFO] - Training step 21680 loss 0.036671943962574005
[2025-03-19 01:38:42,771][model][INFO] - Training step 21840 loss 0.034545473754405975
[2025-03-19 01:40:01,935][model][INFO] - Training step 22000 loss 0.03798661753535271
[2025-03-19 01:41:18,776][model][INFO] - Training step 22160 loss 0.05858679860830307
[2025-03-19 01:42:38,670][model][INFO] - Training step 22320 loss 0.1667480617761612
[2025-03-19 01:44:00,680][model][INFO] - Training step 22480 loss 0.255228728055954
[2025-03-19 01:45:19,230][model][INFO] - Training step 22640 loss 0.27513694763183594
[2025-03-19 01:46:37,251][model][INFO] - Training step 22800 loss 0.04360315203666687
[2025-03-19 01:47:55,687][model][INFO] - Training step 22960 loss 0.26235583424568176
[2025-03-19 01:49:14,382][model][INFO] - Training step 23120 loss 0.0347708985209465
[2025-03-19 01:50:34,266][model][INFO] - Training step 23280 loss 0.04995929077267647
[2025-03-19 01:51:53,776][model][INFO] - Training step 23440 loss 0.03242991864681244
[2025-03-19 01:53:13,294][model][INFO] - Training step 23600 loss 0.007205988746136427
[2025-03-19 01:54:28,112][model][INFO] - Training step 23760 loss 0.09147723764181137
[2025-03-19 01:55:47,135][model][INFO] - Training step 23920 loss 0.060086190700531006
[2025-03-19 01:57:06,284][model][INFO] - Training step 24080 loss 0.13945825397968292
[2025-03-19 01:58:23,960][model][INFO] - Training step 24240 loss 0.06947839260101318
[2025-03-19 01:59:45,078][model][INFO] - Training step 24400 loss 0.10958924889564514
[2025-03-19 02:01:04,626][model][INFO] - Training step 24560 loss 0.27526283264160156
[2025-03-19 02:02:21,687][model][INFO] - Training step 24720 loss 0.004974659997969866
[2025-03-19 02:03:41,128][model][INFO] - Training step 24880 loss 0.09149610251188278
[2025-03-19 02:05:00,230][model][INFO] - Training step 25040 loss 0.262834370136261
[2025-03-19 02:06:20,790][model][INFO] - Training step 25200 loss 0.03875645250082016
[2025-03-19 02:07:37,711][model][INFO] - Training step 25360 loss 0.24605602025985718
[2025-03-19 02:08:54,935][model][INFO] - Training step 25520 loss 0.04865401238203049
[2025-03-19 02:10:13,390][model][INFO] - Training step 25680 loss 0.2790113389492035
[2025-03-19 02:11:32,972][model][INFO] - Training step 25840 loss 0.05203050374984741
[2025-03-19 02:12:51,236][model][INFO] - Training step 26000 loss 0.21721604466438293
[2025-03-19 02:14:09,953][model][INFO] - Training step 26160 loss 0.04413846135139465
[2025-03-19 02:15:29,585][model][INFO] - Training step 26320 loss 0.14547821879386902
[2025-03-19 02:16:48,104][model][INFO] - Training step 26480 loss 0.009572126902639866
[2025-03-19 02:18:07,619][model][INFO] - Training step 26640 loss 0.26032698154449463
[2025-03-19 02:19:28,223][model][INFO] - Training step 26800 loss 0.27220842242240906
[2025-03-19 02:20:45,003][model][INFO] - Training step 26960 loss 0.0937299132347107
[2025-03-19 02:22:03,297][model][INFO] - Training step 27120 loss 0.24643105268478394
[2025-03-19 02:23:23,650][model][INFO] - Training step 27280 loss 0.11333277821540833
[2025-03-19 02:24:44,331][model][INFO] - Training step 27440 loss 0.04059485346078873
[2025-03-19 02:26:02,728][model][INFO] - Training step 27600 loss 0.09534241259098053
[2025-03-19 02:27:24,248][model][INFO] - Training step 27760 loss 0.005609243642538786
[2025-03-19 02:28:42,779][model][INFO] - Training step 27920 loss 0.007895221933722496
[2025-03-19 02:30:03,525][model][INFO] - Training step 28080 loss 0.04395882412791252
[2025-03-19 02:31:23,221][model][INFO] - Training step 28240 loss 0.005919639486819506
[2025-03-19 02:32:41,709][model][INFO] - Training step 28400 loss 0.08849374204874039
[2025-03-19 02:34:03,665][model][INFO] - Training step 28560 loss 0.05050203949213028
[2025-03-19 02:35:21,019][model][INFO] - Training step 28720 loss 0.006960861384868622
[2025-03-19 02:36:41,401][model][INFO] - Training step 28880 loss 0.02058272436261177
[2025-03-19 02:38:03,511][model][INFO] - Training step 29040 loss 0.005589197389781475
[2025-03-19 02:39:22,942][model][INFO] - Training step 29200 loss 0.02116279862821102
[2025-03-19 02:40:42,627][model][INFO] - Training step 29360 loss 0.01445244811475277
[2025-03-19 02:42:01,847][model][INFO] - Training step 29520 loss 0.10631687939167023
[2025-03-19 02:43:19,809][model][INFO] - Training step 29680 loss 0.0384577140212059
[2025-03-19 02:44:36,290][model][INFO] - Training step 29840 loss 0.05904684215784073
[2025-03-19 02:45:56,968][model][INFO] - Training step 30000 loss 0.026860840618610382
[2025-03-19 02:47:16,476][model][INFO] - Training step 30160 loss 0.15838724374771118
[2025-03-19 02:48:33,084][model][INFO] - Training step 30320 loss 0.2576999068260193
[2025-03-19 02:49:52,460][model][INFO] - Training step 30480 loss 0.0872630700469017
[2025-03-19 02:51:09,072][model][INFO] - Training step 30640 loss 0.03725839778780937
[2025-03-19 02:52:24,537][model][INFO] - Training step 30800 loss 0.04947558045387268
[2025-03-19 02:53:43,602][model][INFO] - Training step 30960 loss 0.03647855669260025
[2025-03-19 02:55:03,330][model][INFO] - Training step 31120 loss 0.009455634281039238
[2025-03-19 02:56:22,796][model][INFO] - Training step 31280 loss 0.004934950266033411
[2025-03-19 02:57:41,402][model][INFO] - Training step 31440 loss 0.08840787410736084
[2025-03-19 02:58:59,848][model][INFO] - Training step 31600 loss 0.06720784306526184
[2025-03-19 03:00:22,728][model][INFO] - Training step 31760 loss 0.053857505321502686
[2025-03-19 03:01:41,011][model][INFO] - Training step 31920 loss 0.10717428475618362
[2025-03-19 03:02:59,874][model][INFO] - Training step 32080 loss 0.047268494963645935
[2025-03-19 03:04:19,762][model][INFO] - Training step 32240 loss 0.0253621656447649
[2025-03-19 03:05:42,942][model][INFO] - Training step 32400 loss 0.054304368793964386
[2025-03-19 03:07:00,813][model][INFO] - Training step 32560 loss 0.045667149126529694
[2025-03-19 03:08:19,548][model][INFO] - Training step 32720 loss 0.04251639544963837
[2025-03-19 03:09:39,818][model][INFO] - Training step 32880 loss 0.04359479993581772
[2025-03-19 03:11:00,035][model][INFO] - Training step 33040 loss 0.005200947634875774
[2025-03-19 03:12:19,040][model][INFO] - Training step 33200 loss 0.033982060849666595
[2025-03-19 03:13:35,976][model][INFO] - Training step 33360 loss 0.04520502686500549
[2025-03-19 03:14:55,231][model][INFO] - Training step 33520 loss 0.055510833859443665
[2025-03-19 03:16:15,156][model][INFO] - Training step 33680 loss 0.015598983503878117
[2025-03-19 03:17:34,002][model][INFO] - Training step 33840 loss 0.03256489336490631
[2025-03-19 03:18:51,223][model][INFO] - Training step 34000 loss 0.0060739279724657536
[2025-03-19 03:20:14,551][model][INFO] - Training step 34160 loss 0.2702701687812805
[2025-03-19 03:21:36,455][model][INFO] - Training step 34320 loss 0.045807309448719025
[2025-03-19 03:22:56,145][model][INFO] - Training step 34480 loss 0.05216626822948456
[2025-03-19 03:24:16,216][model][INFO] - Training step 34640 loss 0.045278578996658325
[2025-03-19 03:25:37,475][model][INFO] - Training step 34800 loss 0.04678016155958176
[2025-03-19 03:26:55,846][model][INFO] - Training step 34960 loss 0.044521741569042206
[2025-03-19 03:28:13,756][model][INFO] - Training step 35120 loss 0.02157585695385933
[2025-03-19 03:29:33,386][model][INFO] - Training step 35280 loss 0.08461007475852966
[2025-03-19 03:30:53,127][model][INFO] - Training step 35440 loss 0.06960435211658478
[2025-03-19 03:32:11,897][model][INFO] - Training step 35600 loss 0.045497506856918335
[2025-03-19 03:33:29,938][model][INFO] - Training step 35760 loss 0.10085208714008331
[2025-03-19 03:34:46,156][model][INFO] - Training step 35920 loss 0.07383424043655396
[2025-03-19 03:36:06,555][model][INFO] - Training step 36080 loss 0.08381049335002899
[2025-03-19 03:37:25,514][model][INFO] - Training step 36240 loss 0.04280407354235649
[2025-03-19 03:38:43,170][model][INFO] - Training step 36400 loss 0.03346121311187744
[2025-03-19 03:40:03,077][model][INFO] - Training step 36560 loss 0.03055429831147194
[2025-03-19 03:41:25,618][model][INFO] - Training step 36720 loss 0.012571785598993301
[2025-03-19 03:42:45,337][model][INFO] - Training step 36880 loss 0.07276216149330139
[2025-03-19 03:44:04,001][model][INFO] - Training step 37040 loss 0.04365069419145584
[2025-03-19 03:45:23,439][model][INFO] - Training step 37200 loss 0.06576844304800034
[2025-03-19 03:46:41,897][model][INFO] - Training step 37360 loss 0.07200494408607483
[2025-03-19 03:47:59,560][model][INFO] - Training step 37520 loss 0.26281630992889404
[2025-03-19 03:49:17,499][model][INFO] - Training step 37680 loss 0.24162088334560394
[2025-03-19 03:50:36,684][model][INFO] - Training step 37840 loss 0.043204180896282196
[2025-03-19 03:51:57,542][model][INFO] - Training step 38000 loss 0.014203902333974838
[2025-03-19 03:53:15,934][model][INFO] - Training step 38160 loss 0.025725197046995163
[2025-03-19 03:54:36,865][model][INFO] - Training step 38320 loss 0.05031556636095047
[2025-03-19 03:55:54,307][model][INFO] - Training step 38480 loss 0.008282873779535294
[2025-03-19 03:57:14,935][model][INFO] - Training step 38640 loss 0.0432751327753067
[2025-03-19 03:58:33,617][model][INFO] - Training step 38800 loss 0.020534321665763855
[2025-03-19 03:59:56,303][model][INFO] - Training step 38960 loss 0.02861398458480835
[2025-03-19 04:01:15,618][model][INFO] - Training step 39120 loss 0.029713967815041542
[2025-03-19 04:02:33,939][model][INFO] - Training step 39280 loss 0.032573312520980835
[2025-03-19 04:03:53,263][model][INFO] - Training step 39440 loss 0.020816650241613388
[2025-03-19 04:05:14,884][model][INFO] - Training step 39600 loss 0.02963007241487503
[2025-03-19 04:06:34,617][model][INFO] - Training step 39760 loss 0.02678653784096241
[2025-03-19 04:07:55,089][model][INFO] - Training step 39920 loss 0.031107168644666672
[2025-03-19 04:09:15,357][model][INFO] - Training step 40080 loss 0.24865934252738953
[2025-03-19 04:10:36,562][model][INFO] - Training step 40240 loss 0.039709679782390594
[2025-03-19 04:11:56,600][model][INFO] - Training step 40400 loss 0.25359171628952026
[2025-03-19 04:13:17,972][model][INFO] - Training step 40560 loss 0.2698383331298828
[2025-03-19 04:14:38,966][model][INFO] - Training step 40720 loss 0.1024438664317131
[2025-03-19 04:15:57,065][model][INFO] - Training step 40880 loss 0.048101868480443954
[2025-03-19 04:17:17,358][model][INFO] - Training step 41040 loss 0.26009616255760193
[2025-03-19 04:18:36,497][model][INFO] - Training step 41200 loss 0.24481746554374695
[2025-03-19 04:19:57,766][model][INFO] - Training step 41360 loss 0.24424517154693604
[2025-03-19 04:21:15,599][model][INFO] - Training step 41520 loss 0.05330945551395416
[2025-03-19 04:22:36,575][model][INFO] - Training step 41680 loss 0.26223668456077576
[2025-03-19 04:23:55,748][model][INFO] - Training step 41840 loss 0.023318422958254814
[2025-03-19 04:25:16,379][model][INFO] - Training step 42000 loss 0.062144357711076736
[2025-03-19 04:26:33,420][model][INFO] - Training step 42160 loss 0.03793201595544815
[2025-03-19 04:27:54,234][model][INFO] - Training step 42320 loss 0.0395783931016922
[2025-03-19 04:29:11,813][model][INFO] - Training step 42480 loss 0.13480520248413086
[2025-03-19 04:30:31,756][model][INFO] - Training step 42640 loss 0.012139157392084599
[2025-03-19 04:31:51,536][model][INFO] - Training step 42800 loss 0.03282419592142105
[2025-03-19 04:33:08,849][model][INFO] - Training step 42960 loss 0.038600604981184006
[2025-03-19 04:34:28,843][model][INFO] - Training step 43120 loss 0.07068967819213867
[2025-03-19 04:35:47,662][model][INFO] - Training step 43280 loss 0.07439031451940536
[2025-03-19 04:37:08,580][model][INFO] - Training step 43440 loss 0.12637674808502197
[2025-03-19 04:38:28,889][model][INFO] - Training step 43600 loss 0.21465498208999634
[2025-03-19 04:39:49,781][model][INFO] - Training step 43760 loss 0.01063499040901661
[2025-03-19 04:41:12,259][model][INFO] - Training step 43920 loss 0.005982162896543741
[2025-03-19 04:42:30,708][model][INFO] - Training step 44080 loss 0.008357247337698936
[2025-03-19 04:43:54,074][model][INFO] - Training step 44240 loss 0.034256599843502045
[2025-03-19 04:45:17,202][model][INFO] - Training step 44400 loss 0.05259754881262779
[2025-03-19 04:46:34,479][model][INFO] - Training step 44560 loss 0.21423521637916565
[2025-03-19 04:47:53,718][model][INFO] - Training step 44720 loss 0.0316418893635273
[2025-03-19 04:49:12,348][model][INFO] - Training step 44880 loss 0.08011692762374878
[2025-03-19 04:50:32,327][model][INFO] - Training step 45040 loss 0.044206902384757996
[2025-03-19 04:51:47,281][model][INFO] - Training step 45200 loss 0.017688006162643433
[2025-03-19 04:53:06,340][model][INFO] - Training step 45360 loss 0.25579148530960083
[2025-03-19 04:54:25,319][model][INFO] - Training step 45520 loss 0.06892949342727661
[2025-03-19 04:55:46,138][model][INFO] - Training step 45680 loss 0.01958467811346054
[2025-03-19 04:57:06,915][model][INFO] - Training step 45840 loss 0.2629573941230774
[2025-03-19 04:58:24,606][model][INFO] - Training step 46000 loss 0.05320363491773605
[2025-03-19 04:59:46,464][model][INFO] - Training step 46160 loss 0.04964365437626839
[2025-03-19 05:01:06,380][model][INFO] - Training step 46320 loss 0.03148677572607994
[2025-03-19 05:02:23,882][model][INFO] - Training step 46480 loss 0.08641733229160309
[2025-03-19 05:03:42,101][model][INFO] - Training step 46640 loss 0.05801159888505936
[2025-03-19 05:05:01,105][model][INFO] - Training step 46800 loss 0.06461659073829651
[2025-03-19 05:06:22,304][model][INFO] - Training step 46960 loss 0.1799314022064209
[2025-03-19 05:07:39,697][model][INFO] - Training step 47120 loss 0.06563884764909744
[2025-03-19 05:08:58,685][model][INFO] - Training step 47280 loss 0.02270749770104885
[2025-03-19 05:10:19,553][model][INFO] - Training step 47440 loss 0.024619830772280693
[2025-03-19 05:11:40,312][model][INFO] - Training step 47600 loss 0.05110374093055725
[2025-03-19 05:12:58,337][model][INFO] - Training step 47760 loss 0.1690831035375595
[2025-03-19 05:14:18,654][model][INFO] - Training step 47920 loss 0.2518547773361206
[2025-03-19 05:15:38,956][model][INFO] - Training step 48080 loss 0.03822198137640953
[2025-03-19 05:16:58,281][model][INFO] - Training step 48240 loss 0.036462873220443726
[2025-03-19 05:18:14,935][model][INFO] - Training step 48400 loss 0.011852968484163284
[2025-03-19 05:19:32,152][model][INFO] - Training step 48560 loss 0.09365902841091156
[2025-03-19 05:20:51,576][model][INFO] - Training step 48720 loss 0.00588245177641511
[2025-03-19 05:22:11,308][model][INFO] - Training step 48880 loss 0.036068692803382874
[2025-03-19 05:23:32,064][model][INFO] - Training step 49040 loss 0.03537359833717346
[2025-03-19 05:24:52,732][model][INFO] - Training step 49200 loss 0.04931585118174553
[2025-03-19 05:26:10,246][model][INFO] - Training step 49360 loss 0.031602565199136734
[2025-03-19 05:27:30,944][model][INFO] - Training step 49520 loss 0.09077101945877075
[2025-03-19 05:28:49,683][model][INFO] - Training step 49680 loss 0.019284049049019814
[2025-03-19 05:30:09,392][model][INFO] - Training step 49840 loss 0.10318050533533096
[2025-03-19 05:31:27,955][model][INFO] - Training step 50000 loss 0.03236379474401474
[2025-03-19 05:32:47,581][model][INFO] - Training step 50160 loss 0.02450660988688469
[2025-03-19 05:34:04,092][model][INFO] - Training step 50320 loss 0.21937233209609985
[2025-03-19 05:35:22,151][model][INFO] - Training step 50480 loss 0.06973031908273697
[2025-03-19 05:36:38,257][model][INFO] - Training step 50640 loss 0.22483205795288086
[2025-03-19 05:46:04,179][model][INFO] - Training step 0 loss 0.07145814597606659
[2025-03-19 05:47:23,203][model][INFO] - Training step 160 loss 0.020397353917360306
[2025-03-19 05:48:41,902][model][INFO] - Training step 320 loss 0.059214502573013306
[2025-03-19 05:50:02,064][model][INFO] - Training step 480 loss 0.24880388379096985
[2025-03-19 05:51:20,881][model][INFO] - Training step 640 loss 0.027072586119174957
[2025-03-19 05:52:36,479][model][INFO] - Training step 800 loss 0.00323267700150609
[2025-03-19 05:53:57,740][model][INFO] - Training step 960 loss 0.020421728491783142
[2025-03-19 05:55:16,600][model][INFO] - Training step 1120 loss 0.052390165627002716
[2025-03-19 05:56:37,650][model][INFO] - Training step 1280 loss 0.048695724457502365
[2025-03-19 05:57:58,031][model][INFO] - Training step 1440 loss 0.009962165728211403
[2025-03-19 05:59:15,892][model][INFO] - Training step 1600 loss 0.08080215752124786
[2025-03-19 06:00:33,835][model][INFO] - Training step 1760 loss 0.0488511398434639
[2025-03-19 06:01:50,547][model][INFO] - Training step 1920 loss 0.04577130079269409
[2025-03-19 06:03:08,412][model][INFO] - Training step 2080 loss 0.2845504879951477
[2025-03-19 06:04:27,111][model][INFO] - Training step 2240 loss 0.23232737183570862
[2025-03-19 06:05:44,762][model][INFO] - Training step 2400 loss 0.02829655446112156
[2025-03-19 06:07:02,024][model][INFO] - Training step 2560 loss 0.06667134165763855
[2025-03-19 06:08:22,700][model][INFO] - Training step 2720 loss 0.02721559815108776
[2025-03-19 06:09:41,317][model][INFO] - Training step 2880 loss 0.2483941614627838
[2025-03-19 06:10:58,526][model][INFO] - Training step 3040 loss 0.051023490726947784
[2025-03-19 06:12:18,520][model][INFO] - Training step 3200 loss 0.016848502680659294
[2025-03-19 06:13:36,769][model][INFO] - Training step 3360 loss 0.005899257957935333
[2025-03-19 06:14:55,688][model][INFO] - Training step 3520 loss 0.03728706017136574
[2025-03-19 06:16:15,188][model][INFO] - Training step 3680 loss 0.24670915305614471
[2025-03-19 06:17:34,859][model][INFO] - Training step 3840 loss 0.04698590189218521
[2025-03-19 06:18:56,350][model][INFO] - Training step 4000 loss 0.05282379314303398
[2025-03-19 06:20:15,424][model][INFO] - Training step 4160 loss 0.24915599822998047
[2025-03-19 06:21:33,358][model][INFO] - Training step 4320 loss 0.07523728907108307
[2025-03-19 06:22:53,176][model][INFO] - Training step 4480 loss 0.06779493391513824
[2025-03-19 06:24:12,439][model][INFO] - Training step 4640 loss 0.0479150265455246
[2025-03-19 06:25:29,567][model][INFO] - Training step 4800 loss 0.3948354721069336
[2025-03-19 06:26:47,487][model][INFO] - Training step 4960 loss 0.26883798837661743
[2025-03-19 06:28:07,424][model][INFO] - Training step 5120 loss 0.07767695188522339
[2025-03-19 06:29:29,333][model][INFO] - Training step 5280 loss 0.009140444919466972
[2025-03-19 06:30:48,598][model][INFO] - Training step 5440 loss 0.12049596756696701
[2025-03-19 06:32:06,711][model][INFO] - Training step 5600 loss 0.2664465010166168
[2025-03-19 06:33:27,613][model][INFO] - Training step 5760 loss 0.047220006585121155
[2025-03-19 06:34:49,171][model][INFO] - Training step 5920 loss 0.11773985624313354
[2025-03-19 06:36:08,533][model][INFO] - Training step 6080 loss 0.04303686320781708
[2025-03-19 06:37:31,554][model][INFO] - Training step 6240 loss 0.007981621660292149
[2025-03-19 06:38:54,681][model][INFO] - Training step 6400 loss 0.03468244895339012
[2025-03-19 06:40:14,335][model][INFO] - Training step 6560 loss 0.03793469816446304
[2025-03-19 06:41:33,075][model][INFO] - Training step 6720 loss 0.028740376234054565
[2025-03-19 06:42:52,111][model][INFO] - Training step 6880 loss 0.04819432646036148
[2025-03-19 06:44:12,542][model][INFO] - Training step 7040 loss 0.023698003962635994
[2025-03-19 06:45:32,903][model][INFO] - Training step 7200 loss 0.022770963609218597
[2025-03-19 06:46:52,656][model][INFO] - Training step 7360 loss 0.2554524838924408
[2025-03-19 06:48:08,078][model][INFO] - Training step 7520 loss 0.04007067158818245
[2025-03-19 06:49:28,255][model][INFO] - Training step 7680 loss 0.036520637571811676
[2025-03-19 06:50:47,132][model][INFO] - Training step 7840 loss 0.03662481904029846
[2025-03-19 06:52:06,278][model][INFO] - Training step 8000 loss 0.24999898672103882
[2025-03-19 06:53:26,661][model][INFO] - Training step 8160 loss 0.11047127097845078
[2025-03-19 06:54:44,451][model][INFO] - Training step 8320 loss 0.03728760406374931
[2025-03-19 06:56:01,661][model][INFO] - Training step 8480 loss 0.21215680241584778
[2025-03-19 06:57:20,038][model][INFO] - Training step 8640 loss 0.023725997656583786
[2025-03-19 06:58:37,932][model][INFO] - Training step 8800 loss 0.13485507667064667
[2025-03-19 06:59:56,408][model][INFO] - Training step 8960 loss 0.006926056928932667
[2025-03-19 07:01:14,262][model][INFO] - Training step 9120 loss 0.04113594815135002
[2025-03-19 07:02:32,544][model][INFO] - Training step 9280 loss 0.10085868090391159
[2025-03-19 07:03:50,828][model][INFO] - Training step 9440 loss 0.03609270602464676
[2025-03-19 07:05:09,290][model][INFO] - Training step 9600 loss 0.029173001646995544
[2025-03-19 07:06:30,956][model][INFO] - Training step 9760 loss 0.22832803428173065
[2025-03-19 07:07:52,000][model][INFO] - Training step 9920 loss 0.02709292247891426
[2025-03-19 07:09:11,439][model][INFO] - Training step 10080 loss 0.2584805488586426
[2025-03-19 07:10:28,623][model][INFO] - Training step 10240 loss 0.036816515028476715
[2025-03-19 07:11:48,392][model][INFO] - Training step 10400 loss 0.005453945137560368
[2025-03-19 07:13:10,313][model][INFO] - Training step 10560 loss 0.05711805075407028
[2025-03-19 07:14:27,468][model][INFO] - Training step 10720 loss 0.00804494321346283
[2025-03-19 07:15:44,758][model][INFO] - Training step 10880 loss 0.10709161311388016
[2025-03-19 07:17:02,077][model][INFO] - Training step 11040 loss 0.04005863517522812
[2025-03-19 07:18:17,861][model][INFO] - Training step 11200 loss 0.014889436773955822
[2025-03-19 07:19:36,861][model][INFO] - Training step 11360 loss 0.0068221259862184525
[2025-03-19 07:20:55,744][model][INFO] - Training step 11520 loss 0.2431437373161316
[2025-03-19 07:22:16,067][model][INFO] - Training step 11680 loss 0.053277887403964996
[2025-03-19 07:23:34,073][model][INFO] - Training step 11840 loss 0.03364764526486397
[2025-03-19 07:24:53,157][model][INFO] - Training step 12000 loss 0.07672308385372162
[2025-03-19 07:26:11,606][model][INFO] - Training step 12160 loss 0.03532259166240692
[2025-03-19 07:27:31,030][model][INFO] - Training step 12320 loss 0.042077504098415375
[2025-03-19 07:28:51,959][model][INFO] - Training step 12480 loss 0.031084833666682243
[2025-03-19 07:30:11,247][model][INFO] - Training step 12640 loss 0.04601399973034859
[2025-03-19 07:31:29,682][model][INFO] - Training step 12800 loss 0.033285222947597504
[2025-03-19 07:32:51,097][model][INFO] - Training step 12960 loss 0.09042210876941681
[2025-03-19 07:34:10,585][model][INFO] - Training step 13120 loss 0.028245560824871063
[2025-03-19 07:35:28,988][model][INFO] - Training step 13280 loss 0.033690303564071655
[2025-03-19 07:36:48,445][model][INFO] - Training step 13440 loss 0.0680929571390152
[2025-03-19 07:38:07,691][model][INFO] - Training step 13600 loss 0.0314214825630188
[2025-03-19 07:39:27,462][model][INFO] - Training step 13760 loss 0.040708232671022415
[2025-03-19 07:40:47,769][model][INFO] - Training step 13920 loss 0.10284122824668884
[2025-03-19 07:42:05,434][model][INFO] - Training step 14080 loss 0.04288025200366974
[2025-03-19 07:43:22,738][model][INFO] - Training step 14240 loss 0.004631219431757927
[2025-03-19 07:44:42,297][model][INFO] - Training step 14400 loss 0.08604343235492706
[2025-03-19 07:46:03,924][model][INFO] - Training step 14560 loss 0.06179625913500786
[2025-03-19 07:47:22,442][model][INFO] - Training step 14720 loss 0.26919740438461304
[2025-03-19 07:48:42,348][model][INFO] - Training step 14880 loss 0.04480382800102234
[2025-03-19 07:50:00,998][model][INFO] - Training step 15040 loss 0.3433387279510498
[2025-03-19 07:51:18,639][model][INFO] - Training step 15200 loss 0.03591557592153549
[2025-03-19 07:52:37,163][model][INFO] - Training step 15360 loss 0.006481867749243975
[2025-03-19 07:53:57,432][model][INFO] - Training step 15520 loss 0.02556001767516136
[2025-03-19 07:55:14,583][model][INFO] - Training step 15680 loss 0.04361068084836006
[2025-03-19 07:56:35,293][model][INFO] - Training step 15840 loss 0.09285596013069153
[2025-03-19 07:57:52,843][model][INFO] - Training step 16000 loss 0.0202946774661541
[2025-03-19 07:59:09,726][model][INFO] - Training step 16160 loss 0.2443407028913498
[2025-03-19 08:00:26,927][model][INFO] - Training step 16320 loss 0.03830230236053467
[2025-03-19 08:01:42,977][model][INFO] - Training step 16480 loss 0.24531489610671997
[2025-03-19 08:03:03,705][model][INFO] - Training step 16640 loss 0.02678024023771286
[2025-03-19 08:04:19,999][model][INFO] - Training step 16800 loss 0.03774331510066986
[2025-03-19 08:05:40,636][model][INFO] - Training step 16960 loss 0.10298030823469162
[2025-03-19 08:07:00,484][model][INFO] - Training step 17120 loss 0.2582107186317444
[2025-03-19 08:08:20,875][model][INFO] - Training step 17280 loss 3.6494858264923096
[2025-03-19 08:09:39,071][model][INFO] - Training step 17440 loss 0.057145778089761734
[2025-03-19 08:11:00,200][model][INFO] - Training step 17600 loss 0.17024542391300201
[2025-03-19 08:12:16,703][model][INFO] - Training step 17760 loss 0.07884436100721359
[2025-03-19 08:13:31,145][model][INFO] - Training step 17920 loss 0.06559503078460693
[2025-03-19 08:14:49,131][model][INFO] - Training step 18080 loss 0.04164972901344299
[2025-03-19 08:16:05,483][model][INFO] - Training step 18240 loss 0.060892924666404724
[2025-03-19 08:17:28,223][model][INFO] - Training step 18400 loss 0.24173825979232788
[2025-03-19 08:18:48,559][model][INFO] - Training step 18560 loss 0.28593218326568604
[2025-03-19 08:20:09,475][model][INFO] - Training step 18720 loss 0.007983891293406487
[2025-03-19 08:21:25,910][model][INFO] - Training step 18880 loss 0.026306839659810066
[2025-03-19 08:22:42,873][model][INFO] - Training step 19040 loss 0.04165990650653839
[2025-03-19 08:24:02,253][model][INFO] - Training step 19200 loss 0.053803034126758575
[2025-03-19 08:25:19,767][model][INFO] - Training step 19360 loss 0.25195181369781494
[2025-03-19 08:26:42,440][model][INFO] - Training step 19520 loss 0.25532132387161255
[2025-03-19 08:28:03,685][model][INFO] - Training step 19680 loss 0.16613823175430298
[2025-03-19 08:29:20,028][model][INFO] - Training step 19840 loss 0.006422057282179594
[2025-03-19 08:30:38,301][model][INFO] - Training step 20000 loss 0.04889106750488281
[2025-03-19 08:31:59,209][model][INFO] - Training step 20160 loss 0.04303828626871109
[2025-03-19 08:33:20,394][model][INFO] - Training step 20320 loss 0.0036734547466039658
[2025-03-19 08:34:41,227][model][INFO] - Training step 20480 loss 0.0894218236207962
[2025-03-19 08:36:01,547][model][INFO] - Training step 20640 loss 0.03340698406100273
[2025-03-19 08:37:21,687][model][INFO] - Training step 20800 loss 0.10536422580480576
[2025-03-19 08:38:43,033][model][INFO] - Training step 20960 loss 0.11410894244909286
[2025-03-19 08:40:03,362][model][INFO] - Training step 21120 loss 0.008124316111207008
[2025-03-19 08:41:25,514][model][INFO] - Training step 21280 loss 0.0032825719099491835
[2025-03-19 08:42:43,956][model][INFO] - Training step 21440 loss 0.027032848447561264
[2025-03-19 08:44:03,131][model][INFO] - Training step 21600 loss 0.041323333978652954
[2025-03-19 08:45:21,546][model][INFO] - Training step 21760 loss 0.034193262457847595
[2025-03-19 08:46:40,088][model][INFO] - Training step 21920 loss 0.1451091319322586
[2025-03-19 08:47:57,223][model][INFO] - Training step 22080 loss 0.15283265709877014
[2025-03-19 08:49:14,630][model][INFO] - Training step 22240 loss 0.04759875312447548
[2025-03-19 08:50:35,145][model][INFO] - Training step 22400 loss 0.05150128901004791
[2025-03-19 08:51:53,409][model][INFO] - Training step 22560 loss 0.03617994114756584
[2025-03-19 08:53:15,124][model][INFO] - Training step 22720 loss 0.2612442374229431
[2025-03-19 08:54:31,762][model][INFO] - Training step 22880 loss 0.03377580642700195
[2025-03-19 08:55:51,959][model][INFO] - Training step 23040 loss 0.04868288338184357
[2025-03-19 08:57:12,359][model][INFO] - Training step 23200 loss 0.07201585173606873
[2025-03-19 08:58:30,229][model][INFO] - Training step 23360 loss 0.2510678768157959
[2025-03-19 08:59:47,722][model][INFO] - Training step 23520 loss 0.135491281747818
[2025-03-19 09:01:06,404][model][INFO] - Training step 23680 loss 0.048999786376953125
[2025-03-19 09:02:26,699][model][INFO] - Training step 23840 loss 0.030549578368663788
[2025-03-19 09:03:45,592][model][INFO] - Training step 24000 loss 0.03239267319440842
[2025-03-19 09:05:03,959][model][INFO] - Training step 24160 loss 0.04226731136441231
[2025-03-19 09:06:24,999][model][INFO] - Training step 24320 loss 0.030885428190231323
[2025-03-19 09:07:43,362][model][INFO] - Training step 24480 loss 0.013900382444262505
[2025-03-19 09:09:03,959][model][INFO] - Training step 24640 loss 0.2680322527885437
[2025-03-19 09:10:22,347][model][INFO] - Training step 24800 loss 0.0376623272895813
[2025-03-19 09:11:42,942][model][INFO] - Training step 24960 loss 0.03516320139169693
[2025-03-19 09:13:05,969][model][INFO] - Training step 25120 loss 0.0661306083202362
[2025-03-19 09:14:21,025][model][INFO] - Training step 25280 loss 0.02127533033490181
[2025-03-19 09:15:37,319][model][INFO] - Training step 25440 loss 0.024486111477017403
[2025-03-19 09:16:56,996][model][INFO] - Training step 25600 loss 0.07961460202932358
[2025-03-19 09:18:14,171][model][INFO] - Training step 25760 loss 0.03300093859434128
[2025-03-19 09:19:32,679][model][INFO] - Training step 25920 loss 0.06931344419717789
[2025-03-19 09:20:48,361][model][INFO] - Training step 26080 loss 0.18348479270935059
[2025-03-19 09:22:09,834][model][INFO] - Training step 26240 loss 0.1302596777677536
[2025-03-19 09:23:31,347][model][INFO] - Training step 26400 loss 0.031901177018880844
[2025-03-19 09:24:52,157][model][INFO] - Training step 26560 loss 0.008935950696468353
[2025-03-19 09:26:13,128][model][INFO] - Training step 26720 loss 0.24985599517822266
[2025-03-19 09:27:33,508][model][INFO] - Training step 26880 loss 0.03531930595636368
[2025-03-19 09:28:52,362][model][INFO] - Training step 27040 loss 0.006019996479153633
[2025-03-19 09:30:11,073][model][INFO] - Training step 27200 loss 0.03155820816755295
[2025-03-19 09:31:30,595][model][INFO] - Training step 27360 loss 0.051792826503515244
[2025-03-19 09:32:49,509][model][INFO] - Training step 27520 loss 0.0025361268781125546
[2025-03-19 09:34:06,868][model][INFO] - Training step 27680 loss 0.03725116327404976
[2025-03-19 09:35:26,952][model][INFO] - Training step 27840 loss 0.09511066973209381
[2025-03-19 09:36:45,982][model][INFO] - Training step 28000 loss 0.09741702675819397
[2025-03-19 09:38:04,190][model][INFO] - Training step 28160 loss 0.005428347270935774
[2025-03-19 09:39:22,756][model][INFO] - Training step 28320 loss 0.0256792139261961
[2025-03-19 09:40:43,267][model][INFO] - Training step 28480 loss 0.040994592010974884
[2025-03-19 09:42:00,056][model][INFO] - Training step 28640 loss 0.05288390815258026
[2025-03-19 09:43:17,168][model][INFO] - Training step 28800 loss 0.04353469982743263
[2025-03-19 09:44:36,922][model][INFO] - Training step 28960 loss 0.004106208682060242
[2025-03-19 09:45:56,004][model][INFO] - Training step 29120 loss 0.007676802575588226
[2025-03-19 09:47:18,306][model][INFO] - Training step 29280 loss 0.011779386550188065
[2025-03-19 09:48:38,090][model][INFO] - Training step 29440 loss 0.0043993303552269936
[2025-03-19 09:49:59,255][model][INFO] - Training step 29600 loss 0.05458545684814453
[2025-03-19 09:51:16,859][model][INFO] - Training step 29760 loss 0.09171789884567261
[2025-03-19 09:52:40,342][model][INFO] - Training step 29920 loss 0.04368741810321808
[2025-03-19 09:53:56,112][model][INFO] - Training step 30080 loss 0.02665100060403347
[2025-03-19 09:55:16,372][model][INFO] - Training step 30240 loss 0.23618116974830627
[2025-03-19 09:56:36,866][model][INFO] - Training step 30400 loss 0.03837551176548004
[2025-03-19 09:57:55,627][model][INFO] - Training step 30560 loss 0.3596389591693878
[2025-03-19 09:59:12,169][model][INFO] - Training step 30720 loss 0.2175247073173523
[2025-03-19 10:00:27,967][model][INFO] - Training step 30880 loss 0.0716804563999176
[2025-03-19 10:01:47,144][model][INFO] - Training step 31040 loss 0.03441710025072098
[2025-03-19 10:03:05,602][model][INFO] - Training step 31200 loss 0.050310272723436356
[2025-03-19 10:04:25,391][model][INFO] - Training step 31360 loss 0.006182513665407896
[2025-03-19 10:05:43,945][model][INFO] - Training step 31520 loss 0.10729158669710159
[2025-03-19 10:07:02,895][model][INFO] - Training step 31680 loss 0.044537536799907684
[2025-03-19 10:08:22,311][model][INFO] - Training step 31840 loss 0.035524092614650726
[2025-03-19 10:09:40,470][model][INFO] - Training step 32000 loss 0.03630964457988739
[2025-03-19 10:10:57,316][model][INFO] - Training step 32160 loss 0.05679615959525108
[2025-03-19 10:12:17,832][model][INFO] - Training step 32320 loss 0.0050814347341656685
[2025-03-19 10:13:37,683][model][INFO] - Training step 32480 loss 0.04396551847457886
[2025-03-19 10:14:57,112][model][INFO] - Training step 32640 loss 0.039040565490722656
[2025-03-19 10:16:17,643][model][INFO] - Training step 32800 loss 0.005057922098785639
[2025-03-19 10:17:39,780][model][INFO] - Training step 32960 loss 0.043855831027030945
[2025-03-19 10:18:57,495][model][INFO] - Training step 33120 loss 0.1819504201412201
[2025-03-19 10:20:16,945][model][INFO] - Training step 33280 loss 0.13748180866241455
[2025-03-19 10:21:35,173][model][INFO] - Training step 33440 loss 0.2535094916820526
[2025-03-19 10:22:53,710][model][INFO] - Training step 33600 loss 0.0344405323266983
[2025-03-19 10:24:14,291][model][INFO] - Training step 33760 loss 0.03650656342506409
[2025-03-19 10:25:34,915][model][INFO] - Training step 33920 loss 0.23057712614536285
[2025-03-19 10:26:55,334][model][INFO] - Training step 34080 loss 0.2870221734046936
[2025-03-19 10:28:17,201][model][INFO] - Training step 34240 loss 0.035429153591394424
[2025-03-19 10:29:34,768][model][INFO] - Training step 34400 loss 0.24677127599716187
[2025-03-19 10:30:54,295][model][INFO] - Training step 34560 loss 0.049652837216854095
[2025-03-19 10:32:13,220][model][INFO] - Training step 34720 loss 0.030436791479587555
[2025-03-19 10:33:31,331][model][INFO] - Training step 34880 loss 0.07020749151706696
[2025-03-19 10:34:51,573][model][INFO] - Training step 35040 loss 0.04533074423670769
[2025-03-19 10:36:10,951][model][INFO] - Training step 35200 loss 0.030872546136379242
[2025-03-19 10:37:31,139][model][INFO] - Training step 35360 loss 0.24951496720314026
[2025-03-19 10:38:49,816][model][INFO] - Training step 35520 loss 0.04811512678861618
[2025-03-19 10:40:10,190][model][INFO] - Training step 35680 loss 0.05350831151008606
[2025-03-19 10:41:25,978][model][INFO] - Training step 35840 loss 0.027298150584101677
[2025-03-19 10:42:45,346][model][INFO] - Training step 36000 loss 0.04806862398982048
[2025-03-19 10:44:03,075][model][INFO] - Training step 36160 loss 0.03779993951320648
[2025-03-19 10:45:20,488][model][INFO] - Training step 36320 loss 0.023798316717147827
[2025-03-19 10:46:39,287][model][INFO] - Training step 36480 loss 0.05777712166309357
[2025-03-19 10:48:00,857][model][INFO] - Training step 36640 loss 0.003144472138956189
[2025-03-19 10:49:23,081][model][INFO] - Training step 36800 loss 0.05258255824446678
[2025-03-19 10:50:43,330][model][INFO] - Training step 36960 loss 0.10402902215719223
[2025-03-19 10:52:01,558][model][INFO] - Training step 37120 loss 0.024342751130461693
[2025-03-19 10:53:22,865][model][INFO] - Training step 37280 loss 0.05524416267871857
[2025-03-19 10:54:43,419][model][INFO] - Training step 37440 loss 0.2519318163394928
[2025-03-19 10:56:04,042][model][INFO] - Training step 37600 loss 0.04220615699887276
[2025-03-19 10:57:22,666][model][INFO] - Training step 37760 loss 0.03274615854024887
[2025-03-19 10:58:40,296][model][INFO] - Training step 37920 loss 0.010648278519511223
[2025-03-19 10:59:59,385][model][INFO] - Training step 38080 loss 0.03592725470662117
[2025-03-19 11:01:20,045][model][INFO] - Training step 38240 loss 0.04033985733985901
[2025-03-19 11:02:38,356][model][INFO] - Training step 38400 loss 0.04186310991644859
[2025-03-19 11:03:56,721][model][INFO] - Training step 38560 loss 0.03237076848745346
[2025-03-19 11:05:14,640][model][INFO] - Training step 38720 loss 0.23952016234397888
[2025-03-19 11:06:32,799][model][INFO] - Training step 38880 loss 0.04048411548137665
[2025-03-19 11:07:51,960][model][INFO] - Training step 39040 loss 0.02714204601943493
[2025-03-19 11:09:09,027][model][INFO] - Training step 39200 loss 0.007895705290138721
[2025-03-19 11:10:29,428][model][INFO] - Training step 39360 loss 0.036010731011629105
[2025-03-19 11:11:49,951][model][INFO] - Training step 39520 loss 0.2485267072916031
[2025-03-19 11:13:08,697][model][INFO] - Training step 39680 loss 0.04630274698138237
[2025-03-19 11:14:28,617][model][INFO] - Training step 39840 loss 0.04049764946103096
[2025-03-19 11:15:48,523][model][INFO] - Training step 40000 loss 0.03215370699763298
[2025-03-19 11:17:07,409][model][INFO] - Training step 40160 loss 0.04779350757598877
[2025-03-19 11:18:26,870][model][INFO] - Training step 40320 loss 0.27480193972587585
[2025-03-19 11:19:47,270][model][INFO] - Training step 40480 loss 0.05107428878545761
[2025-03-19 11:21:06,320][model][INFO] - Training step 40640 loss 0.006000473164021969
[2025-03-19 11:22:22,465][model][INFO] - Training step 40800 loss 0.005043413955718279
[2025-03-19 11:23:39,801][model][INFO] - Training step 40960 loss 0.24594277143478394
[2025-03-19 11:24:59,323][model][INFO] - Training step 41120 loss 0.0160592682659626
[2025-03-19 11:26:20,660][model][INFO] - Training step 41280 loss 0.2427002638578415
[2025-03-19 11:27:40,446][model][INFO] - Training step 41440 loss 0.25348734855651855
[2025-03-19 11:28:57,273][model][INFO] - Training step 41600 loss 0.19304528832435608
[2025-03-19 11:30:13,489][model][INFO] - Training step 41760 loss 0.005159247666597366
[2025-03-19 11:31:32,070][model][INFO] - Training step 41920 loss 0.0318821519613266
[2025-03-19 11:32:53,033][model][INFO] - Training step 42080 loss 0.015541406348347664
[2025-03-19 11:34:12,636][model][INFO] - Training step 42240 loss 0.04233128949999809
[2025-03-19 11:35:28,728][model][INFO] - Training step 42400 loss 0.2531221807003021
[2025-03-19 11:36:49,704][model][INFO] - Training step 42560 loss 0.08796849846839905
[2025-03-19 11:38:07,394][model][INFO] - Training step 42720 loss 0.2701571583747864
[2025-03-19 11:39:25,218][model][INFO] - Training step 42880 loss 0.07067233324050903
[2025-03-19 11:40:46,157][model][INFO] - Training step 43040 loss 0.03751587122678757
[2025-03-19 11:42:06,162][model][INFO] - Training step 43200 loss 0.040634769946336746
[2025-03-19 11:43:28,755][model][INFO] - Training step 43360 loss 0.2472696602344513
[2025-03-19 11:44:46,122][model][INFO] - Training step 43520 loss 0.03710822016000748
[2025-03-19 11:46:06,470][model][INFO] - Training step 43680 loss 0.02997136488556862
[2025-03-19 11:47:25,856][model][INFO] - Training step 43840 loss 0.03681156411767006
[2025-03-19 11:48:43,361][model][INFO] - Training step 44000 loss 0.08692853152751923
[2025-03-19 11:50:00,666][model][INFO] - Training step 44160 loss 0.048608291894197464
[2025-03-19 11:51:23,948][model][INFO] - Training step 44320 loss 0.0320529043674469
[2025-03-19 11:52:43,232][model][INFO] - Training step 44480 loss 0.2585378587245941
[2025-03-19 11:53:59,921][model][INFO] - Training step 44640 loss 0.0301252081990242
[2025-03-19 11:55:20,509][model][INFO] - Training step 44800 loss 0.04551989957690239
[2025-03-19 11:56:38,022][model][INFO] - Training step 44960 loss 0.24621179699897766
[2025-03-19 11:57:57,611][model][INFO] - Training step 45120 loss 0.053130559623241425
[2025-03-19 11:59:17,910][model][INFO] - Training step 45280 loss 0.02764221839606762
[2025-03-19 12:00:36,715][model][INFO] - Training step 45440 loss 0.014694691635668278
[2025-03-19 12:01:57,996][model][INFO] - Training step 45600 loss 0.23799985647201538
[2025-03-19 12:03:18,375][model][INFO] - Training step 45760 loss 0.09058276563882828
[2025-03-19 12:04:37,004][model][INFO] - Training step 45920 loss 0.03321698680520058
[2025-03-19 12:05:54,844][model][INFO] - Training step 46080 loss 0.02922816202044487
[2025-03-19 12:07:12,658][model][INFO] - Training step 46240 loss 0.08450926840305328
[2025-03-19 12:08:35,244][model][INFO] - Training step 46400 loss 0.2667257487773895
[2025-03-19 12:09:52,528][model][INFO] - Training step 46560 loss 0.024344120174646378
[2025-03-19 12:11:09,965][model][INFO] - Training step 46720 loss 0.031206771731376648
[2025-03-19 12:12:30,689][model][INFO] - Training step 46880 loss 0.0811559334397316
[2025-03-19 12:13:48,431][model][INFO] - Training step 47040 loss 0.0027866000309586525
[2025-03-19 12:15:08,537][model][INFO] - Training step 47200 loss 0.06745786964893341
[2025-03-19 12:16:30,021][model][INFO] - Training step 47360 loss 0.2507939338684082
[2025-03-19 12:17:51,903][model][INFO] - Training step 47520 loss 0.0053839897736907005
[2025-03-19 12:19:09,935][model][INFO] - Training step 47680 loss 0.049222685396671295
[2025-03-19 12:20:28,797][model][INFO] - Training step 47840 loss 0.023068957030773163
[2025-03-19 12:21:48,413][model][INFO] - Training step 48000 loss 0.06593897938728333
[2025-03-19 12:23:09,773][model][INFO] - Training step 48160 loss 0.006288292817771435
[2025-03-19 12:24:27,850][model][INFO] - Training step 48320 loss 0.027617478743195534
[2025-03-19 12:25:45,351][model][INFO] - Training step 48480 loss 0.2489972710609436
[2025-03-19 12:27:04,002][model][INFO] - Training step 48640 loss 0.046994492411613464
[2025-03-19 12:28:25,362][model][INFO] - Training step 48800 loss 0.028785768896341324
[2025-03-19 12:29:46,349][model][INFO] - Training step 48960 loss 0.03125676140189171
[2025-03-19 12:31:04,736][model][INFO] - Training step 49120 loss 0.1002998948097229
[2025-03-19 12:32:22,990][model][INFO] - Training step 49280 loss 0.050409287214279175
[2025-03-19 12:33:43,572][model][INFO] - Training step 49440 loss 0.0034197077620774508
[2025-03-19 12:35:03,640][model][INFO] - Training step 49600 loss 0.035890936851501465
[2025-03-19 12:36:20,232][model][INFO] - Training step 49760 loss 0.059875667095184326
[2025-03-19 12:37:42,866][model][INFO] - Training step 49920 loss 0.24420510232448578
[2025-03-19 12:39:02,041][model][INFO] - Training step 50080 loss 0.09265996515750885
[2025-03-19 12:40:23,809][model][INFO] - Training step 50240 loss 0.0061919777654111385
[2025-03-19 12:41:40,210][model][INFO] - Training step 50400 loss 0.2460574507713318
[2025-03-19 12:43:00,566][model][INFO] - Training step 50560 loss 0.07389433681964874
[2025-03-19 12:44:18,264][model][INFO] - Training step 50720 loss 0.031574077904224396
[2025-03-19 12:53:47,133][model][INFO] - Training step 80 loss 0.09480880945920944
[2025-03-19 12:55:06,865][model][INFO] - Training step 240 loss 0.037423960864543915
[2025-03-19 12:56:28,213][model][INFO] - Training step 400 loss 0.2527712881565094
[2025-03-19 12:57:47,571][model][INFO] - Training step 560 loss 0.03086717054247856
[2025-03-19 12:59:06,516][model][INFO] - Training step 720 loss 0.032901663333177567
[2025-03-19 13:00:27,510][model][INFO] - Training step 880 loss 0.051053088158369064
[2025-03-19 13:01:47,681][model][INFO] - Training step 1040 loss 0.025007015094161034
[2025-03-19 13:03:05,472][model][INFO] - Training step 1200 loss 0.10531029850244522
[2025-03-19 13:04:26,939][model][INFO] - Training step 1360 loss 0.047605760395526886
[2025-03-19 13:05:43,265][model][INFO] - Training step 1520 loss 0.040522586554288864
[2025-03-19 13:07:02,080][model][INFO] - Training step 1680 loss 0.036260247230529785
[2025-03-19 13:08:25,848][model][INFO] - Training step 1840 loss 0.04278703033924103
[2025-03-19 13:09:45,204][model][INFO] - Training step 2000 loss 0.25699299573898315
[2025-03-19 13:11:06,645][model][INFO] - Training step 2160 loss 0.03551372140645981
[2025-03-19 13:12:25,378][model][INFO] - Training step 2320 loss 0.026954174041748047
[2025-03-19 13:13:45,571][model][INFO] - Training step 2480 loss 0.04138801246881485
[2025-03-19 13:15:03,277][model][INFO] - Training step 2640 loss 0.17991232872009277
[2025-03-19 13:16:21,416][model][INFO] - Training step 2800 loss 0.04463380575180054
[2025-03-19 13:17:42,564][model][INFO] - Training step 2960 loss 0.006111033260822296
[2025-03-19 13:19:02,356][model][INFO] - Training step 3120 loss 0.6607181429862976
[2025-03-19 13:20:20,144][model][INFO] - Training step 3280 loss 0.047227732837200165
[2025-03-19 13:21:39,176][model][INFO] - Training step 3440 loss 0.004016946069896221
[2025-03-19 13:22:57,087][model][INFO] - Training step 3600 loss 0.029561573639512062
[2025-03-19 13:24:15,107][model][INFO] - Training step 3760 loss 0.05779234319925308
[2025-03-19 13:25:33,951][model][INFO] - Training step 3920 loss 0.05860596522688866
[2025-03-19 13:26:55,765][model][INFO] - Training step 4080 loss 0.1496923267841339
[2025-03-19 13:28:15,729][model][INFO] - Training step 4240 loss 0.04893779754638672
[2025-03-19 13:29:35,009][model][INFO] - Training step 4400 loss 0.021400857716798782
[2025-03-19 13:30:54,250][model][INFO] - Training step 4560 loss 0.24517402052879333
[2025-03-19 13:32:15,071][model][INFO] - Training step 4720 loss 0.03169569373130798
[2025-03-19 13:33:32,231][model][INFO] - Training step 4880 loss 0.017591990530490875
[2025-03-19 13:34:50,465][model][INFO] - Training step 5040 loss 0.18377354741096497
[2025-03-19 13:36:10,316][model][INFO] - Training step 5200 loss 0.06608806550502777
[2025-03-19 13:37:31,687][model][INFO] - Training step 5360 loss 0.25359830260276794
[2025-03-19 13:38:50,263][model][INFO] - Training step 5520 loss 0.05145876109600067
[2025-03-19 13:40:07,576][model][INFO] - Training step 5680 loss 0.035670019686222076
[2025-03-19 13:41:27,820][model][INFO] - Training step 5840 loss 0.00533154746517539
[2025-03-19 13:42:48,062][model][INFO] - Training step 6000 loss 0.28147774934768677
[2025-03-19 13:44:06,096][model][INFO] - Training step 6160 loss 0.034892357885837555
[2025-03-19 13:45:25,951][model][INFO] - Training step 6320 loss 0.04258684813976288
[2025-03-19 13:46:47,232][model][INFO] - Training step 6480 loss 0.12873174250125885
[2025-03-19 13:48:04,794][model][INFO] - Training step 6640 loss 0.01119067333638668
[2025-03-19 13:49:24,825][model][INFO] - Training step 6800 loss 0.052051931619644165
[2025-03-19 13:50:43,548][model][INFO] - Training step 6960 loss 0.05403157323598862
[2025-03-19 13:52:03,850][model][INFO] - Training step 7120 loss 0.04185057058930397
[2025-03-19 13:53:25,687][model][INFO] - Training step 7280 loss 0.2564448118209839
[2025-03-19 13:54:44,204][model][INFO] - Training step 7440 loss 0.05140027403831482
[2025-03-19 13:56:02,615][model][INFO] - Training step 7600 loss 0.039303168654441833
[2025-03-19 13:57:25,788][model][INFO] - Training step 7760 loss 0.05836398899555206
[2025-03-19 13:58:47,355][model][INFO] - Training step 7920 loss 0.08186904340982437
[2025-03-19 14:00:06,617][model][INFO] - Training step 8080 loss 0.0025029880926012993
[2025-03-19 14:01:23,779][model][INFO] - Training step 8240 loss 0.25447335839271545
[2025-03-19 14:02:45,426][model][INFO] - Training step 8400 loss 0.005200457759201527
[2025-03-19 14:04:05,498][model][INFO] - Training step 8560 loss 0.034663815051317215
[2025-03-19 14:05:26,408][model][INFO] - Training step 8720 loss 0.014068029820919037
[2025-03-19 14:06:44,211][model][INFO] - Training step 8880 loss 0.24650216102600098
[2025-03-19 14:08:05,604][model][INFO] - Training step 9040 loss 0.006154281087219715
[2025-03-19 14:09:21,370][model][INFO] - Training step 9200 loss 0.011103475466370583
[2025-03-19 14:10:41,234][model][INFO] - Training step 9360 loss 0.09904345870018005
[2025-03-19 14:11:59,008][model][INFO] - Training step 9520 loss 0.052127618342638016
[2025-03-19 14:13:18,081][model][INFO] - Training step 9680 loss 0.2649572193622589
[2025-03-19 14:14:36,872][model][INFO] - Training step 9840 loss 0.06493917107582092
[2025-03-19 14:15:56,240][model][INFO] - Training step 10000 loss 0.23922443389892578
[2025-03-19 14:17:15,654][model][INFO] - Training step 10160 loss 0.035826537758111954
[2025-03-19 14:18:32,894][model][INFO] - Training step 10320 loss 0.0655146986246109
[2025-03-19 14:19:51,551][model][INFO] - Training step 10480 loss 0.030759889632463455
[2025-03-19 14:21:10,475][model][INFO] - Training step 10640 loss 0.004203096032142639
[2025-03-19 14:22:26,762][model][INFO] - Training step 10800 loss 0.042093463242053986
[2025-03-19 14:23:44,427][model][INFO] - Training step 10960 loss 0.1027611792087555
[2025-03-19 14:25:03,897][model][INFO] - Training step 11120 loss 0.2721295654773712
[2025-03-19 14:26:22,327][model][INFO] - Training step 11280 loss 0.07138305902481079
[2025-03-19 14:27:40,081][model][INFO] - Training step 11440 loss 0.0393715500831604
[2025-03-19 14:28:58,309][model][INFO] - Training step 11600 loss 0.021731141954660416
[2025-03-19 14:30:16,991][model][INFO] - Training step 11760 loss 0.05858519300818443
[2025-03-19 14:31:32,560][model][INFO] - Training step 11920 loss 0.08146515488624573
[2025-03-19 14:32:51,801][model][INFO] - Training step 12080 loss 0.05300804227590561
[2025-03-19 14:34:08,865][model][INFO] - Training step 12240 loss 0.011824403889477253
[2025-03-19 14:35:25,188][model][INFO] - Training step 12400 loss 0.04433343932032585
[2025-03-19 14:36:43,395][model][INFO] - Training step 12560 loss 0.24933001399040222
[2025-03-19 14:38:06,177][model][INFO] - Training step 12720 loss 0.061232052743434906
[2025-03-19 14:39:25,035][model][INFO] - Training step 12880 loss 0.0824761688709259
[2025-03-19 14:40:41,557][model][INFO] - Training step 13040 loss 0.05733402073383331
[2025-03-19 14:41:59,292][model][INFO] - Training step 13200 loss 0.037636689841747284
[2025-03-19 14:43:17,080][model][INFO] - Training step 13360 loss 0.16867047548294067
[2025-03-19 14:44:34,266][model][INFO] - Training step 13520 loss 0.0069376686587929726
[2025-03-19 14:45:55,848][model][INFO] - Training step 13680 loss 0.06948807835578918
[2025-03-19 14:47:14,436][model][INFO] - Training step 13840 loss 0.2546152174472809
[2025-03-19 14:48:37,342][model][INFO] - Training step 14000 loss 0.016361435875296593
[2025-03-19 14:49:56,645][model][INFO] - Training step 14160 loss 0.04378692805767059
[2025-03-19 14:51:17,873][model][INFO] - Training step 14320 loss 0.025578387081623077
[2025-03-19 14:52:36,093][model][INFO] - Training step 14480 loss 0.2346010059118271
[2025-03-19 14:53:57,212][model][INFO] - Training step 14640 loss 0.024161439388990402
[2025-03-19 14:55:15,502][model][INFO] - Training step 14800 loss 0.05846148729324341
[2025-03-19 14:56:35,521][model][INFO] - Training step 14960 loss 0.0233122780919075
[2025-03-19 14:57:55,183][model][INFO] - Training step 15120 loss 0.02367224544286728
[2025-03-19 14:59:15,011][model][INFO] - Training step 15280 loss 0.03338281810283661
[2025-03-19 15:00:36,652][model][INFO] - Training step 15440 loss 0.033918339759111404
[2025-03-19 15:01:58,035][model][INFO] - Training step 15600 loss 0.09588614851236343
[2025-03-19 15:03:26,202][model][INFO] - Training step 15760 loss 0.04077541455626488
[2025-03-19 15:04:55,411][model][INFO] - Training step 15920 loss 0.0399823933839798
[2025-03-19 15:06:16,174][model][INFO] - Training step 16080 loss 0.004009856376796961
[2025-03-19 15:07:35,914][model][INFO] - Training step 16240 loss 0.03605220839381218
[2025-03-19 15:08:55,748][model][INFO] - Training step 16400 loss 0.2579744756221771
[2025-03-19 15:10:13,619][model][INFO] - Training step 16560 loss 0.04839484393596649
[2025-03-19 15:11:31,229][model][INFO] - Training step 16720 loss 0.043810389935970306
[2025-03-19 15:12:49,928][model][INFO] - Training step 16880 loss 0.2501178979873657
[2025-03-19 15:14:10,036][model][INFO] - Training step 17040 loss 0.31755101680755615
[2025-03-19 15:15:29,217][model][INFO] - Training step 17200 loss 0.07013101130723953
[2025-03-19 15:16:47,535][model][INFO] - Training step 17360 loss 0.2570643126964569
[2025-03-19 15:18:08,543][model][INFO] - Training step 17520 loss 0.06364689767360687
[2025-03-19 15:19:29,030][model][INFO] - Training step 17680 loss 0.03392895311117172
[2025-03-19 15:20:46,137][model][INFO] - Training step 17840 loss 0.05101738125085831
[2025-03-19 15:22:05,616][model][INFO] - Training step 18000 loss 0.008881540037691593
[2025-03-19 15:23:26,478][model][INFO] - Training step 18160 loss 0.006327432580292225
[2025-03-19 15:24:50,035][model][INFO] - Training step 18320 loss 0.14815279841423035
[2025-03-19 15:26:10,588][model][INFO] - Training step 18480 loss 0.029300138354301453
[2025-03-19 15:27:34,394][model][INFO] - Training step 18640 loss 0.24786338210105896
[2025-03-19 15:28:53,189][model][INFO] - Training step 18800 loss 0.02706555463373661
[2025-03-19 15:30:13,489][model][INFO] - Training step 18960 loss 0.04455925524234772
[2025-03-19 15:31:33,258][model][INFO] - Training step 19120 loss 0.20915745198726654
[2025-03-19 15:32:50,708][model][INFO] - Training step 19280 loss 0.03823619335889816
[2025-03-19 15:34:12,118][model][INFO] - Training step 19440 loss 0.00661293463781476
[2025-03-19 15:35:29,472][model][INFO] - Training step 19600 loss 0.0772419199347496
[2025-03-19 15:36:46,437][model][INFO] - Training step 19760 loss 0.08937649428844452
[2025-03-19 15:38:05,416][model][INFO] - Training step 19920 loss 0.2605644762516022
[2025-03-19 15:39:25,375][model][INFO] - Training step 20080 loss 0.26000142097473145
[2025-03-19 15:40:43,916][model][INFO] - Training step 20240 loss 0.03517831861972809
[2025-03-19 15:42:08,793][model][INFO] - Training step 20400 loss 0.00402851402759552
[2025-03-19 15:43:26,370][model][INFO] - Training step 20560 loss 0.030011992901563644
[2025-03-19 15:44:45,868][model][INFO] - Training step 20720 loss 0.09871300309896469
[2025-03-19 15:46:08,028][model][INFO] - Training step 20880 loss 0.2568032741546631
[2025-03-19 15:47:26,226][model][INFO] - Training step 21040 loss 0.0038398061878979206
[2025-03-19 15:48:45,337][model][INFO] - Training step 21200 loss 0.252247154712677
[2025-03-19 15:50:04,899][model][INFO] - Training step 21360 loss 0.2633553743362427
[2025-03-19 15:51:22,255][model][INFO] - Training step 21520 loss 0.08095212280750275
[2025-03-19 15:52:40,170][model][INFO] - Training step 21680 loss 0.05477885901927948
[2025-03-19 15:54:00,607][model][INFO] - Training step 21840 loss 0.035074904561042786
[2025-03-19 15:55:20,265][model][INFO] - Training step 22000 loss 0.0658009946346283
[2025-03-19 15:56:39,865][model][INFO] - Training step 22160 loss 0.03831218183040619
[2025-03-19 15:58:01,427][model][INFO] - Training step 22320 loss 0.25178438425064087
[2025-03-19 15:59:21,558][model][INFO] - Training step 22480 loss 0.24996773898601532
[2025-03-19 16:00:38,469][model][INFO] - Training step 22640 loss 0.03378404676914215
[2025-03-19 16:01:57,186][model][INFO] - Training step 22800 loss 0.2591512203216553
[2025-03-19 16:03:16,449][model][INFO] - Training step 22960 loss 0.024576442316174507
[2025-03-19 16:04:37,997][model][INFO] - Training step 23120 loss 0.25724807381629944
[2025-03-19 16:05:56,937][model][INFO] - Training step 23280 loss 0.04320625588297844
[2025-03-19 16:07:15,211][model][INFO] - Training step 23440 loss 0.03411421924829483
[2025-03-19 16:08:34,922][model][INFO] - Training step 23600 loss 0.3499763011932373
[2025-03-19 16:09:52,100][model][INFO] - Training step 23760 loss 0.03880523890256882
[2025-03-19 16:11:13,183][model][INFO] - Training step 23920 loss 0.05288803204894066
[2025-03-19 16:12:30,677][model][INFO] - Training step 24080 loss 0.11996489763259888
[2025-03-19 16:13:47,298][model][INFO] - Training step 24240 loss 0.03787359222769737
[2025-03-19 16:15:06,062][model][INFO] - Training step 24400 loss 0.024201348423957825
[2025-03-19 16:16:23,973][model][INFO] - Training step 24560 loss 0.04149109870195389
[2025-03-19 16:17:42,659][model][INFO] - Training step 24720 loss 0.04608968645334244
[2025-03-19 16:19:03,390][model][INFO] - Training step 24880 loss 0.036213889718055725
[2025-03-19 16:20:27,702][model][INFO] - Training step 25040 loss 0.03841354325413704
[2025-03-19 16:21:48,553][model][INFO] - Training step 25200 loss 0.13550157845020294
[2025-03-19 16:23:06,348][model][INFO] - Training step 25360 loss 0.03872838616371155
[2025-03-19 16:24:24,090][model][INFO] - Training step 25520 loss 0.041838210076093674
[2025-03-19 16:25:44,960][model][INFO] - Training step 25680 loss 0.025952953845262527
[2025-03-19 16:27:01,799][model][INFO] - Training step 25840 loss 0.060731444507837296
[2025-03-19 16:28:24,492][model][INFO] - Training step 26000 loss 0.2841670513153076
[2025-03-19 16:29:43,307][model][INFO] - Training step 26160 loss 0.032410942018032074
[2025-03-19 16:31:02,185][model][INFO] - Training step 26320 loss 0.05017971247434616
[2025-03-19 16:32:19,499][model][INFO] - Training step 26480 loss 0.06006133183836937
[2025-03-19 16:33:39,005][model][INFO] - Training step 26640 loss 0.03739325702190399
[2025-03-19 16:34:58,062][model][INFO] - Training step 26800 loss 0.031925275921821594
[2025-03-19 16:36:18,439][model][INFO] - Training step 26960 loss 0.028451431542634964
[2025-03-19 16:37:38,307][model][INFO] - Training step 27120 loss 0.023887164890766144
[2025-03-19 16:38:57,373][model][INFO] - Training step 27280 loss 0.20740464329719543
[2025-03-19 16:40:17,729][model][INFO] - Training step 27440 loss 0.05890171229839325
[2025-03-19 16:41:36,446][model][INFO] - Training step 27600 loss 0.08984580636024475
[2025-03-19 16:42:56,001][model][INFO] - Training step 27760 loss 0.03780047968029976
[2025-03-19 16:44:14,831][model][INFO] - Training step 27920 loss 0.018698886036872864
[2025-03-19 16:45:37,129][model][INFO] - Training step 28080 loss 0.06406842172145844
[2025-03-19 16:47:03,451][model][INFO] - Training step 28240 loss 0.21667861938476562
[2025-03-19 16:48:24,995][model][INFO] - Training step 28400 loss 0.05955532193183899
[2025-03-19 16:49:46,801][model][INFO] - Training step 28560 loss 0.2650716006755829
[2025-03-19 16:51:05,134][model][INFO] - Training step 28720 loss 0.01089018490165472
[2025-03-19 16:52:23,732][model][INFO] - Training step 28880 loss 0.04494510963559151
[2025-03-19 16:53:45,584][model][INFO] - Training step 29040 loss 0.24907009303569794
[2025-03-19 16:55:05,521][model][INFO] - Training step 29200 loss 0.006368726957589388
[2025-03-19 16:56:25,185][model][INFO] - Training step 29360 loss 0.012628024443984032
[2025-03-19 16:57:47,781][model][INFO] - Training step 29520 loss 0.006607464514672756
[2025-03-19 16:59:09,398][model][INFO] - Training step 29680 loss 0.06018652021884918
[2025-03-19 17:00:29,324][model][INFO] - Training step 29840 loss 0.2677626609802246
[2025-03-19 17:01:50,376][model][INFO] - Training step 30000 loss 0.25993025302886963
[2025-03-19 17:03:06,419][model][INFO] - Training step 30160 loss 0.24386844038963318
[2025-03-19 17:04:28,262][model][INFO] - Training step 30320 loss 0.026856493204832077
[2025-03-19 17:05:45,690][model][INFO] - Training step 30480 loss 0.025293277576565742
[2025-03-19 17:06:59,958][model][INFO] - Training step 30640 loss 0.031172052025794983
[2025-03-19 17:08:14,514][model][INFO] - Training step 30800 loss 0.005353727377951145
[2025-03-19 17:09:31,539][model][INFO] - Training step 30960 loss 0.08111172914505005
[2025-03-19 17:10:50,044][model][INFO] - Training step 31120 loss 0.030473148450255394
[2025-03-19 17:12:06,996][model][INFO] - Training step 31280 loss 0.03811705857515335
[2025-03-19 17:13:26,898][model][INFO] - Training step 31440 loss 0.04001827910542488
[2025-03-19 17:14:45,151][model][INFO] - Training step 31600 loss 0.0812874436378479
[2025-03-19 17:16:02,550][model][INFO] - Training step 31760 loss 0.3051927983760834
[2025-03-19 17:17:21,970][model][INFO] - Training step 31920 loss 0.00316428835503757
[2025-03-19 17:18:41,659][model][INFO] - Training step 32080 loss 0.12271735072135925
[2025-03-19 17:20:04,760][model][INFO] - Training step 32240 loss 0.002285843715071678
[2025-03-19 17:21:24,064][model][INFO] - Training step 32400 loss 0.049665164202451706
[2025-03-19 17:22:44,753][model][INFO] - Training step 32560 loss 0.04027850925922394
[2025-03-19 17:24:05,200][model][INFO] - Training step 32720 loss 0.02199012227356434
[2025-03-19 17:25:27,224][model][INFO] - Training step 32880 loss 0.06585463881492615
[2025-03-19 17:26:45,649][model][INFO] - Training step 33040 loss 0.031456392258405685
[2025-03-19 17:28:07,189][model][INFO] - Training step 33200 loss 0.03004739060997963
[2025-03-19 17:29:28,729][model][INFO] - Training step 33360 loss 0.25883811712265015
[2025-03-19 17:30:46,867][model][INFO] - Training step 33520 loss 0.09290681779384613
[2025-03-19 17:32:05,005][model][INFO] - Training step 33680 loss 0.018378108739852905
[2025-03-19 17:33:25,330][model][INFO] - Training step 33840 loss 0.04555866867303848
[2025-03-19 17:34:43,146][model][INFO] - Training step 34000 loss 0.009723817929625511
[2025-03-19 17:36:04,659][model][INFO] - Training step 34160 loss 0.15019674599170685
[2025-03-19 17:37:27,763][model][INFO] - Training step 34320 loss 0.025941554456949234
[2025-03-19 17:38:49,486][model][INFO] - Training step 34480 loss 0.006135384552180767
[2025-03-19 17:40:11,560][model][INFO] - Training step 34640 loss 0.03460121154785156
[2025-03-19 17:41:33,282][model][INFO] - Training step 34800 loss 0.028271205723285675
[2025-03-19 17:42:55,748][model][INFO] - Training step 34960 loss 0.03354445844888687
[2025-03-19 17:44:13,815][model][INFO] - Training step 35120 loss 0.012177732773125172
[2025-03-19 17:45:34,200][model][INFO] - Training step 35280 loss 0.034172773361206055
[2025-03-19 17:46:58,535][model][INFO] - Training step 35440 loss 0.026880009099841118
[2025-03-19 17:48:20,079][model][INFO] - Training step 35600 loss 0.04987334460020065
[2025-03-19 17:49:39,864][model][INFO] - Training step 35760 loss 0.25676092505455017
[2025-03-19 17:50:58,353][model][INFO] - Training step 35920 loss 0.03424067795276642
[2025-03-19 17:52:16,694][model][INFO] - Training step 36080 loss 0.06374095380306244
[2025-03-19 17:53:37,315][model][INFO] - Training step 36240 loss 0.02397739328444004
[2025-03-19 17:54:59,802][model][INFO] - Training step 36400 loss 0.2603808045387268
[2025-03-19 17:56:22,862][model][INFO] - Training step 36560 loss 0.03952307999134064
[2025-03-19 17:57:45,318][model][INFO] - Training step 36720 loss 0.239345982670784
[2025-03-19 17:59:04,883][model][INFO] - Training step 36880 loss 0.5529129505157471
[2025-03-19 18:00:26,837][model][INFO] - Training step 37040 loss 0.04323209077119827
[2025-03-19 18:01:48,700][model][INFO] - Training step 37200 loss 0.062160007655620575
[2025-03-19 18:03:10,742][model][INFO] - Training step 37360 loss 0.03201770409941673
[2025-03-19 18:04:31,094][model][INFO] - Training step 37520 loss 0.018578704446554184
[2025-03-19 18:05:47,638][model][INFO] - Training step 37680 loss 0.04626736417412758
[2025-03-19 18:07:06,549][model][INFO] - Training step 37840 loss 0.2699778974056244
[2025-03-19 18:08:23,476][model][INFO] - Training step 38000 loss 0.029437415301799774
[2025-03-19 18:09:41,020][model][INFO] - Training step 38160 loss 0.03193245828151703
[2025-03-19 18:11:00,323][model][INFO] - Training step 38320 loss 0.05226727947592735
[2025-03-19 18:12:18,570][model][INFO] - Training step 38480 loss 0.040266118943691254
[2025-03-19 18:13:37,944][model][INFO] - Training step 38640 loss 0.004023880232125521
[2025-03-19 18:14:57,431][model][INFO] - Training step 38800 loss 0.018276307731866837
[2025-03-19 18:16:16,539][model][INFO] - Training step 38960 loss 0.027678558602929115
[2025-03-19 18:17:33,901][model][INFO] - Training step 39120 loss 0.02830275520682335
[2025-03-19 18:18:52,535][model][INFO] - Training step 39280 loss 0.0594281405210495
[2025-03-19 18:20:12,810][model][INFO] - Training step 39440 loss 0.026635069400072098
[2025-03-19 18:21:30,600][model][INFO] - Training step 39600 loss 0.028454553335905075
[2025-03-19 18:22:50,166][model][INFO] - Training step 39760 loss 0.03712479770183563
[2025-03-19 18:24:14,180][model][INFO] - Training step 39920 loss 0.05105573311448097
[2025-03-19 18:25:35,103][model][INFO] - Training step 40080 loss 0.024256980046629906
[2025-03-19 18:26:55,593][model][INFO] - Training step 40240 loss 0.0071235038340091705
[2025-03-19 18:28:13,525][model][INFO] - Training step 40400 loss 0.21612179279327393
[2025-03-19 18:29:33,107][model][INFO] - Training step 40560 loss 0.0335768386721611
[2025-03-19 18:30:54,706][model][INFO] - Training step 40720 loss 0.25673362612724304
[2025-03-19 18:32:13,847][model][INFO] - Training step 40880 loss 0.2534894347190857
[2025-03-19 18:33:35,734][model][INFO] - Training step 41040 loss 0.0412416085600853
[2025-03-19 18:34:54,543][model][INFO] - Training step 41200 loss 0.020369328558444977
[2025-03-19 18:36:15,636][model][INFO] - Training step 41360 loss 0.08156786859035492
[2025-03-19 18:37:35,304][model][INFO] - Training step 41520 loss 0.06847376376390457
[2025-03-19 18:38:56,473][model][INFO] - Training step 41680 loss 0.2689775228500366
[2025-03-19 18:40:17,703][model][INFO] - Training step 41840 loss 0.2554546296596527
[2025-03-19 18:41:37,166][model][INFO] - Training step 42000 loss 0.15085269510746002
[2025-03-19 18:42:52,591][model][INFO] - Training step 42160 loss 0.25450456142425537
[2025-03-19 18:44:09,697][model][INFO] - Training step 42320 loss 0.023916644975543022
[2025-03-19 18:45:27,149][model][INFO] - Training step 42480 loss 0.03335142508149147
[2025-03-19 18:46:46,479][model][INFO] - Training step 42640 loss 0.08162902295589447
[2025-03-19 18:48:07,557][model][INFO] - Training step 42800 loss 0.065967857837677
[2025-03-19 18:49:25,175][model][INFO] - Training step 42960 loss 0.023052386939525604
[2025-03-19 18:50:45,555][model][INFO] - Training step 43120 loss 0.24961939454078674
[2025-03-19 18:52:05,849][model][INFO] - Training step 43280 loss 0.010607399977743626
[2025-03-19 18:53:27,160][model][INFO] - Training step 43440 loss 0.251766562461853
[2025-03-19 18:54:46,530][model][INFO] - Training step 43600 loss 0.052803173661231995
[2025-03-19 18:56:07,248][model][INFO] - Training step 43760 loss 0.03031930886209011
[2025-03-19 18:57:30,567][model][INFO] - Training step 43920 loss 0.2541217803955078
[2025-03-19 18:58:50,109][model][INFO] - Training step 44080 loss 0.16151775419712067
[2025-03-19 19:00:13,527][model][INFO] - Training step 44240 loss 0.24843081831932068
[2025-03-19 19:01:33,796][model][INFO] - Training step 44400 loss 0.07554739713668823
[2025-03-19 19:02:52,846][model][INFO] - Training step 44560 loss 0.07486552745103836
[2025-03-19 19:04:11,839][model][INFO] - Training step 44720 loss 0.05055369809269905
[2025-03-19 19:05:30,106][model][INFO] - Training step 44880 loss 0.007807799614965916
[2025-03-19 19:06:52,054][model][INFO] - Training step 45040 loss 0.005537158809602261
[2025-03-19 19:08:11,347][model][INFO] - Training step 45200 loss 0.2246943712234497
[2025-03-19 19:09:33,491][model][INFO] - Training step 45360 loss 0.06785055249929428
[2025-03-19 19:10:54,139][model][INFO] - Training step 45520 loss 0.007089892867952585
[2025-03-19 19:12:15,399][model][INFO] - Training step 45680 loss 0.018600061535835266
[2025-03-19 19:13:35,472][model][INFO] - Training step 45840 loss 0.26846206188201904
[2025-03-19 19:14:54,187][model][INFO] - Training step 46000 loss 0.29226863384246826
[2025-03-19 19:16:16,391][model][INFO] - Training step 46160 loss 0.044213324785232544
[2025-03-19 19:17:36,078][model][INFO] - Training step 46320 loss 0.029980050399899483
[2025-03-19 19:18:57,380][model][INFO] - Training step 46480 loss 0.009020596742630005
[2025-03-19 19:20:17,135][model][INFO] - Training step 46640 loss 0.08231775462627411
[2025-03-19 19:21:34,634][model][INFO] - Training step 46800 loss 0.108756422996521
[2025-03-19 19:22:55,005][model][INFO] - Training step 46960 loss 0.05560413375496864
[2025-03-19 19:24:13,047][model][INFO] - Training step 47120 loss 0.07026606798171997
[2025-03-19 19:25:33,041][model][INFO] - Training step 47280 loss 0.025614183396100998
[2025-03-19 19:26:49,819][model][INFO] - Training step 47440 loss 0.027759060263633728
[2025-03-19 19:28:10,971][model][INFO] - Training step 47600 loss 0.07361122965812683
[2025-03-19 19:29:33,622][model][INFO] - Training step 47760 loss 0.050231318920850754
[2025-03-19 19:30:55,129][model][INFO] - Training step 47920 loss 0.1438891589641571
[2025-03-19 19:32:14,021][model][INFO] - Training step 48080 loss 0.08696910738945007
[2025-03-19 19:33:32,294][model][INFO] - Training step 48240 loss 0.11307339370250702
[2025-03-19 19:34:52,624][model][INFO] - Training step 48400 loss 0.08333706855773926
[2025-03-19 19:36:11,103][model][INFO] - Training step 48560 loss 0.25408831238746643
[2025-03-19 19:37:31,329][model][INFO] - Training step 48720 loss 0.25582772493362427
[2025-03-19 19:38:50,152][model][INFO] - Training step 48880 loss 0.020507507026195526
[2025-03-19 19:40:10,033][model][INFO] - Training step 49040 loss 0.03129792958498001
[2025-03-19 19:41:29,230][model][INFO] - Training step 49200 loss 0.020639413967728615
[2025-03-19 19:42:49,094][model][INFO] - Training step 49360 loss 0.05629187822341919
[2025-03-19 19:44:10,730][model][INFO] - Training step 49520 loss 0.008257783949375153
[2025-03-19 19:45:28,029][model][INFO] - Training step 49680 loss 0.017918355762958527
[2025-03-19 19:46:48,483][model][INFO] - Training step 49840 loss 0.2845030725002289
[2025-03-19 19:48:10,331][model][INFO] - Training step 50000 loss 0.0451490581035614
[2025-03-19 19:49:27,243][model][INFO] - Training step 50160 loss 0.005111760459840298
[2025-03-19 19:50:48,179][model][INFO] - Training step 50320 loss 0.24409322440624237
[2025-03-19 19:52:06,973][model][INFO] - Training step 50480 loss 0.013118905015289783
[2025-03-19 19:53:25,976][model][INFO] - Training step 50640 loss 0.005022262688726187
[2025-03-19 20:02:57,981][model][INFO] - Training step 0 loss 0.028145620599389076
[2025-03-19 20:04:18,995][model][INFO] - Training step 160 loss 0.002608377719298005
[2025-03-19 20:05:40,538][model][INFO] - Training step 320 loss 0.036397188901901245
[2025-03-19 20:07:02,040][model][INFO] - Training step 480 loss 0.032938048243522644
[2025-03-19 20:08:21,286][model][INFO] - Training step 640 loss 0.037825100123882294
[2025-03-19 20:09:38,612][model][INFO] - Training step 800 loss 0.005702901631593704
[2025-03-19 20:11:00,589][model][INFO] - Training step 960 loss 0.030035797506570816
[2025-03-19 20:12:16,815][model][INFO] - Training step 1120 loss 0.0539778470993042
[2025-03-19 20:13:35,465][model][INFO] - Training step 1280 loss 0.25700443983078003
[2025-03-19 20:14:51,412][model][INFO] - Training step 1440 loss 0.039758194237947464
[2025-03-19 20:16:08,823][model][INFO] - Training step 1600 loss 0.2666782736778259
[2025-03-19 20:17:27,912][model][INFO] - Training step 1760 loss 0.03735464811325073
[2025-03-19 20:18:45,113][model][INFO] - Training step 1920 loss 0.09624311327934265
[2025-03-19 20:20:03,695][model][INFO] - Training step 2080 loss 0.03524915128946304
[2025-03-19 20:21:23,682][model][INFO] - Training step 2240 loss 0.028611160814762115
[2025-03-19 20:22:40,057][model][INFO] - Training step 2400 loss 0.005906151607632637
[2025-03-19 20:24:00,570][model][INFO] - Training step 2560 loss 0.2799016833305359
[2025-03-19 20:25:19,181][model][INFO] - Training step 2720 loss 0.03270741552114487
[2025-03-19 20:26:39,632][model][INFO] - Training step 2880 loss 0.26273444294929504
[2025-03-19 20:27:57,929][model][INFO] - Training step 3040 loss 0.03550411015748978
[2025-03-19 20:29:15,048][model][INFO] - Training step 3200 loss 0.018049921840429306
[2025-03-19 20:30:34,061][model][INFO] - Training step 3360 loss 0.03026483952999115
[2025-03-19 20:31:52,925][model][INFO] - Training step 3520 loss 0.04847542941570282
[2025-03-19 20:33:12,750][model][INFO] - Training step 3680 loss 0.03317626938223839
[2025-03-19 20:34:29,319][model][INFO] - Training step 3840 loss 0.26112139225006104
[2025-03-19 20:35:49,579][model][INFO] - Training step 4000 loss 0.04184120148420334
[2025-03-19 20:37:08,931][model][INFO] - Training step 4160 loss 0.054943330585956573
[2025-03-19 20:38:29,057][model][INFO] - Training step 4320 loss 0.2020818144083023
[2025-03-19 20:39:48,692][model][INFO] - Training step 4480 loss 0.08974459022283554
[2025-03-19 20:41:08,642][model][INFO] - Training step 4640 loss 0.047257546335458755
[2025-03-19 20:42:27,887][model][INFO] - Training step 4800 loss 0.04943579435348511
[2025-03-19 20:43:44,442][model][INFO] - Training step 4960 loss 0.041468050330877304
[2025-03-19 20:45:03,650][model][INFO] - Training step 5120 loss 0.15951521694660187
[2025-03-19 20:46:21,259][model][INFO] - Training step 5280 loss 0.020316366106271744
[2025-03-19 20:47:40,596][model][INFO] - Training step 5440 loss 0.004270941950380802
[2025-03-19 20:48:58,474][model][INFO] - Training step 5600 loss 0.27138590812683105
[2025-03-19 20:50:20,011][model][INFO] - Training step 5760 loss 0.27259600162506104
[2025-03-19 20:51:38,706][model][INFO] - Training step 5920 loss 0.03199077397584915
[2025-03-19 20:52:56,933][model][INFO] - Training step 6080 loss 0.026755316182971
[2025-03-19 20:54:20,210][model][INFO] - Training step 6240 loss 0.006754786241799593
[2025-03-19 20:55:40,384][model][INFO] - Training step 6400 loss 0.033922724425792694
[2025-03-19 20:57:00,360][model][INFO] - Training step 6560 loss 0.003329592291265726
[2025-03-19 20:58:20,434][model][INFO] - Training step 6720 loss 0.30115675926208496
[2025-03-19 20:59:41,563][model][INFO] - Training step 6880 loss 0.08512670546770096
[2025-03-19 21:01:02,025][model][INFO] - Training step 7040 loss 0.10213984549045563
[2025-03-19 21:02:21,008][model][INFO] - Training step 7200 loss 0.00432401429861784
[2025-03-19 21:03:41,156][model][INFO] - Training step 7360 loss 0.1558719426393509
[2025-03-19 21:05:01,432][model][INFO] - Training step 7520 loss 0.03614061325788498
[2025-03-19 21:06:23,480][model][INFO] - Training step 7680 loss 0.07439468801021576
[2025-03-19 21:07:45,734][model][INFO] - Training step 7840 loss 0.004407557658851147
[2025-03-19 21:09:05,685][model][INFO] - Training step 8000 loss 0.11267590522766113
[2025-03-19 21:10:23,384][model][INFO] - Training step 8160 loss 0.03842860460281372
[2025-03-19 21:11:43,532][model][INFO] - Training step 8320 loss 0.008566299453377724
[2025-03-19 21:13:00,808][model][INFO] - Training step 8480 loss 0.10194498300552368
[2025-03-19 21:14:21,650][model][INFO] - Training step 8640 loss 0.022489331662654877
[2025-03-19 21:15:41,995][model][INFO] - Training step 8800 loss 0.03040134534239769
[2025-03-19 21:17:03,801][model][INFO] - Training step 8960 loss 0.005283773876726627
[2025-03-19 21:18:25,475][model][INFO] - Training step 9120 loss 0.00787617452442646
[2025-03-19 21:19:43,447][model][INFO] - Training step 9280 loss 0.0400504544377327
[2025-03-19 21:20:59,989][model][INFO] - Training step 9440 loss 0.02142939530313015
[2025-03-19 21:22:20,530][model][INFO] - Training step 9600 loss 0.09744857251644135
[2025-03-19 21:23:40,642][model][INFO] - Training step 9760 loss 0.00260898657143116
[2025-03-19 21:25:00,492][model][INFO] - Training step 9920 loss 0.08423852920532227
[2025-03-19 21:26:20,844][model][INFO] - Training step 10080 loss 0.03187570720911026
[2025-03-19 21:27:37,481][model][INFO] - Training step 10240 loss 0.031032433733344078
[2025-03-19 21:28:54,365][model][INFO] - Training step 10400 loss 0.03980272263288498
[2025-03-19 21:30:14,544][model][INFO] - Training step 10560 loss 0.18302157521247864
[2025-03-19 21:31:32,525][model][INFO] - Training step 10720 loss 0.0032177704852074385
[2025-03-19 21:32:53,083][model][INFO] - Training step 10880 loss 0.03919366002082825
[2025-03-19 21:34:13,010][model][INFO] - Training step 11040 loss 0.03616178035736084
[2025-03-19 21:35:32,826][model][INFO] - Training step 11200 loss 0.24780046939849854
[2025-03-19 21:36:49,264][model][INFO] - Training step 11360 loss 0.030650179833173752
[2025-03-19 21:38:07,688][model][INFO] - Training step 11520 loss 0.2502530813217163
[2025-03-19 21:39:26,005][model][INFO] - Training step 11680 loss 0.061937667429447174
[2025-03-19 21:40:45,055][model][INFO] - Training step 11840 loss 0.26607999205589294
[2025-03-19 21:42:03,249][model][INFO] - Training step 12000 loss 0.05502628535032272
[2025-03-19 21:43:26,563][model][INFO] - Training step 12160 loss 0.03809765726327896
[2025-03-19 21:44:45,290][model][INFO] - Training step 12320 loss 0.01437416858971119
[2025-03-19 21:46:05,729][model][INFO] - Training step 12480 loss 0.05949091538786888
[2025-03-19 21:47:24,056][model][INFO] - Training step 12640 loss 0.11346961557865143
[2025-03-19 21:48:39,473][model][INFO] - Training step 12800 loss 0.0355202816426754
[2025-03-19 21:49:58,293][model][INFO] - Training step 12960 loss 0.025134118273854256
[2025-03-19 21:51:17,684][model][INFO] - Training step 13120 loss 0.020331382751464844
[2025-03-19 21:52:37,404][model][INFO] - Training step 13280 loss 0.03700646013021469
[2025-03-19 21:53:58,159][model][INFO] - Training step 13440 loss 0.1020340546965599
[2025-03-19 21:55:19,544][model][INFO] - Training step 13600 loss 0.025989066809415817
[2025-03-19 21:56:40,855][model][INFO] - Training step 13760 loss 0.13594797253608704
[2025-03-19 21:57:59,624][model][INFO] - Training step 13920 loss 0.009655807167291641
[2025-03-19 21:59:19,084][model][INFO] - Training step 14080 loss 0.021619679406285286
[2025-03-19 22:00:38,187][model][INFO] - Training step 14240 loss 0.07490129768848419
[2025-03-19 22:01:56,856][model][INFO] - Training step 14400 loss 0.11486867070198059
[2025-03-19 22:03:16,944][model][INFO] - Training step 14560 loss 0.05197232961654663
[2025-03-19 22:04:36,464][model][INFO] - Training step 14720 loss 0.02867995575070381
[2025-03-19 22:05:56,126][model][INFO] - Training step 14880 loss 0.0045088184997439384
[2025-03-19 22:07:17,055][model][INFO] - Training step 15040 loss 0.04774774610996246
[2025-03-19 22:08:36,678][model][INFO] - Training step 15200 loss 0.02445254847407341
[2025-03-19 22:09:55,099][model][INFO] - Training step 15360 loss 0.08859462291002274
[2025-03-19 22:11:12,970][model][INFO] - Training step 15520 loss 0.023902157321572304
[2025-03-19 22:12:34,378][model][INFO] - Training step 15680 loss 0.04998394101858139
[2025-03-19 22:13:54,029][model][INFO] - Training step 15840 loss 0.05317307263612747
[2025-03-19 22:15:12,827][model][INFO] - Training step 16000 loss 0.024191662669181824
[2025-03-19 22:16:31,543][model][INFO] - Training step 16160 loss 0.03813805431127548
[2025-03-19 22:17:52,489][model][INFO] - Training step 16320 loss 0.22152896225452423
[2025-03-19 22:19:10,757][model][INFO] - Training step 16480 loss 0.026014970615506172
[2025-03-19 22:20:27,856][model][INFO] - Training step 16640 loss 0.03424448519945145
[2025-03-19 22:21:47,748][model][INFO] - Training step 16800 loss 0.01303004752844572
[2025-03-19 22:23:07,468][model][INFO] - Training step 16960 loss 0.09767183661460876
[2025-03-19 22:24:28,751][model][INFO] - Training step 17120 loss 0.005639259237796068
[2025-03-19 22:25:48,170][model][INFO] - Training step 17280 loss 0.8025058507919312
[2025-03-19 22:27:06,115][model][INFO] - Training step 17440 loss 0.040731485933065414
[2025-03-19 22:28:26,543][model][INFO] - Training step 17600 loss 0.041400179266929626
[2025-03-19 22:29:46,171][model][INFO] - Training step 17760 loss 0.05267731845378876
[2025-03-19 22:31:05,266][model][INFO] - Training step 17920 loss 0.012688497081398964
[2025-03-19 22:32:24,606][model][INFO] - Training step 18080 loss 0.04376218467950821
[2025-03-19 22:33:42,770][model][INFO] - Training step 18240 loss 0.26176339387893677
[2025-03-19 22:35:04,622][model][INFO] - Training step 18400 loss 0.07908055186271667
[2025-03-19 22:36:26,678][model][INFO] - Training step 18560 loss 0.027335213497281075
[2025-03-19 22:37:45,910][model][INFO] - Training step 18720 loss 0.24719828367233276
[2025-03-19 22:39:04,087][model][INFO] - Training step 18880 loss 0.0276314839720726
[2025-03-19 22:40:20,170][model][INFO] - Training step 19040 loss 0.19914686679840088
[2025-03-19 22:41:38,902][model][INFO] - Training step 19200 loss 0.228562593460083
[2025-03-19 22:42:54,285][model][INFO] - Training step 19360 loss 0.09029269218444824
[2025-03-19 22:44:16,403][model][INFO] - Training step 19520 loss 0.032535284757614136
[2025-03-19 22:45:37,697][model][INFO] - Training step 19680 loss 0.03635239228606224
[2025-03-19 22:46:55,935][model][INFO] - Training step 19840 loss 0.04913310334086418
[2025-03-19 22:48:15,774][model][INFO] - Training step 20000 loss 0.004818075802177191
[2025-03-19 22:49:37,594][model][INFO] - Training step 20160 loss 0.029828732833266258
[2025-03-19 22:50:57,056][model][INFO] - Training step 20320 loss 0.03922253102064133
[2025-03-19 22:52:15,014][model][INFO] - Training step 20480 loss 0.17518094182014465
[2025-03-19 22:53:35,293][model][INFO] - Training step 20640 loss 0.08287543058395386
[2025-03-19 22:54:55,398][model][INFO] - Training step 20800 loss 0.23758499324321747
[2025-03-19 22:56:12,785][model][INFO] - Training step 20960 loss 0.04112411290407181
[2025-03-19 22:57:35,733][model][INFO] - Training step 21120 loss 0.5659379959106445
[2025-03-19 22:58:54,153][model][INFO] - Training step 21280 loss 0.019795145839452744
[2025-03-19 23:00:17,925][model][INFO] - Training step 21440 loss 0.02314232848584652
[2025-03-19 23:01:36,655][model][INFO] - Training step 21600 loss 0.15284079313278198
[2025-03-19 23:02:56,721][model][INFO] - Training step 21760 loss 0.0034660124219954014
[2025-03-19 23:04:18,478][model][INFO] - Training step 21920 loss 0.24830074608325958
[2025-03-19 23:05:37,291][model][INFO] - Training step 22080 loss 0.014907771721482277
[2025-03-19 23:06:58,646][model][INFO] - Training step 22240 loss 0.07197174429893494
[2025-03-19 23:08:16,005][model][INFO] - Training step 22400 loss 0.04996723681688309
[2025-03-19 23:09:35,993][model][INFO] - Training step 22560 loss 0.06078632175922394
[2025-03-19 23:10:56,366][model][INFO] - Training step 22720 loss 0.2826383709907532
[2025-03-19 23:12:13,822][model][INFO] - Training step 22880 loss 0.2624015212059021
[2025-03-19 23:13:34,719][model][INFO] - Training step 23040 loss 0.05520719662308693
[2025-03-19 23:14:54,592][model][INFO] - Training step 23200 loss 0.17014314234256744
[2025-03-19 23:16:15,731][model][INFO] - Training step 23360 loss 0.039090171456336975
[2025-03-19 23:17:34,474][model][INFO] - Training step 23520 loss 0.057374533265829086
[2025-03-19 23:18:51,637][model][INFO] - Training step 23680 loss 0.03299260139465332
[2025-03-19 23:20:11,671][model][INFO] - Training step 23840 loss 0.006720650475472212
[2025-03-19 23:21:30,604][model][INFO] - Training step 24000 loss 0.026439785957336426
[2025-03-19 23:22:48,269][model][INFO] - Training step 24160 loss 0.03815637156367302
[2025-03-19 23:24:06,646][model][INFO] - Training step 24320 loss 0.009586695581674576
[2025-03-19 23:25:26,709][model][INFO] - Training step 24480 loss 0.01483015064150095
[2025-03-19 23:26:45,138][model][INFO] - Training step 24640 loss 0.24711674451828003
[2025-03-19 23:28:04,504][model][INFO] - Training step 24800 loss 0.08217000961303711
[2025-03-19 23:29:25,135][model][INFO] - Training step 24960 loss 0.03379703685641289
[2025-03-19 23:30:42,229][model][INFO] - Training step 25120 loss 0.06686244904994965
[2025-03-19 23:31:58,882][model][INFO] - Training step 25280 loss 0.2663177251815796
[2025-03-19 23:33:18,369][model][INFO] - Training step 25440 loss 0.03044382482767105
[2025-03-19 23:34:37,327][model][INFO] - Training step 25600 loss 0.12737387418746948
[2025-03-19 23:35:53,663][model][INFO] - Training step 25760 loss 0.03363474830985069
[2025-03-19 23:37:14,067][model][INFO] - Training step 25920 loss 0.03130480647087097
[2025-03-19 23:38:32,534][model][INFO] - Training step 26080 loss 0.045824356377124786
[2025-03-19 23:39:50,825][model][INFO] - Training step 26240 loss 0.0989784300327301
[2025-03-19 23:41:10,639][model][INFO] - Training step 26400 loss 0.03182438760995865
[2025-03-19 23:42:32,497][model][INFO] - Training step 26560 loss 0.04900722950696945
[2025-03-19 23:43:48,783][model][INFO] - Training step 26720 loss 0.003921503201127052
[2025-03-19 23:45:07,385][model][INFO] - Training step 26880 loss 0.05054119974374771
[2025-03-19 23:46:25,402][model][INFO] - Training step 27040 loss 0.26075780391693115
[2025-03-19 23:47:48,034][model][INFO] - Training step 27200 loss 0.02108762226998806
[2025-03-19 23:49:07,815][model][INFO] - Training step 27360 loss 0.12695151567459106
[2025-03-19 23:50:24,901][model][INFO] - Training step 27520 loss 0.03876610845327377
[2025-03-19 23:51:43,694][model][INFO] - Training step 27680 loss 0.02242596261203289
[2025-03-19 23:53:04,381][model][INFO] - Training step 27840 loss 0.030701130628585815
[2025-03-19 23:54:22,762][model][INFO] - Training step 28000 loss 0.11972696334123611
[2025-03-19 23:55:40,681][model][INFO] - Training step 28160 loss 0.020146645605564117
[2025-03-19 23:56:58,569][model][INFO] - Training step 28320 loss 0.24660339951515198
[2025-03-19 23:58:17,242][model][INFO] - Training step 28480 loss 0.04990512505173683
[2025-03-19 23:59:37,441][model][INFO] - Training step 28640 loss 0.0021400630939751863
[2025-03-20 00:00:53,430][model][INFO] - Training step 28800 loss 0.08641640096902847
[2025-03-20 00:02:13,824][model][INFO] - Training step 28960 loss 0.25672316551208496
[2025-03-20 00:03:32,069][model][INFO] - Training step 29120 loss 0.007187534123659134
[2025-03-20 00:04:53,669][model][INFO] - Training step 29280 loss 0.1028091087937355
[2025-03-20 00:06:12,243][model][INFO] - Training step 29440 loss 0.09893016517162323
[2025-03-20 00:07:32,996][model][INFO] - Training step 29600 loss 0.27429795265197754
[2025-03-20 00:08:56,860][model][INFO] - Training step 29760 loss 0.2012300342321396
[2025-03-20 00:10:19,075][model][INFO] - Training step 29920 loss 0.005291863344609737
[2025-03-20 00:11:38,541][model][INFO] - Training step 30080 loss 0.25251317024230957
[2025-03-20 00:12:57,050][model][INFO] - Training step 30240 loss 0.007484145928174257
[2025-03-20 00:14:16,888][model][INFO] - Training step 30400 loss 0.08439742028713226
[2025-03-20 00:15:38,683][model][INFO] - Training step 30560 loss 0.061116043478250504
[2025-03-20 00:16:53,950][model][INFO] - Training step 30720 loss 0.01700010523200035
[2025-03-20 00:18:11,016][model][INFO] - Training step 30880 loss 0.04592142999172211
[2025-03-20 00:19:34,163][model][INFO] - Training step 31040 loss 0.24942481517791748
[2025-03-20 00:20:50,526][model][INFO] - Training step 31200 loss 0.03236496075987816
[2025-03-20 00:22:08,163][model][INFO] - Training step 31360 loss 0.07939918339252472
[2025-03-20 00:23:25,924][model][INFO] - Training step 31520 loss 0.09789542853832245
[2025-03-20 00:24:45,332][model][INFO] - Training step 31680 loss 0.03689255192875862
[2025-03-20 00:26:03,555][model][INFO] - Training step 31840 loss 0.015206491574645042
[2025-03-20 00:27:24,500][model][INFO] - Training step 32000 loss 0.24769249558448792
[2025-03-20 00:28:44,122][model][INFO] - Training step 32160 loss 0.04079989343881607
[2025-03-20 00:30:03,590][model][INFO] - Training step 32320 loss 0.024519646540284157
[2025-03-20 00:31:24,526][model][INFO] - Training step 32480 loss 0.02297312393784523
[2025-03-20 00:32:47,146][model][INFO] - Training step 32640 loss 0.03735373169183731
[2025-03-20 00:34:05,180][model][INFO] - Training step 32800 loss 0.026487264782190323
[2025-03-20 00:35:29,070][model][INFO] - Training step 32960 loss 0.005241280887275934
[2025-03-20 00:36:48,744][model][INFO] - Training step 33120 loss 0.05656735599040985
[2025-03-20 00:38:07,274][model][INFO] - Training step 33280 loss 0.2098366916179657
[2025-03-20 00:39:29,679][model][INFO] - Training step 33440 loss 0.037917520850896835
[2025-03-20 00:40:47,443][model][INFO] - Training step 33600 loss 0.03638482093811035
[2025-03-20 00:42:09,017][model][INFO] - Training step 33760 loss 0.03569341450929642
[2025-03-20 00:43:27,965][model][INFO] - Training step 33920 loss 0.0311910267919302
[2025-03-20 00:44:47,073][model][INFO] - Training step 34080 loss 0.005721419584006071
[2025-03-20 00:46:06,091][model][INFO] - Training step 34240 loss 0.2393491566181183
[2025-03-20 00:47:27,377][model][INFO] - Training step 34400 loss 0.004714671988040209
[2025-03-20 00:48:50,900][model][INFO] - Training step 34560 loss 0.09341845661401749
[2025-03-20 00:50:12,763][model][INFO] - Training step 34720 loss 0.10380201041698456
[2025-03-20 00:51:31,615][model][INFO] - Training step 34880 loss 0.006568910088390112
[2025-03-20 00:52:53,975][model][INFO] - Training step 35040 loss 0.06699354946613312
[2025-03-20 00:54:13,252][model][INFO] - Training step 35200 loss 0.018082652240991592
[2025-03-20 00:55:33,881][model][INFO] - Training step 35360 loss 0.20464570820331573
[2025-03-20 00:56:54,181][model][INFO] - Training step 35520 loss 0.27902281284332275
[2025-03-20 00:58:13,084][model][INFO] - Training step 35680 loss 0.26046261191368103
[2025-03-20 00:59:30,920][model][INFO] - Training step 35840 loss 0.22680170834064484
[2025-03-20 01:00:49,550][model][INFO] - Training step 36000 loss 0.029639244079589844
[2025-03-20 01:02:10,080][model][INFO] - Training step 36160 loss 0.1692807674407959
[2025-03-20 01:03:28,885][model][INFO] - Training step 36320 loss 0.01899399235844612
[2025-03-20 01:04:50,055][model][INFO] - Training step 36480 loss 0.0966368019580841
[2025-03-20 01:06:08,612][model][INFO] - Training step 36640 loss 0.03507956117391586
[2025-03-20 01:07:25,626][model][INFO] - Training step 36800 loss 0.03171318769454956
[2025-03-20 01:08:46,516][model][INFO] - Training step 36960 loss 0.02159147337079048
[2025-03-20 01:10:07,542][model][INFO] - Training step 37120 loss 0.02517930418252945
[2025-03-20 01:11:30,511][model][INFO] - Training step 37280 loss 0.118336983025074
[2025-03-20 01:12:46,910][model][INFO] - Training step 37440 loss 0.009960079565644264
[2025-03-20 01:14:04,156][model][INFO] - Training step 37600 loss 0.05596735700964928
[2025-03-20 01:15:24,282][model][INFO] - Training step 37760 loss 0.26196274161338806
[2025-03-20 01:16:45,263][model][INFO] - Training step 37920 loss 0.023270227015018463
[2025-03-20 01:18:03,498][model][INFO] - Training step 38080 loss 0.03428585082292557
[2025-03-20 01:19:22,906][model][INFO] - Training step 38240 loss 0.2472081184387207
[2025-03-20 01:20:43,083][model][INFO] - Training step 38400 loss 0.002947990782558918
[2025-03-20 01:22:00,710][model][INFO] - Training step 38560 loss 0.030555564910173416
[2025-03-20 01:23:21,097][model][INFO] - Training step 38720 loss 0.043553225696086884
[2025-03-20 01:24:40,272][model][INFO] - Training step 38880 loss 0.0320155993103981
[2025-03-20 01:26:00,845][model][INFO] - Training step 39040 loss 0.021817347034811974
[2025-03-20 01:27:19,318][model][INFO] - Training step 39200 loss 0.02893190085887909
[2025-03-20 01:28:42,294][model][INFO] - Training step 39360 loss 0.007424233481287956
[2025-03-20 01:29:59,828][model][INFO] - Training step 39520 loss 0.008963033556938171
[2025-03-20 01:31:18,696][model][INFO] - Training step 39680 loss 0.02106432616710663
[2025-03-20 01:32:37,444][model][INFO] - Training step 39840 loss 0.2537485957145691
[2025-03-20 01:33:56,356][model][INFO] - Training step 40000 loss 0.05368901044130325
[2025-03-20 01:35:16,948][model][INFO] - Training step 40160 loss 0.03586937114596367
[2025-03-20 01:36:35,040][model][INFO] - Training step 40320 loss 0.038012709468603134
[2025-03-20 01:37:57,860][model][INFO] - Training step 40480 loss 0.11523087322711945
[2025-03-20 01:39:15,077][model][INFO] - Training step 40640 loss 0.034872252494096756
[2025-03-20 01:40:31,514][model][INFO] - Training step 40800 loss 0.012896761298179626
[2025-03-20 01:41:48,560][model][INFO] - Training step 40960 loss 0.07547342777252197
[2025-03-20 01:43:08,507][model][INFO] - Training step 41120 loss 0.013917472213506699
[2025-03-20 01:44:30,624][model][INFO] - Training step 41280 loss 0.03345838189125061
[2025-03-20 01:45:50,476][model][INFO] - Training step 41440 loss 0.06952698528766632
[2025-03-20 01:47:08,386][model][INFO] - Training step 41600 loss 0.03542177379131317
[2025-03-20 01:48:29,511][model][INFO] - Training step 41760 loss 0.036216624081134796
[2025-03-20 01:49:50,741][model][INFO] - Training step 41920 loss 0.030553236603736877
[2025-03-20 01:51:11,363][model][INFO] - Training step 42080 loss 0.01290735974907875
[2025-03-20 01:52:28,643][model][INFO] - Training step 42240 loss 0.02915738895535469
[2025-03-20 01:53:46,097][model][INFO] - Training step 42400 loss 0.04086112231016159
[2025-03-20 01:55:08,238][model][INFO] - Training step 42560 loss 0.054624930024147034
[2025-03-20 01:56:29,061][model][INFO] - Training step 42720 loss 0.04936414211988449
[2025-03-20 01:57:46,148][model][INFO] - Training step 42880 loss 0.055893801152706146
[2025-03-20 01:59:04,877][model][INFO] - Training step 43040 loss 0.028635980561375618
[2025-03-20 02:00:23,878][model][INFO] - Training step 43200 loss 0.041559550911188126
[2025-03-20 02:01:46,394][model][INFO] - Training step 43360 loss 0.04869109392166138
[2025-03-20 02:03:04,383][model][INFO] - Training step 43520 loss 0.03040822222828865
[2025-03-20 02:04:22,742][model][INFO] - Training step 43680 loss 0.05219221115112305
[2025-03-20 02:05:44,097][model][INFO] - Training step 43840 loss 0.004870792385190725
[2025-03-20 02:06:59,649][model][INFO] - Training step 44000 loss 0.08713079988956451
[2025-03-20 02:08:23,375][model][INFO] - Training step 44160 loss 0.0347200445830822
[2025-03-20 02:09:42,325][model][INFO] - Training step 44320 loss 0.027622871100902557
[2025-03-20 02:11:01,357][model][INFO] - Training step 44480 loss 0.013808336108922958
[2025-03-20 02:12:21,688][model][INFO] - Training step 44640 loss 0.01141173206269741
[2025-03-20 02:13:43,916][model][INFO] - Training step 44800 loss 0.0436478853225708
[2025-03-20 02:15:01,577][model][INFO] - Training step 44960 loss 0.03640236333012581
[2025-03-20 02:16:19,236][model][INFO] - Training step 45120 loss 0.041302524507045746
[2025-03-20 02:17:41,925][model][INFO] - Training step 45280 loss 0.039462611079216
[2025-03-20 02:18:59,370][model][INFO] - Training step 45440 loss 0.018198218196630478
[2025-03-20 02:20:18,496][model][INFO] - Training step 45600 loss 0.005292852874845266
[2025-03-20 02:21:38,169][model][INFO] - Training step 45760 loss 0.08759982883930206
[2025-03-20 02:22:58,074][model][INFO] - Training step 45920 loss 0.03882260620594025
[2025-03-20 02:24:19,454][model][INFO] - Training step 46080 loss 0.032505616545677185
[2025-03-20 02:25:40,446][model][INFO] - Training step 46240 loss 0.00798555463552475
[2025-03-20 02:27:01,198][model][INFO] - Training step 46400 loss 0.018054962158203125
[2025-03-20 02:28:19,636][model][INFO] - Training step 46560 loss 0.008651724085211754
[2025-03-20 02:29:37,993][model][INFO] - Training step 46720 loss 0.02896103262901306
[2025-03-20 02:30:58,324][model][INFO] - Training step 46880 loss 0.04272912070155144
[2025-03-20 02:32:15,762][model][INFO] - Training step 47040 loss 0.09744497388601303
[2025-03-20 02:33:33,290][model][INFO] - Training step 47200 loss 0.016258083283901215
[2025-03-20 02:34:52,622][model][INFO] - Training step 47360 loss 0.04007343947887421
[2025-03-20 02:36:12,847][model][INFO] - Training step 47520 loss 0.02055804803967476
[2025-03-20 02:37:34,489][model][INFO] - Training step 47680 loss 0.2015170007944107
[2025-03-20 02:38:54,034][model][INFO] - Training step 47840 loss 0.04175252467393875
[2025-03-20 02:40:13,437][model][INFO] - Training step 48000 loss 0.06128987297415733
[2025-03-20 02:41:33,290][model][INFO] - Training step 48160 loss 0.01309528574347496
[2025-03-20 02:42:52,117][model][INFO] - Training step 48320 loss 0.13814961910247803
[2025-03-20 02:44:09,682][model][INFO] - Training step 48480 loss 0.053954944014549255
[2025-03-20 02:45:29,944][model][INFO] - Training step 48640 loss 0.038352083414793015
[2025-03-20 02:46:48,396][model][INFO] - Training step 48800 loss 0.2533377408981323
[2025-03-20 02:48:07,628][model][INFO] - Training step 48960 loss 0.03004920668900013
[2025-03-20 02:49:28,368][model][INFO] - Training step 49120 loss 0.26095500588417053
[2025-03-20 02:50:48,234][model][INFO] - Training step 49280 loss 0.2542080879211426
[2025-03-20 02:52:06,575][model][INFO] - Training step 49440 loss 0.03165345638990402
[2025-03-20 02:53:26,368][model][INFO] - Training step 49600 loss 0.004505740012973547
[2025-03-20 02:54:46,753][model][INFO] - Training step 49760 loss 0.263261616230011
[2025-03-20 02:56:05,723][model][INFO] - Training step 49920 loss 0.06527471542358398
[2025-03-20 02:57:29,546][model][INFO] - Training step 50080 loss 0.09858843684196472
[2025-03-20 02:58:49,105][model][INFO] - Training step 50240 loss 0.031018750742077827
[2025-03-20 03:00:06,419][model][INFO] - Training step 50400 loss 0.04254555702209473
[2025-03-20 03:01:25,999][model][INFO] - Training step 50560 loss 0.2483527809381485
[2025-03-20 03:02:43,088][model][INFO] - Training step 50720 loss 0.036705777049064636
[2025-03-20 03:12:14,469][model][INFO] - Training step 80 loss 0.10023841261863708
[2025-03-20 03:13:35,254][model][INFO] - Training step 240 loss 0.060381561517715454
[2025-03-20 03:14:54,232][model][INFO] - Training step 400 loss 0.049480125308036804
[2025-03-20 03:16:10,707][model][INFO] - Training step 560 loss 0.026916008442640305
[2025-03-20 03:17:30,992][model][INFO] - Training step 720 loss 0.03369462862610817
[2025-03-20 03:18:50,836][model][INFO] - Training step 880 loss 0.24137398600578308
[2025-03-20 03:20:07,475][model][INFO] - Training step 1040 loss 0.023680010810494423
[2025-03-20 03:21:29,438][model][INFO] - Training step 1200 loss 0.00752447871491313
[2025-03-20 03:22:50,262][model][INFO] - Training step 1360 loss 0.04531511291861534
[2025-03-20 03:24:06,338][model][INFO] - Training step 1520 loss 0.25657039880752563
[2025-03-20 03:25:26,175][model][INFO] - Training step 1680 loss 0.005508828908205032
[2025-03-20 03:26:45,889][model][INFO] - Training step 1840 loss 0.005381808616220951
[2025-03-20 03:28:05,161][model][INFO] - Training step 2000 loss 0.05145762860774994
[2025-03-20 03:29:22,154][model][INFO] - Training step 2160 loss 0.022325005382299423
[2025-03-20 03:30:41,017][model][INFO] - Training step 2320 loss 0.0028240829706192017
[2025-03-20 03:32:00,413][model][INFO] - Training step 2480 loss 0.1085832417011261
[2025-03-20 03:33:20,191][model][INFO] - Training step 2640 loss 0.0027654985897243023
[2025-03-20 03:34:38,351][model][INFO] - Training step 2800 loss 0.03821762651205063
[2025-03-20 03:35:57,863][model][INFO] - Training step 2960 loss 0.03767067566514015
[2025-03-20 03:37:19,227][model][INFO] - Training step 3120 loss 0.6686967611312866
[2025-03-20 03:38:38,813][model][INFO] - Training step 3280 loss 0.35095661878585815
[2025-03-20 03:39:56,136][model][INFO] - Training step 3440 loss 0.043921612203121185
[2025-03-20 03:41:13,312][model][INFO] - Training step 3600 loss 0.019954156130552292
[2025-03-20 03:42:32,164][model][INFO] - Training step 3760 loss 0.024431262165308
[2025-03-20 03:43:51,962][model][INFO] - Training step 3920 loss 0.2564466595649719
[2025-03-20 03:45:11,554][model][INFO] - Training step 4080 loss 0.030995551496744156
[2025-03-20 03:46:32,569][model][INFO] - Training step 4240 loss 0.06269755959510803
[2025-03-20 03:47:49,635][model][INFO] - Training step 4400 loss 0.23968912661075592
[2025-03-20 03:49:12,712][model][INFO] - Training step 4560 loss 0.026662714779376984
[2025-03-20 03:50:34,948][model][INFO] - Training step 4720 loss 0.07001003623008728
[2025-03-20 03:51:48,831][model][INFO] - Training step 4880 loss 0.01636476442217827
[2025-03-20 03:53:06,498][model][INFO] - Training step 5040 loss 0.0035477427300065756
[2025-03-20 03:54:27,757][model][INFO] - Training step 5200 loss 0.02535976842045784
[2025-03-20 03:55:45,383][model][INFO] - Training step 5360 loss 0.04960016906261444
[2025-03-20 03:57:00,673][model][INFO] - Training step 5520 loss 0.05960780009627342
[2025-03-20 03:58:19,037][model][INFO] - Training step 5680 loss 0.04864734411239624
[2025-03-20 03:59:40,003][model][INFO] - Training step 5840 loss 0.031256016343832016
[2025-03-20 04:01:00,854][model][INFO] - Training step 6000 loss 0.07094921171665192
[2025-03-20 04:02:20,845][model][INFO] - Training step 6160 loss 0.033482279628515244
[2025-03-20 04:03:39,501][model][INFO] - Training step 6320 loss 0.046723127365112305
[2025-03-20 04:05:00,325][model][INFO] - Training step 6480 loss 0.038506899029016495
[2025-03-20 04:06:17,668][model][INFO] - Training step 6640 loss 0.011020665057003498
[2025-03-20 04:07:37,135][model][INFO] - Training step 6800 loss 0.26099446415901184
[2025-03-20 04:08:57,754][model][INFO] - Training step 6960 loss 0.03226873278617859
[2025-03-20 04:10:19,070][model][INFO] - Training step 7120 loss 0.04689052700996399
[2025-03-20 04:11:40,524][model][INFO] - Training step 7280 loss 0.05642962455749512
[2025-03-20 04:12:59,396][model][INFO] - Training step 7440 loss 0.0459844172000885
[2025-03-20 04:14:20,038][model][INFO] - Training step 7600 loss 0.11922946572303772
[2025-03-20 04:15:38,640][model][INFO] - Training step 7760 loss 0.03790227323770523
[2025-03-20 04:16:58,466][model][INFO] - Training step 7920 loss 0.24385949969291687
[2025-03-20 04:18:18,024][model][INFO] - Training step 8080 loss 0.04185035824775696
[2025-03-20 04:19:35,514][model][INFO] - Training step 8240 loss 0.021117214113473892
[2025-03-20 04:20:54,583][model][INFO] - Training step 8400 loss 0.25240036845207214
[2025-03-20 04:22:10,831][model][INFO] - Training step 8560 loss 0.023141033947467804
[2025-03-20 04:23:26,863][model][INFO] - Training step 8720 loss 0.04818274825811386
[2025-03-20 04:24:45,749][model][INFO] - Training step 8880 loss 0.042530357837677
[2025-03-20 04:26:04,178][model][INFO] - Training step 9040 loss 0.012643758207559586
[2025-03-20 04:27:21,108][model][INFO] - Training step 9200 loss 0.11964187026023865
[2025-03-20 04:28:42,447][model][INFO] - Training step 9360 loss 0.04390173405408859
[2025-03-20 04:30:03,002][model][INFO] - Training step 9520 loss 0.2535480260848999
[2025-03-20 04:31:23,891][model][INFO] - Training step 9680 loss 0.25994083285331726
[2025-03-20 04:32:45,170][model][INFO] - Training step 9840 loss 0.08270053565502167
[2025-03-20 04:34:07,494][model][INFO] - Training step 10000 loss 0.02565756067633629
[2025-03-20 04:35:26,296][model][INFO] - Training step 10160 loss 0.019172407686710358
[2025-03-20 04:36:43,462][model][INFO] - Training step 10320 loss 0.25452518463134766
[2025-03-20 04:38:02,800][model][INFO] - Training step 10480 loss 0.033217817544937134
[2025-03-20 04:39:21,783][model][INFO] - Training step 10640 loss 0.03704347088932991
[2025-03-20 04:40:39,855][model][INFO] - Training step 10800 loss 0.25140392780303955
[2025-03-20 04:41:57,987][model][INFO] - Training step 10960 loss 0.3486025035381317
[2025-03-20 04:43:15,505][model][INFO] - Training step 11120 loss 0.04426463693380356
[2025-03-20 04:44:36,066][model][INFO] - Training step 11280 loss 0.06106971204280853
[2025-03-20 04:45:55,852][model][INFO] - Training step 11440 loss 0.035448141396045685
[2025-03-20 04:47:11,547][model][INFO] - Training step 11600 loss 0.03787904977798462
[2025-03-20 04:48:33,834][model][INFO] - Training step 11760 loss 0.07260565459728241
[2025-03-20 04:49:53,645][model][INFO] - Training step 11920 loss 0.07625448703765869
[2025-03-20 04:51:14,747][model][INFO] - Training step 12080 loss 0.20891329646110535
[2025-03-20 04:52:33,814][model][INFO] - Training step 12240 loss 0.05293554440140724
[2025-03-20 04:53:51,911][model][INFO] - Training step 12400 loss 0.04752527177333832
[2025-03-20 04:55:10,774][model][INFO] - Training step 12560 loss 0.05835817754268646
[2025-03-20 04:56:31,416][model][INFO] - Training step 12720 loss 0.06915050745010376
[2025-03-20 04:57:50,102][model][INFO] - Training step 12880 loss 0.035787537693977356
[2025-03-20 04:59:09,760][model][INFO] - Training step 13040 loss 0.006942972540855408
[2025-03-20 05:00:28,736][model][INFO] - Training step 13200 loss 0.007225103210657835
[2025-03-20 05:01:47,569][model][INFO] - Training step 13360 loss 0.07633709907531738
[2025-03-20 05:03:06,415][model][INFO] - Training step 13520 loss 0.031981874257326126
[2025-03-20 05:04:27,151][model][INFO] - Training step 13680 loss 0.10167524218559265
[2025-03-20 05:05:44,980][model][INFO] - Training step 13840 loss 0.2536300718784332
[2025-03-20 05:07:05,263][model][INFO] - Training step 14000 loss 0.005938549060374498
[2025-03-20 05:08:24,061][model][INFO] - Training step 14160 loss 0.028847932815551758
[2025-03-20 05:09:42,105][model][INFO] - Training step 14320 loss 0.004840188659727573
[2025-03-20 05:10:59,139][model][INFO] - Training step 14480 loss 0.028941785916686058
[2025-03-20 05:12:16,775][model][INFO] - Training step 14640 loss 0.06836074590682983
[2025-03-20 05:13:37,275][model][INFO] - Training step 14800 loss 0.06779639422893524
[2025-03-20 05:14:57,322][model][INFO] - Training step 14960 loss 0.28167539834976196
[2025-03-20 05:16:21,267][model][INFO] - Training step 15120 loss 0.024836361408233643
[2025-03-20 05:17:40,391][model][INFO] - Training step 15280 loss 0.1687597930431366
[2025-03-20 05:18:58,963][model][INFO] - Training step 15440 loss 0.014095727354288101
[2025-03-20 05:20:17,314][model][INFO] - Training step 15600 loss 0.08875377476215363
[2025-03-20 05:21:37,825][model][INFO] - Training step 15760 loss 0.03814385458827019
[2025-03-20 05:22:57,858][model][INFO] - Training step 15920 loss 0.13232694566249847
[2025-03-20 05:24:16,715][model][INFO] - Training step 16080 loss 0.025215592235326767
[2025-03-20 05:25:37,005][model][INFO] - Training step 16240 loss 0.06084802746772766
[2025-03-20 05:26:57,133][model][INFO] - Training step 16400 loss 0.05509709566831589
[2025-03-20 05:28:14,254][model][INFO] - Training step 16560 loss 0.045368634164333344
[2025-03-20 05:29:34,365][model][INFO] - Training step 16720 loss 0.2576866149902344
[2025-03-20 05:30:52,595][model][INFO] - Training step 16880 loss 0.044366683810949326
[2025-03-20 05:32:10,764][model][INFO] - Training step 17040 loss 0.08179599791765213
[2025-03-20 05:33:30,251][model][INFO] - Training step 17200 loss 0.08364885300397873
[2025-03-20 05:34:50,156][model][INFO] - Training step 17360 loss 0.2645551562309265
[2025-03-20 05:36:11,064][model][INFO] - Training step 17520 loss 0.06606965512037277
[2025-03-20 05:37:32,465][model][INFO] - Training step 17680 loss 0.03560724854469299
[2025-03-20 05:38:50,654][model][INFO] - Training step 17840 loss 0.052732303738594055
[2025-03-20 05:40:08,814][model][INFO] - Training step 18000 loss 0.03752543777227402
[2025-03-20 05:41:27,501][model][INFO] - Training step 18160 loss 0.045794904232025146
[2025-03-20 05:42:46,658][model][INFO] - Training step 18320 loss 0.22746923565864563
[2025-03-20 05:44:05,216][model][INFO] - Training step 18480 loss 0.2950616478919983
[2025-03-20 05:45:26,184][model][INFO] - Training step 18640 loss 0.032827019691467285
[2025-03-20 05:46:43,486][model][INFO] - Training step 18800 loss 0.02149369567632675
[2025-03-20 05:48:00,841][model][INFO] - Training step 18960 loss 0.1167716234922409
[2025-03-20 05:49:18,075][model][INFO] - Training step 19120 loss 0.025026502087712288
[2025-03-20 05:50:34,789][model][INFO] - Training step 19280 loss 0.03267288953065872
[2025-03-20 05:51:53,919][model][INFO] - Training step 19440 loss 0.17601701617240906
[2025-03-20 05:53:16,573][model][INFO] - Training step 19600 loss 0.042812444269657135
[2025-03-20 05:54:35,099][model][INFO] - Training step 19760 loss 0.021047847345471382
[2025-03-20 05:55:56,702][model][INFO] - Training step 19920 loss 0.05998693406581879
[2025-03-20 05:57:19,091][model][INFO] - Training step 20080 loss 0.005684261210262775
[2025-03-20 05:58:37,057][model][INFO] - Training step 20240 loss 0.033996351063251495
[2025-03-20 05:59:55,649][model][INFO] - Training step 20400 loss 0.06860526651144028
[2025-03-20 06:01:14,474][model][INFO] - Training step 20560 loss 0.0046875933185219765
[2025-03-20 06:02:35,010][model][INFO] - Training step 20720 loss 0.05164047330617905
[2025-03-20 06:03:53,272][model][INFO] - Training step 20880 loss 0.03586068004369736
[2025-03-20 06:05:15,300][model][INFO] - Training step 21040 loss 0.2624148726463318
[2025-03-20 06:06:34,190][model][INFO] - Training step 21200 loss 0.03469914197921753
[2025-03-20 06:07:55,279][model][INFO] - Training step 21360 loss 0.24779143929481506
[2025-03-20 06:09:13,491][model][INFO] - Training step 21520 loss 0.25410768389701843
[2025-03-20 06:10:32,389][model][INFO] - Training step 21680 loss 0.03484559804201126
[2025-03-20 06:11:53,149][model][INFO] - Training step 21840 loss 0.25718867778778076
[2025-03-20 06:13:15,322][model][INFO] - Training step 22000 loss 0.24263235926628113
[2025-03-20 06:14:33,883][model][INFO] - Training step 22160 loss 0.042477384209632874
[2025-03-20 06:15:53,898][model][INFO] - Training step 22320 loss 0.2514314651489258
[2025-03-20 06:17:13,687][model][INFO] - Training step 22480 loss 0.0379457101225853
[2025-03-20 06:18:34,458][model][INFO] - Training step 22640 loss 0.02913004904985428
[2025-03-20 06:19:53,254][model][INFO] - Training step 22800 loss 0.00634803157299757
[2025-03-20 06:21:10,268][model][INFO] - Training step 22960 loss 0.030481960624456406
[2025-03-20 06:22:31,004][model][INFO] - Training step 23120 loss 0.005978052504360676
[2025-03-20 06:23:49,795][model][INFO] - Training step 23280 loss 0.24964220821857452
[2025-03-20 06:25:09,519][model][INFO] - Training step 23440 loss 0.03240589797496796
[2025-03-20 06:26:30,562][model][INFO] - Training step 23600 loss 0.0035843439400196075
[2025-03-20 06:27:49,279][model][INFO] - Training step 23760 loss 0.04359026998281479
[2025-03-20 06:29:08,891][model][INFO] - Training step 23920 loss 0.03197244554758072
[2025-03-20 06:30:28,201][model][INFO] - Training step 24080 loss 0.35695844888687134
[2025-03-20 06:31:49,168][model][INFO] - Training step 24240 loss 0.2392941266298294
[2025-03-20 06:33:07,512][model][INFO] - Training step 24400 loss 0.023227715864777565
[2025-03-20 06:34:25,661][model][INFO] - Training step 24560 loss 0.1754787117242813
[2025-03-20 06:35:45,035][model][INFO] - Training step 24720 loss 0.0433446429669857
[2025-03-20 06:37:05,707][model][INFO] - Training step 24880 loss 0.036020271480083466
[2025-03-20 06:38:26,774][model][INFO] - Training step 25040 loss 0.03591842204332352
[2025-03-20 06:39:46,027][model][INFO] - Training step 25200 loss 0.034683965146541595
[2025-03-20 06:41:04,071][model][INFO] - Training step 25360 loss 0.23359982669353485
[2025-03-20 06:42:22,455][model][INFO] - Training step 25520 loss 0.05242016166448593
[2025-03-20 06:43:38,630][model][INFO] - Training step 25680 loss 0.04030294716358185
[2025-03-20 06:44:54,262][model][INFO] - Training step 25840 loss 0.25660669803619385
[2025-03-20 06:46:14,515][model][INFO] - Training step 26000 loss 0.08923324197530746
[2025-03-20 06:47:33,445][model][INFO] - Training step 26160 loss 0.04182472825050354
[2025-03-20 06:48:51,178][model][INFO] - Training step 26320 loss 0.03935450688004494
[2025-03-20 06:50:10,690][model][INFO] - Training step 26480 loss 0.2716240882873535
[2025-03-20 06:51:32,150][model][INFO] - Training step 26640 loss 0.038473717868328094
[2025-03-20 06:52:50,120][model][INFO] - Training step 26800 loss 0.020596351474523544
[2025-03-20 06:54:07,705][model][INFO] - Training step 26960 loss 0.2681083679199219
[2025-03-20 06:55:25,561][model][INFO] - Training step 27120 loss 0.23540903627872467
[2025-03-20 06:56:44,969][model][INFO] - Training step 27280 loss 0.26274603605270386
[2025-03-20 06:58:04,739][model][INFO] - Training step 27440 loss 0.005395827814936638
[2025-03-20 06:59:25,978][model][INFO] - Training step 27600 loss 0.2546718120574951
[2025-03-20 07:00:45,126][model][INFO] - Training step 27760 loss 0.2509896755218506
[2025-03-20 07:02:03,236][model][INFO] - Training step 27920 loss 0.018407754600048065
[2025-03-20 07:03:22,934][model][INFO] - Training step 28080 loss 0.08599594980478287
[2025-03-20 07:04:40,569][model][INFO] - Training step 28240 loss 0.04353728145360947
[2025-03-20 07:05:57,973][model][INFO] - Training step 28400 loss 0.10615518689155579
[2025-03-20 07:07:18,156][model][INFO] - Training step 28560 loss 0.2584969401359558
[2025-03-20 07:08:33,685][model][INFO] - Training step 28720 loss 0.08644846081733704
[2025-03-20 07:09:53,593][model][INFO] - Training step 28880 loss 0.004605113994330168
[2025-03-20 07:11:13,131][model][INFO] - Training step 29040 loss 0.09350042045116425
[2025-03-20 07:12:33,555][model][INFO] - Training step 29200 loss 0.04753629490733147
[2025-03-20 07:13:52,268][model][INFO] - Training step 29360 loss 0.024719133973121643
[2025-03-20 07:15:08,750][model][INFO] - Training step 29520 loss 0.044769592583179474
[2025-03-20 07:16:28,596][model][INFO] - Training step 29680 loss 0.2490297555923462
[2025-03-20 07:17:49,831][model][INFO] - Training step 29840 loss 0.06331706047058105
[2025-03-20 07:19:09,693][model][INFO] - Training step 30000 loss 0.0164229366928339
[2025-03-20 07:20:27,158][model][INFO] - Training step 30160 loss 0.05846767500042915
[2025-03-20 07:21:47,099][model][INFO] - Training step 30320 loss 0.23046573996543884
[2025-03-20 07:23:07,461][model][INFO] - Training step 30480 loss 0.1823505163192749
[2025-03-20 07:24:23,000][model][INFO] - Training step 30640 loss 0.03397710621356964
[2025-03-20 07:25:38,281][model][INFO] - Training step 30800 loss 0.04342317208647728
[2025-03-20 07:27:00,062][model][INFO] - Training step 30960 loss 0.033714402467012405
[2025-03-20 07:28:20,272][model][INFO] - Training step 31120 loss 0.04451531171798706
[2025-03-20 07:29:37,496][model][INFO] - Training step 31280 loss 0.0481187179684639
[2025-03-20 07:30:56,455][model][INFO] - Training step 31440 loss 0.05379880592226982
[2025-03-20 07:32:15,802][model][INFO] - Training step 31600 loss 0.043902020901441574
[2025-03-20 07:33:34,202][model][INFO] - Training step 31760 loss 0.05632360652089119
[2025-03-20 07:34:54,088][model][INFO] - Training step 31920 loss 0.04007977247238159
[2025-03-20 07:36:13,796][model][INFO] - Training step 32080 loss 0.02807636372745037
[2025-03-20 07:37:31,614][model][INFO] - Training step 32240 loss 0.017719585448503494
[2025-03-20 07:38:50,197][model][INFO] - Training step 32400 loss 0.006284942850470543
[2025-03-20 07:40:10,291][model][INFO] - Training step 32560 loss 0.006128145381808281
[2025-03-20 07:41:32,176][model][INFO] - Training step 32720 loss 0.024578729644417763
[2025-03-20 07:42:51,836][model][INFO] - Training step 32880 loss 0.03784925490617752
[2025-03-20 07:44:10,466][model][INFO] - Training step 33040 loss 0.03287755325436592
[2025-03-20 07:45:31,109][model][INFO] - Training step 33200 loss 0.24987129867076874
[2025-03-20 07:46:53,262][model][INFO] - Training step 33360 loss 0.023314613848924637
[2025-03-20 07:48:12,277][model][INFO] - Training step 33520 loss 0.041819486767053604
[2025-03-20 07:49:32,939][model][INFO] - Training step 33680 loss 0.2479003220796585
[2025-03-20 07:50:51,782][model][INFO] - Training step 33840 loss 0.02438696101307869
[2025-03-20 07:52:08,283][model][INFO] - Training step 34000 loss 0.01559714786708355
[2025-03-20 07:53:27,050][model][INFO] - Training step 34160 loss 0.08823533356189728
[2025-03-20 07:54:49,695][model][INFO] - Training step 34320 loss 0.006086396984755993
[2025-03-20 07:56:09,318][model][INFO] - Training step 34480 loss 0.04827210307121277
[2025-03-20 07:57:28,428][model][INFO] - Training step 34640 loss 0.03758840635418892
[2025-03-20 07:58:46,398][model][INFO] - Training step 34800 loss 0.024949416518211365
[2025-03-20 08:00:05,696][model][INFO] - Training step 34960 loss 0.03708671033382416
[2025-03-20 08:01:24,512][model][INFO] - Training step 35120 loss 0.29354384541511536
[2025-03-20 08:02:45,214][model][INFO] - Training step 35280 loss 0.0067230938002467155
[2025-03-20 08:04:06,184][model][INFO] - Training step 35440 loss 0.007287575397640467
[2025-03-20 08:05:26,174][model][INFO] - Training step 35600 loss 0.13389386236667633
[2025-03-20 08:06:43,235][model][INFO] - Training step 35760 loss 0.02647988498210907
[2025-03-20 08:08:01,296][model][INFO] - Training step 35920 loss 0.030471595004200935
[2025-03-20 08:09:23,963][model][INFO] - Training step 36080 loss 0.04050065577030182
[2025-03-20 08:10:44,410][model][INFO] - Training step 36240 loss 0.024111080914735794
[2025-03-20 08:12:05,360][model][INFO] - Training step 36400 loss 0.0069693466648459435
[2025-03-20 08:13:24,503][model][INFO] - Training step 36560 loss 0.22640907764434814
[2025-03-20 08:14:46,228][model][INFO] - Training step 36720 loss 0.015336726792156696
[2025-03-20 08:16:04,512][model][INFO] - Training step 36880 loss 0.029721014201641083
[2025-03-20 08:17:22,124][model][INFO] - Training step 37040 loss 0.006526975892484188
[2025-03-20 08:18:43,863][model][INFO] - Training step 37200 loss 0.04446756839752197
[2025-03-20 08:20:05,853][model][INFO] - Training step 37360 loss 0.04905860871076584
[2025-03-20 08:21:27,028][model][INFO] - Training step 37520 loss 0.01610201597213745
[2025-03-20 08:22:44,736][model][INFO] - Training step 37680 loss 0.029362164437770844
[2025-03-20 08:24:04,638][model][INFO] - Training step 37840 loss 0.26770472526550293
[2025-03-20 08:25:21,540][model][INFO] - Training step 38000 loss 0.0510779470205307
[2025-03-20 08:26:41,394][model][INFO] - Training step 38160 loss 0.024543453007936478
[2025-03-20 08:28:03,712][model][INFO] - Training step 38320 loss 0.007909434847533703
[2025-03-20 08:29:21,807][model][INFO] - Training step 38480 loss 0.06509868800640106
[2025-03-20 08:30:42,772][model][INFO] - Training step 38640 loss 0.033902887254953384
[2025-03-20 08:31:57,546][model][INFO] - Training step 38800 loss 0.01970769837498665
[2025-03-20 08:33:19,598][model][INFO] - Training step 38960 loss 0.251285582780838
[2025-03-20 08:34:40,377][model][INFO] - Training step 39120 loss 0.028852326795458794
[2025-03-20 08:35:59,654][model][INFO] - Training step 39280 loss 0.07386699318885803
[2025-03-20 08:37:21,462][model][INFO] - Training step 39440 loss 0.021390056237578392
[2025-03-20 08:38:39,820][model][INFO] - Training step 39600 loss 0.041250910609960556
[2025-03-20 08:39:58,262][model][INFO] - Training step 39760 loss 0.005820604972541332
[2025-03-20 08:41:20,012][model][INFO] - Training step 39920 loss 0.026138626039028168
[2025-03-20 08:42:39,205][model][INFO] - Training step 40080 loss 0.04047524183988571
[2025-03-20 08:43:58,009][model][INFO] - Training step 40240 loss 0.052231721580028534
[2025-03-20 08:45:15,374][model][INFO] - Training step 40400 loss 0.03331705182790756
[2025-03-20 08:46:37,286][model][INFO] - Training step 40560 loss 0.006194186396896839
[2025-03-20 08:47:52,813][model][INFO] - Training step 40720 loss 0.2605605721473694
[2025-03-20 08:49:10,644][model][INFO] - Training step 40880 loss 0.025184404104948044
[2025-03-20 08:50:29,476][model][INFO] - Training step 41040 loss 0.034106481820344925
[2025-03-20 08:51:45,884][model][INFO] - Training step 41200 loss 0.24266543984413147
[2025-03-20 08:53:07,010][model][INFO] - Training step 41360 loss 0.053759559988975525
[2025-03-20 08:54:27,383][model][INFO] - Training step 41520 loss 0.17188650369644165
[2025-03-20 08:55:47,270][model][INFO] - Training step 41680 loss 0.12218247354030609
[2025-03-20 08:57:04,944][model][INFO] - Training step 41840 loss 0.05638943612575531
[2025-03-20 08:58:27,960][model][INFO] - Training step 42000 loss 0.07643292844295502
[2025-03-20 08:59:48,062][model][INFO] - Training step 42160 loss 0.06357080489397049
[2025-03-20 09:01:08,435][model][INFO] - Training step 42320 loss 0.01989275962114334
[2025-03-20 09:02:31,647][model][INFO] - Training step 42480 loss 0.024887429550290108
[2025-03-20 09:03:50,055][model][INFO] - Training step 42640 loss 0.0030300894286483526
[2025-03-20 09:05:09,359][model][INFO] - Training step 42800 loss 0.24256742000579834
[2025-03-20 09:06:28,315][model][INFO] - Training step 42960 loss 0.23365738987922668
[2025-03-20 09:07:48,343][model][INFO] - Training step 43120 loss 0.05313028395175934
[2025-03-20 09:09:09,671][model][INFO] - Training step 43280 loss 0.006007415242493153
[2025-03-20 09:10:30,637][model][INFO] - Training step 43440 loss 0.24999535083770752
[2025-03-20 09:11:50,348][model][INFO] - Training step 43600 loss 0.06020267307758331
[2025-03-20 09:13:11,672][model][INFO] - Training step 43760 loss 0.0402456596493721
[2025-03-20 09:14:30,351][model][INFO] - Training step 43920 loss 0.05521911382675171
[2025-03-20 09:15:51,332][model][INFO] - Training step 44080 loss 0.03373553976416588
[2025-03-20 09:17:10,947][model][INFO] - Training step 44240 loss 0.009991631843149662
[2025-03-20 09:18:30,177][model][INFO] - Training step 44400 loss 0.003357375506311655
[2025-03-20 09:19:48,969][model][INFO] - Training step 44560 loss 0.06336475908756256
[2025-03-20 09:21:08,753][model][INFO] - Training step 44720 loss 0.03691893815994263
[2025-03-20 09:22:27,915][model][INFO] - Training step 44880 loss 0.0945245623588562
[2025-03-20 09:23:48,921][model][INFO] - Training step 45040 loss 0.030372004956007004
[2025-03-20 09:25:07,485][model][INFO] - Training step 45200 loss 0.015594061464071274
[2025-03-20 09:26:28,704][model][INFO] - Training step 45360 loss 0.02458936721086502
[2025-03-20 09:27:46,563][model][INFO] - Training step 45520 loss 0.034667953848838806
[2025-03-20 09:29:07,768][model][INFO] - Training step 45680 loss 0.03581583872437477
[2025-03-20 09:30:29,393][model][INFO] - Training step 45840 loss 0.005694221239537001
[2025-03-20 09:31:46,823][model][INFO] - Training step 46000 loss 0.04888177663087845
[2025-03-20 09:33:03,452][model][INFO] - Training step 46160 loss 0.24983368813991547
[2025-03-20 09:34:23,187][model][INFO] - Training step 46320 loss 0.024982495233416557
[2025-03-20 09:35:42,141][model][INFO] - Training step 46480 loss 0.035001255571842194
[2025-03-20 09:36:58,349][model][INFO] - Training step 46640 loss 0.04565904289484024
[2025-03-20 09:38:19,543][model][INFO] - Training step 46800 loss 0.06452919542789459
[2025-03-20 09:39:37,101][model][INFO] - Training step 46960 loss 0.14837899804115295
[2025-03-20 09:40:52,731][model][INFO] - Training step 47120 loss 0.049238212406635284
[2025-03-20 09:42:14,690][model][INFO] - Training step 47280 loss 0.003833973780274391
[2025-03-20 09:43:33,077][model][INFO] - Training step 47440 loss 0.24470867216587067
[2025-03-20 09:44:51,219][model][INFO] - Training step 47600 loss 0.005387083161622286
[2025-03-20 09:46:11,120][model][INFO] - Training step 47760 loss 0.08451294898986816
[2025-03-20 09:47:28,534][model][INFO] - Training step 47920 loss 0.07443946599960327
[2025-03-20 09:48:49,694][model][INFO] - Training step 48080 loss 0.060292378067970276
[2025-03-20 09:50:07,177][model][INFO] - Training step 48240 loss 0.021627718582749367
[2025-03-20 09:51:25,240][model][INFO] - Training step 48400 loss 0.292390912771225
[2025-03-20 09:52:40,547][model][INFO] - Training step 48560 loss 0.2545927166938782
[2025-03-20 09:54:01,200][model][INFO] - Training step 48720 loss 0.08451846241950989
[2025-03-20 09:55:21,756][model][INFO] - Training step 48880 loss 0.005037601105868816
[2025-03-20 09:56:39,964][model][INFO] - Training step 49040 loss 0.028157413005828857
[2025-03-20 09:58:03,165][model][INFO] - Training step 49200 loss 0.007718352600932121
[2025-03-20 09:59:22,933][model][INFO] - Training step 49360 loss 0.04260306432843208
[2025-03-20 10:00:43,334][model][INFO] - Training step 49520 loss 0.0492967814207077
[2025-03-20 10:02:02,551][model][INFO] - Training step 49680 loss 0.02162042073905468
[2025-03-20 10:03:21,568][model][INFO] - Training step 49840 loss 0.08289128541946411
[2025-03-20 10:04:42,782][model][INFO] - Training step 50000 loss 0.0386640727519989
[2025-03-20 10:06:01,858][model][INFO] - Training step 50160 loss 0.022062890231609344
[2025-03-20 10:07:20,416][model][INFO] - Training step 50320 loss 0.02626725286245346
[2025-03-20 10:08:37,931][model][INFO] - Training step 50480 loss 0.2153220772743225
[2025-03-20 10:09:56,392][model][INFO] - Training step 50640 loss 0.020049558952450752
[2025-03-20 10:19:24,526][model][INFO] - Training step 0 loss 0.004098816774785519
[2025-03-20 10:20:45,297][model][INFO] - Training step 160 loss 0.2505844235420227
[2025-03-20 10:22:06,197][model][INFO] - Training step 320 loss 0.03162959963083267
[2025-03-20 10:23:28,784][model][INFO] - Training step 480 loss 0.02931346744298935
[2025-03-20 10:24:47,700][model][INFO] - Training step 640 loss 0.02383657731115818
[2025-03-20 10:26:05,999][model][INFO] - Training step 800 loss 0.27492278814315796
[2025-03-20 10:27:27,312][model][INFO] - Training step 960 loss 0.01924959011375904
[2025-03-20 10:28:45,294][model][INFO] - Training step 1120 loss 0.12378150224685669
[2025-03-20 10:30:07,496][model][INFO] - Training step 1280 loss 0.02176298387348652
[2025-03-20 10:31:25,724][model][INFO] - Training step 1440 loss 0.07966887205839157
[2025-03-20 10:32:43,991][model][INFO] - Training step 1600 loss 0.26120704412460327
[2025-03-20 10:34:03,335][model][INFO] - Training step 1760 loss 0.05612754076719284
[2025-03-20 10:35:21,805][model][INFO] - Training step 1920 loss 0.024647966027259827
[2025-03-20 10:36:40,070][model][INFO] - Training step 2080 loss 0.10327554494142532
[2025-03-20 10:37:57,476][model][INFO] - Training step 2240 loss 0.0235909353941679
[2025-03-20 10:39:15,898][model][INFO] - Training step 2400 loss 0.19631747901439667
[2025-03-20 10:40:36,222][model][INFO] - Training step 2560 loss 0.05083286017179489
[2025-03-20 10:41:53,581][model][INFO] - Training step 2720 loss 0.028481468558311462
[2025-03-20 10:43:13,851][model][INFO] - Training step 2880 loss 0.03327016159892082
[2025-03-20 10:44:32,722][model][INFO] - Training step 3040 loss 0.294803261756897
[2025-03-20 10:45:50,701][model][INFO] - Training step 3200 loss 0.030626676976680756
[2025-03-20 10:47:10,874][model][INFO] - Training step 3360 loss 0.016252566128969193
[2025-03-20 10:48:29,213][model][INFO] - Training step 3520 loss 0.0488479807972908
[2025-03-20 10:49:47,105][model][INFO] - Training step 3680 loss 0.03593813627958298
[2025-03-20 10:51:04,434][model][INFO] - Training step 3840 loss 0.03643999621272087
[2025-03-20 10:52:24,546][model][INFO] - Training step 4000 loss 0.2026180922985077
[2025-03-20 10:53:44,342][model][INFO] - Training step 4160 loss 0.259080708026886
[2025-03-20 10:55:05,961][model][INFO] - Training step 4320 loss 0.044387705624103546
[2025-03-20 10:56:27,387][model][INFO] - Training step 4480 loss 0.0316179096698761
[2025-03-20 10:57:48,877][model][INFO] - Training step 4640 loss 0.251865953207016
[2025-03-20 10:59:07,925][model][INFO] - Training step 4800 loss 0.06368665397167206
[2025-03-20 11:00:24,899][model][INFO] - Training step 4960 loss 0.005034155212342739
[2025-03-20 11:01:44,999][model][INFO] - Training step 5120 loss 0.6593082547187805
[2025-03-20 11:03:03,884][model][INFO] - Training step 5280 loss 0.03204786032438278
[2025-03-20 11:04:23,673][model][INFO] - Training step 5440 loss 0.007828551344573498
[2025-03-20 11:05:40,522][model][INFO] - Training step 5600 loss 0.04920172691345215
[2025-03-20 11:07:02,076][model][INFO] - Training step 5760 loss 0.04066605865955353
[2025-03-20 11:08:22,404][model][INFO] - Training step 5920 loss 0.024442026391625404
[2025-03-20 11:09:39,364][model][INFO] - Training step 6080 loss 0.028689958155155182
[2025-03-20 11:10:59,399][model][INFO] - Training step 6240 loss 0.24965256452560425
[2025-03-20 11:12:20,291][model][INFO] - Training step 6400 loss 0.26433300971984863
[2025-03-20 11:13:36,829][model][INFO] - Training step 6560 loss 0.05330228805541992
[2025-03-20 11:14:57,610][model][INFO] - Training step 6720 loss 0.0051954360678792
[2025-03-20 11:16:15,675][model][INFO] - Training step 6880 loss 0.05595149099826813
[2025-03-20 11:17:31,780][model][INFO] - Training step 7040 loss 0.0705292746424675
[2025-03-20 11:18:51,610][model][INFO] - Training step 7200 loss 0.0055246357806026936
[2025-03-20 11:20:11,833][model][INFO] - Training step 7360 loss 0.1530543565750122
[2025-03-20 11:21:31,603][model][INFO] - Training step 7520 loss 0.04328364133834839
[2025-03-20 11:22:51,613][model][INFO] - Training step 7680 loss 0.031272515654563904
[2025-03-20 11:24:10,258][model][INFO] - Training step 7840 loss 0.12078454345464706
[2025-03-20 11:25:30,318][model][INFO] - Training step 8000 loss 0.24464727938175201
[2025-03-20 11:26:46,675][model][INFO] - Training step 8160 loss 0.24677996337413788
[2025-03-20 11:28:06,275][model][INFO] - Training step 8320 loss 0.028289755806326866
[2025-03-20 11:29:24,664][model][INFO] - Training step 8480 loss 0.07694022357463837
[2025-03-20 11:30:43,694][model][INFO] - Training step 8640 loss 0.0211094431579113
[2025-03-20 11:32:04,194][model][INFO] - Training step 8800 loss 0.02937418967485428
[2025-03-20 11:33:22,755][model][INFO] - Training step 8960 loss 0.05175552889704704
[2025-03-20 11:34:42,354][model][INFO] - Training step 9120 loss 0.24492597579956055
[2025-03-20 11:36:00,289][model][INFO] - Training step 9280 loss 0.029213260859251022
[2025-03-20 11:37:22,664][model][INFO] - Training step 9440 loss 0.017335951328277588
[2025-03-20 11:38:41,448][model][INFO] - Training step 9600 loss 0.2554827928543091
[2025-03-20 11:40:03,925][model][INFO] - Training step 9760 loss 0.053256869316101074
[2025-03-20 11:41:24,038][model][INFO] - Training step 9920 loss 0.24929344654083252
[2025-03-20 11:42:44,635][model][INFO] - Training step 10080 loss 0.025357702746987343
[2025-03-20 11:44:03,402][model][INFO] - Training step 10240 loss 0.015960481017827988
[2025-03-20 11:45:21,661][model][INFO] - Training step 10400 loss 0.029421187937259674
[2025-03-20 11:46:39,723][model][INFO] - Training step 10560 loss 0.11954780668020248
[2025-03-20 11:47:58,242][model][INFO] - Training step 10720 loss 0.024329695850610733
[2025-03-20 11:49:18,829][model][INFO] - Training step 10880 loss 0.2661566734313965
[2025-03-20 11:50:38,983][model][INFO] - Training step 11040 loss 0.00412467448040843
[2025-03-20 11:51:54,255][model][INFO] - Training step 11200 loss 0.2511707842350006
[2025-03-20 11:53:14,595][model][INFO] - Training step 11360 loss 0.004638414829969406
[2025-03-20 11:54:33,016][model][INFO] - Training step 11520 loss 0.024680383503437042
[2025-03-20 11:55:52,160][model][INFO] - Training step 11680 loss 0.04898519441485405
[2025-03-20 11:57:11,455][model][INFO] - Training step 11840 loss 0.0695706307888031
[2025-03-20 11:58:28,644][model][INFO] - Training step 12000 loss 0.0038169492036104202
[2025-03-20 11:59:46,586][model][INFO] - Training step 12160 loss 0.24660804867744446
[2025-03-20 12:01:02,778][model][INFO] - Training step 12320 loss 0.24869698286056519
[2025-03-20 12:02:22,989][model][INFO] - Training step 12480 loss 0.03912612050771713
[2025-03-20 12:03:41,054][model][INFO] - Training step 12640 loss 0.03158235922455788
[2025-03-20 12:04:58,101][model][INFO] - Training step 12800 loss 0.041144952178001404
[2025-03-20 12:06:17,570][model][INFO] - Training step 12960 loss 0.027720529586076736
[2025-03-20 12:07:36,872][model][INFO] - Training step 13120 loss 0.018779918551445007
[2025-03-20 12:08:55,519][model][INFO] - Training step 13280 loss 0.025432869791984558
[2025-03-20 12:10:15,398][model][INFO] - Training step 13440 loss 0.5104386806488037
[2025-03-20 12:11:35,432][model][INFO] - Training step 13600 loss 0.010517962276935577
[2025-03-20 12:12:55,580][model][INFO] - Training step 13760 loss 0.03872743993997574
[2025-03-20 12:14:13,963][model][INFO] - Training step 13920 loss 0.0813407152891159
[2025-03-20 12:15:35,454][model][INFO] - Training step 14080 loss 0.02277323603630066
[2025-03-20 12:16:53,288][model][INFO] - Training step 14240 loss 0.6203855872154236
[2025-03-20 12:18:09,281][model][INFO] - Training step 14400 loss 0.22697585821151733
[2025-03-20 12:19:28,240][model][INFO] - Training step 14560 loss 0.21024569869041443
[2025-03-20 12:20:50,329][model][INFO] - Training step 14720 loss 0.04007738083600998
[2025-03-20 12:22:08,454][model][INFO] - Training step 14880 loss 0.2939361333847046
[2025-03-20 12:23:29,328][model][INFO] - Training step 15040 loss 0.04223553463816643
[2025-03-20 12:24:51,585][model][INFO] - Training step 15200 loss 0.03298906236886978
[2025-03-20 12:26:09,610][model][INFO] - Training step 15360 loss 0.015728570520877838
[2025-03-20 12:27:29,917][model][INFO] - Training step 15520 loss 0.022958051413297653
[2025-03-20 12:28:51,122][model][INFO] - Training step 15680 loss 0.050215691328048706
[2025-03-20 12:30:08,691][model][INFO] - Training step 15840 loss 0.06629705429077148
[2025-03-20 12:31:24,154][model][INFO] - Training step 16000 loss 0.033343032002449036
[2025-03-20 12:32:43,497][model][INFO] - Training step 16160 loss 0.2536039352416992
[2025-03-20 12:34:05,712][model][INFO] - Training step 16320 loss 0.04909380525350571
[2025-03-20 12:35:25,911][model][INFO] - Training step 16480 loss 0.23738422989845276
[2025-03-20 12:36:44,152][model][INFO] - Training step 16640 loss 0.03620915487408638
[2025-03-20 12:38:03,025][model][INFO] - Training step 16800 loss 0.03738565370440483
[2025-03-20 12:39:23,889][model][INFO] - Training step 16960 loss 0.27256786823272705
[2025-03-20 12:40:44,906][model][INFO] - Training step 17120 loss 0.314802885055542
[2025-03-20 12:42:04,376][model][INFO] - Training step 17280 loss 0.0691518560051918
[2025-03-20 12:43:26,949][model][INFO] - Training step 17440 loss 0.07112289220094681
[2025-03-20 12:44:48,472][model][INFO] - Training step 17600 loss 0.011722367256879807
[2025-03-20 12:46:08,421][model][INFO] - Training step 17760 loss 0.047251492738723755
[2025-03-20 12:47:26,087][model][INFO] - Training step 17920 loss 0.2569795846939087
[2025-03-20 12:48:44,473][model][INFO] - Training step 18080 loss 0.030579958111047745
[2025-03-20 12:50:00,449][model][INFO] - Training step 18240 loss 0.05165952071547508
[2025-03-20 12:51:24,351][model][INFO] - Training step 18400 loss 0.03820221126079559
[2025-03-20 12:52:43,114][model][INFO] - Training step 18560 loss 0.025722039863467216
[2025-03-20 12:54:04,531][model][INFO] - Training step 18720 loss 0.007196747697889805
[2025-03-20 12:55:24,632][model][INFO] - Training step 18880 loss 0.001333508058451116
[2025-03-20 12:56:42,207][model][INFO] - Training step 19040 loss 0.040314145386219025
[2025-03-20 12:58:04,251][model][INFO] - Training step 19200 loss 0.008059106767177582
[2025-03-20 12:59:24,671][model][INFO] - Training step 19360 loss 0.05484738573431969
[2025-03-20 13:00:45,293][model][INFO] - Training step 19520 loss 0.06641551107168198
[2025-03-20 13:02:05,234][model][INFO] - Training step 19680 loss 0.04170657694339752
[2025-03-20 13:03:24,187][model][INFO] - Training step 19840 loss 0.007858953438699245
[2025-03-20 13:04:45,611][model][INFO] - Training step 20000 loss 0.19159594178199768
[2025-03-20 13:06:07,047][model][INFO] - Training step 20160 loss 0.04067372530698776
[2025-03-20 13:07:28,784][model][INFO] - Training step 20320 loss 0.04812336713075638
[2025-03-20 13:08:48,783][model][INFO] - Training step 20480 loss 0.19574227929115295
[2025-03-20 13:10:08,393][model][INFO] - Training step 20640 loss 0.043287038803100586
[2025-03-20 13:11:33,101][model][INFO] - Training step 20800 loss 0.10995209962129593
[2025-03-20 13:12:55,101][model][INFO] - Training step 20960 loss 0.04143901541829109
[2025-03-20 13:14:15,795][model][INFO] - Training step 21120 loss 0.07504063844680786
[2025-03-20 13:15:33,433][model][INFO] - Training step 21280 loss 0.01814153976738453
[2025-03-20 13:16:50,358][model][INFO] - Training step 21440 loss 0.0808095633983612
[2025-03-20 13:18:08,014][model][INFO] - Training step 21600 loss 0.0058322180993855
[2025-03-20 13:19:26,860][model][INFO] - Training step 21760 loss 0.04176678508520126
[2025-03-20 13:20:45,583][model][INFO] - Training step 21920 loss 0.00683193514123559
[2025-03-20 13:22:05,787][model][INFO] - Training step 22080 loss 0.04927767068147659
[2025-03-20 13:23:22,242][model][INFO] - Training step 22240 loss 0.035691943019628525
[2025-03-20 13:24:42,237][model][INFO] - Training step 22400 loss 0.26099443435668945
[2025-03-20 13:26:00,721][model][INFO] - Training step 22560 loss 0.03123726323246956
[2025-03-20 13:27:24,035][model][INFO] - Training step 22720 loss 0.046084433794021606
[2025-03-20 13:28:45,616][model][INFO] - Training step 22880 loss 0.26146602630615234
[2025-03-20 13:30:05,282][model][INFO] - Training step 23040 loss 0.26437169313430786
[2025-03-20 13:31:26,136][model][INFO] - Training step 23200 loss 0.08933719247579575
[2025-03-20 13:32:47,966][model][INFO] - Training step 23360 loss 0.04692872613668442
[2025-03-20 13:34:06,938][model][INFO] - Training step 23520 loss 0.21111956238746643
[2025-03-20 13:35:24,868][model][INFO] - Training step 23680 loss 0.11773838102817535
[2025-03-20 13:36:43,443][model][INFO] - Training step 23840 loss 0.05273441597819328
[2025-03-20 13:37:59,844][model][INFO] - Training step 24000 loss 0.026608888059854507
[2025-03-20 13:39:16,493][model][INFO] - Training step 24160 loss 0.04303349554538727
[2025-03-20 13:40:36,212][model][INFO] - Training step 24320 loss 0.028710804879665375
[2025-03-20 13:41:55,116][model][INFO] - Training step 24480 loss 0.012766169384121895
[2025-03-20 13:43:15,372][model][INFO] - Training step 24640 loss 0.2576887905597687
[2025-03-20 13:44:36,905][model][INFO] - Training step 24800 loss 0.05593816563487053
[2025-03-20 13:45:56,970][model][INFO] - Training step 24960 loss 0.03710415959358215
[2025-03-20 13:47:17,693][model][INFO] - Training step 25120 loss 0.32973986864089966
[2025-03-20 13:48:38,502][model][INFO] - Training step 25280 loss 0.006084061227738857
[2025-03-20 13:49:57,587][model][INFO] - Training step 25440 loss 0.025895562022924423
[2025-03-20 13:51:18,861][model][INFO] - Training step 25600 loss 0.0042440020479261875
[2025-03-20 13:52:36,014][model][INFO] - Training step 25760 loss 0.04680408164858818
[2025-03-20 13:53:56,083][model][INFO] - Training step 25920 loss 0.2518264055252075
[2025-03-20 13:55:15,124][model][INFO] - Training step 26080 loss 0.11586502939462662
[2025-03-20 13:56:35,686][model][INFO] - Training step 26240 loss 0.004060098901391029
[2025-03-20 13:57:54,026][model][INFO] - Training step 26400 loss 0.08120729774236679
[2025-03-20 13:59:15,030][model][INFO] - Training step 26560 loss 0.019503256306052208
[2025-03-20 14:00:32,073][model][INFO] - Training step 26720 loss 0.026293449103832245
[2025-03-20 14:01:52,020][model][INFO] - Training step 26880 loss 0.03776910901069641
[2025-03-20 14:03:12,236][model][INFO] - Training step 27040 loss 0.022909928113222122
[2025-03-20 14:04:29,684][model][INFO] - Training step 27200 loss 0.0827438235282898
[2025-03-20 14:05:48,759][model][INFO] - Training step 27360 loss 0.03617359697818756
[2025-03-20 14:07:05,966][model][INFO] - Training step 27520 loss 0.035865794867277145
[2025-03-20 14:08:38,892][model][INFO] - Training step 27680 loss 0.14239388704299927
[2025-03-20 14:10:23,347][model][INFO] - Training step 27840 loss 0.028767364099621773
[2025-03-20 14:12:03,126][model][INFO] - Training step 28000 loss 0.006082847714424133
[2025-03-20 14:13:44,439][model][INFO] - Training step 28160 loss 0.020749570801854134
[2025-03-20 14:15:24,148][model][INFO] - Training step 28320 loss 0.055466484278440475
[2025-03-20 14:17:03,886][model][INFO] - Training step 28480 loss 0.006439948454499245
[2025-03-20 14:18:38,935][model][INFO] - Training step 28640 loss 0.0035864554811269045
[2025-03-20 14:20:17,715][model][INFO] - Training step 28800 loss 0.0788581371307373
[2025-03-20 14:22:01,429][model][INFO] - Training step 28960 loss 0.052018795162439346
[2025-03-20 14:23:41,518][model][INFO] - Training step 29120 loss 0.04681318998336792
[2025-03-20 14:25:27,017][model][INFO] - Training step 29280 loss 0.04606100916862488
[2025-03-20 14:27:06,672][model][INFO] - Training step 29440 loss 0.3451668620109558
[2025-03-20 14:28:44,676][model][INFO] - Training step 29600 loss 0.2900784909725189
[2025-03-20 14:30:24,617][model][INFO] - Training step 29760 loss 0.04141848534345627
[2025-03-20 14:32:09,250][model][INFO] - Training step 29920 loss 0.028291666880249977
[2025-03-20 14:33:54,143][model][INFO] - Training step 30080 loss 0.24612128734588623
[2025-03-20 14:35:36,861][model][INFO] - Training step 30240 loss 0.059071023017168045
[2025-03-20 14:37:17,320][model][INFO] - Training step 30400 loss 0.03659549355506897
[2025-03-20 14:38:46,435][model][INFO] - Training step 30560 loss 0.037037864327430725
[2025-03-20 14:40:01,397][model][INFO] - Training step 30720 loss 0.013056153431534767
[2025-03-20 14:41:18,514][model][INFO] - Training step 30880 loss 0.03228627145290375
[2025-03-20 14:42:43,038][model][INFO] - Training step 31040 loss 0.026871787384152412
[2025-03-20 14:44:01,103][model][INFO] - Training step 31200 loss 0.022675473242998123
[2025-03-20 14:45:20,882][model][INFO] - Training step 31360 loss 0.09169138967990875
[2025-03-20 14:46:39,769][model][INFO] - Training step 31520 loss 0.252152681350708
[2025-03-20 14:47:59,784][model][INFO] - Training step 31680 loss 0.03137078136205673
[2025-03-20 14:49:17,282][model][INFO] - Training step 31840 loss 0.23534387350082397
[2025-03-20 14:50:38,322][model][INFO] - Training step 32000 loss 0.250397264957428
[2025-03-20 14:51:59,018][model][INFO] - Training step 32160 loss 0.09277398884296417
[2025-03-20 14:53:17,487][model][INFO] - Training step 32320 loss 0.029218479990959167
[2025-03-20 14:54:39,275][model][INFO] - Training step 32480 loss 0.004866692703217268
[2025-03-20 14:56:01,183][model][INFO] - Training step 32640 loss 0.2759757339954376
[2025-03-20 14:57:20,300][model][INFO] - Training step 32800 loss 0.2485765814781189
[2025-03-20 14:58:43,276][model][INFO] - Training step 32960 loss 0.27156752347946167
[2025-03-20 15:00:00,583][model][INFO] - Training step 33120 loss 0.03783688694238663
[2025-03-20 15:01:20,528][model][INFO] - Training step 33280 loss 0.2018108069896698
[2025-03-20 15:02:47,489][model][INFO] - Training step 33440 loss 0.03264103829860687
[2025-03-20 15:04:07,849][model][INFO] - Training step 33600 loss 0.07931401580572128
[2025-03-20 15:05:25,365][model][INFO] - Training step 33760 loss 0.03196084499359131
[2025-03-20 15:06:44,440][model][INFO] - Training step 33920 loss 0.23269163072109222
[2025-03-20 15:08:03,387][model][INFO] - Training step 34080 loss 0.022555116564035416
[2025-03-20 15:09:24,632][model][INFO] - Training step 34240 loss 0.1172291487455368
[2025-03-20 15:10:43,332][model][INFO] - Training step 34400 loss 0.06990403681993484
[2025-03-20 15:12:02,195][model][INFO] - Training step 34560 loss 0.043848916888237
[2025-03-20 15:13:17,923][model][INFO] - Training step 34720 loss 0.029862018302083015
[2025-03-20 15:14:38,859][model][INFO] - Training step 34880 loss 0.03250645846128464
[2025-03-20 15:15:57,684][model][INFO] - Training step 35040 loss 0.051178790628910065
[2025-03-20 15:17:17,780][model][INFO] - Training step 35200 loss 0.0031142740044742823
[2025-03-20 15:18:39,022][model][INFO] - Training step 35360 loss 0.03450339287519455
[2025-03-20 15:19:58,126][model][INFO] - Training step 35520 loss 0.07961559295654297
[2025-03-20 15:21:18,909][model][INFO] - Training step 35680 loss 0.03612140938639641
[2025-03-20 15:22:36,995][model][INFO] - Training step 35840 loss 0.023448102176189423
[2025-03-20 15:23:53,739][model][INFO] - Training step 36000 loss 0.2511122226715088
[2025-03-20 15:25:13,398][model][INFO] - Training step 36160 loss 0.2914138734340668
[2025-03-20 15:26:35,150][model][INFO] - Training step 36320 loss 0.25347769260406494
[2025-03-20 15:27:55,022][model][INFO] - Training step 36480 loss 0.18858808279037476
[2025-03-20 15:29:15,607][model][INFO] - Training step 36640 loss 0.14768734574317932
[2025-03-20 15:30:34,609][model][INFO] - Training step 36800 loss 0.08130025863647461
[2025-03-20 15:31:59,011][model][INFO] - Training step 36960 loss 0.014604945667088032
[2025-03-20 15:33:17,449][model][INFO] - Training step 37120 loss 0.028204116970300674
[2025-03-20 15:34:36,223][model][INFO] - Training step 37280 loss 0.037243105471134186
[2025-03-20 15:35:56,472][model][INFO] - Training step 37440 loss 0.03857726603746414
[2025-03-20 15:37:12,965][model][INFO] - Training step 37600 loss 0.0064467331394553185
[2025-03-20 15:38:32,516][model][INFO] - Training step 37760 loss 0.0292811281979084
[2025-03-20 15:39:51,145][model][INFO] - Training step 37920 loss 0.0061066411435604095
[2025-03-20 15:41:10,050][model][INFO] - Training step 38080 loss 0.03515758365392685
[2025-03-20 15:42:33,777][model][INFO] - Training step 38240 loss 0.009189926087856293
[2025-03-20 15:43:51,832][model][INFO] - Training step 38400 loss 0.005924075376242399
[2025-03-20 15:45:09,633][model][INFO] - Training step 38560 loss 0.035000890493392944
[2025-03-20 15:46:30,107][model][INFO] - Training step 38720 loss 0.09564035385847092
[2025-03-20 15:47:48,667][model][INFO] - Training step 38880 loss 0.03587152063846588
[2025-03-20 15:49:07,170][model][INFO] - Training step 39040 loss 0.02116221934556961
[2025-03-20 15:50:23,762][model][INFO] - Training step 39200 loss 0.029866937547922134
[2025-03-20 15:51:44,588][model][INFO] - Training step 39360 loss 0.032210420817136765
[2025-03-20 15:53:04,517][model][INFO] - Training step 39520 loss 0.2406752109527588
[2025-03-20 15:54:24,838][model][INFO] - Training step 39680 loss 0.02007858268916607
[2025-03-20 15:55:44,932][model][INFO] - Training step 39840 loss 0.085261270403862
[2025-03-20 15:57:05,015][model][INFO] - Training step 40000 loss 0.045530110597610474
[2025-03-20 15:58:25,083][model][INFO] - Training step 40160 loss 0.04933164268732071
[2025-03-20 15:59:43,589][model][INFO] - Training step 40320 loss 0.23660019040107727
[2025-03-20 16:01:04,216][model][INFO] - Training step 40480 loss 0.06317199766635895
[2025-03-20 16:02:25,195][model][INFO] - Training step 40640 loss 0.04196587949991226
[2025-03-20 16:03:46,271][model][INFO] - Training step 40800 loss 0.017405332997441292
[2025-03-20 16:05:04,183][model][INFO] - Training step 40960 loss 0.03196091577410698
[2025-03-20 16:06:22,445][model][INFO] - Training step 41120 loss 0.004289326258003712
[2025-03-20 16:07:44,418][model][INFO] - Training step 41280 loss 0.005666645709425211
[2025-03-20 16:09:04,536][model][INFO] - Training step 41440 loss 0.0513385534286499
[2025-03-20 16:10:26,023][model][INFO] - Training step 41600 loss 0.007547159679234028
[2025-03-20 16:11:46,462][model][INFO] - Training step 41760 loss 0.01893504709005356
[2025-03-20 16:13:06,367][model][INFO] - Training step 41920 loss 0.05422501266002655
[2025-03-20 16:14:27,912][model][INFO] - Training step 42080 loss 0.014494022354483604
[2025-03-20 16:15:46,930][model][INFO] - Training step 42240 loss 0.03537557274103165
[2025-03-20 16:17:03,517][model][INFO] - Training step 42400 loss 0.03893228620290756
[2025-03-20 16:18:23,048][model][INFO] - Training step 42560 loss 0.05304360389709473
[2025-03-20 16:19:39,903][model][INFO] - Training step 42720 loss 0.02757440321147442
[2025-03-20 16:20:57,008][model][INFO] - Training step 42880 loss 0.036913689225912094
[2025-03-20 16:22:17,031][model][INFO] - Training step 43040 loss 0.024958103895187378
[2025-03-20 16:23:37,437][model][INFO] - Training step 43200 loss 0.32338646054267883
[2025-03-20 16:24:57,544][model][INFO] - Training step 43360 loss 0.04440984129905701
[2025-03-20 16:26:18,435][model][INFO] - Training step 43520 loss 0.029722891747951508
[2025-03-20 16:27:40,004][model][INFO] - Training step 43680 loss 0.003156680380925536
[2025-03-20 16:29:01,489][model][INFO] - Training step 43840 loss 0.1828022301197052
[2025-03-20 16:30:20,730][model][INFO] - Training step 44000 loss 0.04861598461866379
[2025-03-20 16:31:42,430][model][INFO] - Training step 44160 loss 0.015165518969297409
[2025-03-20 16:33:05,091][model][INFO] - Training step 44320 loss 0.10112379491329193
[2025-03-20 16:34:23,664][model][INFO] - Training step 44480 loss 0.26388484239578247
[2025-03-20 16:35:41,293][model][INFO] - Training step 44640 loss 0.25891345739364624
[2025-03-20 16:37:01,632][model][INFO] - Training step 44800 loss 0.25136739015579224
[2025-03-20 16:38:21,144][model][INFO] - Training step 44960 loss 0.23519814014434814
[2025-03-20 16:39:39,434][model][INFO] - Training step 45120 loss 0.050227731466293335
[2025-03-20 16:41:00,118][model][INFO] - Training step 45280 loss 0.01133785117417574
[2025-03-20 16:42:21,642][model][INFO] - Training step 45440 loss 0.006794858258217573
[2025-03-20 16:43:41,040][model][INFO] - Training step 45600 loss 0.028247177600860596
[2025-03-20 16:45:04,227][model][INFO] - Training step 45760 loss 0.03734033554792404
[2025-03-20 16:46:24,662][model][INFO] - Training step 45920 loss 0.033858880400657654
[2025-03-20 16:47:45,196][model][INFO] - Training step 46080 loss 0.028996745124459267
[2025-03-20 16:49:03,885][model][INFO] - Training step 46240 loss 0.2481699436903
[2025-03-20 16:50:22,839][model][INFO] - Training step 46400 loss 0.020606473088264465
[2025-03-20 16:51:38,061][model][INFO] - Training step 46560 loss 0.02728346735239029
[2025-03-20 16:52:57,258][model][INFO] - Training step 46720 loss 0.2460460364818573
[2025-03-20 16:54:15,755][model][INFO] - Training step 46880 loss 0.006630327086895704
[2025-03-20 16:55:36,624][model][INFO] - Training step 47040 loss 0.002914179116487503
[2025-03-20 16:56:56,688][model][INFO] - Training step 47200 loss 0.03286441043019295
[2025-03-20 16:58:18,610][model][INFO] - Training step 47360 loss 0.02666722983121872
[2025-03-20 16:59:39,477][model][INFO] - Training step 47520 loss 0.005913831293582916
[2025-03-20 17:00:59,149][model][INFO] - Training step 47680 loss 0.005838788580149412
[2025-03-20 17:02:17,030][model][INFO] - Training step 47840 loss 0.03199109435081482
[2025-03-20 17:03:37,521][model][INFO] - Training step 48000 loss 0.10546822845935822
[2025-03-20 17:04:58,137][model][INFO] - Training step 48160 loss 0.024612579494714737
[2025-03-20 17:06:15,418][model][INFO] - Training step 48320 loss 0.12899436056613922
[2025-03-20 17:07:34,034][model][INFO] - Training step 48480 loss 0.2469533085823059
[2025-03-20 17:08:54,040][model][INFO] - Training step 48640 loss 0.03348828852176666
[2025-03-20 17:10:15,491][model][INFO] - Training step 48800 loss 0.034627918154001236
[2025-03-20 17:11:32,607][model][INFO] - Training step 48960 loss 0.08925552666187286
[2025-03-20 17:12:50,709][model][INFO] - Training step 49120 loss 0.023219328373670578
[2025-03-20 17:14:12,674][model][INFO] - Training step 49280 loss 0.03191196173429489
[2025-03-20 17:15:30,563][model][INFO] - Training step 49440 loss 0.02911100909113884
[2025-03-20 17:16:49,627][model][INFO] - Training step 49600 loss 0.03779584914445877
[2025-03-20 17:18:07,334][model][INFO] - Training step 49760 loss 0.26214706897735596
[2025-03-20 17:19:27,354][model][INFO] - Training step 49920 loss 0.022596541792154312
[2025-03-20 17:20:48,083][model][INFO] - Training step 50080 loss 0.02836725302040577
[2025-03-20 17:22:07,230][model][INFO] - Training step 50240 loss 0.016977904364466667
[2025-03-20 17:23:24,779][model][INFO] - Training step 50400 loss 0.031811557710170746
[2025-03-20 17:24:45,594][model][INFO] - Training step 50560 loss 0.03274661302566528
[2025-03-20 17:26:06,356][model][INFO] - Training step 50720 loss 0.027917049825191498
[2025-03-20 17:35:44,598][model][INFO] - Training step 80 loss 0.1160338819026947
[2025-03-20 17:37:06,140][model][INFO] - Training step 240 loss 0.03223574534058571
[2025-03-20 17:38:28,183][model][INFO] - Training step 400 loss 0.04549937695264816
[2025-03-20 17:39:45,649][model][INFO] - Training step 560 loss 0.027912378311157227
[2025-03-20 17:41:05,950][model][INFO] - Training step 720 loss 0.05051324889063835
[2025-03-20 17:42:26,366][model][INFO] - Training step 880 loss 0.033732011914253235
[2025-03-20 17:43:44,854][model][INFO] - Training step 1040 loss 0.25127846002578735
[2025-03-20 17:45:04,718][model][INFO] - Training step 1200 loss 0.006214774213731289
[2025-03-20 17:46:23,862][model][INFO] - Training step 1360 loss 0.16419851779937744
[2025-03-20 17:47:43,353][model][INFO] - Training step 1520 loss 0.24927207827568054
[2025-03-20 17:49:04,797][model][INFO] - Training step 1680 loss 0.2514136731624603
[2025-03-20 17:50:25,874][model][INFO] - Training step 1840 loss 0.253878116607666
[2025-03-20 17:51:49,692][model][INFO] - Training step 2000 loss 0.25363561511039734
[2025-03-20 17:53:09,212][model][INFO] - Training step 2160 loss 0.019800912588834763
[2025-03-20 17:54:29,439][model][INFO] - Training step 2320 loss 0.029732637107372284
[2025-03-20 17:55:47,259][model][INFO] - Training step 2480 loss 0.04472312331199646
[2025-03-20 17:57:05,834][model][INFO] - Training step 2640 loss 0.03542143851518631
[2025-03-20 17:58:24,206][model][INFO] - Training step 2800 loss 0.03632783144712448
[2025-03-20 17:59:45,123][model][INFO] - Training step 2960 loss 0.006762358359992504
[2025-03-20 18:01:05,297][model][INFO] - Training step 3120 loss 0.24609604477882385
[2025-03-20 18:02:23,364][model][INFO] - Training step 3280 loss 0.21797150373458862
[2025-03-20 18:03:46,778][model][INFO] - Training step 3440 loss 0.03658690303564072
[2025-03-20 18:05:06,535][model][INFO] - Training step 3600 loss 0.02304614894092083
[2025-03-20 18:06:23,309][model][INFO] - Training step 3760 loss 0.025522615760564804
[2025-03-20 18:07:42,974][model][INFO] - Training step 3920 loss 0.0159774050116539
[2025-03-20 18:09:04,208][model][INFO] - Training step 4080 loss 0.030015617609024048
[2025-03-20 18:10:24,423][model][INFO] - Training step 4240 loss 0.25026217103004456
[2025-03-20 18:11:43,939][model][INFO] - Training step 4400 loss 0.0910460501909256
[2025-03-20 18:13:03,953][model][INFO] - Training step 4560 loss 0.005275976378470659
[2025-03-20 18:14:27,541][model][INFO] - Training step 4720 loss 0.006013616919517517
[2025-03-20 18:15:46,483][model][INFO] - Training step 4880 loss 0.04346534237265587
[2025-03-20 18:17:04,247][model][INFO] - Training step 5040 loss 0.13399814069271088
[2025-03-20 18:18:23,091][model][INFO] - Training step 5200 loss 0.005817367695271969
[2025-03-20 18:19:44,098][model][INFO] - Training step 5360 loss 0.05492856353521347
[2025-03-20 18:21:02,414][model][INFO] - Training step 5520 loss 0.04665786772966385
[2025-03-20 18:22:20,821][model][INFO] - Training step 5680 loss 0.022234207019209862
[2025-03-20 18:23:40,386][model][INFO] - Training step 5840 loss 0.026067368686199188
[2025-03-20 18:24:58,673][model][INFO] - Training step 6000 loss 0.004123002290725708
[2025-03-20 18:26:17,560][model][INFO] - Training step 6160 loss 0.17466917634010315
[2025-03-20 18:27:38,746][model][INFO] - Training step 6320 loss 0.041222669184207916
[2025-03-20 18:29:00,365][model][INFO] - Training step 6480 loss 0.041905149817466736
[2025-03-20 18:30:19,413][model][INFO] - Training step 6640 loss 0.010610598139464855
[2025-03-20 18:31:40,360][model][INFO] - Training step 6800 loss 0.02010834403336048
[2025-03-20 18:32:59,885][model][INFO] - Training step 6960 loss 0.03885333240032196
[2025-03-20 18:34:20,134][model][INFO] - Training step 7120 loss 0.06083320826292038
[2025-03-20 18:35:41,372][model][INFO] - Training step 7280 loss 0.030093654990196228
[2025-03-20 18:37:00,296][model][INFO] - Training step 7440 loss 0.02136579528450966
[2025-03-20 18:38:19,973][model][INFO] - Training step 7600 loss 0.03324250131845474
[2025-03-20 18:39:39,141][model][INFO] - Training step 7760 loss 0.031573280692100525
[2025-03-20 18:41:01,117][model][INFO] - Training step 7920 loss 0.24244269728660583
[2025-03-20 18:42:21,553][model][INFO] - Training step 8080 loss 0.09811870008707047
[2025-03-20 18:43:39,944][model][INFO] - Training step 8240 loss 0.03169317543506622
[2025-03-20 18:44:59,302][model][INFO] - Training step 8400 loss 0.24531526863574982
[2025-03-20 18:46:20,274][model][INFO] - Training step 8560 loss 0.006264717783778906
[2025-03-20 18:47:39,992][model][INFO] - Training step 8720 loss 0.0471431240439415
[2025-03-20 18:48:59,560][model][INFO] - Training step 8880 loss 0.02864886447787285
[2025-03-20 18:50:18,209][model][INFO] - Training step 9040 loss 0.10850763320922852
[2025-03-20 18:51:35,150][model][INFO] - Training step 9200 loss 0.004986532963812351
[2025-03-20 18:52:53,571][model][INFO] - Training step 9360 loss 0.06686221063137054
[2025-03-20 18:54:15,720][model][INFO] - Training step 9520 loss 0.018061287701129913
[2025-03-20 18:55:36,175][model][INFO] - Training step 9680 loss 0.04501120001077652
[2025-03-20 18:56:57,285][model][INFO] - Training step 9840 loss 0.053222596645355225
[2025-03-20 18:58:20,039][model][INFO] - Training step 10000 loss 0.007656784262508154
[2025-03-20 18:59:38,085][model][INFO] - Training step 10160 loss 0.02062245085835457
[2025-03-20 19:00:55,591][model][INFO] - Training step 10320 loss 0.2669535279273987
[2025-03-20 19:02:15,767][model][INFO] - Training step 10480 loss 0.04831822216510773
[2025-03-20 19:03:32,737][model][INFO] - Training step 10640 loss 0.03605026751756668
[2025-03-20 19:04:49,971][model][INFO] - Training step 10800 loss 0.041356101632118225
[2025-03-20 19:06:13,183][model][INFO] - Training step 10960 loss 0.00839230976998806
[2025-03-20 19:07:33,763][model][INFO] - Training step 11120 loss 0.2577901780605316
[2025-03-20 19:08:50,588][model][INFO] - Training step 11280 loss 0.031282249838113785
[2025-03-20 19:10:09,035][model][INFO] - Training step 11440 loss 0.06405270099639893
[2025-03-20 19:11:28,640][model][INFO] - Training step 11600 loss 0.017590612173080444
[2025-03-20 19:12:48,542][model][INFO] - Training step 11760 loss 0.17796283960342407
[2025-03-20 19:14:08,083][model][INFO] - Training step 11920 loss 0.004204694181680679
[2025-03-20 19:15:29,438][model][INFO] - Training step 12080 loss 0.13534268736839294
[2025-03-20 19:16:47,662][model][INFO] - Training step 12240 loss 0.05966363474726677
[2025-03-20 19:18:05,353][model][INFO] - Training step 12400 loss 0.2456895262002945
[2025-03-20 19:19:24,612][model][INFO] - Training step 12560 loss 0.07580794394016266
[2025-03-20 19:20:43,836][model][INFO] - Training step 12720 loss 0.013527875766158104
[2025-03-20 19:22:03,687][model][INFO] - Training step 12880 loss 0.02340121380984783
[2025-03-20 19:23:21,980][model][INFO] - Training step 13040 loss 0.037455786019563675
[2025-03-20 19:24:41,808][model][INFO] - Training step 13200 loss 0.03851098567247391
[2025-03-20 19:25:58,762][model][INFO] - Training step 13360 loss 0.07692238688468933
[2025-03-20 19:27:19,588][model][INFO] - Training step 13520 loss 0.18713140487670898
[2025-03-20 19:28:40,772][model][INFO] - Training step 13680 loss 0.018533803522586823
[2025-03-20 19:29:57,942][model][INFO] - Training step 13840 loss 0.12488365173339844
[2025-03-20 19:31:18,900][model][INFO] - Training step 14000 loss 0.2509796619415283
[2025-03-20 19:32:37,445][model][INFO] - Training step 14160 loss 0.03537888079881668
[2025-03-20 19:33:55,337][model][INFO] - Training step 14320 loss 0.027590833604335785
[2025-03-20 19:35:13,388][model][INFO] - Training step 14480 loss 0.006589577533304691
[2025-03-20 19:36:33,778][model][INFO] - Training step 14640 loss 0.003530403831973672
[2025-03-20 19:37:50,125][model][INFO] - Training step 14800 loss 0.06922023743391037
[2025-03-20 19:39:11,894][model][INFO] - Training step 14960 loss 0.020087439566850662
[2025-03-20 19:40:31,237][model][INFO] - Training step 15120 loss 0.005371547304093838
[2025-03-20 19:41:52,068][model][INFO] - Training step 15280 loss 0.12567664682865143
[2025-03-20 19:43:12,900][model][INFO] - Training step 15440 loss 0.01894398406147957
[2025-03-20 19:44:34,234][model][INFO] - Training step 15600 loss 0.003680657362565398
[2025-03-20 19:45:55,647][model][INFO] - Training step 15760 loss 0.056316595524549484
[2025-03-20 19:47:14,360][model][INFO] - Training step 15920 loss 0.036759600043296814
[2025-03-20 19:48:33,767][model][INFO] - Training step 16080 loss 0.022206690162420273
[2025-03-20 19:49:51,690][model][INFO] - Training step 16240 loss 0.1556161791086197
[2025-03-20 19:51:09,164][model][INFO] - Training step 16400 loss 0.05802200362086296
[2025-03-20 19:52:26,473][model][INFO] - Training step 16560 loss 0.047529496252536774
[2025-03-20 19:53:44,505][model][INFO] - Training step 16720 loss 0.2567982077598572
[2025-03-20 19:55:04,835][model][INFO] - Training step 16880 loss 0.02411499246954918
[2025-03-20 19:56:24,934][model][INFO] - Training step 17040 loss 0.01867097243666649
[2025-03-20 19:57:45,178][model][INFO] - Training step 17200 loss 0.06215565651655197
[2025-03-20 19:59:03,608][model][INFO] - Training step 17360 loss 0.08645036816596985
[2025-03-20 20:00:23,376][model][INFO] - Training step 17520 loss 0.044410835951566696
[2025-03-20 20:01:42,972][model][INFO] - Training step 17680 loss 0.04704776406288147
[2025-03-20 20:03:00,736][model][INFO] - Training step 17840 loss 0.04739106446504593
[2025-03-20 20:04:19,355][model][INFO] - Training step 18000 loss 0.03901522979140282
[2025-03-20 20:05:38,525][model][INFO] - Training step 18160 loss 0.052954625338315964
[2025-03-20 20:07:00,101][model][INFO] - Training step 18320 loss 0.028632018715143204
[2025-03-20 20:08:20,356][model][INFO] - Training step 18480 loss 0.2847253084182739
[2025-03-20 20:09:39,758][model][INFO] - Training step 18640 loss 0.007020718418061733
[2025-03-20 20:11:02,173][model][INFO] - Training step 18800 loss 0.017251010984182358
[2025-03-20 20:12:21,679][model][INFO] - Training step 18960 loss 0.07734496891498566
[2025-03-20 20:13:38,907][model][INFO] - Training step 19120 loss 0.046219609677791595
[2025-03-20 20:14:58,157][model][INFO] - Training step 19280 loss 0.0348241962492466
[2025-03-20 20:16:15,145][model][INFO] - Training step 19440 loss 0.03842984512448311
[2025-03-20 20:17:35,634][model][INFO] - Training step 19600 loss 0.11178833246231079
[2025-03-20 20:18:57,541][model][INFO] - Training step 19760 loss 0.036816760897636414
[2025-03-20 20:20:19,022][model][INFO] - Training step 19920 loss 0.08536551892757416
[2025-03-20 20:21:40,887][model][INFO] - Training step 20080 loss 0.2595677375793457
[2025-03-20 20:22:58,071][model][INFO] - Training step 20240 loss 0.25536417961120605
[2025-03-20 20:24:15,579][model][INFO] - Training step 20400 loss 0.06348693370819092
[2025-03-20 20:25:35,875][model][INFO] - Training step 20560 loss 0.031177273020148277
[2025-03-20 20:26:58,508][model][INFO] - Training step 20720 loss 0.153195321559906
[2025-03-20 20:28:18,061][model][INFO] - Training step 20880 loss 0.13991448283195496
[2025-03-20 20:29:39,918][model][INFO] - Training step 21040 loss 0.03713612258434296
[2025-03-20 20:31:01,907][model][INFO] - Training step 21200 loss 0.029485667124390602
[2025-03-20 20:32:18,372][model][INFO] - Training step 21360 loss 0.11610890179872513
[2025-03-20 20:33:41,818][model][INFO] - Training step 21520 loss 0.0404275581240654
[2025-03-20 20:35:04,264][model][INFO] - Training step 21680 loss 0.0021021428983658552
[2025-03-20 20:36:24,982][model][INFO] - Training step 21840 loss 0.032462723553180695
[2025-03-20 20:37:43,256][model][INFO] - Training step 22000 loss 0.03856223449110985
[2025-03-20 20:39:05,547][model][INFO] - Training step 22160 loss 0.05241096019744873
[2025-03-20 20:40:26,872][model][INFO] - Training step 22320 loss 0.02968667820096016
[2025-03-20 20:41:49,525][model][INFO] - Training step 22480 loss 0.012826955877244473
[2025-03-20 20:43:09,814][model][INFO] - Training step 22640 loss 0.054136358201503754
[2025-03-20 20:44:28,311][model][INFO] - Training step 22800 loss 0.02535705640912056
[2025-03-20 20:45:48,075][model][INFO] - Training step 22960 loss 0.024791229516267776
[2025-03-20 20:47:09,493][model][INFO] - Training step 23120 loss 0.0058417911641299725
[2025-03-20 20:48:30,141][model][INFO] - Training step 23280 loss 0.05178898200392723
[2025-03-20 20:49:49,456][model][INFO] - Training step 23440 loss 0.05486918240785599
[2025-03-20 20:51:12,316][model][INFO] - Training step 23600 loss 0.058118291199207306
[2025-03-20 20:52:28,325][model][INFO] - Training step 23760 loss 0.04093850404024124
[2025-03-20 20:53:48,300][model][INFO] - Training step 23920 loss 0.04289120435714722
[2025-03-20 20:55:08,198][model][INFO] - Training step 24080 loss 0.04385661706328392
[2025-03-20 20:56:26,753][model][INFO] - Training step 24240 loss 0.026155730709433556
[2025-03-20 20:57:45,163][model][INFO] - Training step 24400 loss 0.05694445222616196
[2025-03-20 20:59:04,782][model][INFO] - Training step 24560 loss 0.21601398289203644
[2025-03-20 21:00:23,327][model][INFO] - Training step 24720 loss 0.031496547162532806
[2025-03-20 21:01:46,857][model][INFO] - Training step 24880 loss 0.07381976395845413
[2025-03-20 21:03:05,530][model][INFO] - Training step 25040 loss 0.07910504937171936
[2025-03-20 21:04:22,261][model][INFO] - Training step 25200 loss 0.02308207005262375
[2025-03-20 21:05:41,373][model][INFO] - Training step 25360 loss 0.03783159703016281
[2025-03-20 21:06:59,952][model][INFO] - Training step 25520 loss 0.038890864700078964
[2025-03-20 21:08:21,902][model][INFO] - Training step 25680 loss 0.25148218870162964
[2025-03-20 21:09:40,959][model][INFO] - Training step 25840 loss 0.05915537849068642
[2025-03-20 21:11:00,293][model][INFO] - Training step 26000 loss 0.09195919334888458
[2025-03-20 21:12:19,022][model][INFO] - Training step 26160 loss 0.03364333510398865
[2025-03-20 21:13:40,226][model][INFO] - Training step 26320 loss 0.22939005494117737
[2025-03-20 21:15:01,199][model][INFO] - Training step 26480 loss 0.26678889989852905
[2025-03-20 21:16:21,430][model][INFO] - Training step 26640 loss 0.10998226702213287
[2025-03-20 21:17:40,221][model][INFO] - Training step 26800 loss 0.014722065068781376
[2025-03-20 21:18:57,505][model][INFO] - Training step 26960 loss 0.010893475264310837
[2025-03-20 21:20:17,726][model][INFO] - Training step 27120 loss 0.024592865258455276
[2025-03-20 21:21:37,561][model][INFO] - Training step 27280 loss 0.20807760953903198
[2025-03-20 21:22:54,786][model][INFO] - Training step 27440 loss 0.0524914488196373
[2025-03-20 21:24:11,882][model][INFO] - Training step 27600 loss 0.05901350453495979
[2025-03-20 21:25:30,468][model][INFO] - Training step 27760 loss 0.0361131876707077
[2025-03-20 21:26:46,780][model][INFO] - Training step 27920 loss 0.2664085626602173
[2025-03-20 21:28:06,864][model][INFO] - Training step 28080 loss 0.045210100710392
[2025-03-20 21:29:22,822][model][INFO] - Training step 28240 loss 0.0155254565179348
[2025-03-20 21:30:41,938][model][INFO] - Training step 28400 loss 0.09985316544771194
[2025-03-20 21:32:04,459][model][INFO] - Training step 28560 loss 0.14940151572227478
[2025-03-20 21:33:23,328][model][INFO] - Training step 28720 loss 0.016467906534671783
[2025-03-20 21:34:43,654][model][INFO] - Training step 28880 loss 0.13772805035114288
[2025-03-20 21:36:03,126][model][INFO] - Training step 29040 loss 0.025945089757442474
[2025-03-20 21:37:20,533][model][INFO] - Training step 29200 loss 0.24054981768131256
[2025-03-20 21:38:41,012][model][INFO] - Training step 29360 loss 0.026702620089054108
[2025-03-20 21:40:01,317][model][INFO] - Training step 29520 loss 0.2593457102775574
[2025-03-20 21:41:21,248][model][INFO] - Training step 29680 loss 0.08310894668102264
[2025-03-20 21:42:38,451][model][INFO] - Training step 29840 loss 0.04296542704105377
[2025-03-20 21:43:57,928][model][INFO] - Training step 30000 loss 0.053825244307518005
[2025-03-20 21:45:16,782][model][INFO] - Training step 30160 loss 0.06015114113688469
[2025-03-20 21:46:39,578][model][INFO] - Training step 30320 loss 0.028389286249876022
[2025-03-20 21:47:57,205][model][INFO] - Training step 30480 loss 0.08315451443195343
[2025-03-20 21:49:10,232][model][INFO] - Training step 30640 loss 0.033750973641872406
[2025-03-20 21:50:26,985][model][INFO] - Training step 30800 loss 0.12769892811775208
[2025-03-20 21:51:46,639][model][INFO] - Training step 30960 loss 0.013261089101433754
[2025-03-20 21:53:05,898][model][INFO] - Training step 31120 loss 0.05521925538778305
[2025-03-20 21:54:22,793][model][INFO] - Training step 31280 loss 0.07325972616672516
[2025-03-20 21:55:44,231][model][INFO] - Training step 31440 loss 0.08168990910053253
[2025-03-20 21:57:03,885][model][INFO] - Training step 31600 loss 0.004776572342962027
[2025-03-20 21:58:23,871][model][INFO] - Training step 31760 loss 0.04518992081284523
[2025-03-20 21:59:43,936][model][INFO] - Training step 31920 loss 0.03348995000123978
[2025-03-20 22:01:02,098][model][INFO] - Training step 32080 loss 0.02644483372569084
[2025-03-20 22:02:23,060][model][INFO] - Training step 32240 loss 0.002428492996841669
[2025-03-20 22:03:43,721][model][INFO] - Training step 32400 loss 0.0349828265607357
[2025-03-20 22:05:01,268][model][INFO] - Training step 32560 loss 0.03482896089553833
[2025-03-20 22:06:23,127][model][INFO] - Training step 32720 loss 0.022805392742156982
[2025-03-20 22:07:49,113][model][INFO] - Training step 32880 loss 0.03606121987104416
[2025-03-20 22:09:08,534][model][INFO] - Training step 33040 loss 0.02949976548552513
[2025-03-20 22:10:29,919][model][INFO] - Training step 33200 loss 0.025811875239014626
[2025-03-20 22:11:48,667][model][INFO] - Training step 33360 loss 0.03693991154432297
[2025-03-20 22:13:07,752][model][INFO] - Training step 33520 loss 0.05731819570064545
[2025-03-20 22:14:29,166][model][INFO] - Training step 33680 loss 0.24781718850135803
[2025-03-20 22:15:45,537][model][INFO] - Training step 33840 loss 0.021766815334558487
[2025-03-20 22:17:06,669][model][INFO] - Training step 34000 loss 0.032754600048065186
[2025-03-20 22:18:30,420][model][INFO] - Training step 34160 loss 0.06182866171002388
[2025-03-20 22:19:49,298][model][INFO] - Training step 34320 loss 0.2516149580478668
[2025-03-20 22:21:12,873][model][INFO] - Training step 34480 loss 0.0987473577260971
[2025-03-20 22:22:33,828][model][INFO] - Training step 34640 loss 0.0438949316740036
[2025-03-20 22:23:53,285][model][INFO] - Training step 34800 loss 0.26839131116867065
[2025-03-20 22:25:14,307][model][INFO] - Training step 34960 loss 0.06885488331317902
[2025-03-20 22:26:32,161][model][INFO] - Training step 35120 loss 0.28921520709991455
[2025-03-20 22:27:54,235][model][INFO] - Training step 35280 loss 0.2600215673446655
[2025-03-20 22:29:15,924][model][INFO] - Training step 35440 loss 0.2540047764778137
[2025-03-20 22:30:36,735][model][INFO] - Training step 35600 loss 0.05641063302755356
[2025-03-20 22:31:55,161][model][INFO] - Training step 35760 loss 0.24693134427070618
[2025-03-20 22:33:12,045][model][INFO] - Training step 35920 loss 0.05656442791223526
[2025-03-20 22:34:32,390][model][INFO] - Training step 36080 loss 0.087662473320961
[2025-03-20 22:35:53,461][model][INFO] - Training step 36240 loss 0.2564023733139038
[2025-03-20 22:37:13,398][model][INFO] - Training step 36400 loss 0.2617783546447754
[2025-03-20 22:38:32,657][model][INFO] - Training step 36560 loss 0.004522915929555893
[2025-03-20 22:39:52,408][model][INFO] - Training step 36720 loss 0.010234433226287365
[2025-03-20 22:41:13,800][model][INFO] - Training step 36880 loss 0.35366690158843994
[2025-03-20 22:42:37,568][model][INFO] - Training step 37040 loss 0.01923433691263199
[2025-03-20 22:43:57,916][model][INFO] - Training step 37200 loss 0.24168801307678223
[2025-03-20 22:45:17,004][model][INFO] - Training step 37360 loss 0.008336675353348255
[2025-03-20 22:46:39,569][model][INFO] - Training step 37520 loss 0.02712083049118519
[2025-03-20 22:47:57,343][model][INFO] - Training step 37680 loss 0.059975527226924896
[2025-03-20 22:49:17,822][model][INFO] - Training step 37840 loss 0.038947366178035736
[2025-03-20 22:50:36,054][model][INFO] - Training step 38000 loss 0.24343827366828918
[2025-03-20 22:51:54,522][model][INFO] - Training step 38160 loss 0.010501435026526451
[2025-03-20 22:53:14,699][model][INFO] - Training step 38320 loss 0.035853855311870575
[2025-03-20 22:54:33,451][model][INFO] - Training step 38480 loss 0.0627375915646553
[2025-03-20 22:55:54,358][model][INFO] - Training step 38640 loss 0.035108380019664764
[2025-03-20 22:57:12,516][model][INFO] - Training step 38800 loss 0.06833993643522263
[2025-03-20 22:58:33,177][model][INFO] - Training step 38960 loss 0.028594329953193665
[2025-03-20 22:59:54,440][model][INFO] - Training step 39120 loss 0.004202519543468952
[2025-03-20 23:01:12,949][model][INFO] - Training step 39280 loss 0.05431857705116272
[2025-03-20 23:02:33,341][model][INFO] - Training step 39440 loss 0.0014455387135967612
[2025-03-20 23:03:54,028][model][INFO] - Training step 39600 loss 0.024082070216536522
[2025-03-20 23:05:13,100][model][INFO] - Training step 39760 loss 0.15356352925300598
[2025-03-20 23:06:32,145][model][INFO] - Training step 39920 loss 0.02842785231769085
[2025-03-20 23:07:51,609][model][INFO] - Training step 40080 loss 0.031140532344579697
[2025-03-20 23:09:11,880][model][INFO] - Training step 40240 loss 0.04869922250509262
[2025-03-20 23:10:32,637][model][INFO] - Training step 40400 loss 0.25253796577453613
[2025-03-20 23:11:55,580][model][INFO] - Training step 40560 loss 0.03503705561161041
[2025-03-20 23:13:14,855][model][INFO] - Training step 40720 loss 0.04125651717185974
[2025-03-20 23:14:34,763][model][INFO] - Training step 40880 loss 0.017610536888241768
[2025-03-20 23:15:53,068][model][INFO] - Training step 41040 loss 0.22222530841827393
[2025-03-20 23:17:12,531][model][INFO] - Training step 41200 loss 0.01517064031213522
[2025-03-20 23:18:34,035][model][INFO] - Training step 41360 loss 0.21887095272541046
[2025-03-20 23:19:52,482][model][INFO] - Training step 41520 loss 0.03815902769565582
[2025-03-20 23:21:12,164][model][INFO] - Training step 41680 loss 0.29125863313674927
[2025-03-20 23:22:30,603][model][INFO] - Training step 41840 loss 0.01918710395693779
[2025-03-20 23:23:50,701][model][INFO] - Training step 42000 loss 0.05508803948760033
[2025-03-20 23:25:11,805][model][INFO] - Training step 42160 loss 0.058913249522447586
[2025-03-20 23:26:30,132][model][INFO] - Training step 42320 loss 0.017888901755213737
[2025-03-20 23:27:55,867][model][INFO] - Training step 42480 loss 0.003750026226043701
[2025-03-20 23:29:12,709][model][INFO] - Training step 42640 loss 0.23199531435966492
[2025-03-20 23:30:31,097][model][INFO] - Training step 42800 loss 0.03182246536016464
[2025-03-20 23:31:52,379][model][INFO] - Training step 42960 loss 0.020918184891343117
[2025-03-20 23:33:13,211][model][INFO] - Training step 43120 loss 0.05461355298757553
[2025-03-20 23:34:33,842][model][INFO] - Training step 43280 loss 0.24811461567878723
[2025-03-20 23:35:56,459][model][INFO] - Training step 43440 loss 0.005331703927367926
[2025-03-20 23:37:15,788][model][INFO] - Training step 43600 loss 0.07909484207630157
[2025-03-20 23:38:34,198][model][INFO] - Training step 43760 loss 0.23359549045562744
[2025-03-20 23:39:54,590][model][INFO] - Training step 43920 loss 0.11056169867515564
[2025-03-20 23:41:11,300][model][INFO] - Training step 44080 loss 0.24370431900024414
[2025-03-20 23:42:30,825][model][INFO] - Training step 44240 loss 0.01112588681280613
[2025-03-20 23:43:53,475][model][INFO] - Training step 44400 loss 0.012365620583295822
[2025-03-20 23:45:10,694][model][INFO] - Training step 44560 loss 0.010986099019646645
[2025-03-20 23:46:31,163][model][INFO] - Training step 44720 loss 0.03052464872598648
[2025-03-20 23:47:47,266][model][INFO] - Training step 44880 loss 0.25721967220306396
[2025-03-20 23:49:06,268][model][INFO] - Training step 45040 loss 0.03131551295518875
[2025-03-20 23:50:24,109][model][INFO] - Training step 45200 loss 0.015806928277015686
[2025-03-20 23:51:44,477][model][INFO] - Training step 45360 loss 0.08812077343463898
[2025-03-20 23:53:05,676][model][INFO] - Training step 45520 loss 0.03763961419463158
[2025-03-20 23:54:25,289][model][INFO] - Training step 45680 loss 0.019215945154428482
[2025-03-20 23:55:47,224][model][INFO] - Training step 45840 loss 0.07886789739131927
[2025-03-20 23:57:04,706][model][INFO] - Training step 46000 loss 0.0027914918027818203
[2025-03-20 23:58:24,689][model][INFO] - Training step 46160 loss 0.037833698093891144
[2025-03-20 23:59:44,029][model][INFO] - Training step 46320 loss 0.2490263283252716
[2025-03-21 00:01:04,385][model][INFO] - Training step 46480 loss 0.012677861377596855
[2025-03-21 00:02:24,324][model][INFO] - Training step 46640 loss 0.04816340282559395
[2025-03-21 00:03:44,609][model][INFO] - Training step 46800 loss 0.03290097415447235
[2025-03-21 00:05:03,552][model][INFO] - Training step 46960 loss 0.0023429261054843664
[2025-03-21 00:06:21,218][model][INFO] - Training step 47120 loss 0.06607197970151901
[2025-03-21 00:07:43,959][model][INFO] - Training step 47280 loss 0.022144483402371407
[2025-03-21 00:09:02,879][model][INFO] - Training step 47440 loss 0.02168162167072296
[2025-03-21 00:10:21,306][model][INFO] - Training step 47600 loss 0.058574117720127106
[2025-03-21 00:11:42,926][model][INFO] - Training step 47760 loss 0.24209924042224884
[2025-03-21 00:13:01,965][model][INFO] - Training step 47920 loss 0.03549864515662193
[2025-03-21 00:14:18,544][model][INFO] - Training step 48080 loss 0.04998753219842911
[2025-03-21 00:15:37,760][model][INFO] - Training step 48240 loss 0.0241167601197958
[2025-03-21 00:16:58,923][model][INFO] - Training step 48400 loss 0.0762983113527298
[2025-03-21 00:18:17,357][model][INFO] - Training step 48560 loss 0.06099331006407738
[2025-03-21 00:19:37,213][model][INFO] - Training step 48720 loss 0.030734499916434288
[2025-03-21 00:20:56,357][model][INFO] - Training step 48880 loss 0.01367886457592249
[2025-03-21 00:22:15,599][model][INFO] - Training step 49040 loss 0.23669402301311493
[2025-03-21 00:23:37,761][model][INFO] - Training step 49200 loss 0.023703675717115402
[2025-03-21 00:24:56,551][model][INFO] - Training step 49360 loss 0.05863439291715622
[2025-03-21 00:26:18,116][model][INFO] - Training step 49520 loss 0.006442726589739323
[2025-03-21 00:27:36,236][model][INFO] - Training step 49680 loss 0.012017603032290936
[2025-03-21 00:28:54,836][model][INFO] - Training step 49840 loss 0.2990635633468628
[2025-03-21 00:30:13,702][model][INFO] - Training step 50000 loss 0.25716736912727356
[2025-03-21 00:31:35,313][model][INFO] - Training step 50160 loss 0.0171417985111475
[2025-03-21 00:32:56,543][model][INFO] - Training step 50320 loss 0.23175999522209167
[2025-03-21 00:34:16,820][model][INFO] - Training step 50480 loss 0.010650040581822395
[2025-03-21 00:35:36,425][model][INFO] - Training step 50640 loss 0.11777083575725555
[2025-03-21 00:45:05,314][model][INFO] - Training step 0 loss 0.2418595850467682
[2025-03-21 00:46:25,453][model][INFO] - Training step 160 loss 0.036467794328927994
[2025-03-21 00:47:49,967][model][INFO] - Training step 320 loss 0.029513444751501083
[2025-03-21 00:49:09,737][model][INFO] - Training step 480 loss 0.24501854181289673
[2025-03-21 00:50:25,620][model][INFO] - Training step 640 loss 0.03608303517103195
[2025-03-21 00:51:45,501][model][INFO] - Training step 800 loss 0.0629388689994812
[2025-03-21 00:53:04,765][model][INFO] - Training step 960 loss 0.024329572916030884
[2025-03-21 00:54:24,427][model][INFO] - Training step 1120 loss 0.1395963579416275
[2025-03-21 00:55:45,128][model][INFO] - Training step 1280 loss 0.03573831170797348
[2025-03-21 00:57:03,038][model][INFO] - Training step 1440 loss 0.09786070883274078
[2025-03-21 00:58:24,981][model][INFO] - Training step 1600 loss 0.049624472856521606
[2025-03-21 00:59:45,415][model][INFO] - Training step 1760 loss 0.09535769373178482
[2025-03-21 01:01:04,100][model][INFO] - Training step 1920 loss 0.2544439136981964
[2025-03-21 01:02:24,539][model][INFO] - Training step 2080 loss 0.006786925718188286
[2025-03-21 01:03:44,029][model][INFO] - Training step 2240 loss 0.2552216053009033
[2025-03-21 01:04:59,370][model][INFO] - Training step 2400 loss 0.2566114664077759
[2025-03-21 01:06:17,588][model][INFO] - Training step 2560 loss 0.1029156744480133
[2025-03-21 01:07:38,208][model][INFO] - Training step 2720 loss 0.2456054389476776
[2025-03-21 01:08:56,988][model][INFO] - Training step 2880 loss 0.02736217901110649
[2025-03-21 01:10:15,214][model][INFO] - Training step 3040 loss 0.007139056921005249
[2025-03-21 01:11:33,226][model][INFO] - Training step 3200 loss 0.014716384001076221
[2025-03-21 01:12:53,780][model][INFO] - Training step 3360 loss 0.0058017298579216
[2025-03-21 01:14:13,195][model][INFO] - Training step 3520 loss 0.03299225866794586
[2025-03-21 01:15:33,214][model][INFO] - Training step 3680 loss 0.2464272677898407
[2025-03-21 01:16:51,049][model][INFO] - Training step 3840 loss 0.10023491084575653
[2025-03-21 01:18:10,093][model][INFO] - Training step 4000 loss 0.043530527502298355
[2025-03-21 01:19:36,279][model][INFO] - Training step 4160 loss 0.026159361004829407
[2025-03-21 01:20:55,308][model][INFO] - Training step 4320 loss 0.05309279263019562
[2025-03-21 01:22:11,594][model][INFO] - Training step 4480 loss 0.07511703670024872
[2025-03-21 01:23:30,201][model][INFO] - Training step 4640 loss 0.05540013313293457
[2025-03-21 01:24:48,717][model][INFO] - Training step 4800 loss 0.37503737211227417
[2025-03-21 01:26:05,486][model][INFO] - Training step 4960 loss 0.025889191776514053
[2025-03-21 01:27:23,699][model][INFO] - Training step 5120 loss 0.014962874352931976
[2025-03-21 01:28:41,940][model][INFO] - Training step 5280 loss 0.02076675370335579
[2025-03-21 01:29:58,946][model][INFO] - Training step 5440 loss 0.06259410083293915
[2025-03-21 01:31:15,008][model][INFO] - Training step 5600 loss 0.023365546017885208
[2025-03-21 01:32:34,834][model][INFO] - Training step 5760 loss 0.02348705753684044
[2025-03-21 01:33:54,324][model][INFO] - Training step 5920 loss 0.023645006120204926
[2025-03-21 01:35:12,794][model][INFO] - Training step 6080 loss 0.027024079114198685
[2025-03-21 01:36:32,323][model][INFO] - Training step 6240 loss 0.014315653592348099
[2025-03-21 01:37:52,586][model][INFO] - Training step 6400 loss 0.037316225469112396
[2025-03-21 01:39:09,376][model][INFO] - Training step 6560 loss 0.0295250304043293
[2025-03-21 01:40:31,704][model][INFO] - Training step 6720 loss 0.004182911477982998
[2025-03-21 01:41:49,073][model][INFO] - Training step 6880 loss 0.10993258655071259
[2025-03-21 01:43:06,145][model][INFO] - Training step 7040 loss 0.012933263555169106
[2025-03-21 01:44:26,188][model][INFO] - Training step 7200 loss 0.08780747652053833
[2025-03-21 01:45:44,880][model][INFO] - Training step 7360 loss 0.04327763617038727
[2025-03-21 01:47:04,538][model][INFO] - Training step 7520 loss 0.006890547461807728
[2025-03-21 01:48:22,596][model][INFO] - Training step 7680 loss 0.03398241102695465
[2025-03-21 01:49:44,055][model][INFO] - Training step 7840 loss 0.033995430916547775
[2025-03-21 01:51:04,617][model][INFO] - Training step 8000 loss 0.008057237602770329
[2025-03-21 01:52:21,974][model][INFO] - Training step 8160 loss 0.07192091643810272
[2025-03-21 01:53:40,472][model][INFO] - Training step 8320 loss 0.22859758138656616
[2025-03-21 01:54:57,754][model][INFO] - Training step 8480 loss 0.11591746658086777
[2025-03-21 01:56:17,233][model][INFO] - Training step 8640 loss 0.018088215962052345
[2025-03-21 01:57:35,648][model][INFO] - Training step 8800 loss 0.039773598313331604
[2025-03-21 01:58:56,729][model][INFO] - Training step 8960 loss 0.6583586931228638
[2025-03-21 02:00:15,015][model][INFO] - Training step 9120 loss 0.03503891080617905
[2025-03-21 02:01:32,180][model][INFO] - Training step 9280 loss 0.03807810693979263
[2025-03-21 02:02:53,876][model][INFO] - Training step 9440 loss 0.003788707312196493
[2025-03-21 02:04:12,936][model][INFO] - Training step 9600 loss 0.05525672435760498
[2025-03-21 02:05:30,387][model][INFO] - Training step 9760 loss 0.22961565852165222
[2025-03-21 02:06:48,154][model][INFO] - Training step 9920 loss 0.020260294899344444
[2025-03-21 02:08:08,918][model][INFO] - Training step 10080 loss 0.040317438542842865
[2025-03-21 02:09:30,637][model][INFO] - Training step 10240 loss 0.017895124852657318
[2025-03-21 02:10:49,645][model][INFO] - Training step 10400 loss 0.15284733474254608
[2025-03-21 02:12:08,434][model][INFO] - Training step 10560 loss 0.9174402952194214
[2025-03-21 02:13:27,334][model][INFO] - Training step 10720 loss 0.2509939968585968
[2025-03-21 02:14:46,395][model][INFO] - Training step 10880 loss 0.03848312795162201
[2025-03-21 02:16:05,196][model][INFO] - Training step 11040 loss 0.06804783642292023
[2025-03-21 02:17:21,866][model][INFO] - Training step 11200 loss 0.10681739449501038
[2025-03-21 02:18:42,066][model][INFO] - Training step 11360 loss 0.0481296181678772
[2025-03-21 02:19:58,162][model][INFO] - Training step 11520 loss 0.039708226919174194
[2025-03-21 02:21:16,963][model][INFO] - Training step 11680 loss 0.08725393563508987
[2025-03-21 02:22:36,060][model][INFO] - Training step 11840 loss 0.029413411393761635
[2025-03-21 02:23:56,398][model][INFO] - Training step 12000 loss 0.0024993738625198603
[2025-03-21 02:25:17,601][model][INFO] - Training step 12160 loss 0.004800856579095125
[2025-03-21 02:26:34,845][model][INFO] - Training step 12320 loss 0.03858964145183563
[2025-03-21 02:27:54,957][model][INFO] - Training step 12480 loss 0.026847384870052338
[2025-03-21 02:29:15,348][model][INFO] - Training step 12640 loss 0.051015403121709824
[2025-03-21 02:30:35,358][model][INFO] - Training step 12800 loss 0.04800674319267273
[2025-03-21 02:31:51,798][model][INFO] - Training step 12960 loss 0.04373034089803696
[2025-03-21 02:33:09,335][model][INFO] - Training step 13120 loss 0.025126181542873383
[2025-03-21 02:34:29,235][model][INFO] - Training step 13280 loss 0.015195408836007118
[2025-03-21 02:35:47,771][model][INFO] - Training step 13440 loss 0.5139927864074707
[2025-03-21 02:37:07,009][model][INFO] - Training step 13600 loss 0.2662994861602783
[2025-03-21 02:38:27,950][model][INFO] - Training step 13760 loss 0.03148052841424942
[2025-03-21 02:39:45,745][model][INFO] - Training step 13920 loss 0.06911008059978485
[2025-03-21 02:41:06,759][model][INFO] - Training step 14080 loss 0.01947987824678421
[2025-03-21 02:42:23,934][model][INFO] - Training step 14240 loss 0.07794054597616196
[2025-03-21 02:43:43,409][model][INFO] - Training step 14400 loss 0.01635473221540451
[2025-03-21 02:45:04,088][model][INFO] - Training step 14560 loss 0.0278707854449749
[2025-03-21 02:46:21,701][model][INFO] - Training step 14720 loss 0.03188055753707886
[2025-03-21 02:47:40,572][model][INFO] - Training step 14880 loss 0.0026583087164908648
[2025-03-21 02:48:59,274][model][INFO] - Training step 15040 loss 0.03301411122083664
[2025-03-21 02:50:19,267][model][INFO] - Training step 15200 loss 0.021263426169753075
[2025-03-21 02:51:39,818][model][INFO] - Training step 15360 loss 0.22671814262866974
[2025-03-21 02:53:00,205][model][INFO] - Training step 15520 loss 0.009595056995749474
[2025-03-21 02:54:20,123][model][INFO] - Training step 15680 loss 0.2759060859680176
[2025-03-21 02:55:40,757][model][INFO] - Training step 15840 loss 0.0070130424574017525
[2025-03-21 02:56:56,327][model][INFO] - Training step 16000 loss 0.10239394009113312
[2025-03-21 02:58:12,902][model][INFO] - Training step 16160 loss 0.024554185569286346
[2025-03-21 02:59:33,022][model][INFO] - Training step 16320 loss 0.04201812297105789
[2025-03-21 03:00:51,886][model][INFO] - Training step 16480 loss 0.2719060182571411
[2025-03-21 03:02:12,934][model][INFO] - Training step 16640 loss 0.03041992522776127
[2025-03-21 03:03:32,070][model][INFO] - Training step 16800 loss 0.043419599533081055
[2025-03-21 03:04:50,089][model][INFO] - Training step 16960 loss 0.039818551391363144
[2025-03-21 03:06:07,278][model][INFO] - Training step 17120 loss 0.07053195685148239
[2025-03-21 03:07:29,340][model][INFO] - Training step 17280 loss 0.02396094799041748
[2025-03-21 03:08:49,573][model][INFO] - Training step 17440 loss 0.03627719730138779
[2025-03-21 03:10:12,272][model][INFO] - Training step 17600 loss 0.26735153794288635
[2025-03-21 03:11:31,277][model][INFO] - Training step 17760 loss 0.04917270690202713
[2025-03-21 03:12:47,239][model][INFO] - Training step 17920 loss 0.02457442879676819
[2025-03-21 03:14:07,731][model][INFO] - Training step 18080 loss 0.027333373203873634
[2025-03-21 03:15:26,377][model][INFO] - Training step 18240 loss 0.13805650174617767
[2025-03-21 03:16:47,196][model][INFO] - Training step 18400 loss 0.04598952457308769
[2025-03-21 03:18:05,381][model][INFO] - Training step 18560 loss 0.2614873945713043
[2025-03-21 03:19:25,022][model][INFO] - Training step 18720 loss 0.08060324937105179
[2025-03-21 03:20:43,072][model][INFO] - Training step 18880 loss 0.264914333820343
[2025-03-21 03:22:05,339][model][INFO] - Training step 19040 loss 0.05536603555083275
[2025-03-21 03:23:26,305][model][INFO] - Training step 19200 loss 0.039476145058870316
[2025-03-21 03:24:44,071][model][INFO] - Training step 19360 loss 0.03740518167614937
[2025-03-21 03:26:04,957][model][INFO] - Training step 19520 loss 0.02593667432665825
[2025-03-21 03:27:26,313][model][INFO] - Training step 19680 loss 0.004245285876095295
[2025-03-21 03:28:43,527][model][INFO] - Training step 19840 loss 0.02488655224442482
[2025-03-21 03:30:02,515][model][INFO] - Training step 20000 loss 0.005384409334510565
[2025-03-21 03:31:22,142][model][INFO] - Training step 20160 loss 0.2517566680908203
[2025-03-21 03:32:41,292][model][INFO] - Training step 20320 loss 0.034628935158252716
[2025-03-21 03:33:59,015][model][INFO] - Training step 20480 loss 0.039901819080114365
[2025-03-21 03:35:21,704][model][INFO] - Training step 20640 loss 0.04224309325218201
[2025-03-21 03:36:40,203][model][INFO] - Training step 20800 loss 0.1096227839589119
[2025-03-21 03:37:59,325][model][INFO] - Training step 20960 loss 0.047143321484327316
[2025-03-21 03:39:20,932][model][INFO] - Training step 21120 loss 0.31458574533462524
[2025-03-21 03:40:39,889][model][INFO] - Training step 21280 loss 0.02039480395615101
[2025-03-21 03:41:57,571][model][INFO] - Training step 21440 loss 0.08126641064882278
[2025-03-21 03:43:16,790][model][INFO] - Training step 21600 loss 0.057908594608306885
[2025-03-21 03:44:35,221][model][INFO] - Training step 21760 loss 0.03291253745555878
[2025-03-21 03:45:52,862][model][INFO] - Training step 21920 loss 0.06468351185321808
[2025-03-21 03:47:14,433][model][INFO] - Training step 22080 loss 0.13446983695030212
[2025-03-21 03:48:32,965][model][INFO] - Training step 22240 loss 0.24247075617313385
[2025-03-21 03:49:54,275][model][INFO] - Training step 22400 loss 0.053879305720329285
[2025-03-21 03:51:12,628][model][INFO] - Training step 22560 loss 0.0317438468337059
[2025-03-21 03:52:31,906][model][INFO] - Training step 22720 loss 0.25713083148002625
[2025-03-21 03:53:52,704][model][INFO] - Training step 22880 loss 0.04547543451189995
[2025-03-21 03:55:13,965][model][INFO] - Training step 23040 loss 0.0037254805210977793
[2025-03-21 03:56:33,947][model][INFO] - Training step 23200 loss 0.16640859842300415
[2025-03-21 03:57:52,954][model][INFO] - Training step 23360 loss 0.07658617198467255
[2025-03-21 03:59:13,270][model][INFO] - Training step 23520 loss 0.024843741208314896
[2025-03-21 04:00:30,478][model][INFO] - Training step 23680 loss 0.04096842184662819
[2025-03-21 04:01:48,559][model][INFO] - Training step 23840 loss 0.25017356872558594
[2025-03-21 04:03:04,380][model][INFO] - Training step 24000 loss 0.03781241178512573
[2025-03-21 04:04:20,247][model][INFO] - Training step 24160 loss 0.028211943805217743
[2025-03-21 04:05:39,645][model][INFO] - Training step 24320 loss 0.028322432190179825
[2025-03-21 04:06:59,838][model][INFO] - Training step 24480 loss 0.012126702815294266
[2025-03-21 04:08:18,068][model][INFO] - Training step 24640 loss 0.04169261455535889
[2025-03-21 04:09:38,692][model][INFO] - Training step 24800 loss 0.042778223752975464
[2025-03-21 04:10:58,866][model][INFO] - Training step 24960 loss 0.054033227264881134
[2025-03-21 04:12:18,301][model][INFO] - Training step 25120 loss 0.07141634821891785
[2025-03-21 04:13:34,202][model][INFO] - Training step 25280 loss 0.20660340785980225
[2025-03-21 04:14:53,037][model][INFO] - Training step 25440 loss 0.02659222111105919
[2025-03-21 04:16:12,409][model][INFO] - Training step 25600 loss 0.06525106728076935
[2025-03-21 04:17:29,492][model][INFO] - Training step 25760 loss 0.04187267646193504
[2025-03-21 04:18:50,900][model][INFO] - Training step 25920 loss 0.2512218952178955
[2025-03-21 04:20:08,626][model][INFO] - Training step 26080 loss 0.040854595601558685
[2025-03-21 04:21:26,273][model][INFO] - Training step 26240 loss 0.036510735750198364
[2025-03-21 04:22:43,595][model][INFO] - Training step 26400 loss 0.06480169296264648
[2025-03-21 04:24:03,688][model][INFO] - Training step 26560 loss 0.022029731422662735
[2025-03-21 04:25:21,857][model][INFO] - Training step 26720 loss 0.23578161001205444
[2025-03-21 04:26:41,394][model][INFO] - Training step 26880 loss 0.003741120919585228
[2025-03-21 04:27:59,305][model][INFO] - Training step 27040 loss 0.03380148112773895
[2025-03-21 04:29:20,905][model][INFO] - Training step 27200 loss 0.253309965133667
[2025-03-21 04:30:38,384][model][INFO] - Training step 27360 loss 0.03789237141609192
[2025-03-21 04:31:57,090][model][INFO] - Training step 27520 loss 0.2675832509994507
[2025-03-21 04:33:17,025][model][INFO] - Training step 27680 loss 0.025996632874011993
[2025-03-21 04:34:36,089][model][INFO] - Training step 27840 loss 0.23859046399593353
[2025-03-21 04:35:52,146][model][INFO] - Training step 28000 loss 0.05895104259252548
[2025-03-21 04:37:12,455][model][INFO] - Training step 28160 loss 0.01781269907951355
[2025-03-21 04:38:31,511][model][INFO] - Training step 28320 loss 0.03716776520013809
[2025-03-21 04:39:52,760][model][INFO] - Training step 28480 loss 0.0490100234746933
[2025-03-21 04:41:11,337][model][INFO] - Training step 28640 loss 0.25386548042297363
[2025-03-21 04:42:29,002][model][INFO] - Training step 28800 loss 0.28338682651519775
[2025-03-21 04:43:49,462][model][INFO] - Training step 28960 loss 0.2505117654800415
[2025-03-21 04:45:08,635][model][INFO] - Training step 29120 loss 0.008581538684666157
[2025-03-21 04:46:29,011][model][INFO] - Training step 29280 loss 0.007316529750823975
[2025-03-21 04:47:47,422][model][INFO] - Training step 29440 loss 0.07432830333709717
[2025-03-21 04:49:03,835][model][INFO] - Training step 29600 loss 0.04084201529622078
[2025-03-21 04:50:20,151][model][INFO] - Training step 29760 loss 0.0696946382522583
[2025-03-21 04:51:40,594][model][INFO] - Training step 29920 loss 0.030335718765854836
[2025-03-21 04:52:59,232][model][INFO] - Training step 30080 loss 0.24371206760406494
[2025-03-21 04:54:18,350][model][INFO] - Training step 30240 loss 0.03704473376274109
[2025-03-21 04:55:37,796][model][INFO] - Training step 30400 loss 0.033709172159433365
[2025-03-21 04:56:59,252][model][INFO] - Training step 30560 loss 0.05144188553094864
[2025-03-21 04:58:14,340][model][INFO] - Training step 30720 loss 0.013350551016628742
[2025-03-21 04:59:33,342][model][INFO] - Training step 30880 loss 0.005777312442660332
[2025-03-21 05:00:53,323][model][INFO] - Training step 31040 loss 0.24972060322761536
[2025-03-21 05:02:09,307][model][INFO] - Training step 31200 loss 0.0364975780248642
[2025-03-21 05:03:29,891][model][INFO] - Training step 31360 loss 0.026020381599664688
[2025-03-21 05:04:47,669][model][INFO] - Training step 31520 loss 0.2582476735115051
[2025-03-21 05:06:09,576][model][INFO] - Training step 31680 loss 0.059206828474998474
[2025-03-21 05:07:27,470][model][INFO] - Training step 31840 loss 0.3059081733226776
[2025-03-21 05:08:45,746][model][INFO] - Training step 32000 loss 0.10106484591960907
[2025-03-21 05:10:05,812][model][INFO] - Training step 32160 loss 0.037591345608234406
[2025-03-21 05:11:24,840][model][INFO] - Training step 32320 loss 0.020709458738565445
[2025-03-21 05:12:45,038][model][INFO] - Training step 32480 loss 0.2556360363960266
[2025-03-21 05:14:05,845][model][INFO] - Training step 32640 loss 0.08011622726917267
[2025-03-21 05:15:28,316][model][INFO] - Training step 32800 loss 0.0034263976849615574
[2025-03-21 05:16:48,558][model][INFO] - Training step 32960 loss 0.026857445016503334
[2025-03-21 05:18:08,950][model][INFO] - Training step 33120 loss 0.2486158311367035
[2025-03-21 05:19:28,664][model][INFO] - Training step 33280 loss 0.09903639554977417
[2025-03-21 05:20:47,069][model][INFO] - Training step 33440 loss 0.03176778554916382
[2025-03-21 05:22:06,879][model][INFO] - Training step 33600 loss 0.2589811682701111
[2025-03-21 05:23:25,319][model][INFO] - Training step 33760 loss 0.011159231886267662
[2025-03-21 05:24:45,311][model][INFO] - Training step 33920 loss 0.003622788470238447
[2025-03-21 05:26:03,317][model][INFO] - Training step 34080 loss 0.10148973762989044
[2025-03-21 05:27:22,437][model][INFO] - Training step 34240 loss 0.04076433181762695
[2025-03-21 05:28:44,246][model][INFO] - Training step 34400 loss 0.034499265253543854
[2025-03-21 05:30:06,514][model][INFO] - Training step 34560 loss 0.07820095121860504
[2025-03-21 05:31:25,468][model][INFO] - Training step 34720 loss 0.26065945625305176
[2025-03-21 05:32:45,612][model][INFO] - Training step 34880 loss 0.041123438626527786
[2025-03-21 05:34:05,766][model][INFO] - Training step 35040 loss 0.0300370454788208
[2025-03-21 05:35:23,736][model][INFO] - Training step 35200 loss 0.018751520663499832
[2025-03-21 05:36:43,369][model][INFO] - Training step 35360 loss 0.014028157107532024
[2025-03-21 05:38:01,585][model][INFO] - Training step 35520 loss 0.02859443798661232
[2025-03-21 05:39:19,438][model][INFO] - Training step 35680 loss 0.0640353113412857
[2025-03-21 05:40:37,484][model][INFO] - Training step 35840 loss 0.010611334815621376
[2025-03-21 05:41:55,793][model][INFO] - Training step 36000 loss 0.027799706906080246
[2025-03-21 05:43:18,183][model][INFO] - Training step 36160 loss 0.002136911265552044
[2025-03-21 05:44:38,861][model][INFO] - Training step 36320 loss 0.26021331548690796
[2025-03-21 05:45:57,397][model][INFO] - Training step 36480 loss 0.005416248459368944
[2025-03-21 05:47:18,161][model][INFO] - Training step 36640 loss 0.027435021474957466
[2025-03-21 05:48:35,451][model][INFO] - Training step 36800 loss 0.02794067934155464
[2025-03-21 05:49:57,813][model][INFO] - Training step 36960 loss 0.014903824776411057
[2025-03-21 05:51:19,594][model][INFO] - Training step 37120 loss 0.020592086017131805
[2025-03-21 05:52:38,837][model][INFO] - Training step 37280 loss 0.029631558805704117
[2025-03-21 05:53:59,828][model][INFO] - Training step 37440 loss 0.060022782534360886
[2025-03-21 05:55:15,304][model][INFO] - Training step 37600 loss 0.03371087461709976
[2025-03-21 05:56:33,249][model][INFO] - Training step 37760 loss 0.03907965123653412
[2025-03-21 05:57:54,288][model][INFO] - Training step 37920 loss 0.24765954911708832
[2025-03-21 05:59:12,265][model][INFO] - Training step 38080 loss 0.03489813208580017
[2025-03-21 06:00:34,184][model][INFO] - Training step 38240 loss 0.16354858875274658
[2025-03-21 06:01:54,359][model][INFO] - Training step 38400 loss 0.010059736669063568
[2025-03-21 06:03:11,997][model][INFO] - Training step 38560 loss 0.04546955227851868
[2025-03-21 06:04:29,542][model][INFO] - Training step 38720 loss 0.03741595149040222
[2025-03-21 06:05:49,937][model][INFO] - Training step 38880 loss 0.2604089379310608
[2025-03-21 06:07:10,100][model][INFO] - Training step 39040 loss 0.020510606467723846
[2025-03-21 06:08:25,628][model][INFO] - Training step 39200 loss 0.034584127366542816
[2025-03-21 06:09:46,821][model][INFO] - Training step 39360 loss 0.024788394570350647
[2025-03-21 06:11:09,805][model][INFO] - Training step 39520 loss 0.03042646124958992
[2025-03-21 06:12:28,304][model][INFO] - Training step 39680 loss 0.01678013987839222
[2025-03-21 06:13:46,689][model][INFO] - Training step 39840 loss 0.04494302719831467
[2025-03-21 06:15:02,763][model][INFO] - Training step 40000 loss 0.010258831083774567
[2025-03-21 06:16:22,660][model][INFO] - Training step 40160 loss 0.0404931977391243
[2025-03-21 06:17:43,626][model][INFO] - Training step 40320 loss 0.03417680040001869
[2025-03-21 06:19:03,047][model][INFO] - Training step 40480 loss 0.0425475612282753
[2025-03-21 06:20:21,183][model][INFO] - Training step 40640 loss 0.02984730899333954
[2025-03-21 06:21:40,283][model][INFO] - Training step 40800 loss 0.00649507250636816
[2025-03-21 06:22:57,803][model][INFO] - Training step 40960 loss 0.0042198095470666885
[2025-03-21 06:24:20,107][model][INFO] - Training step 41120 loss 0.01663808338344097
[2025-03-21 06:25:43,487][model][INFO] - Training step 41280 loss 0.07034546881914139
[2025-03-21 06:27:03,533][model][INFO] - Training step 41440 loss 0.24848483502864838
[2025-03-21 06:28:21,833][model][INFO] - Training step 41600 loss 0.050937362015247345
[2025-03-21 06:29:41,210][model][INFO] - Training step 41760 loss 0.020065443590283394
[2025-03-21 06:30:58,829][model][INFO] - Training step 41920 loss 0.04085412994027138
[2025-03-21 06:32:19,837][model][INFO] - Training step 42080 loss 0.01466128695756197
[2025-03-21 06:33:38,595][model][INFO] - Training step 42240 loss 0.030071578919887543
[2025-03-21 06:34:58,115][model][INFO] - Training step 42400 loss 0.06509283930063248
[2025-03-21 06:36:18,393][model][INFO] - Training step 42560 loss 0.02565019205212593
[2025-03-21 06:37:38,355][model][INFO] - Training step 42720 loss 0.013195672072470188
[2025-03-21 06:38:58,550][model][INFO] - Training step 42880 loss 0.04301801323890686
[2025-03-21 06:40:17,891][model][INFO] - Training step 43040 loss 0.05213145911693573
[2025-03-21 06:41:34,419][model][INFO] - Training step 43200 loss 0.053466133773326874
[2025-03-21 06:42:55,273][model][INFO] - Training step 43360 loss 0.2394973486661911
[2025-03-21 06:44:15,101][model][INFO] - Training step 43520 loss 0.2933208644390106
[2025-03-21 06:45:33,449][model][INFO] - Training step 43680 loss 0.07449675351381302
[2025-03-21 06:46:53,581][model][INFO] - Training step 43840 loss 0.00569098349660635
[2025-03-21 06:48:14,016][model][INFO] - Training step 44000 loss 0.16900597512722015
[2025-03-21 06:49:35,010][model][INFO] - Training step 44160 loss 0.0320810005068779
[2025-03-21 06:50:55,585][model][INFO] - Training step 44320 loss 0.20344235002994537
[2025-03-21 06:52:15,274][model][INFO] - Training step 44480 loss 0.009220687672495842
[2025-03-21 06:53:34,115][model][INFO] - Training step 44640 loss 0.0014162661973387003
[2025-03-21 06:54:54,334][model][INFO] - Training step 44800 loss 0.023514486849308014
[2025-03-21 06:56:11,810][model][INFO] - Training step 44960 loss 0.06257051974534988
[2025-03-21 06:57:29,984][model][INFO] - Training step 45120 loss 0.039243847131729126
[2025-03-21 06:58:48,969][model][INFO] - Training step 45280 loss 0.02548803761601448
[2025-03-21 07:00:06,714][model][INFO] - Training step 45440 loss 0.2515662908554077
[2025-03-21 07:01:31,187][model][INFO] - Training step 45600 loss 0.02623998373746872
[2025-03-21 07:02:52,963][model][INFO] - Training step 45760 loss 0.03749895840883255
[2025-03-21 07:04:13,834][model][INFO] - Training step 45920 loss 0.10881884396076202
[2025-03-21 07:05:35,599][model][INFO] - Training step 46080 loss 0.02621186152100563
[2025-03-21 07:06:53,495][model][INFO] - Training step 46240 loss 0.020231908187270164
[2025-03-21 07:08:17,587][model][INFO] - Training step 46400 loss 0.24970677495002747
[2025-03-21 07:09:34,132][model][INFO] - Training step 46560 loss 0.04790361225605011
[2025-03-21 07:10:55,745][model][INFO] - Training step 46720 loss 0.0018250752473250031
[2025-03-21 07:12:14,350][model][INFO] - Training step 46880 loss 0.03279000148177147
[2025-03-21 07:13:37,425][model][INFO] - Training step 47040 loss 0.04572548717260361
[2025-03-21 07:14:57,814][model][INFO] - Training step 47200 loss 0.01755821332335472
[2025-03-21 07:16:17,366][model][INFO] - Training step 47360 loss 0.03805128484964371
[2025-03-21 07:17:38,959][model][INFO] - Training step 47520 loss 0.004985200706869364
[2025-03-21 07:18:57,487][model][INFO] - Training step 47680 loss 0.043447189033031464
[2025-03-21 07:20:18,840][model][INFO] - Training step 47840 loss 0.03165839985013008
[2025-03-21 07:21:39,387][model][INFO] - Training step 48000 loss 0.11005987226963043
[2025-03-21 07:23:00,573][model][INFO] - Training step 48160 loss 0.20561811327934265
[2025-03-21 07:24:19,496][model][INFO] - Training step 48320 loss 0.03089630976319313
[2025-03-21 07:25:36,700][model][INFO] - Training step 48480 loss 0.0634763091802597
[2025-03-21 07:26:56,173][model][INFO] - Training step 48640 loss 0.03268418088555336
[2025-03-21 07:28:15,949][model][INFO] - Training step 48800 loss 0.024911511689424515
[2025-03-21 07:29:35,343][model][INFO] - Training step 48960 loss 0.015316084027290344
[2025-03-21 07:30:55,025][model][INFO] - Training step 49120 loss 0.1640641987323761
[2025-03-21 07:32:15,984][model][INFO] - Training step 49280 loss 0.02847817912697792
[2025-03-21 07:33:32,005][model][INFO] - Training step 49440 loss 0.029964741319417953
[2025-03-21 07:34:52,094][model][INFO] - Training step 49600 loss 0.2782515287399292
[2025-03-21 07:36:13,063][model][INFO] - Training step 49760 loss 0.051744259893894196
[2025-03-21 07:37:31,185][model][INFO] - Training step 49920 loss 0.01599304936826229
[2025-03-21 07:38:51,797][model][INFO] - Training step 50080 loss 0.02303609810769558
[2025-03-21 07:40:11,057][model][INFO] - Training step 50240 loss 0.0159907229244709
[2025-03-21 07:41:28,891][model][INFO] - Training step 50400 loss 0.02399403229355812
[2025-03-21 07:42:47,251][model][INFO] - Training step 50560 loss 0.01850048638880253
[2025-03-21 07:44:05,621][model][INFO] - Training step 50720 loss 0.037163589149713516
[2025-03-21 07:53:36,411][model][INFO] - Training step 80 loss 0.2488870620727539
[2025-03-21 07:54:56,189][model][INFO] - Training step 240 loss 0.0417679101228714
[2025-03-21 07:56:16,504][model][INFO] - Training step 400 loss 0.03193835914134979
[2025-03-21 07:57:35,102][model][INFO] - Training step 560 loss 0.050613731145858765
[2025-03-21 07:58:53,826][model][INFO] - Training step 720 loss 0.029189743101596832
[2025-03-21 08:00:14,961][model][INFO] - Training step 880 loss 0.07388512790203094
[2025-03-21 08:01:34,645][model][INFO] - Training step 1040 loss 0.01645367592573166
[2025-03-21 08:02:53,173][model][INFO] - Training step 1200 loss 0.031389325857162476
[2025-03-21 08:04:14,888][model][INFO] - Training step 1360 loss 0.2570260763168335
[2025-03-21 08:05:33,700][model][INFO] - Training step 1520 loss 0.06288199871778488
[2025-03-21 08:06:51,140][model][INFO] - Training step 1680 loss 0.03021150268614292
[2025-03-21 08:08:11,506][model][INFO] - Training step 1840 loss 0.007382004056125879
[2025-03-21 08:09:28,386][model][INFO] - Training step 2000 loss 0.3195687532424927
[2025-03-21 08:10:45,571][model][INFO] - Training step 2160 loss 0.24236764013767242
[2025-03-21 08:12:03,805][model][INFO] - Training step 2320 loss 0.04414188489317894
[2025-03-21 08:13:23,734][model][INFO] - Training step 2480 loss 0.02462678775191307
[2025-03-21 08:14:41,411][model][INFO] - Training step 2640 loss 0.007612478919327259
[2025-03-21 08:15:59,314][model][INFO] - Training step 2800 loss 0.03804665058851242
[2025-03-21 08:17:19,866][model][INFO] - Training step 2960 loss 0.05735842511057854
[2025-03-21 08:18:36,345][model][INFO] - Training step 3120 loss 0.09931528568267822
[2025-03-21 08:19:56,834][model][INFO] - Training step 3280 loss 0.07005945593118668
[2025-03-21 08:21:13,558][model][INFO] - Training step 3440 loss 0.026405755430459976
[2025-03-21 08:22:30,427][model][INFO] - Training step 3600 loss 0.00908919982612133
[2025-03-21 08:23:51,507][model][INFO] - Training step 3760 loss 0.028576817363500595
[2025-03-21 08:25:11,244][model][INFO] - Training step 3920 loss 0.2570241093635559
[2025-03-21 08:26:32,794][model][INFO] - Training step 4080 loss 0.03260887414216995
[2025-03-21 08:27:51,702][model][INFO] - Training step 4240 loss 0.06939677894115448
[2025-03-21 08:29:12,172][model][INFO] - Training step 4400 loss 0.017007628455758095
[2025-03-21 08:30:31,922][model][INFO] - Training step 4560 loss 0.24282453954219818
[2025-03-21 08:31:50,623][model][INFO] - Training step 4720 loss 0.04134821146726608
[2025-03-21 08:33:07,642][model][INFO] - Training step 4880 loss 0.022292811423540115
[2025-03-21 08:34:26,158][model][INFO] - Training step 5040 loss 0.08748390525579453
[2025-03-21 08:35:44,307][model][INFO] - Training step 5200 loss 0.2513272762298584
[2025-03-21 08:37:05,004][model][INFO] - Training step 5360 loss 0.007579016499221325
[2025-03-21 08:38:26,508][model][INFO] - Training step 5520 loss 0.08146334439516068
[2025-03-21 08:39:45,366][model][INFO] - Training step 5680 loss 0.023072240874171257
[2025-03-21 08:41:03,258][model][INFO] - Training step 5840 loss 0.2497270703315735
[2025-03-21 08:42:23,167][model][INFO] - Training step 6000 loss 0.01324775442481041
[2025-03-21 08:43:43,240][model][INFO] - Training step 6160 loss 0.04835215583443642
[2025-03-21 08:45:03,275][model][INFO] - Training step 6320 loss 0.04944206774234772
[2025-03-21 08:46:24,179][model][INFO] - Training step 6480 loss 0.08682528138160706
[2025-03-21 08:47:41,678][model][INFO] - Training step 6640 loss 0.008678382262587547
[2025-03-21 08:49:03,961][model][INFO] - Training step 6800 loss 0.023779388517141342
[2025-03-21 08:50:24,365][model][INFO] - Training step 6960 loss 0.0303984135389328
[2025-03-21 08:51:47,285][model][INFO] - Training step 7120 loss 0.0416257306933403
[2025-03-21 08:53:08,478][model][INFO] - Training step 7280 loss 0.01569356769323349
[2025-03-21 08:54:25,378][model][INFO] - Training step 7440 loss 0.03204452246427536
[2025-03-21 08:55:44,217][model][INFO] - Training step 7600 loss 0.03166519105434418
[2025-03-21 08:57:01,039][model][INFO] - Training step 7760 loss 0.25451821088790894
[2025-03-21 08:58:22,080][model][INFO] - Training step 7920 loss 0.03178183361887932
[2025-03-21 08:59:41,410][model][INFO] - Training step 8080 loss 0.09701494127511978
[2025-03-21 09:01:00,616][model][INFO] - Training step 8240 loss 0.018674960359930992
[2025-03-21 09:02:20,005][model][INFO] - Training step 8400 loss 0.043137386441230774
[2025-03-21 09:03:41,661][model][INFO] - Training step 8560 loss 0.022958215326070786
[2025-03-21 09:05:01,408][model][INFO] - Training step 8720 loss 0.028071071952581406
[2025-03-21 09:06:22,477][model][INFO] - Training step 8880 loss 0.23386085033416748
[2025-03-21 09:07:39,545][model][INFO] - Training step 9040 loss 0.05484338104724884
[2025-03-21 09:08:56,263][model][INFO] - Training step 9200 loss 0.04820651561021805
[2025-03-21 09:10:14,026][model][INFO] - Training step 9360 loss 0.03051096573472023
[2025-03-21 09:11:31,646][model][INFO] - Training step 9520 loss 0.016921505331993103
[2025-03-21 09:12:51,554][model][INFO] - Training step 9680 loss 0.05260058492422104
[2025-03-21 09:14:13,748][model][INFO] - Training step 9840 loss 0.06552788615226746
[2025-03-21 09:15:34,521][model][INFO] - Training step 10000 loss 0.0250808484852314
[2025-03-21 09:16:55,096][model][INFO] - Training step 10160 loss 0.020603815093636513
[2025-03-21 09:18:11,464][model][INFO] - Training step 10320 loss 0.17243406176567078
[2025-03-21 09:19:28,614][model][INFO] - Training step 10480 loss 0.027268674224615097
[2025-03-21 09:20:48,363][model][INFO] - Training step 10640 loss 0.2533225119113922
[2025-03-21 09:22:06,362][model][INFO] - Training step 10800 loss 0.04881170019507408
[2025-03-21 09:23:24,276][model][INFO] - Training step 10960 loss 0.09915816783905029
[2025-03-21 09:24:44,007][model][INFO] - Training step 11120 loss 0.02153809741139412
[2025-03-21 09:26:03,827][model][INFO] - Training step 11280 loss 0.08639496564865112
[2025-03-21 09:27:19,798][model][INFO] - Training step 11440 loss 0.02499823272228241
[2025-03-21 09:28:38,994][model][INFO] - Training step 11600 loss 0.2558400630950928
[2025-03-21 09:29:59,770][model][INFO] - Training step 11760 loss 0.06184995174407959
[2025-03-21 09:31:19,018][model][INFO] - Training step 11920 loss 0.07638700306415558
[2025-03-21 09:32:38,476][model][INFO] - Training step 12080 loss 0.2527391314506531
[2025-03-21 09:33:57,038][model][INFO] - Training step 12240 loss 0.25219228863716125
[2025-03-21 09:35:14,864][model][INFO] - Training step 12400 loss 0.2484857141971588
[2025-03-21 09:36:31,839][model][INFO] - Training step 12560 loss 0.12652413547039032
[2025-03-21 09:37:50,144][model][INFO] - Training step 12720 loss 0.007271885871887207
[2025-03-21 09:39:07,922][model][INFO] - Training step 12880 loss 0.02713002637028694
[2025-03-21 09:40:25,533][model][INFO] - Training step 13040 loss 0.03337428718805313
[2025-03-21 09:41:46,148][model][INFO] - Training step 13200 loss 0.07206079363822937
[2025-03-21 09:43:05,689][model][INFO] - Training step 13360 loss 0.05537966638803482
[2025-03-21 09:44:23,880][model][INFO] - Training step 13520 loss 0.25587016344070435
[2025-03-21 09:45:43,055][model][INFO] - Training step 13680 loss 0.031550899147987366
[2025-03-21 09:47:04,119][model][INFO] - Training step 13840 loss 0.0247858427464962
[2025-03-21 09:48:26,616][model][INFO] - Training step 14000 loss 0.054460249841213226
[2025-03-21 09:49:43,914][model][INFO] - Training step 14160 loss 0.005361218936741352
[2025-03-21 09:51:02,175][model][INFO] - Training step 14320 loss 0.033986710011959076
[2025-03-21 09:52:20,757][model][INFO] - Training step 14480 loss 0.24309468269348145
[2025-03-21 09:53:40,018][model][INFO] - Training step 14640 loss 0.04333844780921936
[2025-03-21 09:54:57,592][model][INFO] - Training step 14800 loss 0.036628082394599915
[2025-03-21 09:56:18,151][model][INFO] - Training step 14960 loss 0.03015577420592308
[2025-03-21 09:57:39,079][model][INFO] - Training step 15120 loss 0.2617949843406677
[2025-03-21 09:58:57,299][model][INFO] - Training step 15280 loss 0.25311338901519775
[2025-03-21 10:00:16,950][model][INFO] - Training step 15440 loss 0.01549236848950386
[2025-03-21 10:01:37,263][model][INFO] - Training step 15600 loss 0.25401514768600464
[2025-03-21 10:02:57,699][model][INFO] - Training step 15760 loss 0.03129815682768822
[2025-03-21 10:04:19,797][model][INFO] - Training step 15920 loss 0.09855375438928604
[2025-03-21 10:05:37,226][model][INFO] - Training step 16080 loss 0.06291672587394714
[2025-03-21 10:06:56,139][model][INFO] - Training step 16240 loss 0.04054807126522064
[2025-03-21 10:08:15,224][model][INFO] - Training step 16400 loss 0.2551405131816864
[2025-03-21 10:09:35,777][model][INFO] - Training step 16560 loss 0.061281684786081314
[2025-03-21 10:10:51,811][model][INFO] - Training step 16720 loss 0.0034581513609737158
[2025-03-21 10:12:13,561][model][INFO] - Training step 16880 loss 0.023048818111419678
[2025-03-21 10:13:35,267][model][INFO] - Training step 17040 loss 1.899040937423706
[2025-03-21 10:14:55,718][model][INFO] - Training step 17200 loss 0.07782024145126343
[2025-03-21 10:16:15,668][model][INFO] - Training step 17360 loss 0.0866539478302002
[2025-03-21 10:17:33,470][model][INFO] - Training step 17520 loss 0.045965734869241714
[2025-03-21 10:18:53,012][model][INFO] - Training step 17680 loss 0.026609433814883232
[2025-03-21 10:20:10,485][model][INFO] - Training step 17840 loss 0.0406409427523613
[2025-03-21 10:21:32,479][model][INFO] - Training step 18000 loss 0.033865079283714294
[2025-03-21 10:22:49,837][model][INFO] - Training step 18160 loss 0.08091889321804047
[2025-03-21 10:24:06,979][model][INFO] - Training step 18320 loss 0.2320009171962738
[2025-03-21 10:25:25,504][model][INFO] - Training step 18480 loss 0.04607945308089256
[2025-03-21 10:26:46,217][model][INFO] - Training step 18640 loss 0.24173107743263245
[2025-03-21 10:28:06,476][model][INFO] - Training step 18800 loss 0.01027965173125267
[2025-03-21 10:29:24,172][model][INFO] - Training step 18960 loss 0.036729034036397934
[2025-03-21 10:30:43,467][model][INFO] - Training step 19120 loss 0.022627711296081543
[2025-03-21 10:32:00,232][model][INFO] - Training step 19280 loss 0.03012705408036709
[2025-03-21 10:33:17,820][model][INFO] - Training step 19440 loss 0.005099506117403507
[2025-03-21 10:34:36,690][model][INFO] - Training step 19600 loss 0.0024888115003705025
[2025-03-21 10:35:52,845][model][INFO] - Training step 19760 loss 0.017829477787017822
[2025-03-21 10:37:13,691][model][INFO] - Training step 19920 loss 0.05814671516418457
[2025-03-21 10:38:33,015][model][INFO] - Training step 20080 loss 0.05232255905866623
[2025-03-21 10:39:52,012][model][INFO] - Training step 20240 loss 0.023463986814022064
[2025-03-21 10:41:10,896][model][INFO] - Training step 20400 loss 0.06000063195824623
[2025-03-21 10:42:27,777][model][INFO] - Training step 20560 loss 0.032642196863889694
[2025-03-21 10:43:47,576][model][INFO] - Training step 20720 loss 0.24890464544296265
[2025-03-21 10:45:05,445][model][INFO] - Training step 20880 loss 0.033801451325416565
[2025-03-21 10:46:22,619][model][INFO] - Training step 21040 loss 0.25169631838798523
[2025-03-21 10:47:42,112][model][INFO] - Training step 21200 loss 0.035679835826158524
----------------------------------------------------------------
Activating environment
Python version used:
Python 3.10.15
Starting training...
NVML Initialized
Driver Version: b'450.80.02'
[2025-03-21 11:10:29,171][__main__][INFO] - Start experiment: exp/default/2025-03-21_11-10-29_
[2025-03-21 11:10:29,195][__main__][INFO] - create datalogger
[2025-03-21 11:10:29,195][__main__][INFO] - Create new model
[2025-03-21 11:10:31,261][models.ncsnpp][DEBUG] - NCSNpp.__init__
[2025-03-21 11:10:31,261][models.ncsnpp][DEBUG] - all_resolutions: [256, 128, 64, 32, 16, 8, 4]
[2025-03-21 11:10:31,263][models.ncsnpp][DEBUG] - num_channels: 6
[2025-03-21 11:10:34,251][__main__][INFO] - start training
CHECKPOINT FOUND
[2025-03-21 11:10:55,968][model][INFO] - set optim with {'_target_': 'torch.optim.Adam', 'lr': 0.0001, 'weight_decay': 0.0}
┏━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓
┃   ┃ Name        ┃ Type             ┃ Params ┃ Mode  ┃
┡━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩
│ 0 │ model       │ ScoreModelNCSNpp │ 65.9 M │ train │
│ 1 │ loss        │ MSELoss          │      0 │ train │
│ 2 │ si_sdr_loss │ SISDRLoss        │      0 │ train │
└───┴─────────────┴──────────────────┴────────┴───────┘
Trainable params: 65.9 M                                                        
Non-trainable params: 128                                                       
Total params: 65.9 M                                                            
Total estimated model params size (MB): 263                                     
Modules in train mode: 444                                                      
Modules in eval mode: 0                                                         
[2025-03-21 11:11:56,777][model][INFO] - Training step 80 loss 0.0646003857254982
[2025-03-21 11:13:17,265][model][INFO] - Training step 240 loss 0.045520756393671036
[2025-03-21 11:14:36,090][model][INFO] - Training step 400 loss 0.106833815574646
[2025-03-21 11:15:54,320][model][INFO] - Training step 560 loss 0.02479397878050804
[2025-03-21 11:17:13,770][model][INFO] - Training step 720 loss 0.02964208275079727
[2025-03-21 11:18:35,950][model][INFO] - Training step 880 loss 0.029138531535863876
[2025-03-21 11:19:51,786][model][INFO] - Training step 1040 loss 0.04122546315193176
[2025-03-21 11:21:09,584][model][INFO] - Training step 1200 loss 0.03564665466547012
[2025-03-21 11:22:33,660][model][INFO] - Training step 1360 loss 0.0557861328125
[2025-03-21 11:23:50,850][model][INFO] - Training step 1520 loss 0.03783075511455536
[2025-03-21 11:25:10,340][model][INFO] - Training step 1680 loss 0.036078520119190216
[2025-03-21 11:26:30,019][model][INFO] - Training step 1840 loss 0.03653142601251602
[2025-03-21 11:27:51,746][model][INFO] - Training step 2000 loss 0.0034583136439323425
[2025-03-21 11:29:11,377][model][INFO] - Training step 2160 loss 0.04003471881151199
[2025-03-21 11:30:30,793][model][INFO] - Training step 2320 loss 0.027875304222106934
[2025-03-21 11:31:51,149][model][INFO] - Training step 2480 loss 0.2541743516921997
[2025-03-21 11:33:11,463][model][INFO] - Training step 2640 loss 0.24801820516586304
[2025-03-21 11:34:30,588][model][INFO] - Training step 2800 loss 0.0492277517914772
[2025-03-21 11:35:51,051][model][INFO] - Training step 2960 loss 0.018774453550577164
[2025-03-21 11:37:13,809][model][INFO] - Training step 3120 loss 0.0947171226143837
[2025-03-21 11:38:33,652][model][INFO] - Training step 3280 loss 0.030402017757296562
[2025-03-21 11:39:54,636][model][INFO] - Training step 3440 loss 0.23867802321910858
[2025-03-21 11:41:11,933][model][INFO] - Training step 3600 loss 0.01659407652914524
[2025-03-21 11:42:33,757][model][INFO] - Training step 3760 loss 0.008814503438770771
[2025-03-21 11:43:53,817][model][INFO] - Training step 3920 loss 0.06993371993303299
[2025-03-21 11:45:16,471][model][INFO] - Training step 4080 loss 0.25961825251579285
[2025-03-21 11:46:37,215][model][INFO] - Training step 4240 loss 0.25141507387161255
[2025-03-21 11:47:55,643][model][INFO] - Training step 4400 loss 0.049623653292655945
[2025-03-21 11:49:15,844][model][INFO] - Training step 4560 loss 0.04886886849999428
[2025-03-21 11:50:36,249][model][INFO] - Training step 4720 loss 0.026043463498353958
[2025-03-21 11:51:52,750][model][INFO] - Training step 4880 loss 0.013337956741452217
[2025-03-21 11:53:13,620][model][INFO] - Training step 5040 loss 0.22819359600543976
[2025-03-21 11:54:31,984][model][INFO] - Training step 5200 loss 0.02487153187394142
[2025-03-21 11:55:52,363][model][INFO] - Training step 5360 loss 0.051889024674892426
[2025-03-21 11:57:12,762][model][INFO] - Training step 5520 loss 0.2684018909931183
[2025-03-21 11:58:30,141][model][INFO] - Training step 5680 loss 0.022907838225364685
[2025-03-21 11:59:52,545][model][INFO] - Training step 5840 loss 0.02898440882563591
[2025-03-21 12:01:13,324][model][INFO] - Training step 6000 loss 0.012494120746850967
[2025-03-21 12:02:32,864][model][INFO] - Training step 6160 loss 0.024651087820529938
[2025-03-21 12:03:54,224][model][INFO] - Training step 6320 loss 0.04538170248270035
[2025-03-21 12:05:12,923][model][INFO] - Training step 6480 loss 0.10971769690513611
[2025-03-21 12:06:33,361][model][INFO] - Training step 6640 loss 0.011814499273896217
[2025-03-21 12:07:52,465][model][INFO] - Training step 6800 loss 0.02871224656701088
[2025-03-21 12:09:12,527][model][INFO] - Training step 6960 loss 0.03424965590238571
[2025-03-21 12:10:32,144][model][INFO] - Training step 7120 loss 0.13335515558719635
[2025-03-21 12:11:54,640][model][INFO] - Training step 7280 loss 0.021166060119867325
[2025-03-21 12:13:12,406][model][INFO] - Training step 7440 loss 0.022074103355407715
[2025-03-21 12:14:29,305][model][INFO] - Training step 7600 loss 0.02997901663184166
[2025-03-21 12:15:49,789][model][INFO] - Training step 7760 loss 0.21171224117279053
[2025-03-21 12:17:08,684][model][INFO] - Training step 7920 loss 0.09438053518533707
[2025-03-21 12:18:24,392][model][INFO] - Training step 8080 loss 0.029377203434705734
[2025-03-21 12:19:47,250][model][INFO] - Training step 8240 loss 0.029297523200511932
[2025-03-21 12:21:01,801][model][INFO] - Training step 8400 loss 0.04175123572349548
[2025-03-21 12:22:21,721][model][INFO] - Training step 8560 loss 0.0403163768351078
[2025-03-21 12:23:40,489][model][INFO] - Training step 8720 loss 0.09702032804489136
[2025-03-21 12:25:00,895][model][INFO] - Training step 8880 loss 0.24620305001735687
[2025-03-21 12:26:20,014][model][INFO] - Training step 9040 loss 0.25293952226638794
[2025-03-21 12:27:38,817][model][INFO] - Training step 9200 loss 0.025018487125635147
[2025-03-21 12:28:59,033][model][INFO] - Training step 9360 loss 0.054063260555267334
[2025-03-21 12:30:17,931][model][INFO] - Training step 9520 loss 0.018136639147996902
[2025-03-21 12:31:38,022][model][INFO] - Training step 9680 loss 0.09072056412696838
[2025-03-21 12:33:00,457][model][INFO] - Training step 9840 loss 0.15433740615844727
[2025-03-21 12:34:20,047][model][INFO] - Training step 10000 loss 0.019541330635547638
[2025-03-21 12:35:37,059][model][INFO] - Training step 10160 loss 0.25148501992225647
[2025-03-21 12:36:56,008][model][INFO] - Training step 10320 loss 0.007302131038159132
[2025-03-21 12:38:13,747][model][INFO] - Training step 10480 loss 0.029585743322968483
[2025-03-21 12:39:34,871][model][INFO] - Training step 10640 loss 0.015203936025500298
[2025-03-21 12:40:52,681][model][INFO] - Training step 10800 loss 0.03968539834022522
[2025-03-21 12:42:13,631][model][INFO] - Training step 10960 loss 0.054957710206508636
[2025-03-21 12:43:29,613][model][INFO] - Training step 11120 loss 0.025055434554815292
[2025-03-21 12:44:47,024][model][INFO] - Training step 11280 loss 0.029332498088479042
[2025-03-21 12:46:04,084][model][INFO] - Training step 11440 loss 0.027028584852814674
[2025-03-21 12:47:21,459][model][INFO] - Training step 11600 loss 0.12528139352798462
[2025-03-21 12:48:42,336][model][INFO] - Training step 11760 loss 0.249066561460495
[2025-03-21 12:50:00,138][model][INFO] - Training step 11920 loss 0.250410795211792
[2025-03-21 12:51:18,126][model][INFO] - Training step 12080 loss 0.048428431153297424
[2025-03-21 12:52:37,952][model][INFO] - Training step 12240 loss 0.13016168773174286
[2025-03-21 12:53:57,401][model][INFO] - Training step 12400 loss 0.24228209257125854
[2025-03-21 12:55:15,625][model][INFO] - Training step 12560 loss 0.061441756784915924
[2025-03-21 12:56:33,894][model][INFO] - Training step 12720 loss 0.23634983599185944
[2025-03-21 12:57:50,802][model][INFO] - Training step 12880 loss 0.021129311993718147
[2025-03-21 12:59:10,850][model][INFO] - Training step 13040 loss 0.028705960139632225
[2025-03-21 13:00:32,201][model][INFO] - Training step 13200 loss 0.034837085753679276
[2025-03-21 13:01:49,109][model][INFO] - Training step 13360 loss 0.04969704896211624
[2025-03-21 13:03:07,041][model][INFO] - Training step 13520 loss 0.0254173893481493
[2025-03-21 13:04:27,950][model][INFO] - Training step 13680 loss 0.005898609291762114
[2025-03-21 13:05:49,763][model][INFO] - Training step 13840 loss 0.019340410828590393
[2025-03-21 13:07:08,969][model][INFO] - Training step 14000 loss 0.044950395822525024
[2025-03-21 13:08:24,584][model][INFO] - Training step 14160 loss 0.1149468719959259
[2025-03-21 13:09:42,416][model][INFO] - Training step 14320 loss 0.022040488198399544
[2025-03-21 13:11:00,853][model][INFO] - Training step 14480 loss 0.022711221128702164
[2025-03-21 13:12:21,381][model][INFO] - Training step 14640 loss 0.001907623140141368
[2025-03-21 13:13:40,901][model][INFO] - Training step 14800 loss 0.17820830643177032
[2025-03-21 13:15:00,443][model][INFO] - Training step 14960 loss 0.2912878692150116
[2025-03-21 13:16:20,817][model][INFO] - Training step 15120 loss 0.024038247764110565
[2025-03-21 13:17:40,113][model][INFO] - Training step 15280 loss 0.030136793851852417
[2025-03-21 13:18:59,588][model][INFO] - Training step 15440 loss 0.02261240780353546
[2025-03-21 13:20:19,457][model][INFO] - Training step 15600 loss 0.2654646933078766
[2025-03-21 13:21:39,276][model][INFO] - Training step 15760 loss 0.0061115240678191185
[2025-03-21 13:22:58,577][model][INFO] - Training step 15920 loss 0.033180445432662964
[2025-03-21 13:24:18,041][model][INFO] - Training step 16080 loss 0.02144690230488777
[2025-03-21 13:25:35,009][model][INFO] - Training step 16240 loss 0.035486966371536255
[2025-03-21 13:26:53,651][model][INFO] - Training step 16400 loss 0.05894254520535469
[2025-03-21 13:28:13,235][model][INFO] - Training step 16560 loss 0.044009964913129807
[2025-03-21 13:29:31,115][model][INFO] - Training step 16720 loss 0.03187540918588638
[2025-03-21 13:30:50,488][model][INFO] - Training step 16880 loss 0.02334745228290558
[2025-03-21 13:32:11,490][model][INFO] - Training step 17040 loss 0.01187831535935402
[2025-03-21 13:33:27,672][model][INFO] - Training step 17200 loss 0.0038288109935820103
[2025-03-21 13:34:47,373][model][INFO] - Training step 17360 loss 0.27812421321868896
[2025-03-21 13:36:07,107][model][INFO] - Training step 17520 loss 0.14489537477493286
[2025-03-21 13:37:27,792][model][INFO] - Training step 17680 loss 0.031004294753074646
[2025-03-21 13:38:46,691][model][INFO] - Training step 17840 loss 0.16318167746067047
[2025-03-21 13:40:07,272][model][INFO] - Training step 18000 loss 0.004196334630250931
[2025-03-21 13:41:26,915][model][INFO] - Training step 18160 loss 0.05252675712108612
[2025-03-21 13:42:50,926][model][INFO] - Training step 18320 loss 0.04023199528455734
[2025-03-21 13:44:07,985][model][INFO] - Training step 18480 loss 0.04099469631910324
[2025-03-21 13:45:26,662][model][INFO] - Training step 18640 loss 0.033615827560424805
[2025-03-21 13:46:45,623][model][INFO] - Training step 18800 loss 0.02410183846950531
[2025-03-21 13:48:02,220][model][INFO] - Training step 18960 loss 0.2707812786102295
[2025-03-21 13:49:22,005][model][INFO] - Training step 19120 loss 0.030513308942317963
[2025-03-21 13:50:42,458][model][INFO] - Training step 19280 loss 0.030309800058603287
[2025-03-21 13:52:02,765][model][INFO] - Training step 19440 loss 0.007522439118474722
[2025-03-21 13:53:23,484][model][INFO] - Training step 19600 loss 0.043323226273059845
[2025-03-21 13:54:42,518][model][INFO] - Training step 19760 loss 0.004072367213666439
[2025-03-21 13:56:00,325][model][INFO] - Training step 19920 loss 0.055157773196697235
[2025-03-21 13:57:20,702][model][INFO] - Training step 20080 loss 0.0440494641661644
[2025-03-21 13:58:41,229][model][INFO] - Training step 20240 loss 0.032638151198625565
[2025-03-21 14:00:01,078][model][INFO] - Training step 20400 loss 0.0024953894317150116
[2025-03-21 14:01:19,465][model][INFO] - Training step 20560 loss 0.03011918254196644
[2025-03-21 14:02:39,452][model][INFO] - Training step 20720 loss 0.255767822265625
[2025-03-21 14:03:57,444][model][INFO] - Training step 20880 loss 0.04382360354065895
[2025-03-21 14:05:17,601][model][INFO] - Training step 21040 loss 0.03604961559176445
[2025-03-21 14:06:38,054][model][INFO] - Training step 21200 loss 0.12764832377433777
[2025-03-21 14:07:58,596][model][INFO] - Training step 21360 loss 0.272311270236969
[2025-03-21 14:09:18,228][model][INFO] - Training step 21520 loss 0.03892117366194725
[2025-03-21 14:10:38,050][model][INFO] - Training step 21680 loss 0.0028923742938786745
[2025-03-21 14:11:58,413][model][INFO] - Training step 21840 loss 0.28361427783966064
[2025-03-21 14:13:15,207][model][INFO] - Training step 22000 loss 0.005591396242380142
[2025-03-21 14:14:31,197][model][INFO] - Training step 22160 loss 0.04012282192707062
[2025-03-21 14:15:52,333][model][INFO] - Training step 22320 loss 0.03576440364122391
[2025-03-21 14:17:15,064][model][INFO] - Training step 22480 loss 0.011256981641054153
[2025-03-21 14:18:33,716][model][INFO] - Training step 22640 loss 0.010982698760926723
[2025-03-21 14:19:53,759][model][INFO] - Training step 22800 loss 0.005144154187291861
[2025-03-21 14:21:16,802][model][INFO] - Training step 22960 loss 0.253500759601593
[2025-03-21 14:22:36,350][model][INFO] - Training step 23120 loss 0.03118356317281723
[2025-03-21 14:23:57,110][model][INFO] - Training step 23280 loss 0.24685223400592804
[2025-03-21 14:25:18,890][model][INFO] - Training step 23440 loss 0.037356846034526825
[2025-03-21 14:26:36,119][model][INFO] - Training step 23600 loss 0.17213472723960876
[2025-03-21 14:27:53,094][model][INFO] - Training step 23760 loss 0.06995443254709244
[2025-03-21 14:29:14,824][model][INFO] - Training step 23920 loss 0.03979812562465668
[2025-03-21 14:30:32,793][model][INFO] - Training step 24080 loss 0.24896150827407837
[2025-03-21 14:31:51,486][model][INFO] - Training step 24240 loss 0.05036209151148796
[2025-03-21 14:33:09,793][model][INFO] - Training step 24400 loss 0.0333729088306427
[2025-03-21 14:34:27,785][model][INFO] - Training step 24560 loss 0.038677141070365906
[2025-03-21 14:35:44,896][model][INFO] - Training step 24720 loss 0.021453063935041428
[2025-03-21 14:37:07,714][model][INFO] - Training step 24880 loss 0.030737459659576416
[2025-03-21 14:38:26,320][model][INFO] - Training step 25040 loss 0.048063792288303375
[2025-03-21 14:39:44,416][model][INFO] - Training step 25200 loss 0.0223730206489563
[2025-03-21 14:40:59,992][model][INFO] - Training step 25360 loss 0.03326849639415741
[2025-03-21 14:42:20,974][model][INFO] - Training step 25520 loss 0.03697824850678444
[2025-03-21 14:43:37,987][model][INFO] - Training step 25680 loss 0.06496595591306686
[2025-03-21 14:44:56,522][model][INFO] - Training step 25840 loss 0.2567831873893738
[2025-03-21 14:46:15,007][model][INFO] - Training step 26000 loss 0.06092865392565727
[2025-03-21 14:47:34,132][model][INFO] - Training step 26160 loss 0.03155110776424408
[2025-03-21 14:48:54,088][model][INFO] - Training step 26320 loss 0.14769935607910156
[2025-03-21 14:50:13,558][model][INFO] - Training step 26480 loss 0.04218636453151703
[2025-03-21 14:51:35,831][model][INFO] - Training step 26640 loss 0.04698767513036728
[2025-03-21 14:52:56,088][model][INFO] - Training step 26800 loss 0.016147391870617867
[2025-03-21 14:54:14,119][model][INFO] - Training step 26960 loss 0.011827582493424416
[2025-03-21 14:55:36,912][model][INFO] - Training step 27120 loss 0.003846290521323681
[2025-03-21 14:56:56,295][model][INFO] - Training step 27280 loss 0.06503665447235107
[2025-03-21 14:58:17,061][model][INFO] - Training step 27440 loss 0.2750154435634613
[2025-03-21 14:59:35,383][model][INFO] - Training step 27600 loss 0.00758894020691514
[2025-03-21 15:00:54,217][model][INFO] - Training step 27760 loss 0.2529086470603943
[2025-03-21 15:02:12,646][model][INFO] - Training step 27920 loss 0.04179426282644272
[2025-03-21 15:03:41,078][model][INFO] - Training step 28080 loss 0.038338854908943176
[2025-03-21 15:05:00,184][model][INFO] - Training step 28240 loss 0.23937492072582245
[2025-03-21 15:06:19,520][model][INFO] - Training step 28400 loss 0.05177011340856552
[2025-03-21 15:07:38,493][model][INFO] - Training step 28560 loss 0.05974912643432617
[2025-03-21 15:08:57,275][model][INFO] - Training step 28720 loss 0.02105012908577919
[2025-03-21 15:10:18,216][model][INFO] - Training step 28880 loss 0.024553479626774788
[2025-03-21 15:11:36,375][model][INFO] - Training step 29040 loss 0.028876878321170807
[2025-03-21 15:12:54,941][model][INFO] - Training step 29200 loss 0.017263399437069893
[2025-03-21 15:14:15,817][model][INFO] - Training step 29360 loss 0.013004780746996403
[2025-03-21 15:15:35,169][model][INFO] - Training step 29520 loss 0.17934422194957733
[2025-03-21 15:16:56,903][model][INFO] - Training step 29680 loss 0.03585432469844818
[2025-03-21 15:18:11,487][model][INFO] - Training step 29840 loss 0.00262711220420897
[2025-03-21 15:19:33,000][model][INFO] - Training step 30000 loss 0.051809072494506836
[2025-03-21 15:20:49,759][model][INFO] - Training step 30160 loss 0.24191007018089294
[2025-03-21 15:22:11,014][model][INFO] - Training step 30320 loss 0.028070826083421707
[2025-03-21 15:23:30,281][model][INFO] - Training step 30480 loss 0.00451023131608963
[2025-03-21 15:24:46,305][model][INFO] - Training step 30640 loss 0.23100551962852478
[2025-03-21 15:26:03,370][model][INFO] - Training step 30800 loss 0.09800679981708527
[2025-03-21 15:27:21,805][model][INFO] - Training step 30960 loss 0.06563540548086166
[2025-03-21 15:28:42,942][model][INFO] - Training step 31120 loss 0.03633482754230499
[2025-03-21 15:30:02,415][model][INFO] - Training step 31280 loss 0.03797328844666481
[2025-03-21 15:31:22,264][model][INFO] - Training step 31440 loss 0.25542864203453064
[2025-03-21 15:32:42,011][model][INFO] - Training step 31600 loss 0.03476663678884506
[2025-03-21 15:34:01,830][model][INFO] - Training step 31760 loss 0.07934948056936264
[2025-03-21 15:35:18,089][model][INFO] - Training step 31920 loss 0.038211703300476074
[2025-03-21 15:36:35,078][model][INFO] - Training step 32080 loss 0.005933849606662989
[2025-03-21 15:37:55,536][model][INFO] - Training step 32240 loss 0.23803289234638214
[2025-03-21 15:39:14,114][model][INFO] - Training step 32400 loss 0.04070950672030449
[2025-03-21 15:40:34,720][model][INFO] - Training step 32560 loss 0.2529701590538025
[2025-03-21 15:41:55,735][model][INFO] - Training step 32720 loss 0.25317907333374023
[2025-03-21 15:43:17,305][model][INFO] - Training step 32880 loss 0.01050817035138607
[2025-03-21 15:44:37,772][model][INFO] - Training step 33040 loss 0.004559439606964588
[2025-03-21 15:45:57,539][model][INFO] - Training step 33200 loss 0.25128883123397827
[2025-03-21 15:47:16,463][model][INFO] - Training step 33360 loss 0.021486006677150726
[2025-03-21 15:48:39,220][model][INFO] - Training step 33520 loss 0.0945306196808815
[2025-03-21 15:49:58,020][model][INFO] - Training step 33680 loss 0.01221148855984211
[2025-03-21 15:51:19,143][model][INFO] - Training step 33840 loss 0.02080969139933586
[2025-03-21 15:52:39,315][model][INFO] - Training step 34000 loss 0.006049586459994316
[2025-03-21 15:54:01,585][model][INFO] - Training step 34160 loss 0.005302991718053818
[2025-03-21 15:55:21,441][model][INFO] - Training step 34320 loss 0.02859760820865631
[2025-03-21 15:56:42,743][model][INFO] - Training step 34480 loss 0.2557489275932312
[2025-03-21 15:58:03,133][model][INFO] - Training step 34640 loss 0.03278058394789696
[2025-03-21 15:59:19,944][model][INFO] - Training step 34800 loss 0.2761198878288269
[2025-03-21 16:00:42,517][model][INFO] - Training step 34960 loss 0.06069260835647583
[2025-03-21 16:02:03,210][model][INFO] - Training step 35120 loss 0.014641109853982925
[2025-03-21 16:03:23,200][model][INFO] - Training step 35280 loss 0.026571335271000862
[2025-03-21 16:04:44,404][model][INFO] - Training step 35440 loss 0.25397810339927673
[2025-03-21 16:06:04,073][model][INFO] - Training step 35600 loss 0.0027604198548942804
[2025-03-21 16:07:22,585][model][INFO] - Training step 35760 loss 0.06791314482688904
[2025-03-21 16:08:39,023][model][INFO] - Training step 35920 loss 0.053392745554447174
[2025-03-21 16:09:57,591][model][INFO] - Training step 36080 loss 0.049833692610263824
[2025-03-21 16:11:16,222][model][INFO] - Training step 36240 loss 0.2602148652076721
[2025-03-21 16:12:35,390][model][INFO] - Training step 36400 loss 0.07756686210632324
[2025-03-21 16:13:54,389][model][INFO] - Training step 36560 loss 0.0043172831647098064
[2025-03-21 16:15:16,099][model][INFO] - Training step 36720 loss 0.004601633176207542
[2025-03-21 16:16:34,904][model][INFO] - Training step 36880 loss 0.006320715881884098
[2025-03-21 16:17:56,614][model][INFO] - Training step 37040 loss 0.2558332085609436
[2025-03-21 16:19:16,540][model][INFO] - Training step 37200 loss 0.24972525238990784
[2025-03-21 16:20:34,570][model][INFO] - Training step 37360 loss 0.053511008620262146
[2025-03-21 16:21:54,021][model][INFO] - Training step 37520 loss 0.031099770218133926
[2025-03-21 16:23:11,501][model][INFO] - Training step 37680 loss 0.0315779373049736
[2025-03-21 16:24:31,439][model][INFO] - Training step 37840 loss 0.041707005351781845
[2025-03-21 16:25:50,155][model][INFO] - Training step 38000 loss 0.25408750772476196
[2025-03-21 16:27:05,806][model][INFO] - Training step 38160 loss 0.023060377687215805
[2025-03-21 16:28:25,459][model][INFO] - Training step 38320 loss 0.037624895572662354
[2025-03-21 16:29:43,359][model][INFO] - Training step 38480 loss 0.035064272582530975
[2025-03-21 16:31:01,290][model][INFO] - Training step 38640 loss 0.05341557785868645
[2025-03-21 16:32:21,479][model][INFO] - Training step 38800 loss 0.24994772672653198
[2025-03-21 16:33:39,112][model][INFO] - Training step 38960 loss 0.2503586709499359
[2025-03-21 16:34:56,042][model][INFO] - Training step 39120 loss 0.002846714574843645
[2025-03-21 16:36:19,031][model][INFO] - Training step 39280 loss 0.146164208650589
[2025-03-21 16:37:39,046][model][INFO] - Training step 39440 loss 0.016914546489715576
[2025-03-21 16:38:56,977][model][INFO] - Training step 39600 loss 0.007225359324365854
[2025-03-21 16:40:14,012][model][INFO] - Training step 39760 loss 0.24786949157714844
[2025-03-21 16:41:36,508][model][INFO] - Training step 39920 loss 0.06646068394184113
[2025-03-21 16:42:57,463][model][INFO] - Training step 40080 loss 0.2546505928039551
[2025-03-21 16:44:17,292][model][INFO] - Training step 40240 loss 0.032852694392204285
[2025-03-21 16:45:36,273][model][INFO] - Training step 40400 loss 0.040078479796648026
[2025-03-21 16:46:57,440][model][INFO] - Training step 40560 loss 0.03825193643569946
[2025-03-21 16:48:15,113][model][INFO] - Training step 40720 loss 0.035653091967105865
[2025-03-21 16:49:34,652][model][INFO] - Training step 40880 loss 0.2562403380870819
[2025-03-21 16:50:52,440][model][INFO] - Training step 41040 loss 0.031191494315862656
[2025-03-21 16:52:12,412][model][INFO] - Training step 41200 loss 0.01741993986070156
[2025-03-21 16:53:33,739][model][INFO] - Training step 41360 loss 0.010965391993522644
[2025-03-21 16:54:50,062][model][INFO] - Training step 41520 loss 0.12901422381401062
[2025-03-21 16:56:11,801][model][INFO] - Training step 41680 loss 0.19113968312740326
[2025-03-21 16:57:32,135][model][INFO] - Training step 41840 loss 0.024370023980736732
[2025-03-21 16:58:50,638][model][INFO] - Training step 42000 loss 0.046273477375507355
[2025-03-21 17:00:07,543][model][INFO] - Training step 42160 loss 0.029584724456071854
[2025-03-21 17:01:24,002][model][INFO] - Training step 42320 loss 0.0500667542219162
[2025-03-21 17:02:45,246][model][INFO] - Training step 42480 loss 0.033952001482248306
[2025-03-21 17:04:03,362][model][INFO] - Training step 42640 loss 0.021273326128721237
[2025-03-21 17:05:23,702][model][INFO] - Training step 42800 loss 0.02077415958046913
[2025-03-21 17:06:42,337][model][INFO] - Training step 42960 loss 0.0284903421998024
[2025-03-21 17:08:01,353][model][INFO] - Training step 43120 loss 0.05975470691919327
[2025-03-21 17:09:19,573][model][INFO] - Training step 43280 loss 0.04900510236620903
[2025-03-21 17:10:38,720][model][INFO] - Training step 43440 loss 0.04955507442355156
[2025-03-21 17:11:58,047][model][INFO] - Training step 43600 loss 0.0227276012301445
[2025-03-21 17:13:22,292][model][INFO] - Training step 43760 loss 0.0635867789387703
[2025-03-21 17:14:41,507][model][INFO] - Training step 43920 loss 0.043854955583810806
[2025-03-21 17:15:59,200][model][INFO] - Training step 44080 loss 0.08748120814561844
[2025-03-21 17:17:20,411][model][INFO] - Training step 44240 loss 0.03751278668642044
[2025-03-21 17:18:40,385][model][INFO] - Training step 44400 loss 0.171915665268898
[2025-03-21 17:19:58,415][model][INFO] - Training step 44560 loss 0.032366927713155746
[2025-03-21 17:21:17,890][model][INFO] - Training step 44720 loss 0.009348596446216106
[2025-03-21 17:22:33,125][model][INFO] - Training step 44880 loss 0.05688507854938507
[2025-03-21 17:23:55,662][model][INFO] - Training step 45040 loss 0.05328075587749481
[2025-03-21 17:25:14,615][model][INFO] - Training step 45200 loss 0.0188450887799263
[2025-03-21 17:26:38,775][model][INFO] - Training step 45360 loss 0.006490780971944332
[2025-03-21 17:27:57,802][model][INFO] - Training step 45520 loss 0.033352166414260864
[2025-03-21 17:29:20,854][model][INFO] - Training step 45680 loss 0.020347777754068375
[2025-03-21 17:30:41,504][model][INFO] - Training step 45840 loss 0.06583231687545776
[2025-03-21 17:32:02,324][model][INFO] - Training step 46000 loss 0.04653071612119675
[2025-03-21 17:33:19,689][model][INFO] - Training step 46160 loss 0.07505815476179123
[2025-03-21 17:34:41,781][model][INFO] - Training step 46320 loss 0.03478851169347763
[2025-03-21 17:36:00,580][model][INFO] - Training step 46480 loss 0.03069540113210678
[2025-03-21 17:37:19,376][model][INFO] - Training step 46640 loss 0.005425719544291496
[2025-03-21 17:38:36,894][model][INFO] - Training step 46800 loss 0.032380010932683945
[2025-03-21 17:39:56,961][model][INFO] - Training step 46960 loss 0.0627686008810997
[2025-03-21 17:41:16,483][model][INFO] - Training step 47120 loss 0.08569978177547455
[2025-03-21 17:42:35,538][model][INFO] - Training step 47280 loss 0.031477898359298706
[2025-03-21 17:43:53,412][model][INFO] - Training step 47440 loss 0.01764843612909317
[2025-03-21 17:45:15,079][model][INFO] - Training step 47600 loss 0.24603116512298584
[2025-03-21 17:46:33,574][model][INFO] - Training step 47760 loss 0.05192824825644493
[2025-03-21 17:47:52,886][model][INFO] - Training step 47920 loss 0.25478509068489075
[2025-03-21 17:49:14,535][model][INFO] - Training step 48080 loss 0.0028366786427795887
[2025-03-21 17:50:30,082][model][INFO] - Training step 48240 loss 0.0026536518707871437
[2025-03-21 17:51:50,809][model][INFO] - Training step 48400 loss 0.06529109179973602
[2025-03-21 17:53:10,485][model][INFO] - Training step 48560 loss 0.2524413764476776
[2025-03-21 17:54:32,335][model][INFO] - Training step 48720 loss 0.005514448508620262
[2025-03-21 17:55:51,811][model][INFO] - Training step 48880 loss 0.003255571238696575
[2025-03-21 17:57:11,970][model][INFO] - Training step 49040 loss 0.03927593678236008
[2025-03-21 17:58:33,903][model][INFO] - Training step 49200 loss 0.004743438679724932
[2025-03-21 17:59:55,811][model][INFO] - Training step 49360 loss 0.0328003391623497
[2025-03-21 18:01:15,559][model][INFO] - Training step 49520 loss 0.007097335532307625
[2025-03-21 18:02:34,626][model][INFO] - Training step 49680 loss 0.012729167938232422
[2025-03-21 18:03:56,713][model][INFO] - Training step 49840 loss 0.05691204220056534
[2025-03-21 18:05:16,387][model][INFO] - Training step 50000 loss 0.03284738212823868
[2025-03-21 18:06:34,276][model][INFO] - Training step 50160 loss 0.23503318428993225
[2025-03-21 18:07:53,316][model][INFO] - Training step 50320 loss 0.02996370941400528
[2025-03-21 18:09:14,441][model][INFO] - Training step 50480 loss 0.026268508285284042
[2025-03-21 18:10:32,009][model][INFO] - Training step 50640 loss 0.01685570925474167
[2025-03-21 18:20:07,936][model][INFO] - Training step 0 loss 0.1278296411037445
[2025-03-21 18:21:26,969][model][INFO] - Training step 160 loss 0.006899802479892969
[2025-03-21 18:22:44,295][model][INFO] - Training step 320 loss 0.2466805875301361
[2025-03-21 18:24:06,956][model][INFO] - Training step 480 loss 0.025811471045017242
[2025-03-21 18:25:28,276][model][INFO] - Training step 640 loss 0.25191789865493774
[2025-03-21 18:26:50,046][model][INFO] - Training step 800 loss 0.07226164638996124
[2025-03-21 18:28:10,378][model][INFO] - Training step 960 loss 0.24530929327011108
[2025-03-21 18:29:26,760][model][INFO] - Training step 1120 loss 0.04902683198451996
[2025-03-21 18:30:46,740][model][INFO] - Training step 1280 loss 0.24963706731796265
[2025-03-21 18:32:04,546][model][INFO] - Training step 1440 loss 0.25351816415786743
[2025-03-21 18:33:22,508][model][INFO] - Training step 1600 loss 0.1328865885734558
[2025-03-21 18:34:43,458][model][INFO] - Training step 1760 loss 0.012991789728403091
[2025-03-21 18:36:02,599][model][INFO] - Training step 1920 loss 0.05422823876142502
[2025-03-21 18:37:26,318][model][INFO] - Training step 2080 loss 0.02716919593513012
[2025-03-21 18:38:45,127][model][INFO] - Training step 2240 loss 0.04093225300312042
[2025-03-21 18:40:03,180][model][INFO] - Training step 2400 loss 0.2518184781074524
[2025-03-21 18:41:21,554][model][INFO] - Training step 2560 loss 0.126468688249588
[2025-03-21 18:42:41,348][model][INFO] - Training step 2720 loss 0.055766165256500244
[2025-03-21 18:44:02,004][model][INFO] - Training step 2880 loss 0.14053307473659515
[2025-03-21 18:45:21,396][model][INFO] - Training step 3040 loss 0.05922691524028778
[2025-03-21 18:46:40,328][model][INFO] - Training step 3200 loss 0.006871093530207872
[2025-03-21 18:47:58,618][model][INFO] - Training step 3360 loss 0.013578737154603004
[2025-03-21 18:49:18,100][model][INFO] - Training step 3520 loss 0.031133972108364105
[2025-03-21 18:50:38,796][model][INFO] - Training step 3680 loss 0.049096010625362396
[2025-03-21 18:51:59,927][model][INFO] - Training step 3840 loss 0.032250791788101196
[2025-03-21 18:53:21,540][model][INFO] - Training step 4000 loss 0.04867319390177727
[2025-03-21 18:54:41,695][model][INFO] - Training step 4160 loss 0.0058010537177324295
[2025-03-21 18:56:00,625][model][INFO] - Training step 4320 loss 0.029549915343523026
[2025-03-21 18:57:21,902][model][INFO] - Training step 4480 loss 0.08430038392543793
[2025-03-21 18:58:42,167][model][INFO] - Training step 4640 loss 0.0029809712432324886
[2025-03-21 19:00:02,161][model][INFO] - Training step 4800 loss 0.07091675698757172
[2025-03-21 19:01:22,742][model][INFO] - Training step 4960 loss 0.010334663093090057
[2025-03-21 19:02:41,918][model][INFO] - Training step 5120 loss 0.10438939183950424
[2025-03-21 19:04:00,641][model][INFO] - Training step 5280 loss 0.027355361729860306
[2025-03-21 19:05:20,525][model][INFO] - Training step 5440 loss 0.005320845637470484
[2025-03-21 19:06:37,922][model][INFO] - Training step 5600 loss 0.2619538903236389
[2025-03-21 19:07:57,295][model][INFO] - Training step 5760 loss 0.2617477476596832
[2025-03-21 19:09:17,040][model][INFO] - Training step 5920 loss 0.02268826588988304
[2025-03-21 19:10:35,279][model][INFO] - Training step 6080 loss 0.02540459856390953
[2025-03-21 19:11:56,453][model][INFO] - Training step 6240 loss 0.25925764441490173
[2025-03-21 19:13:16,489][model][INFO] - Training step 6400 loss 0.025935977697372437
[2025-03-21 19:14:34,559][model][INFO] - Training step 6560 loss 0.028795309364795685
[2025-03-21 19:15:54,194][model][INFO] - Training step 6720 loss 0.0032424263190478086
[2025-03-21 19:17:13,911][model][INFO] - Training step 6880 loss 0.04807499423623085
[2025-03-21 19:18:30,396][model][INFO] - Training step 7040 loss 0.015841709449887276
[2025-03-21 19:19:52,391][model][INFO] - Training step 7200 loss 0.01962272636592388
[2025-03-21 19:21:12,487][model][INFO] - Training step 7360 loss 0.060888729989528656
[2025-03-21 19:22:30,704][model][INFO] - Training step 7520 loss 0.04526040703058243
[2025-03-21 19:23:49,468][model][INFO] - Training step 7680 loss 0.2544066905975342
[2025-03-21 19:25:09,568][model][INFO] - Training step 7840 loss 0.005888685584068298
[2025-03-21 19:26:28,243][model][INFO] - Training step 8000 loss 0.12163902819156647
[2025-03-21 19:27:47,257][model][INFO] - Training step 8160 loss 0.016659975051879883
[2025-03-21 19:29:07,678][model][INFO] - Training step 8320 loss 0.02149498090147972
[2025-03-21 19:30:26,116][model][INFO] - Training step 8480 loss 0.060685910284519196
[2025-03-21 19:31:44,397][model][INFO] - Training step 8640 loss 0.042047224938869476
[2025-03-21 19:33:01,879][model][INFO] - Training step 8800 loss 0.0341997966170311
[2025-03-21 19:34:18,324][model][INFO] - Training step 8960 loss 0.2849358022212982
[2025-03-21 19:35:36,910][model][INFO] - Training step 9120 loss 0.049936551600694656
[2025-03-21 19:36:53,460][model][INFO] - Training step 9280 loss 0.07909243553876877
[2025-03-21 19:38:14,094][model][INFO] - Training step 9440 loss 0.020609930157661438
[2025-03-21 19:39:31,608][model][INFO] - Training step 9600 loss 0.024615958333015442
[2025-03-21 19:40:53,927][model][INFO] - Training step 9760 loss 0.023647572845220566
[2025-03-21 19:42:13,879][model][INFO] - Training step 9920 loss 0.04829609394073486
[2025-03-21 19:43:36,018][model][INFO] - Training step 10080 loss 0.039204493165016174
[2025-03-21 19:44:54,470][model][INFO] - Training step 10240 loss 0.024066708981990814
[2025-03-21 19:46:15,116][model][INFO] - Training step 10400 loss 0.005846427753567696
[2025-03-21 19:47:34,923][model][INFO] - Training step 10560 loss 0.04090903326869011
[2025-03-21 19:48:53,284][model][INFO] - Training step 10720 loss 0.03649132698774338
[2025-03-21 19:50:15,638][model][INFO] - Training step 10880 loss 0.037391677498817444
[2025-03-21 19:51:34,769][model][INFO] - Training step 11040 loss 0.2569321393966675
[2025-03-21 19:52:52,115][model][INFO] - Training step 11200 loss 0.009030899032950401
[2025-03-21 19:54:09,259][model][INFO] - Training step 11360 loss 0.2440827190876007
[2025-03-21 19:55:27,623][model][INFO] - Training step 11520 loss 0.025476079434156418
[2025-03-21 19:56:46,306][model][INFO] - Training step 11680 loss 0.06743583083152771
[2025-03-21 19:58:08,613][model][INFO] - Training step 11840 loss 0.2541651725769043
[2025-03-21 19:59:28,767][model][INFO] - Training step 12000 loss 0.0818454846739769
[2025-03-21 20:00:48,999][model][INFO] - Training step 12160 loss 0.03697144240140915
[2025-03-21 20:02:07,250][model][INFO] - Training step 12320 loss 0.07416501641273499
[2025-03-21 20:03:28,875][model][INFO] - Training step 12480 loss 0.06990306079387665
[2025-03-21 20:04:45,552][model][INFO] - Training step 12640 loss 0.2409171760082245
[2025-03-21 20:06:06,484][model][INFO] - Training step 12800 loss 0.08201174437999725
[2025-03-21 20:07:24,517][model][INFO] - Training step 12960 loss 0.019999589771032333
[2025-03-21 20:08:43,890][model][INFO] - Training step 13120 loss 0.017148010432720184
[2025-03-21 20:10:02,432][model][INFO] - Training step 13280 loss 0.016571637243032455
[2025-03-21 20:11:18,457][model][INFO] - Training step 13440 loss 0.056679777801036835
[2025-03-21 20:12:38,923][model][INFO] - Training step 13600 loss 0.03285425901412964
[2025-03-21 20:13:59,410][model][INFO] - Training step 13760 loss 0.029299158602952957
[2025-03-21 20:15:16,176][model][INFO] - Training step 13920 loss 0.24033282697200775
[2025-03-21 20:16:36,014][model][INFO] - Training step 14080 loss 0.002693834248930216
[2025-03-21 20:17:54,927][model][INFO] - Training step 14240 loss 0.09801889955997467
[2025-03-21 20:19:16,279][model][INFO] - Training step 14400 loss 0.2549699544906616
[2025-03-21 20:20:33,672][model][INFO] - Training step 14560 loss 0.03111761063337326
[2025-03-21 20:21:52,885][model][INFO] - Training step 14720 loss 0.023301538079977036
[2025-03-21 20:23:13,564][model][INFO] - Training step 14880 loss 0.03330720216035843
[2025-03-21 20:24:35,963][model][INFO] - Training step 15040 loss 0.043238792568445206
[2025-03-21 20:25:54,768][model][INFO] - Training step 15200 loss 0.023908862844109535
[2025-03-21 20:27:15,482][model][INFO] - Training step 15360 loss 0.015055220574140549
[2025-03-21 20:28:36,050][model][INFO] - Training step 15520 loss 0.26140785217285156
[2025-03-21 20:29:54,134][model][INFO] - Training step 15680 loss 0.05393441393971443
[2025-03-21 20:31:15,456][model][INFO] - Training step 15840 loss 0.04584958404302597
[2025-03-21 20:32:32,730][model][INFO] - Training step 16000 loss 0.05737455561757088
[2025-03-21 20:33:53,585][model][INFO] - Training step 16160 loss 0.006378651596605778
[2025-03-21 20:35:12,841][model][INFO] - Training step 16320 loss 0.10392668843269348
[2025-03-21 20:36:29,040][model][INFO] - Training step 16480 loss 0.02047087252140045
[2025-03-21 20:37:49,212][model][INFO] - Training step 16640 loss 0.37435317039489746
[2025-03-21 20:39:08,506][model][INFO] - Training step 16800 loss 0.03527899459004402
[2025-03-21 20:40:30,808][model][INFO] - Training step 16960 loss 0.06408356875181198
[2025-03-21 20:41:51,602][model][INFO] - Training step 17120 loss 0.2559082508087158
[2025-03-21 20:43:10,219][model][INFO] - Training step 17280 loss 0.02645876258611679
[2025-03-21 20:44:28,282][model][INFO] - Training step 17440 loss 0.0046746074222028255
[2025-03-21 20:45:47,989][model][INFO] - Training step 17600 loss 0.035134971141815186
[2025-03-21 20:47:08,182][model][INFO] - Training step 17760 loss 0.03847189247608185
[2025-03-21 20:48:25,168][model][INFO] - Training step 17920 loss 0.2642291188240051
[2025-03-21 20:49:45,014][model][INFO] - Training step 18080 loss 0.2366829514503479
[2025-03-21 20:51:05,136][model][INFO] - Training step 18240 loss 0.007505442947149277
[2025-03-21 20:52:27,918][model][INFO] - Training step 18400 loss 0.040273912250995636
[2025-03-21 20:53:47,749][model][INFO] - Training step 18560 loss 0.023859616369009018
[2025-03-21 20:55:07,127][model][INFO] - Training step 18720 loss 0.03779003024101257
[2025-03-21 20:56:29,580][model][INFO] - Training step 18880 loss 0.0447746217250824
[2025-03-21 20:57:46,660][model][INFO] - Training step 19040 loss 0.04021567106246948
[2025-03-21 20:59:02,326][model][INFO] - Training step 19200 loss 0.05340424180030823
[2025-03-21 21:00:18,338][model][INFO] - Training step 19360 loss 0.02703351154923439
[2025-03-21 21:01:36,344][model][INFO] - Training step 19520 loss 0.07939231395721436
[2025-03-21 21:02:56,190][model][INFO] - Training step 19680 loss 0.03360895812511444
[2025-03-21 21:04:14,020][model][INFO] - Training step 19840 loss 0.03696764260530472
[2025-03-21 21:05:34,779][model][INFO] - Training step 20000 loss 0.2308226376771927
[2025-03-21 21:06:53,900][model][INFO] - Training step 20160 loss 0.02645689621567726
[2025-03-21 21:08:12,739][model][INFO] - Training step 20320 loss 0.006329565774649382
[2025-03-21 21:09:35,337][model][INFO] - Training step 20480 loss 0.037564292550086975
[2025-03-21 21:10:56,180][model][INFO] - Training step 20640 loss 0.24960392713546753
[2025-03-21 21:12:15,776][model][INFO] - Training step 20800 loss 0.24798841774463654
[2025-03-21 21:13:34,252][model][INFO] - Training step 20960 loss 0.23955562710762024
[2025-03-21 21:14:54,938][model][INFO] - Training step 21120 loss 0.15244680643081665
[2025-03-21 21:16:14,435][model][INFO] - Training step 21280 loss 0.0353240966796875
[2025-03-21 21:17:34,345][model][INFO] - Training step 21440 loss 0.02755231037735939
[2025-03-21 21:18:54,531][model][INFO] - Training step 21600 loss 0.25716519355773926
[2025-03-21 21:20:14,723][model][INFO] - Training step 21760 loss 0.02648889645934105
[2025-03-21 21:21:34,676][model][INFO] - Training step 21920 loss 0.03197447955608368
[2025-03-21 21:22:53,422][model][INFO] - Training step 22080 loss 0.2573659420013428
[2025-03-21 21:24:13,888][model][INFO] - Training step 22240 loss 0.24161185324192047
[2025-03-21 21:25:33,480][model][INFO] - Training step 22400 loss 0.25074705481529236
[2025-03-21 21:26:51,779][model][INFO] - Training step 22560 loss 0.06862294673919678
[2025-03-21 21:28:10,049][model][INFO] - Training step 22720 loss 0.01643887162208557
[2025-03-21 21:29:27,803][model][INFO] - Training step 22880 loss 0.024542367085814476
[2025-03-21 21:30:46,491][model][INFO] - Training step 23040 loss 0.05685887485742569
[2025-03-21 21:32:08,633][model][INFO] - Training step 23200 loss 0.04680477827787399
[2025-03-21 21:33:28,479][model][INFO] - Training step 23360 loss 0.03659961372613907
[2025-03-21 21:34:46,101][model][INFO] - Training step 23520 loss 0.0452328696846962
[2025-03-21 21:36:04,222][model][INFO] - Training step 23680 loss 0.002420357195660472
[2025-03-21 21:37:23,520][model][INFO] - Training step 23840 loss 0.03208557516336441
[2025-03-21 21:38:41,271][model][INFO] - Training step 24000 loss 0.05260182172060013
[2025-03-21 21:40:00,193][model][INFO] - Training step 24160 loss 0.25666552782058716
[2025-03-21 21:41:17,786][model][INFO] - Training step 24320 loss 0.04103017598390579
[2025-03-21 21:42:39,867][model][INFO] - Training step 24480 loss 0.23451688885688782
[2025-03-21 21:43:56,631][model][INFO] - Training step 24640 loss 0.2749509811401367
[2025-03-21 21:45:15,897][model][INFO] - Training step 24800 loss 0.12465611100196838
[2025-03-21 21:46:32,984][model][INFO] - Training step 24960 loss 0.2610803246498108
[2025-03-21 21:47:52,057][model][INFO] - Training step 25120 loss 0.007486077956855297
[2025-03-21 21:49:10,650][model][INFO] - Training step 25280 loss 0.030313201248645782
[2025-03-21 21:50:30,035][model][INFO] - Training step 25440 loss 0.2476130723953247
[2025-03-21 21:51:47,495][model][INFO] - Training step 25600 loss 0.11704792827367783
[2025-03-21 21:53:03,516][model][INFO] - Training step 25760 loss 0.07811485975980759
[2025-03-21 21:54:23,850][model][INFO] - Training step 25920 loss 0.09195870161056519
[2025-03-21 21:55:44,463][model][INFO] - Training step 26080 loss 0.25473538041114807
[2025-03-21 21:57:04,685][model][INFO] - Training step 26240 loss 0.2509385049343109
[2025-03-21 21:58:25,230][model][INFO] - Training step 26400 loss 0.025758182629942894
[2025-03-21 21:59:44,765][model][INFO] - Training step 26560 loss 0.017069149762392044
[2025-03-21 22:01:03,265][model][INFO] - Training step 26720 loss 0.027050618082284927
[2025-03-21 22:02:25,670][model][INFO] - Training step 26880 loss 0.06307192891836166
[2025-03-21 22:03:42,306][model][INFO] - Training step 27040 loss 0.023034360259771347
[2025-03-21 22:05:01,659][model][INFO] - Training step 27200 loss 0.03704972565174103
[2025-03-21 22:06:22,256][model][INFO] - Training step 27360 loss 0.03853049874305725
[2025-03-21 22:07:38,023][model][INFO] - Training step 27520 loss 0.04257762432098389
[2025-03-21 22:08:59,168][model][INFO] - Training step 27680 loss 0.24974524974822998
[2025-03-21 22:10:19,164][model][INFO] - Training step 27840 loss 0.04053947702050209
[2025-03-21 22:11:37,464][model][INFO] - Training step 28000 loss 0.004238208290189505
[2025-03-21 22:12:58,375][model][INFO] - Training step 28160 loss 0.04621955007314682
[2025-03-21 22:14:13,484][model][INFO] - Training step 28320 loss 0.04700974375009537
[2025-03-21 22:15:31,939][model][INFO] - Training step 28480 loss 0.040293194353580475
[2025-03-21 22:16:52,973][model][INFO] - Training step 28640 loss 0.25523707270622253
[2025-03-21 22:18:10,733][model][INFO] - Training step 28800 loss 0.25186267495155334
[2025-03-21 22:19:32,464][model][INFO] - Training step 28960 loss 0.25433167815208435
[2025-03-21 22:20:51,399][model][INFO] - Training step 29120 loss 0.04353844374418259
[2025-03-21 22:22:12,361][model][INFO] - Training step 29280 loss 0.05484888702630997
[2025-03-21 22:23:35,776][model][INFO] - Training step 29440 loss 0.02298593893647194
[2025-03-21 22:24:55,943][model][INFO] - Training step 29600 loss 0.08600916713476181
[2025-03-21 22:26:16,296][model][INFO] - Training step 29760 loss 0.08378762006759644
[2025-03-21 22:27:38,615][model][INFO] - Training step 29920 loss 0.03456622362136841
[2025-03-21 22:28:54,833][model][INFO] - Training step 30080 loss 0.027434512972831726
[2025-03-21 22:30:14,353][model][INFO] - Training step 30240 loss 0.050193902105093
[2025-03-21 22:31:33,323][model][INFO] - Training step 30400 loss 0.06781598925590515
[2025-03-21 22:32:54,948][model][INFO] - Training step 30560 loss 0.30516642332077026
[2025-03-21 22:34:09,325][model][INFO] - Training step 30720 loss 0.02107354626059532
[2025-03-21 22:35:27,209][model][INFO] - Training step 30880 loss 0.028653902933001518
[2025-03-21 22:36:46,549][model][INFO] - Training step 31040 loss 0.0055155097506940365
[2025-03-21 22:38:03,950][model][INFO] - Training step 31200 loss 0.03187807649374008
[2025-03-21 22:39:24,563][model][INFO] - Training step 31360 loss 0.07092180848121643
[2025-03-21 22:40:45,521][model][INFO] - Training step 31520 loss 0.06547875702381134
[2025-03-21 22:42:05,154][model][INFO] - Training step 31680 loss 0.029706452041864395
[2025-03-21 22:43:24,269][model][INFO] - Training step 31840 loss 0.037971459329128265
[2025-03-21 22:44:43,035][model][INFO] - Training step 32000 loss 0.018903445452451706
[2025-03-21 22:46:02,567][model][INFO] - Training step 32160 loss 0.21610510349273682
[2025-03-21 22:47:23,499][model][INFO] - Training step 32320 loss 0.0228711050003767
[2025-03-21 22:48:45,262][model][INFO] - Training step 32480 loss 0.06808583438396454
[2025-03-21 22:50:07,133][model][INFO] - Training step 32640 loss 0.039203692227602005
[2025-03-21 22:51:27,927][model][INFO] - Training step 32800 loss 0.022846996784210205
[2025-03-21 22:52:52,668][model][INFO] - Training step 32960 loss 0.04752488434314728
[2025-03-21 22:54:08,115][model][INFO] - Training step 33120 loss 0.03401874005794525
[2025-03-21 22:55:28,592][model][INFO] - Training step 33280 loss 0.06878677755594254
[2025-03-21 22:56:47,398][model][INFO] - Training step 33440 loss 0.028479494154453278
[2025-03-21 22:58:07,601][model][INFO] - Training step 33600 loss 0.02445213310420513
[2025-03-21 22:59:24,852][model][INFO] - Training step 33760 loss 0.25111305713653564
[2025-03-21 23:00:42,275][model][INFO] - Training step 33920 loss 0.03598989546298981
[2025-03-21 23:02:04,127][model][INFO] - Training step 34080 loss 0.00741828978061676
[2025-03-21 23:03:25,392][model][INFO] - Training step 34240 loss 0.03269265219569206
[2025-03-21 23:04:49,091][model][INFO] - Training step 34400 loss 0.20139315724372864
[2025-03-21 23:06:11,602][model][INFO] - Training step 34560 loss 0.011738927103579044
[2025-03-21 23:07:28,089][model][INFO] - Training step 34720 loss 0.024130579084157944
[2025-03-21 23:08:46,698][model][INFO] - Training step 34880 loss 0.25114905834198
[2025-03-21 23:10:07,320][model][INFO] - Training step 35040 loss 0.04932379350066185
[2025-03-21 23:11:26,201][model][INFO] - Training step 35200 loss 0.016820454970002174
[2025-03-21 23:12:44,604][model][INFO] - Training step 35360 loss 0.01637364737689495
[2025-03-21 23:14:04,003][model][INFO] - Training step 35520 loss 0.004325524903833866
[2025-03-21 23:15:22,919][model][INFO] - Training step 35680 loss 0.029353376477956772
[2025-03-21 23:16:42,013][model][INFO] - Training step 35840 loss 0.019137244671583176
[2025-03-21 23:18:01,359][model][INFO] - Training step 36000 loss 0.028459541499614716
[2025-03-21 23:19:21,597][model][INFO] - Training step 36160 loss 0.03963663429021835
[2025-03-21 23:20:42,656][model][INFO] - Training step 36320 loss 0.02938976138830185
[2025-03-21 23:22:01,656][model][INFO] - Training step 36480 loss 0.16846337914466858
[2025-03-21 23:23:20,518][model][INFO] - Training step 36640 loss 0.058045465499162674
[2025-03-21 23:24:38,136][model][INFO] - Training step 36800 loss 0.025463566184043884
[2025-03-21 23:26:01,295][model][INFO] - Training step 36960 loss 0.01250416599214077
[2025-03-21 23:27:20,247][model][INFO] - Training step 37120 loss 0.023319553583860397
[2025-03-21 23:28:38,906][model][INFO] - Training step 37280 loss 0.26482605934143066
[2025-03-21 23:30:00,218][model][INFO] - Training step 37440 loss 0.041035816073417664
[2025-03-21 23:31:18,102][model][INFO] - Training step 37600 loss 0.026514288038015366
[2025-03-21 23:32:35,211][model][INFO] - Training step 37760 loss 0.03348417952656746
[2025-03-21 23:33:53,030][model][INFO] - Training step 37920 loss 0.025241021066904068
[2025-03-21 23:35:12,504][model][INFO] - Training step 38080 loss 0.2537077069282532
[2025-03-21 23:36:32,807][model][INFO] - Training step 38240 loss 0.05408282205462456
[2025-03-21 23:37:53,494][model][INFO] - Training step 38400 loss 0.07073405385017395
[2025-03-21 23:39:10,561][model][INFO] - Training step 38560 loss 0.02844308689236641
[2025-03-21 23:40:27,777][model][INFO] - Training step 38720 loss 0.25518798828125
[2025-03-21 23:41:46,952][model][INFO] - Training step 38880 loss 0.24544650316238403
[2025-03-21 23:43:06,072][model][INFO] - Training step 39040 loss 0.019159315153956413
[2025-03-21 23:44:22,494][model][INFO] - Training step 39200 loss 0.13184386491775513
[2025-03-21 23:45:39,075][model][INFO] - Training step 39360 loss 0.021537447348237038
[2025-03-21 23:46:59,835][model][INFO] - Training step 39520 loss 0.024634970352053642
[2025-03-21 23:48:17,789][model][INFO] - Training step 39680 loss 0.018850170075893402
[2025-03-21 23:49:39,092][model][INFO] - Training step 39840 loss 0.006280185654759407
[2025-03-21 23:50:56,416][model][INFO] - Training step 40000 loss 0.02538853883743286
[2025-03-21 23:52:16,929][model][INFO] - Training step 40160 loss 0.04029522091150284
[2025-03-21 23:53:39,006][model][INFO] - Training step 40320 loss 0.08469266444444656
[2025-03-21 23:54:58,863][model][INFO] - Training step 40480 loss 0.24137607216835022
[2025-03-21 23:56:16,876][model][INFO] - Training step 40640 loss 0.24050940573215485
[2025-03-21 23:57:33,986][model][INFO] - Training step 40800 loss 0.21589931845664978
[2025-03-21 23:58:52,616][model][INFO] - Training step 40960 loss 0.03901556879281998
[2025-03-22 00:00:14,494][model][INFO] - Training step 41120 loss 0.034165166318416595
[2025-03-22 00:01:32,834][model][INFO] - Training step 41280 loss 0.052367907017469406
[2025-03-22 00:02:50,836][model][INFO] - Training step 41440 loss 0.048061303794384
[2025-03-22 00:04:10,307][model][INFO] - Training step 41600 loss 0.03420232981443405
[2025-03-22 00:05:28,092][model][INFO] - Training step 41760 loss 0.018591558560729027
[2025-03-22 00:06:47,584][model][INFO] - Training step 41920 loss 0.25693678855895996
[2025-03-22 00:08:07,331][model][INFO] - Training step 42080 loss 0.009528091177344322
[2025-03-22 00:09:25,105][model][INFO] - Training step 42240 loss 0.024089235812425613
[2025-03-22 00:10:44,486][model][INFO] - Training step 42400 loss 0.2523750066757202
[2025-03-22 00:12:03,654][model][INFO] - Training step 42560 loss 0.013234823942184448
[2025-03-22 00:13:24,759][model][INFO] - Training step 42720 loss 0.0059923334047198296
[2025-03-22 00:14:41,782][model][INFO] - Training step 42880 loss 0.10537589341402054
[2025-03-22 00:16:01,645][model][INFO] - Training step 43040 loss 0.022707529366016388
[2025-03-22 00:17:19,606][model][INFO] - Training step 43200 loss 0.10878030210733414
[2025-03-22 00:18:38,485][model][INFO] - Training step 43360 loss 0.04881840571761131
[2025-03-22 00:19:59,213][model][INFO] - Training step 43520 loss 0.022494446486234665
[2025-03-22 00:21:19,234][model][INFO] - Training step 43680 loss 0.24502043426036835
[2025-03-22 00:22:35,248][model][INFO] - Training step 43840 loss 0.08387294411659241
[2025-03-22 00:23:54,698][model][INFO] - Training step 44000 loss 0.005644411779940128
[2025-03-22 00:25:15,896][model][INFO] - Training step 44160 loss 0.01328899897634983
[2025-03-22 00:26:33,581][model][INFO] - Training step 44320 loss 0.004080713260918856
[2025-03-22 00:27:50,657][model][INFO] - Training step 44480 loss 0.01233474537730217
[2025-03-22 00:29:11,198][model][INFO] - Training step 44640 loss 0.10798116028308868
[2025-03-22 00:30:33,752][model][INFO] - Training step 44800 loss 0.02137831412255764
[2025-03-22 00:31:52,421][model][INFO] - Training step 44960 loss 0.005311432760208845
[2025-03-22 00:33:13,208][model][INFO] - Training step 45120 loss 0.09921193867921829
[2025-03-22 00:34:32,316][model][INFO] - Training step 45280 loss 0.2498610019683838
[2025-03-22 00:35:54,040][model][INFO] - Training step 45440 loss 0.01051317062228918
[2025-03-22 00:37:14,513][model][INFO] - Training step 45600 loss 0.0025353292003273964
[2025-03-22 00:38:35,822][model][INFO] - Training step 45760 loss 0.033861950039863586
[2025-03-22 00:39:56,586][model][INFO] - Training step 45920 loss 0.2622920274734497
[2025-03-22 00:41:19,203][model][INFO] - Training step 46080 loss 0.027195656672120094
[2025-03-22 00:42:39,461][model][INFO] - Training step 46240 loss 0.24081102013587952
[2025-03-22 00:43:59,556][model][INFO] - Training step 46400 loss 0.0056765116751194
[2025-03-22 00:45:17,682][model][INFO] - Training step 46560 loss 0.09982934594154358
[2025-03-22 00:46:37,198][model][INFO] - Training step 46720 loss 0.047835029661655426
[2025-03-22 00:47:55,691][model][INFO] - Training step 46880 loss 0.029875103384256363
[2025-03-22 00:49:13,176][model][INFO] - Training step 47040 loss 0.21616309881210327
[2025-03-22 00:50:31,295][model][INFO] - Training step 47200 loss 0.2660962641239166
[2025-03-22 00:51:52,254][model][INFO] - Training step 47360 loss 0.02545229345560074
[2025-03-22 00:53:13,328][model][INFO] - Training step 47520 loss 0.017646608874201775
[2025-03-22 00:54:32,471][model][INFO] - Training step 47680 loss 0.20559750497341156
[2025-03-22 00:55:50,353][model][INFO] - Training step 47840 loss 0.0489330068230629
[2025-03-22 00:57:10,228][model][INFO] - Training step 48000 loss 0.1094050258398056
[2025-03-22 00:58:29,678][model][INFO] - Training step 48160 loss 0.03315505385398865
[2025-03-22 00:59:47,331][model][INFO] - Training step 48320 loss 0.05366741865873337
[2025-03-22 01:01:07,659][model][INFO] - Training step 48480 loss 0.009603617712855339
[2025-03-22 01:02:27,983][model][INFO] - Training step 48640 loss 0.25212347507476807
[2025-03-22 01:03:48,012][model][INFO] - Training step 48800 loss 0.025106169283390045
[2025-03-22 01:05:05,051][model][INFO] - Training step 48960 loss 0.01573651283979416
[2025-03-22 01:06:23,784][model][INFO] - Training step 49120 loss 0.04809361323714256
[2025-03-22 01:07:42,630][model][INFO] - Training step 49280 loss 0.029651757329702377
[2025-03-22 01:09:00,327][model][INFO] - Training step 49440 loss 0.032277852296829224
[2025-03-22 01:10:21,752][model][INFO] - Training step 49600 loss 0.037767402827739716
[2025-03-22 01:11:40,835][model][INFO] - Training step 49760 loss 0.04308738932013512
[2025-03-22 01:13:03,061][model][INFO] - Training step 49920 loss 0.009254766628146172
[2025-03-22 01:14:21,363][model][INFO] - Training step 50080 loss 0.27991729974746704
[2025-03-22 01:15:42,031][model][INFO] - Training step 50240 loss 0.005244767758995295
[2025-03-22 01:17:01,140][model][INFO] - Training step 50400 loss 0.008558464236557484
[2025-03-22 01:18:19,272][model][INFO] - Training step 50560 loss 0.23247447609901428
[2025-03-22 01:19:35,809][model][INFO] - Training step 50720 loss 0.05606626719236374
[2025-03-22 01:29:10,209][model][INFO] - Training step 80 loss 0.25330650806427
[2025-03-22 01:30:31,416][model][INFO] - Training step 240 loss 0.007145441137254238
[2025-03-22 01:31:50,859][model][INFO] - Training step 400 loss 0.24224331974983215
[2025-03-22 01:33:08,860][model][INFO] - Training step 560 loss 0.2518872022628784
[2025-03-22 01:34:29,945][model][INFO] - Training step 720 loss 0.0337655246257782
[2025-03-22 01:35:49,959][model][INFO] - Training step 880 loss 0.25603026151657104
[2025-03-22 01:37:06,658][model][INFO] - Training step 1040 loss 0.01762794703245163
[2025-03-22 01:38:25,769][model][INFO] - Training step 1200 loss 0.040426403284072876
[2025-03-22 01:39:47,483][model][INFO] - Training step 1360 loss 0.004263157956302166
[2025-03-22 01:41:04,269][model][INFO] - Training step 1520 loss 0.03611477091908455
[2025-03-22 01:42:24,518][model][INFO] - Training step 1680 loss 0.021885346621274948
[2025-03-22 01:43:42,669][model][INFO] - Training step 1840 loss 0.03463846445083618
[2025-03-22 01:45:00,550][model][INFO] - Training step 2000 loss 0.042074136435985565
[2025-03-22 01:46:18,935][model][INFO] - Training step 2160 loss 0.01790395937860012
[2025-03-22 01:47:39,744][model][INFO] - Training step 2320 loss 0.02228602021932602
[2025-03-22 01:49:01,461][model][INFO] - Training step 2480 loss 0.043100275099277496
[2025-03-22 01:50:21,924][model][INFO] - Training step 2640 loss 0.04054006561636925
[2025-03-22 01:51:38,953][model][INFO] - Training step 2800 loss 0.006915513426065445
[2025-03-22 01:52:57,538][model][INFO] - Training step 2960 loss 0.00981791503727436
[2025-03-22 01:54:14,348][model][INFO] - Training step 3120 loss 0.14237289130687714
[2025-03-22 01:55:34,304][model][INFO] - Training step 3280 loss 0.00583877507597208
[2025-03-22 01:56:53,480][model][INFO] - Training step 3440 loss 0.029013093560934067
[2025-03-22 01:58:09,614][model][INFO] - Training step 3600 loss 0.016669459640979767
[2025-03-22 01:59:28,675][model][INFO] - Training step 3760 loss 0.023742318153381348
[2025-03-22 02:00:46,770][model][INFO] - Training step 3920 loss 0.021545900031924248
[2025-03-22 02:02:09,058][model][INFO] - Training step 4080 loss 0.09486453235149384
[2025-03-22 02:03:30,167][model][INFO] - Training step 4240 loss 0.25153279304504395
[2025-03-22 02:04:48,707][model][INFO] - Training step 4400 loss 0.00998753309249878
[2025-03-22 02:06:06,864][model][INFO] - Training step 4560 loss 0.031056631356477737
[2025-03-22 02:07:27,792][model][INFO] - Training step 4720 loss 0.034329675137996674
[2025-03-22 02:08:44,645][model][INFO] - Training step 4880 loss 0.014082789421081543
[2025-03-22 02:10:05,250][model][INFO] - Training step 5040 loss 0.26817071437835693
[2025-03-22 02:11:23,889][model][INFO] - Training step 5200 loss 0.03949577361345291
[2025-03-22 02:12:43,482][model][INFO] - Training step 5360 loss 0.05117837339639664
[2025-03-22 02:14:01,762][model][INFO] - Training step 5520 loss 0.2600109279155731
[2025-03-22 02:15:22,787][model][INFO] - Training step 5680 loss 0.028467923402786255
[2025-03-22 02:16:44,265][model][INFO] - Training step 5840 loss 0.028878426179289818
[2025-03-22 02:18:03,160][model][INFO] - Training step 6000 loss 0.28007787466049194
[2025-03-22 02:19:20,169][model][INFO] - Training step 6160 loss 0.028592539951205254
[2025-03-22 02:20:41,871][model][INFO] - Training step 6320 loss 0.13336768746376038
[2025-03-22 02:21:59,307][model][INFO] - Training step 6480 loss 0.034903377294540405
[2025-03-22 02:23:17,743][model][INFO] - Training step 6640 loss 0.008532288484275341
[2025-03-22 02:24:35,557][model][INFO] - Training step 6800 loss 0.2595168948173523
[2025-03-22 02:25:56,597][model][INFO] - Training step 6960 loss 0.006066774483770132
[2025-03-22 02:27:17,447][model][INFO] - Training step 7120 loss 0.035533152520656586
[2025-03-22 02:28:38,232][model][INFO] - Training step 7280 loss 0.015186639502644539
[2025-03-22 02:29:56,362][model][INFO] - Training step 7440 loss 0.2595231533050537
[2025-03-22 02:31:16,336][model][INFO] - Training step 7600 loss 0.06383591890335083
[2025-03-22 02:32:35,490][model][INFO] - Training step 7760 loss 0.029466502368450165
[2025-03-22 02:33:56,219][model][INFO] - Training step 7920 loss 0.03759269416332245
[2025-03-22 02:35:15,696][model][INFO] - Training step 8080 loss 0.2597113847732544
[2025-03-22 02:36:33,322][model][INFO] - Training step 8240 loss 0.019194401800632477
[2025-03-22 02:37:50,745][model][INFO] - Training step 8400 loss 0.037751950323581696
[2025-03-22 02:39:07,735][model][INFO] - Training step 8560 loss 0.02132786437869072
[2025-03-22 02:40:24,699][model][INFO] - Training step 8720 loss 0.03259485960006714
[2025-03-22 02:41:44,337][model][INFO] - Training step 8880 loss 0.05556280165910721
[2025-03-22 02:43:02,623][model][INFO] - Training step 9040 loss 0.02412368729710579
[2025-03-22 02:44:17,774][model][INFO] - Training step 9200 loss 0.0050911372527480125
[2025-03-22 02:45:36,843][model][INFO] - Training step 9360 loss 0.2608363926410675
[2025-03-22 02:46:56,138][model][INFO] - Training step 9520 loss 0.014427028596401215
[2025-03-22 02:48:16,173][model][INFO] - Training step 9680 loss 0.04463142529129982
[2025-03-22 02:49:33,756][model][INFO] - Training step 9840 loss 0.08554849028587341
[2025-03-22 02:50:56,825][model][INFO] - Training step 10000 loss 0.23118320107460022
[2025-03-22 02:52:14,409][model][INFO] - Training step 10160 loss 0.24928587675094604
[2025-03-22 02:53:33,789][model][INFO] - Training step 10320 loss 0.110466867685318
[2025-03-22 02:54:55,905][model][INFO] - Training step 10480 loss 0.00614775950089097
[2025-03-22 02:56:16,160][model][INFO] - Training step 10640 loss 0.005724740214645863
[2025-03-22 02:57:35,459][model][INFO] - Training step 10800 loss 0.040684279054403305
[2025-03-22 02:58:55,054][model][INFO] - Training step 10960 loss 0.25500547885894775
[2025-03-22 03:00:15,539][model][INFO] - Training step 11120 loss 0.017847513779997826
[2025-03-22 03:01:33,694][model][INFO] - Training step 11280 loss 0.047209687530994415
[2025-03-22 03:02:53,814][model][INFO] - Training step 11440 loss 0.03401649743318558
[2025-03-22 03:04:10,456][model][INFO] - Training step 11600 loss 0.2541946768760681
[2025-03-22 03:05:32,921][model][INFO] - Training step 11760 loss 0.24975991249084473
[2025-03-22 03:06:52,284][model][INFO] - Training step 11920 loss 0.08565981686115265
[2025-03-22 03:08:10,686][model][INFO] - Training step 12080 loss 0.05721335858106613
[2025-03-22 03:09:30,051][model][INFO] - Training step 12240 loss 0.04754846543073654
[2025-03-22 03:10:50,926][model][INFO] - Training step 12400 loss 0.24646314978599548
[2025-03-22 03:12:10,677][model][INFO] - Training step 12560 loss 0.05019892007112503
[2025-03-22 03:13:30,363][model][INFO] - Training step 12720 loss 0.005687340162694454
[2025-03-22 03:14:51,027][model][INFO] - Training step 12880 loss 0.027952980250120163
[2025-03-22 03:16:09,536][model][INFO] - Training step 13040 loss 0.0071965111419558525
[2025-03-22 03:17:30,551][model][INFO] - Training step 13200 loss 0.032682716846466064
[2025-03-22 03:18:49,497][model][INFO] - Training step 13360 loss 0.2501230835914612
[2025-03-22 03:20:10,716][model][INFO] - Training step 13520 loss 0.035730890929698944
[2025-03-22 03:21:32,155][model][INFO] - Training step 13680 loss 0.11275693774223328
[2025-03-22 03:22:51,249][model][INFO] - Training step 13840 loss 0.1955459713935852
[2025-03-22 03:24:10,987][model][INFO] - Training step 14000 loss 0.02194581925868988
[2025-03-22 03:25:29,500][model][INFO] - Training step 14160 loss 0.06363646686077118
[2025-03-22 03:26:49,637][model][INFO] - Training step 14320 loss 0.00578369852155447
[2025-03-22 03:28:10,112][model][INFO] - Training step 14480 loss 0.0284989383071661
[2025-03-22 03:29:27,150][model][INFO] - Training step 14640 loss 0.03833102434873581
[2025-03-22 03:30:45,483][model][INFO] - Training step 14800 loss 0.005434680730104446
[2025-03-22 03:32:07,017][model][INFO] - Training step 14960 loss 0.022620510309934616
[2025-03-22 03:33:28,767][model][INFO] - Training step 15120 loss 0.002541491761803627
[2025-03-22 03:34:47,767][model][INFO] - Training step 15280 loss 0.03989516943693161
[2025-03-22 03:36:06,990][model][INFO] - Training step 15440 loss 0.018005676567554474
[2025-03-22 03:37:24,965][model][INFO] - Training step 15600 loss 0.08786916732788086
[2025-03-22 03:38:43,077][model][INFO] - Training step 15760 loss 0.0319441556930542
[2025-03-22 03:40:00,473][model][INFO] - Training step 15920 loss 0.03359059989452362
[2025-03-22 03:41:20,655][model][INFO] - Training step 16080 loss 0.21861009299755096
[2025-03-22 03:42:42,194][model][INFO] - Training step 16240 loss 0.27412229776382446
[2025-03-22 03:44:02,128][model][INFO] - Training step 16400 loss 0.04374585300683975
[2025-03-22 03:45:22,208][model][INFO] - Training step 16560 loss 0.2567465901374817
[2025-03-22 03:46:37,500][model][INFO] - Training step 16720 loss 0.02834290638566017
[2025-03-22 03:47:56,741][model][INFO] - Training step 16880 loss 0.026051532477140427
[2025-03-22 03:49:14,935][model][INFO] - Training step 17040 loss 0.7484519481658936
[2025-03-22 03:50:32,394][model][INFO] - Training step 17200 loss 0.1472238302230835
[2025-03-22 03:51:52,686][model][INFO] - Training step 17360 loss 0.06603133678436279
[2025-03-22 03:53:13,110][model][INFO] - Training step 17520 loss 0.2521023452281952
[2025-03-22 03:54:31,015][model][INFO] - Training step 17680 loss 0.028674650937318802
[2025-03-22 03:55:47,848][model][INFO] - Training step 17840 loss 0.03195573017001152
[2025-03-22 03:57:04,948][model][INFO] - Training step 18000 loss 0.031479526311159134
[2025-03-22 03:58:24,503][model][INFO] - Training step 18160 loss 0.25582948327064514
[2025-03-22 03:59:41,210][model][INFO] - Training step 18320 loss 0.05605989694595337
[2025-03-22 04:00:59,117][model][INFO] - Training step 18480 loss 0.26635563373565674
[2025-03-22 04:02:22,538][model][INFO] - Training step 18640 loss 0.25468021631240845
[2025-03-22 04:03:40,956][model][INFO] - Training step 18800 loss 0.014887545257806778
[2025-03-22 04:04:57,575][model][INFO] - Training step 18960 loss 0.03274064138531685
[2025-03-22 04:06:18,085][model][INFO] - Training step 19120 loss 0.025373689830303192
[2025-03-22 04:07:37,463][model][INFO] - Training step 19280 loss 0.00623372383415699
[2025-03-22 04:08:57,342][model][INFO] - Training step 19440 loss 0.211807519197464
[2025-03-22 04:10:18,450][model][INFO] - Training step 19600 loss 0.27028125524520874
[2025-03-22 04:11:36,634][model][INFO] - Training step 19760 loss 0.01740642637014389
[2025-03-22 04:12:57,185][model][INFO] - Training step 19920 loss 0.05429643765091896
[2025-03-22 04:14:17,672][model][INFO] - Training step 20080 loss 0.08982482552528381
[2025-03-22 04:15:37,178][model][INFO] - Training step 20240 loss 0.25444385409355164
[2025-03-22 04:16:55,564][model][INFO] - Training step 20400 loss 0.045234695076942444
[2025-03-22 04:18:12,171][model][INFO] - Training step 20560 loss 0.032260291278362274
[2025-03-22 04:19:32,518][model][INFO] - Training step 20720 loss 0.043844178318977356
[2025-03-22 04:20:53,787][model][INFO] - Training step 20880 loss 0.008014056831598282
[2025-03-22 04:22:15,117][model][INFO] - Training step 21040 loss 0.03778868541121483
[2025-03-22 04:23:37,169][model][INFO] - Training step 21200 loss 0.029155103489756584
[2025-03-22 04:24:58,772][model][INFO] - Training step 21360 loss 0.056500159204006195
[2025-03-22 04:26:15,598][model][INFO] - Training step 21520 loss 0.03259396553039551
[2025-03-22 04:27:36,067][model][INFO] - Training step 21680 loss 0.026051007211208344
[2025-03-22 04:28:57,543][model][INFO] - Training step 21840 loss 0.04500735551118851
[2025-03-22 04:30:17,365][model][INFO] - Training step 22000 loss 0.046806082129478455
[2025-03-22 04:31:35,150][model][INFO] - Training step 22160 loss 0.1578458845615387
[2025-03-22 04:32:56,489][model][INFO] - Training step 22320 loss 0.029031764715909958
[2025-03-22 04:34:17,228][model][INFO] - Training step 22480 loss 0.018539272248744965
[2025-03-22 04:35:37,768][model][INFO] - Training step 22640 loss 0.03265804424881935
[2025-03-22 04:36:56,483][model][INFO] - Training step 22800 loss 0.006182827055454254
[2025-03-22 04:38:14,979][model][INFO] - Training step 22960 loss 0.03244003653526306
[2025-03-22 04:39:34,762][model][INFO] - Training step 23120 loss 0.031552985310554504
[2025-03-22 04:40:56,882][model][INFO] - Training step 23280 loss 0.022511091083288193
[2025-03-22 04:42:17,333][model][INFO] - Training step 23440 loss 0.0076499031856656075
[2025-03-22 04:43:38,722][model][INFO] - Training step 23600 loss 0.06117798760533333
[2025-03-22 04:44:56,700][model][INFO] - Training step 23760 loss 0.2649562954902649
[2025-03-22 04:46:17,137][model][INFO] - Training step 23920 loss 0.030182640999555588
[2025-03-22 04:47:35,705][model][INFO] - Training step 24080 loss 0.22267913818359375
[2025-03-22 04:48:53,582][model][INFO] - Training step 24240 loss 0.005938166752457619
[2025-03-22 04:50:12,323][model][INFO] - Training step 24400 loss 0.007268044166266918
[2025-03-22 04:51:31,016][model][INFO] - Training step 24560 loss 0.03618272393941879
[2025-03-22 04:52:49,618][model][INFO] - Training step 24720 loss 0.244217187166214
[2025-03-22 04:54:11,545][model][INFO] - Training step 24880 loss 0.03984617069363594
[2025-03-22 04:55:30,545][model][INFO] - Training step 25040 loss 0.02799568697810173
[2025-03-22 04:56:46,102][model][INFO] - Training step 25200 loss 0.24783259630203247
[2025-03-22 04:58:04,448][model][INFO] - Training step 25360 loss 0.035885680466890335
[2025-03-22 04:59:22,958][model][INFO] - Training step 25520 loss 0.007009301334619522
[2025-03-22 05:00:41,875][model][INFO] - Training step 25680 loss 0.03329447656869888
[2025-03-22 05:01:59,654][model][INFO] - Training step 25840 loss 0.11733783036470413
[2025-03-22 05:03:20,387][model][INFO] - Training step 26000 loss 0.11850854754447937
[2025-03-22 05:04:36,195][model][INFO] - Training step 26160 loss 0.022435925900936127
[2025-03-22 05:05:55,525][model][INFO] - Training step 26320 loss 0.24841463565826416
[2025-03-22 05:07:16,625][model][INFO] - Training step 26480 loss 0.03337305411696434
[2025-03-22 05:08:39,434][model][INFO] - Training step 26640 loss 0.03211454302072525
[2025-03-22 05:09:58,562][model][INFO] - Training step 26800 loss 0.04293888434767723
[2025-03-22 05:11:14,717][model][INFO] - Training step 26960 loss 0.025538109242916107
[2025-03-22 05:12:32,072][model][INFO] - Training step 27120 loss 0.005145229399204254
[2025-03-22 05:13:50,372][model][INFO] - Training step 27280 loss 0.0358247235417366
[2025-03-22 05:15:09,809][model][INFO] - Training step 27440 loss 0.03530324250459671
[2025-03-22 05:16:27,454][model][INFO] - Training step 27600 loss 0.25292226672172546
[2025-03-22 05:17:44,936][model][INFO] - Training step 27760 loss 0.2526133954524994
[2025-03-22 05:19:04,682][model][INFO] - Training step 27920 loss 0.016074299812316895
[2025-03-22 05:20:25,214][model][INFO] - Training step 28080 loss 0.03433062881231308
[2025-03-22 05:21:44,375][model][INFO] - Training step 28240 loss 0.14272856712341309
[2025-03-22 05:23:02,899][model][INFO] - Training step 28400 loss 0.2516084611415863
[2025-03-22 05:24:25,371][model][INFO] - Training step 28560 loss 0.026179105043411255
[2025-03-22 05:25:43,194][model][INFO] - Training step 28720 loss 0.12402366101741791
[2025-03-22 05:27:04,501][model][INFO] - Training step 28880 loss 0.014073243364691734
[2025-03-22 05:28:22,691][model][INFO] - Training step 29040 loss 0.0255880206823349
[2025-03-22 05:29:40,468][model][INFO] - Training step 29200 loss 0.017036642879247665
[2025-03-22 05:31:01,221][model][INFO] - Training step 29360 loss 0.018920667469501495
[2025-03-22 05:32:19,059][model][INFO] - Training step 29520 loss 0.041272155940532684
[2025-03-22 05:33:40,855][model][INFO] - Training step 29680 loss 0.2396223098039627
[2025-03-22 05:35:01,076][model][INFO] - Training step 29840 loss 0.12524321675300598
[2025-03-22 05:36:21,592][model][INFO] - Training step 30000 loss 0.0017551128985360265
[2025-03-22 05:37:37,987][model][INFO] - Training step 30160 loss 0.041611768305301666
[2025-03-22 05:38:56,941][model][INFO] - Training step 30320 loss 0.08472361415624619
[2025-03-22 05:40:17,627][model][INFO] - Training step 30480 loss 0.04164300113916397
[2025-03-22 05:41:32,481][model][INFO] - Training step 30640 loss 0.16704091429710388
[2025-03-22 05:42:50,252][model][INFO] - Training step 30800 loss 0.0052230628207325935
[2025-03-22 05:44:09,536][model][INFO] - Training step 30960 loss 0.2464478462934494
[2025-03-22 05:45:27,549][model][INFO] - Training step 31120 loss 0.07037282735109329
[2025-03-22 05:46:45,258][model][INFO] - Training step 31280 loss 0.03471270576119423
[2025-03-22 05:48:04,235][model][INFO] - Training step 31440 loss 0.038643959909677505
[2025-03-22 05:49:20,442][model][INFO] - Training step 31600 loss 0.05502702668309212
[2025-03-22 05:50:40,616][model][INFO] - Training step 31760 loss 0.006644028704613447
[2025-03-22 05:52:02,117][model][INFO] - Training step 31920 loss 0.056295618414878845
[2025-03-22 05:53:21,773][model][INFO] - Training step 32080 loss 0.0233662948012352
[2025-03-22 05:54:42,387][model][INFO] - Training step 32240 loss 0.014137495309114456
[2025-03-22 05:56:02,190][model][INFO] - Training step 32400 loss 0.061885762959718704
[2025-03-22 05:57:24,223][model][INFO] - Training step 32560 loss 0.02935405820608139
[2025-03-22 05:58:44,385][model][INFO] - Training step 32720 loss 0.020379137247800827
[2025-03-22 06:00:06,865][model][INFO] - Training step 32880 loss 0.25754231214523315
[2025-03-22 06:01:22,680][model][INFO] - Training step 33040 loss 0.02867765910923481
[2025-03-22 06:02:42,297][model][INFO] - Training step 33200 loss 0.005277497228235006
[2025-03-22 06:04:04,227][model][INFO] - Training step 33360 loss 0.018380431458353996
[2025-03-22 06:05:25,317][model][INFO] - Training step 33520 loss 0.03264018893241882
[2025-03-22 06:06:43,386][model][INFO] - Training step 33680 loss 0.02568691596388817
[2025-03-22 06:08:02,560][model][INFO] - Training step 33840 loss 0.021277885884046555
[2025-03-22 06:09:20,435][model][INFO] - Training step 34000 loss 0.020130567252635956
[2025-03-22 06:10:42,282][model][INFO] - Training step 34160 loss 0.04573265090584755
[2025-03-22 06:12:04,087][model][INFO] - Training step 34320 loss 0.02187098190188408
[2025-03-22 06:13:23,645][model][INFO] - Training step 34480 loss 0.18840177357196808
[2025-03-22 06:14:41,225][model][INFO] - Training step 34640 loss 0.02918224036693573
[2025-03-22 06:15:58,132][model][INFO] - Training step 34800 loss 0.25428763031959534
[2025-03-22 06:17:16,368][model][INFO] - Training step 34960 loss 0.07744771242141724
[2025-03-22 06:18:35,954][model][INFO] - Training step 35120 loss 0.04977304860949516
[2025-03-22 06:19:55,703][model][INFO] - Training step 35280 loss 0.25861656665802
[2025-03-22 06:21:15,522][model][INFO] - Training step 35440 loss 0.01555999368429184
[2025-03-22 06:22:34,796][model][INFO] - Training step 35600 loss 0.10755688697099686
[2025-03-22 06:23:54,489][model][INFO] - Training step 35760 loss 0.03341222554445267
[2025-03-22 06:25:12,885][model][INFO] - Training step 35920 loss 0.24768346548080444
[2025-03-22 06:26:31,173][model][INFO] - Training step 36080 loss 0.03922639787197113
[2025-03-22 06:27:49,639][model][INFO] - Training step 36240 loss 0.032695867121219635
[2025-03-22 06:29:09,747][model][INFO] - Training step 36400 loss 0.011252731084823608
[2025-03-22 06:30:28,043][model][INFO] - Training step 36560 loss 0.025359364226460457
[2025-03-22 06:31:49,440][model][INFO] - Training step 36720 loss 0.23923733830451965
[2025-03-22 06:33:07,155][model][INFO] - Training step 36880 loss 0.061370015144348145
[2025-03-22 06:34:27,522][model][INFO] - Training step 37040 loss 0.010065274313092232
[2025-03-22 06:35:47,474][model][INFO] - Training step 37200 loss 0.08699224889278412
[2025-03-22 06:37:08,577][model][INFO] - Training step 37360 loss 0.03682713210582733
[2025-03-22 06:38:27,524][model][INFO] - Training step 37520 loss 0.01365870051085949
[2025-03-22 06:39:46,711][model][INFO] - Training step 37680 loss 0.003999954089522362
[2025-03-22 06:41:05,700][model][INFO] - Training step 37840 loss 0.03370507434010506
[2025-03-22 06:42:23,214][model][INFO] - Training step 38000 loss 0.24171185493469238
[2025-03-22 06:43:42,250][model][INFO] - Training step 38160 loss 0.2495661824941635
[2025-03-22 06:45:01,945][model][INFO] - Training step 38320 loss 0.25142574310302734
[2025-03-22 06:46:20,678][model][INFO] - Training step 38480 loss 0.031462162733078
[2025-03-22 06:47:39,489][model][INFO] - Training step 38640 loss 0.03619803860783577
[2025-03-22 06:48:57,888][model][INFO] - Training step 38800 loss 0.20881551504135132
[2025-03-22 06:50:18,662][model][INFO] - Training step 38960 loss 0.016810663044452667
[2025-03-22 06:51:35,710][model][INFO] - Training step 39120 loss 0.024388233199715614
[2025-03-22 06:52:55,733][model][INFO] - Training step 39280 loss 0.038830555975437164
[2025-03-22 06:54:17,393][model][INFO] - Training step 39440 loss 0.01680784672498703
[2025-03-22 06:55:35,859][model][INFO] - Training step 39600 loss 0.27818170189857483
[2025-03-22 06:56:54,851][model][INFO] - Training step 39760 loss 0.020383983850479126
[2025-03-22 06:58:15,900][model][INFO] - Training step 39920 loss 0.0050690872594714165
[2025-03-22 06:59:35,944][model][INFO] - Training step 40080 loss 0.016421228647232056
[2025-03-22 07:00:54,001][model][INFO] - Training step 40240 loss 0.025215469300746918
[2025-03-22 07:02:11,835][model][INFO] - Training step 40400 loss 0.02667473629117012
[2025-03-22 07:03:33,229][model][INFO] - Training step 40560 loss 0.031167160719633102
[2025-03-22 07:04:51,815][model][INFO] - Training step 40720 loss 0.25839677453041077
[2025-03-22 07:06:10,722][model][INFO] - Training step 40880 loss 0.26609790325164795
[2025-03-22 07:07:31,914][model][INFO] - Training step 41040 loss 0.08860547840595245
[2025-03-22 07:08:48,985][model][INFO] - Training step 41200 loss 0.01681922934949398
[2025-03-22 07:10:12,394][model][INFO] - Training step 41360 loss 0.006305335089564323
[2025-03-22 07:11:32,340][model][INFO] - Training step 41520 loss 0.06861177086830139
[2025-03-22 07:12:54,978][model][INFO] - Training step 41680 loss 0.08504907041788101
[2025-03-22 07:14:15,051][model][INFO] - Training step 41840 loss 0.01736343652009964
[2025-03-22 07:15:35,042][model][INFO] - Training step 42000 loss 0.24795739352703094
[2025-03-22 07:16:55,544][model][INFO] - Training step 42160 loss 0.2594979405403137
[2025-03-22 07:18:14,513][model][INFO] - Training step 42320 loss 0.015682226046919823
[2025-03-22 07:19:32,929][model][INFO] - Training step 42480 loss 0.030429206788539886
[2025-03-22 07:20:50,615][model][INFO] - Training step 42640 loss 0.07481648027896881
[2025-03-22 07:22:07,494][model][INFO] - Training step 42800 loss 0.0211517121642828
[2025-03-22 07:23:28,828][model][INFO] - Training step 42960 loss 0.020223623141646385
[2025-03-22 07:24:45,788][model][INFO] - Training step 43120 loss 0.04542417451739311
[2025-03-22 07:26:07,117][model][INFO] - Training step 43280 loss 0.049725569784641266
[2025-03-22 07:27:26,826][model][INFO] - Training step 43440 loss 0.07458630949258804
[2025-03-22 07:28:47,303][model][INFO] - Training step 43600 loss 0.015136593021452427
[2025-03-22 07:30:08,201][model][INFO] - Training step 43760 loss 0.02165386639535427
[2025-03-22 07:31:28,778][model][INFO] - Training step 43920 loss 0.0026603234000504017
[2025-03-22 07:32:47,649][model][INFO] - Training step 44080 loss 0.22157913446426392
[2025-03-22 07:34:07,271][model][INFO] - Training step 44240 loss 0.026275992393493652
[2025-03-22 07:35:27,476][model][INFO] - Training step 44400 loss 0.03280554339289665
[2025-03-22 07:36:45,229][model][INFO] - Training step 44560 loss 0.025217846035957336
[2025-03-22 07:38:06,356][model][INFO] - Training step 44720 loss 0.24499759078025818
[2025-03-22 07:39:20,977][model][INFO] - Training step 44880 loss 0.07269050180912018
[2025-03-22 07:40:42,004][model][INFO] - Training step 45040 loss 0.07032755017280579
[2025-03-22 07:41:59,653][model][INFO] - Training step 45200 loss 0.015947535634040833
[2025-03-22 07:43:25,420][model][INFO] - Training step 45360 loss 0.021765422075986862
[2025-03-22 07:44:42,527][model][INFO] - Training step 45520 loss 0.04234463721513748
[2025-03-22 07:46:01,540][model][INFO] - Training step 45680 loss 0.015589771792292595
[2025-03-22 07:47:21,368][model][INFO] - Training step 45840 loss 0.0053824507631361485
[2025-03-22 07:48:36,802][model][INFO] - Training step 46000 loss 0.04898341745138168
[2025-03-22 07:49:59,264][model][INFO] - Training step 46160 loss 0.0337146557867527
[2025-03-22 07:51:19,273][model][INFO] - Training step 46320 loss 0.022916071116924286
[2025-03-22 07:52:40,047][model][INFO] - Training step 46480 loss 0.03806992620229721
[2025-03-22 07:53:59,627][model][INFO] - Training step 46640 loss 0.042186275124549866
[2025-03-22 07:55:16,176][model][INFO] - Training step 46800 loss 0.07793086022138596
[2025-03-22 07:56:34,290][model][INFO] - Training step 46960 loss 0.004350210539996624
[2025-03-22 07:57:52,616][model][INFO] - Training step 47120 loss 0.040884457528591156
[2025-03-22 07:59:15,744][model][INFO] - Training step 47280 loss 0.018394680693745613
[2025-03-22 08:00:34,428][model][INFO] - Training step 47440 loss 0.018936529755592346
[2025-03-22 08:01:52,265][model][INFO] - Training step 47600 loss 0.00834883563220501
[2025-03-22 08:03:15,415][model][INFO] - Training step 47760 loss 0.16359668970108032
[2025-03-22 08:04:34,254][model][INFO] - Training step 47920 loss 0.008053394965827465
[2025-03-22 08:05:55,599][model][INFO] - Training step 48080 loss 0.0010918239131569862
[2025-03-22 08:07:12,412][model][INFO] - Training step 48240 loss 0.021150145679712296
[2025-03-22 08:08:30,712][model][INFO] - Training step 48400 loss 0.04084308072924614
[2025-03-22 08:09:48,430][model][INFO] - Training step 48560 loss 0.04778783768415451
[2025-03-22 08:11:08,147][model][INFO] - Training step 48720 loss 0.004184811841696501
[2025-03-22 08:12:28,689][model][INFO] - Training step 48880 loss 0.01965356059372425
[2025-03-22 08:13:46,895][model][INFO] - Training step 49040 loss 0.04146691411733627
[2025-03-22 08:15:07,619][model][INFO] - Training step 49200 loss 0.02450679987668991
[2025-03-22 08:16:25,130][model][INFO] - Training step 49360 loss 0.047107163816690445
[2025-03-22 08:17:48,862][model][INFO] - Training step 49520 loss 0.24982693791389465
[2025-03-22 08:19:06,518][model][INFO] - Training step 49680 loss 0.017514139413833618
[2025-03-22 08:20:25,774][model][INFO] - Training step 49840 loss 0.0065017808228731155
[2025-03-22 08:21:45,688][model][INFO] - Training step 50000 loss 0.005601012147963047
[2025-03-22 08:23:06,306][model][INFO] - Training step 50160 loss 0.04645217955112457
[2025-03-22 08:24:25,572][model][INFO] - Training step 50320 loss 0.027936309576034546
[2025-03-22 08:25:45,868][model][INFO] - Training step 50480 loss 0.014791024848818779
[2025-03-22 08:27:05,987][model][INFO] - Training step 50640 loss 0.01553228497505188
[2025-03-22 08:36:35,899][model][INFO] - Training step 0 loss 0.02099115028977394
[2025-03-22 08:37:56,411][model][INFO] - Training step 160 loss 0.014409130439162254
[2025-03-22 08:39:15,437][model][INFO] - Training step 320 loss 0.02683035284280777
[2025-03-22 08:40:36,266][model][INFO] - Training step 480 loss 0.02557692676782608
[2025-03-22 08:41:53,283][model][INFO] - Training step 640 loss 0.020912233740091324
[2025-03-22 08:43:16,465][model][INFO] - Training step 800 loss 0.06156988441944122
[2025-03-22 08:44:36,943][model][INFO] - Training step 960 loss 0.019602369517087936
[2025-03-22 08:45:52,263][model][INFO] - Training step 1120 loss 0.1151299774646759
[2025-03-22 08:47:12,677][model][INFO] - Training step 1280 loss 0.05589893460273743
[2025-03-22 08:48:31,357][model][INFO] - Training step 1440 loss 0.0337909534573555
[2025-03-22 08:49:50,256][model][INFO] - Training step 1600 loss 0.05166197568178177
[2025-03-22 08:51:09,486][model][INFO] - Training step 1760 loss 0.11286170780658722
[2025-03-22 08:52:26,043][model][INFO] - Training step 1920 loss 0.02150113508105278
[2025-03-22 08:53:45,526][model][INFO] - Training step 2080 loss 0.0277806855738163
[2025-03-22 08:55:03,969][model][INFO] - Training step 2240 loss 0.23116075992584229
[2025-03-22 08:56:19,605][model][INFO] - Training step 2400 loss 0.02053697779774666
[2025-03-22 08:57:39,270][model][INFO] - Training step 2560 loss 0.26981163024902344
[2025-03-22 08:58:58,705][model][INFO] - Training step 2720 loss 0.027489952743053436
[2025-03-22 09:00:18,601][model][INFO] - Training step 2880 loss 0.1172439232468605
[2025-03-22 09:01:38,480][model][INFO] - Training step 3040 loss 0.030521972104907036
[2025-03-22 09:02:57,808][model][INFO] - Training step 3200 loss 0.014631321653723717
[2025-03-22 09:04:17,840][model][INFO] - Training step 3360 loss 0.005217196885496378
[2025-03-22 09:05:34,930][model][INFO] - Training step 3520 loss 0.004255094099789858
[2025-03-22 09:06:55,015][model][INFO] - Training step 3680 loss 0.24707967042922974
[2025-03-22 09:08:15,428][model][INFO] - Training step 3840 loss 0.0788983702659607
[2025-03-22 09:09:35,741][model][INFO] - Training step 4000 loss 0.05073582008481026
[2025-03-22 09:10:56,539][model][INFO] - Training step 4160 loss 0.014539750292897224
[2025-03-22 09:12:14,281][model][INFO] - Training step 4320 loss 0.03674847632646561
[2025-03-22 09:13:35,507][model][INFO] - Training step 4480 loss 0.08319240808486938
[2025-03-22 09:14:54,911][model][INFO] - Training step 4640 loss 0.25117921829223633
[2025-03-22 09:16:15,607][model][INFO] - Training step 4800 loss 0.3832949995994568
[2025-03-22 09:17:35,613][model][INFO] - Training step 4960 loss 0.006560378707945347
[2025-03-22 09:18:55,472][model][INFO] - Training step 5120 loss 0.05341857671737671
[2025-03-22 09:20:12,950][model][INFO] - Training step 5280 loss 0.04063546657562256
[2025-03-22 09:21:31,410][model][INFO] - Training step 5440 loss 0.047188807278871536
[2025-03-22 09:22:49,362][model][INFO] - Training step 5600 loss 0.020632360130548477
[2025-03-22 09:24:10,562][model][INFO] - Training step 5760 loss 0.023273419588804245
[2025-03-22 09:25:30,955][model][INFO] - Training step 5920 loss 0.022642720490694046
[2025-03-22 09:26:48,116][model][INFO] - Training step 6080 loss 0.02232142724096775
[2025-03-22 09:28:07,257][model][INFO] - Training step 6240 loss 0.023519985377788544
[2025-03-22 09:29:27,173][model][INFO] - Training step 6400 loss 0.09279735386371613
[2025-03-22 09:30:46,295][model][INFO] - Training step 6560 loss 0.02671205811202526
[2025-03-22 09:32:08,206][model][INFO] - Training step 6720 loss 0.0747029185295105
[2025-03-22 09:33:27,319][model][INFO] - Training step 6880 loss 0.2643911838531494
[2025-03-22 09:34:48,295][model][INFO] - Training step 7040 loss 0.08782261610031128
[2025-03-22 09:36:08,021][model][INFO] - Training step 7200 loss 0.01621711067855358
[2025-03-22 09:37:28,342][model][INFO] - Training step 7360 loss 0.028076091781258583
[2025-03-22 09:38:49,285][model][INFO] - Training step 7520 loss 0.05450936034321785
[2025-03-22 09:40:09,252][model][INFO] - Training step 7680 loss 0.04178960621356964
[2025-03-22 09:41:26,550][model][INFO] - Training step 7840 loss 0.24686215817928314
[2025-03-22 09:42:45,388][model][INFO] - Training step 8000 loss 0.044057756662368774
[2025-03-22 09:44:05,284][model][INFO] - Training step 8160 loss 0.005391363054513931
[2025-03-22 09:45:26,500][model][INFO] - Training step 8320 loss 0.25146207213401794
[2025-03-22 09:46:42,803][model][INFO] - Training step 8480 loss 0.008397330529987812
[2025-03-22 09:48:02,300][model][INFO] - Training step 8640 loss 0.06289153546094894
[2025-03-22 09:49:21,940][model][INFO] - Training step 8800 loss 0.05703555792570114
[2025-03-22 09:50:40,035][model][INFO] - Training step 8960 loss 0.07999654114246368
[2025-03-22 09:51:59,342][model][INFO] - Training step 9120 loss 0.006502097472548485
[2025-03-22 09:53:15,304][model][INFO] - Training step 9280 loss 0.08797064423561096
[2025-03-22 09:54:34,559][model][INFO] - Training step 9440 loss 0.015822365880012512
[2025-03-22 09:55:52,562][model][INFO] - Training step 9600 loss 0.02520596608519554
[2025-03-22 09:57:12,670][model][INFO] - Training step 9760 loss 0.0021181635092943907
[2025-03-22 09:58:31,856][model][INFO] - Training step 9920 loss 0.2433088719844818
[2025-03-22 09:59:54,040][model][INFO] - Training step 10080 loss 0.006262714974582195
[2025-03-22 10:01:13,609][model][INFO] - Training step 10240 loss 0.01565105840563774
[2025-03-22 10:02:33,959][model][INFO] - Training step 10400 loss 0.021182170137763023
[2025-03-22 10:03:54,570][model][INFO] - Training step 10560 loss 0.05175122991204262
[2025-03-22 10:05:12,150][model][INFO] - Training step 10720 loss 0.01528426818549633
[2025-03-22 10:06:31,715][model][INFO] - Training step 10880 loss 0.006028221920132637
[2025-03-22 10:07:51,862][model][INFO] - Training step 11040 loss 0.029678061604499817
[2025-03-22 10:09:10,046][model][INFO] - Training step 11200 loss 0.08942060172557831
[2025-03-22 10:10:28,791][model][INFO] - Training step 11360 loss 0.029937461018562317
[2025-03-22 10:11:46,087][model][INFO] - Training step 11520 loss 0.024230409413576126
[2025-03-22 10:13:05,891][model][INFO] - Training step 11680 loss 0.20786309242248535
[2025-03-22 10:14:28,415][model][INFO] - Training step 11840 loss 0.24878448247909546
[2025-03-22 10:15:46,726][model][INFO] - Training step 12000 loss 0.045767657458782196
[2025-03-22 10:17:09,133][model][INFO] - Training step 12160 loss 0.2455417960882187
[2025-03-22 10:18:26,909][model][INFO] - Training step 12320 loss 0.05114451050758362
[2025-03-22 10:19:49,213][model][INFO] - Training step 12480 loss 0.008366234600543976
[2025-03-22 10:21:06,820][model][INFO] - Training step 12640 loss 0.03162272274494171
[2025-03-22 10:22:27,057][model][INFO] - Training step 12800 loss 0.009814240038394928
[2025-03-22 10:23:46,040][model][INFO] - Training step 12960 loss 0.272582471370697
[2025-03-22 10:25:05,203][model][INFO] - Training step 13120 loss 0.15944239497184753
[2025-03-22 10:26:23,679][model][INFO] - Training step 13280 loss 0.2597779631614685
[2025-03-22 10:27:42,971][model][INFO] - Training step 13440 loss 0.04303152114152908
[2025-03-22 10:29:02,583][model][INFO] - Training step 13600 loss 0.023469064384698868
[2025-03-22 10:30:24,584][model][INFO] - Training step 13760 loss 0.0050130910240113735
[2025-03-22 10:31:44,683][model][INFO] - Training step 13920 loss 0.0556720569729805
[2025-03-22 10:33:04,389][model][INFO] - Training step 14080 loss 0.01900201290845871
[2025-03-22 10:34:21,993][model][INFO] - Training step 14240 loss 0.005458315834403038
[2025-03-22 10:35:39,518][model][INFO] - Training step 14400 loss 0.009484929963946342
[2025-03-22 10:36:58,642][model][INFO] - Training step 14560 loss 0.028623228892683983
[2025-03-22 10:38:18,592][model][INFO] - Training step 14720 loss 0.277815043926239
[2025-03-22 10:39:35,441][model][INFO] - Training step 14880 loss 0.0431012287735939
[2025-03-22 10:40:58,738][model][INFO] - Training step 15040 loss 0.0058458782732486725
[2025-03-22 10:42:17,987][model][INFO] - Training step 15200 loss 0.09970429539680481
[2025-03-22 10:43:36,209][model][INFO] - Training step 15360 loss 0.009333113208413124
[2025-03-22 10:44:53,449][model][INFO] - Training step 15520 loss 0.017784016206860542
[2025-03-22 10:46:12,731][model][INFO] - Training step 15680 loss 0.033078890293836594
[2025-03-22 10:47:32,314][model][INFO] - Training step 15840 loss 0.01076133269816637
[2025-03-22 10:48:49,229][model][INFO] - Training step 16000 loss 0.021163441240787506
[2025-03-22 10:50:09,078][model][INFO] - Training step 16160 loss 0.024642296135425568
[2025-03-22 10:51:28,409][model][INFO] - Training step 16320 loss 0.035127364099025726
[2025-03-22 10:52:48,447][model][INFO] - Training step 16480 loss 0.05853291600942612
[2025-03-22 10:54:05,880][model][INFO] - Training step 16640 loss 0.08848968148231506
[2025-03-22 10:55:25,113][model][INFO] - Training step 16800 loss 0.17087391018867493
[2025-03-22 10:56:43,821][model][INFO] - Training step 16960 loss 0.0451790988445282
[2025-03-22 10:58:05,441][model][INFO] - Training step 17120 loss 0.003042504657059908
[2025-03-22 10:59:24,368][model][INFO] - Training step 17280 loss 0.039339423179626465
[2025-03-22 11:00:43,727][model][INFO] - Training step 17440 loss 0.03539270907640457
[2025-03-22 11:02:04,620][model][INFO] - Training step 17600 loss 0.11076299846172333
[2025-03-22 11:03:23,247][model][INFO] - Training step 17760 loss 0.0033212683629244566
[2025-03-22 11:04:39,789][model][INFO] - Training step 17920 loss 0.14075495302677155
[2025-03-22 11:05:57,437][model][INFO] - Training step 18080 loss 0.025789296254515648
[2025-03-22 11:07:15,428][model][INFO] - Training step 18240 loss 0.03779129683971405
[2025-03-22 11:08:33,538][model][INFO] - Training step 18400 loss 0.03299747407436371
[2025-03-22 11:09:52,545][model][INFO] - Training step 18560 loss 0.029435373842716217
[2025-03-22 11:11:13,717][model][INFO] - Training step 18720 loss 0.2632650136947632
[2025-03-22 11:12:32,751][model][INFO] - Training step 18880 loss 0.2542456388473511
[2025-03-22 11:13:52,356][model][INFO] - Training step 19040 loss 0.05109194666147232
[2025-03-22 11:15:12,252][model][INFO] - Training step 19200 loss 0.006139399018138647
[2025-03-22 11:16:27,755][model][INFO] - Training step 19360 loss 0.03469536080956459
[2025-03-22 11:17:46,043][model][INFO] - Training step 19520 loss 0.24344003200531006
[2025-03-22 11:19:07,869][model][INFO] - Training step 19680 loss 0.00262325257062912
[2025-03-22 11:20:28,516][model][INFO] - Training step 19840 loss 0.026775378733873367
[2025-03-22 11:21:49,868][model][INFO] - Training step 20000 loss 0.0917523205280304
[2025-03-22 11:23:07,048][model][INFO] - Training step 20160 loss 0.02282952517271042
[2025-03-22 11:24:26,643][model][INFO] - Training step 20320 loss 0.050988174974918365
[2025-03-22 11:25:45,398][model][INFO] - Training step 20480 loss 0.0472029447555542
[2025-03-22 11:27:03,326][model][INFO] - Training step 20640 loss 0.09343087673187256
[2025-03-22 11:28:21,688][model][INFO] - Training step 20800 loss 0.035458773374557495
[2025-03-22 11:29:39,119][model][INFO] - Training step 20960 loss 0.229861319065094
[2025-03-22 11:31:00,188][model][INFO] - Training step 21120 loss 0.11423380672931671
[2025-03-22 11:32:20,173][model][INFO] - Training step 21280 loss 0.020344723016023636
[2025-03-22 11:33:37,843][model][INFO] - Training step 21440 loss 0.019974347203969955
[2025-03-22 11:35:01,549][model][INFO] - Training step 21600 loss 0.10995088517665863
[2025-03-22 11:36:20,291][model][INFO] - Training step 21760 loss 0.10129159688949585
[2025-03-22 11:37:38,673][model][INFO] - Training step 21920 loss 0.10048814117908478
[2025-03-22 11:38:54,352][model][INFO] - Training step 22080 loss 0.04066836088895798
[2025-03-22 11:40:11,698][model][INFO] - Training step 22240 loss 0.02699834108352661
[2025-03-22 11:41:32,969][model][INFO] - Training step 22400 loss 0.0070105744525790215
[2025-03-22 11:42:53,709][model][INFO] - Training step 22560 loss 0.03690014034509659
[2025-03-22 11:44:11,549][model][INFO] - Training step 22720 loss 0.014587216079235077
[2025-03-22 11:45:32,132][model][INFO] - Training step 22880 loss 0.015753943473100662
[2025-03-22 11:46:51,256][model][INFO] - Training step 23040 loss 0.05023832619190216
[2025-03-22 11:48:11,905][model][INFO] - Training step 23200 loss 0.16123200953006744
[2025-03-22 11:49:31,053][model][INFO] - Training step 23360 loss 0.06475409865379333
[2025-03-22 11:50:51,119][model][INFO] - Training step 23520 loss 0.09214575588703156
[2025-03-22 11:52:09,340][model][INFO] - Training step 23680 loss 0.21799501776695251
[2025-03-22 11:53:28,684][model][INFO] - Training step 23840 loss 0.08828149735927582
[2025-03-22 11:54:48,989][model][INFO] - Training step 24000 loss 0.2537425756454468
[2025-03-22 11:56:06,600][model][INFO] - Training step 24160 loss 0.09129268676042557
[2025-03-22 11:57:29,628][model][INFO] - Training step 24320 loss 0.024256963282823563
[2025-03-22 11:58:51,302][model][INFO] - Training step 24480 loss 0.009360341355204582
[2025-03-22 12:00:07,571][model][INFO] - Training step 24640 loss 0.017855508252978325
[2025-03-22 12:01:27,031][model][INFO] - Training step 24800 loss 0.2569541335105896
[2025-03-22 12:02:46,820][model][INFO] - Training step 24960 loss 0.007236300501972437
[2025-03-22 12:04:07,167][model][INFO] - Training step 25120 loss 0.15605413913726807
[2025-03-22 12:05:26,060][model][INFO] - Training step 25280 loss 0.030599180608987808
[2025-03-22 12:06:43,502][model][INFO] - Training step 25440 loss 0.03889150172472
[2025-03-22 12:08:05,064][model][INFO] - Training step 25600 loss 0.07432422041893005
[2025-03-22 12:09:21,895][model][INFO] - Training step 25760 loss 0.024376824498176575
[2025-03-22 12:10:43,586][model][INFO] - Training step 25920 loss 0.06253770738840103
[2025-03-22 12:12:04,561][model][INFO] - Training step 26080 loss 0.02110248990356922
[2025-03-22 12:13:26,771][model][INFO] - Training step 26240 loss 0.02781110815703869
[2025-03-22 12:14:45,686][model][INFO] - Training step 26400 loss 0.026287533342838287
[2025-03-22 12:16:04,193][model][INFO] - Training step 26560 loss 0.12741801142692566
[2025-03-22 12:17:22,461][model][INFO] - Training step 26720 loss 0.0366692841053009
[2025-03-22 12:18:41,821][model][INFO] - Training step 26880 loss 0.05564113333821297
[2025-03-22 12:20:00,155][model][INFO] - Training step 27040 loss 0.023092815652489662
[2025-03-22 12:21:20,554][model][INFO] - Training step 27200 loss 0.028140762820839882
[2025-03-22 12:22:38,807][model][INFO] - Training step 27360 loss 0.1035614013671875
[2025-03-22 12:23:57,055][model][INFO] - Training step 27520 loss 0.005369230173528194
[2025-03-22 12:25:17,230][model][INFO] - Training step 27680 loss 0.0038123736158013344
[2025-03-22 12:26:36,101][model][INFO] - Training step 27840 loss 0.24681690335273743
[2025-03-22 12:27:52,529][model][INFO] - Training step 28000 loss 0.060794636607170105
[2025-03-22 12:29:14,527][model][INFO] - Training step 28160 loss 0.2684064507484436
[2025-03-22 12:30:32,746][model][INFO] - Training step 28320 loss 0.025998208671808243
[2025-03-22 12:31:55,761][model][INFO] - Training step 28480 loss 0.25416579842567444
[2025-03-22 12:33:13,656][model][INFO] - Training step 28640 loss 0.24324709177017212
[2025-03-22 12:34:29,755][model][INFO] - Training step 28800 loss 0.07499931007623672
[2025-03-22 12:35:49,540][model][INFO] - Training step 28960 loss 0.03676505386829376
[2025-03-22 12:37:07,183][model][INFO] - Training step 29120 loss 0.040445584803819656
[2025-03-22 12:38:28,994][model][INFO] - Training step 29280 loss 0.03383035957813263
[2025-03-22 12:39:48,632][model][INFO] - Training step 29440 loss 0.03668547421693802
[2025-03-22 12:41:10,542][model][INFO] - Training step 29600 loss 0.05956794694066048
[2025-03-22 12:42:30,128][model][INFO] - Training step 29760 loss 0.0376904234290123
[2025-03-22 12:43:50,595][model][INFO] - Training step 29920 loss 0.09438195079565048
[2025-03-22 12:45:11,748][model][INFO] - Training step 30080 loss 0.018777593970298767
[2025-03-22 12:46:28,293][model][INFO] - Training step 30240 loss 0.10694824159145355
[2025-03-22 12:47:47,877][model][INFO] - Training step 30400 loss 0.2404516637325287
[2025-03-22 12:49:05,766][model][INFO] - Training step 30560 loss 0.2914276123046875
[2025-03-22 12:50:22,011][model][INFO] - Training step 30720 loss 0.011681174859404564
[2025-03-22 12:51:38,439][model][INFO] - Training step 30880 loss 0.02043376863002777
[2025-03-22 12:52:58,099][model][INFO] - Training step 31040 loss 0.0303171556442976
[2025-03-22 12:54:15,685][model][INFO] - Training step 31200 loss 0.02211407572031021
[2025-03-22 12:55:33,231][model][INFO] - Training step 31360 loss 0.026350244879722595
[2025-03-22 12:56:50,405][model][INFO] - Training step 31520 loss 0.05866584926843643
[2025-03-22 12:58:09,916][model][INFO] - Training step 31680 loss 0.07487177848815918
[2025-03-22 12:59:29,593][model][INFO] - Training step 31840 loss 0.26532840728759766
[2025-03-22 13:00:47,490][model][INFO] - Training step 32000 loss 0.03178941085934639
[2025-03-22 13:02:06,362][model][INFO] - Training step 32160 loss 0.25313109159469604
[2025-03-22 13:03:26,476][model][INFO] - Training step 32320 loss 0.021473854780197144
[2025-03-22 13:04:45,870][model][INFO] - Training step 32480 loss 0.018129993230104446
[2025-03-22 13:06:07,338][model][INFO] - Training step 32640 loss 0.052602365612983704
[2025-03-22 13:07:27,123][model][INFO] - Training step 32800 loss 0.022319475188851357
[2025-03-22 13:08:48,112][model][INFO] - Training step 32960 loss 0.04590544104576111
[2025-03-22 13:10:07,406][model][INFO] - Training step 33120 loss 0.02323528379201889
[2025-03-22 13:11:26,828][model][INFO] - Training step 33280 loss 0.058219678699970245
[2025-03-22 13:12:44,566][model][INFO] - Training step 33440 loss 0.031020041555166245
[2025-03-22 13:14:05,948][model][INFO] - Training step 33600 loss 0.005460021551698446
[2025-03-22 13:15:25,483][model][INFO] - Training step 33760 loss 0.030937738716602325
[2025-03-22 13:16:44,096][model][INFO] - Training step 33920 loss 0.00242322264239192
[2025-03-22 13:18:05,995][model][INFO] - Training step 34080 loss 0.008700262755155563
[2025-03-22 13:19:24,832][model][INFO] - Training step 34240 loss 0.2473183572292328
[2025-03-22 13:20:44,720][model][INFO] - Training step 34400 loss 0.25139120221138
[2025-03-22 13:22:05,116][model][INFO] - Training step 34560 loss 0.22489695250988007
[2025-03-22 13:23:27,342][model][INFO] - Training step 34720 loss 0.26955634355545044
[2025-03-22 13:24:46,090][model][INFO] - Training step 34880 loss 0.27191925048828125
[2025-03-22 13:26:06,576][model][INFO] - Training step 35040 loss 0.24652099609375
[2025-03-22 13:27:23,070][model][INFO] - Training step 35200 loss 0.022145122289657593
[2025-03-22 13:28:41,724][model][INFO] - Training step 35360 loss 0.24859753251075745
[2025-03-22 13:30:02,154][model][INFO] - Training step 35520 loss 0.0018564654747024179
[2025-03-22 13:31:18,442][model][INFO] - Training step 35680 loss 0.01935558393597603
[2025-03-22 13:32:36,742][model][INFO] - Training step 35840 loss 0.018180742859840393
[2025-03-22 13:33:54,818][model][INFO] - Training step 36000 loss 0.25197792053222656
[2025-03-22 13:35:15,055][model][INFO] - Training step 36160 loss 0.03012346662580967
[2025-03-22 13:36:35,497][model][INFO] - Training step 36320 loss 0.23987843096256256
[2025-03-22 13:37:51,629][model][INFO] - Training step 36480 loss 0.02961644157767296
[2025-03-22 13:39:11,808][model][INFO] - Training step 36640 loss 0.027535662055015564
[2025-03-22 13:40:31,911][model][INFO] - Training step 36800 loss 0.05668628215789795
[2025-03-22 13:41:52,624][model][INFO] - Training step 36960 loss 0.08872446417808533
[2025-03-22 13:43:12,144][model][INFO] - Training step 37120 loss 0.24831601977348328
[2025-03-22 13:44:30,419][model][INFO] - Training step 37280 loss 0.26212242245674133
[2025-03-22 13:45:51,022][model][INFO] - Training step 37440 loss 0.049720413982868195
[2025-03-22 13:47:08,079][model][INFO] - Training step 37600 loss 0.025440512225031853
[2025-03-22 13:48:28,770][model][INFO] - Training step 37760 loss 0.2739343047142029
[2025-03-22 13:49:48,432][model][INFO] - Training step 37920 loss 0.25417494773864746
[2025-03-22 13:51:06,454][model][INFO] - Training step 38080 loss 0.24755960702896118
[2025-03-22 13:52:28,109][model][INFO] - Training step 38240 loss 0.003009159816429019
[2025-03-22 13:53:47,032][model][INFO] - Training step 38400 loss 0.19996002316474915
[2025-03-22 13:55:04,195][model][INFO] - Training step 38560 loss 0.029060883447527885
[2025-03-22 13:56:23,927][model][INFO] - Training step 38720 loss 0.05902944877743721
[2025-03-22 13:57:42,396][model][INFO] - Training step 38880 loss 0.04181854426860809
[2025-03-22 13:59:01,467][model][INFO] - Training step 39040 loss 0.004691571928560734
[2025-03-22 14:00:18,296][model][INFO] - Training step 39200 loss 0.225619375705719
[2025-03-22 14:01:39,141][model][INFO] - Training step 39360 loss 0.041375283151865005
[2025-03-22 14:02:59,143][model][INFO] - Training step 39520 loss 0.03163069486618042
[2025-03-22 14:04:15,508][model][INFO] - Training step 39680 loss 0.017323479056358337
[2025-03-22 14:05:35,014][model][INFO] - Training step 39840 loss 0.2635033130645752
[2025-03-22 14:06:54,807][model][INFO] - Training step 40000 loss 0.07963600754737854
[2025-03-22 14:08:15,047][model][INFO] - Training step 40160 loss 0.04023245349526405
[2025-03-22 14:09:36,036][model][INFO] - Training step 40320 loss 0.033134348690509796
[2025-03-22 14:10:55,633][model][INFO] - Training step 40480 loss 0.2333763837814331
[2025-03-22 14:12:14,352][model][INFO] - Training step 40640 loss 0.08765800297260284
[2025-03-22 14:13:32,286][model][INFO] - Training step 40800 loss 0.011654921807348728
[2025-03-22 14:14:49,175][model][INFO] - Training step 40960 loss 0.03117898851633072
[2025-03-22 14:16:08,052][model][INFO] - Training step 41120 loss 0.01265896949917078
[2025-03-22 14:17:29,588][model][INFO] - Training step 41280 loss 0.03353282809257507
[2025-03-22 14:18:45,952][model][INFO] - Training step 41440 loss 0.04394089803099632
[2025-03-22 14:20:06,770][model][INFO] - Training step 41600 loss 0.05480113625526428
[2025-03-22 14:21:27,538][model][INFO] - Training step 41760 loss 0.016601860523223877
[2025-03-22 14:22:47,597][model][INFO] - Training step 41920 loss 0.24373392760753632
[2025-03-22 14:24:07,116][model][INFO] - Training step 42080 loss 0.050637006759643555
[2025-03-22 14:25:27,228][model][INFO] - Training step 42240 loss 0.2522643208503723
[2025-03-22 14:26:46,522][model][INFO] - Training step 42400 loss 0.10454991459846497
[2025-03-22 14:28:05,773][model][INFO] - Training step 42560 loss 0.0032317135483026505
[2025-03-22 14:29:25,495][model][INFO] - Training step 42720 loss 0.2830391526222229
[2025-03-22 14:30:42,138][model][INFO] - Training step 42880 loss 0.034976206719875336
[2025-03-22 14:32:01,886][model][INFO] - Training step 43040 loss 0.021779004484415054
[2025-03-22 14:33:20,241][model][INFO] - Training step 43200 loss 0.0058745453134179115
[2025-03-22 14:34:40,486][model][INFO] - Training step 43360 loss 0.049712829291820526
[2025-03-22 14:36:02,067][model][INFO] - Training step 43520 loss 0.025614451617002487
[2025-03-22 14:37:21,678][model][INFO] - Training step 43680 loss 0.02071237564086914
[2025-03-22 14:38:46,036][model][INFO] - Training step 43840 loss 0.029780104756355286
[2025-03-22 14:40:05,147][model][INFO] - Training step 44000 loss 0.24691055715084076
[2025-03-22 14:41:24,684][model][INFO] - Training step 44160 loss 0.26968348026275635
[2025-03-22 14:42:46,056][model][INFO] - Training step 44320 loss 0.018236029893159866
[2025-03-22 14:44:05,689][model][INFO] - Training step 44480 loss 0.0030275213066488504
[2025-03-22 14:45:25,577][model][INFO] - Training step 44640 loss 0.023890983313322067
[2025-03-22 14:46:43,282][model][INFO] - Training step 44800 loss 0.027102891355752945
[2025-03-22 14:48:01,076][model][INFO] - Training step 44960 loss 0.0048271669074893
[2025-03-22 14:49:19,777][model][INFO] - Training step 45120 loss 0.03775877133011818
[2025-03-22 14:50:39,469][model][INFO] - Training step 45280 loss 0.009049799293279648
[2025-03-22 14:51:59,378][model][INFO] - Training step 45440 loss 0.008626239374279976
[2025-03-22 14:53:18,628][model][INFO] - Training step 45600 loss 0.025684405118227005
[2025-03-22 14:54:40,740][model][INFO] - Training step 45760 loss 0.16366547346115112
[2025-03-22 14:55:58,525][model][INFO] - Training step 45920 loss 0.062493909150362015
[2025-03-22 14:57:17,591][model][INFO] - Training step 46080 loss 0.25958433747291565
[2025-03-22 14:58:35,432][model][INFO] - Training step 46240 loss 0.25381794571876526
[2025-03-22 14:59:54,944][model][INFO] - Training step 46400 loss 0.22960078716278076
[2025-03-22 15:01:13,254][model][INFO] - Training step 46560 loss 0.01928340271115303
[2025-03-22 15:02:31,733][model][INFO] - Training step 46720 loss 0.2492446005344391
[2025-03-22 15:03:55,165][model][INFO] - Training step 46880 loss 0.03487817570567131
[2025-03-22 15:05:15,007][model][INFO] - Training step 47040 loss 0.05323753505945206
[2025-03-22 15:06:34,771][model][INFO] - Training step 47200 loss 0.015709005296230316
[2025-03-22 15:07:56,977][model][INFO] - Training step 47360 loss 0.24742265045642853
[2025-03-22 15:09:16,812][model][INFO] - Training step 47520 loss 0.02276378497481346
[2025-03-22 15:10:37,526][model][INFO] - Training step 47680 loss 0.038122281432151794
[2025-03-22 15:11:57,790][model][INFO] - Training step 47840 loss 0.0074839601293206215
[2025-03-22 15:13:17,398][model][INFO] - Training step 48000 loss 0.047231100499629974
[2025-03-22 15:14:38,485][model][INFO] - Training step 48160 loss 0.26416996121406555
[2025-03-22 15:15:56,686][model][INFO] - Training step 48320 loss 0.2354583442211151
[2025-03-22 15:17:13,447][model][INFO] - Training step 48480 loss 0.01831350103020668
[2025-03-22 15:18:31,220][model][INFO] - Training step 48640 loss 0.02947639673948288
[2025-03-22 15:19:52,382][model][INFO] - Training step 48800 loss 0.25507640838623047
[2025-03-22 15:21:10,887][model][INFO] - Training step 48960 loss 0.014641160145401955
[2025-03-22 15:22:30,772][model][INFO] - Training step 49120 loss 0.02469242364168167
[2025-03-22 15:23:47,657][model][INFO] - Training step 49280 loss 0.004773618653416634
[2025-03-22 15:25:06,061][model][INFO] - Training step 49440 loss 0.030911937355995178
[2025-03-22 15:26:27,117][model][INFO] - Training step 49600 loss 0.029927831143140793
[2025-03-22 15:27:48,395][model][INFO] - Training step 49760 loss 0.261158287525177
[2025-03-22 15:29:10,448][model][INFO] - Training step 49920 loss 0.25314807891845703
[2025-03-22 15:30:32,646][model][INFO] - Training step 50080 loss 0.11638003587722778
[2025-03-22 15:31:53,825][model][INFO] - Training step 50240 loss 0.015648843720555305
[2025-03-22 15:33:11,971][model][INFO] - Training step 50400 loss 0.025044068694114685
[2025-03-22 15:34:28,902][model][INFO] - Training step 50560 loss 0.016928283497691154
[2025-03-22 15:35:46,652][model][INFO] - Training step 50720 loss 0.024636633694171906
[2025-03-22 15:45:19,582][model][INFO] - Training step 80 loss 0.044551242142915726
[2025-03-22 15:46:41,960][model][INFO] - Training step 240 loss 0.02669801563024521
[2025-03-22 15:48:03,055][model][INFO] - Training step 400 loss 0.03437455743551254
[2025-03-22 15:49:21,092][model][INFO] - Training step 560 loss 0.0058843526057899
[2025-03-22 15:50:41,032][model][INFO] - Training step 720 loss 0.13916292786598206
[2025-03-22 15:52:01,120][model][INFO] - Training step 880 loss 0.025629473850131035
[2025-03-22 15:53:22,695][model][INFO] - Training step 1040 loss 0.06225576996803284
[2025-03-22 15:54:42,281][model][INFO] - Training step 1200 loss 0.03212163597345352
[2025-03-22 15:56:04,172][model][INFO] - Training step 1360 loss 0.03002312406897545
[2025-03-22 15:57:21,403][model][INFO] - Training step 1520 loss 0.25230780243873596
[2025-03-22 15:58:40,595][model][INFO] - Training step 1680 loss 0.00526377372443676
[2025-03-22 15:59:59,210][model][INFO] - Training step 1840 loss 0.024259105324745178
[2025-03-22 16:01:16,629][model][INFO] - Training step 2000 loss 0.040794163942337036
[2025-03-22 16:02:35,057][model][INFO] - Training step 2160 loss 0.026302434504032135
[2025-03-22 16:03:54,368][model][INFO] - Training step 2320 loss 0.02881047874689102
[2025-03-22 16:05:13,289][model][INFO] - Training step 2480 loss 0.2555769681930542
[2025-03-22 16:06:30,535][model][INFO] - Training step 2640 loss 0.024571221321821213
[2025-03-22 16:07:50,493][model][INFO] - Training step 2800 loss 0.0034087528474628925
[2025-03-22 16:09:08,343][model][INFO] - Training step 2960 loss 0.24624601006507874
[2025-03-22 16:10:27,364][model][INFO] - Training step 3120 loss 0.004708113148808479
[2025-03-22 16:11:46,327][model][INFO] - Training step 3280 loss 0.029527533799409866
[2025-03-22 16:13:02,846][model][INFO] - Training step 3440 loss 0.05882777273654938
[2025-03-22 16:14:22,389][model][INFO] - Training step 3600 loss 0.043956201523542404
[2025-03-22 16:15:42,134][model][INFO] - Training step 3760 loss 0.022224295884370804
[2025-03-22 16:17:00,988][model][INFO] - Training step 3920 loss 0.15104737877845764
[2025-03-22 16:18:21,160][model][INFO] - Training step 4080 loss 0.00515758665278554
[2025-03-22 16:19:40,812][model][INFO] - Training step 4240 loss 0.25136032700538635
[2025-03-22 16:21:02,646][model][INFO] - Training step 4400 loss 0.02442770078778267
[2025-03-22 16:22:25,232][model][INFO] - Training step 4560 loss 0.14276257157325745
[2025-03-22 16:23:48,670][model][INFO] - Training step 4720 loss 0.05547527223825455
[2025-03-22 16:25:06,892][model][INFO] - Training step 4880 loss 0.23470395803451538
[2025-03-22 16:26:26,029][model][INFO] - Training step 5040 loss 0.07214434444904327
[2025-03-22 16:27:45,504][model][INFO] - Training step 5200 loss 0.04046773910522461
[2025-03-22 16:29:06,520][model][INFO] - Training step 5360 loss 0.1559535264968872
[2025-03-22 16:30:25,017][model][INFO] - Training step 5520 loss 0.043265409767627716
[2025-03-22 16:31:42,351][model][INFO] - Training step 5680 loss 0.02671918459236622
[2025-03-22 16:33:02,476][model][INFO] - Training step 5840 loss 0.04540242627263069
[2025-03-22 16:34:20,520][model][INFO] - Training step 6000 loss 0.01447927113622427
[2025-03-22 16:35:38,994][model][INFO] - Training step 6160 loss 0.024783357977867126
[2025-03-22 16:36:59,541][model][INFO] - Training step 6320 loss 0.003759020008146763
[2025-03-22 16:38:17,350][model][INFO] - Training step 6480 loss 0.038522470742464066
[2025-03-22 16:39:36,016][model][INFO] - Training step 6640 loss 0.007464709226042032
[2025-03-22 16:40:54,416][model][INFO] - Training step 6800 loss 0.017018351703882217
[2025-03-22 16:42:13,907][model][INFO] - Training step 6960 loss 0.007113210391253233
[2025-03-22 16:43:33,460][model][INFO] - Training step 7120 loss 0.250418484210968
[2025-03-22 16:44:53,506][model][INFO] - Training step 7280 loss 0.007551032118499279
[2025-03-22 16:46:09,894][model][INFO] - Training step 7440 loss 0.2422206550836563
[2025-03-22 16:47:28,510][model][INFO] - Training step 7600 loss 0.14000965654850006
[2025-03-22 16:48:46,350][model][INFO] - Training step 7760 loss 0.0394393615424633
[2025-03-22 16:50:06,568][model][INFO] - Training step 7920 loss 0.03524482995271683
[2025-03-22 16:51:27,810][model][INFO] - Training step 8080 loss 0.026026122272014618
[2025-03-22 16:52:45,391][model][INFO] - Training step 8240 loss 0.2531452476978302
[2025-03-22 16:54:05,369][model][INFO] - Training step 8400 loss 0.0017649815417826176
[2025-03-22 16:55:24,195][model][INFO] - Training step 8560 loss 0.021801739931106567
[2025-03-22 16:56:42,799][model][INFO] - Training step 8720 loss 0.010719282552599907
[2025-03-22 16:58:01,382][model][INFO] - Training step 8880 loss 0.01717676967382431
[2025-03-22 16:59:18,344][model][INFO] - Training step 9040 loss 0.020664194598793983
[2025-03-22 17:00:33,607][model][INFO] - Training step 9200 loss 0.024996232241392136
[2025-03-22 17:01:51,021][model][INFO] - Training step 9360 loss 0.030933091416954994
[2025-03-22 17:03:07,069][model][INFO] - Training step 9520 loss 0.03601144999265671
[2025-03-22 17:04:26,336][model][INFO] - Training step 9680 loss 0.01161094382405281
[2025-03-22 17:05:45,220][model][INFO] - Training step 9840 loss 0.12076142430305481
[2025-03-22 17:07:04,831][model][INFO] - Training step 10000 loss 0.01568927988409996
[2025-03-22 17:08:25,402][model][INFO] - Training step 10160 loss 0.04479432851076126
[2025-03-22 17:09:41,448][model][INFO] - Training step 10320 loss 0.12115710973739624
[2025-03-22 17:11:04,225][model][INFO] - Training step 10480 loss 0.03355275094509125
[2025-03-22 17:12:22,893][model][INFO] - Training step 10640 loss 0.03667094558477402
[2025-03-22 17:13:43,610][model][INFO] - Training step 10800 loss 0.03961329162120819
[2025-03-22 17:15:06,570][model][INFO] - Training step 10960 loss 0.055374257266521454
[2025-03-22 17:16:23,721][model][INFO] - Training step 11120 loss 0.003921374678611755
[2025-03-22 17:17:41,399][model][INFO] - Training step 11280 loss 0.026018567383289337
[2025-03-22 17:19:02,157][model][INFO] - Training step 11440 loss 0.04729356989264488
[2025-03-22 17:20:20,126][model][INFO] - Training step 11600 loss 0.03452384099364281
[2025-03-22 17:21:40,176][model][INFO] - Training step 11760 loss 0.0623474158346653
[2025-03-22 17:22:59,348][model][INFO] - Training step 11920 loss 0.07429321110248566
[2025-03-22 17:24:17,139][model][INFO] - Training step 12080 loss 0.040083929896354675
[2025-03-22 17:25:37,167][model][INFO] - Training step 12240 loss 0.053684867918491364
[2025-03-22 17:26:56,975][model][INFO] - Training step 12400 loss 0.2529129385948181
[2025-03-22 17:28:17,698][model][INFO] - Training step 12560 loss 0.24043859541416168
[2025-03-22 17:29:37,141][model][INFO] - Training step 12720 loss 0.11106608062982559
[2025-03-22 17:30:56,667][model][INFO] - Training step 12880 loss 0.02205008640885353
[2025-03-22 17:32:12,491][model][INFO] - Training step 13040 loss 0.265083372592926
[2025-03-22 17:33:30,289][model][INFO] - Training step 13200 loss 0.22341865301132202
[2025-03-22 17:34:49,251][model][INFO] - Training step 13360 loss 0.08954927325248718
[2025-03-22 17:36:07,705][model][INFO] - Training step 13520 loss 0.023556441068649292
[2025-03-22 17:37:27,046][model][INFO] - Training step 13680 loss 0.023538602516055107
[2025-03-22 17:38:44,223][model][INFO] - Training step 13840 loss 0.019050996750593185
[2025-03-22 17:40:03,881][model][INFO] - Training step 14000 loss 0.024254946038126945
[2025-03-22 17:41:20,165][model][INFO] - Training step 14160 loss 0.02524535171687603
[2025-03-22 17:42:39,632][model][INFO] - Training step 14320 loss 0.020000699907541275
[2025-03-22 17:43:58,616][model][INFO] - Training step 14480 loss 0.024468952789902687
[2025-03-22 17:45:17,958][model][INFO] - Training step 14640 loss 0.020677931606769562
[2025-03-22 17:46:35,502][model][INFO] - Training step 14800 loss 0.04730498045682907
[2025-03-22 17:47:54,917][model][INFO] - Training step 14960 loss 0.017696011811494827
[2025-03-22 17:49:14,789][model][INFO] - Training step 15120 loss 0.022915499284863472
[2025-03-22 17:50:32,406][model][INFO] - Training step 15280 loss 0.033573634922504425
[2025-03-22 17:51:51,510][model][INFO] - Training step 15440 loss 0.038283735513687134
[2025-03-22 17:53:12,820][model][INFO] - Training step 15600 loss 0.05867119878530502
[2025-03-22 17:54:30,438][model][INFO] - Training step 15760 loss 0.03314463421702385
[2025-03-22 17:55:47,849][model][INFO] - Training step 15920 loss 0.007423647679388523
[2025-03-22 17:57:06,287][model][INFO] - Training step 16080 loss 0.018698327243328094
[2025-03-22 17:58:23,726][model][INFO] - Training step 16240 loss 0.1415090262889862
[2025-03-22 17:59:40,273][model][INFO] - Training step 16400 loss 0.03432661294937134
[2025-03-22 18:00:59,642][model][INFO] - Training step 16560 loss 0.25660592317581177
[2025-03-22 18:02:15,850][model][INFO] - Training step 16720 loss 0.25431907176971436
[2025-03-22 18:03:35,304][model][INFO] - Training step 16880 loss 0.021852971985936165
[2025-03-22 18:04:55,336][model][INFO] - Training step 17040 loss 0.038969289511442184
[2025-03-22 18:06:18,644][model][INFO] - Training step 17200 loss 0.006303727626800537
[2025-03-22 18:07:37,636][model][INFO] - Training step 17360 loss 0.016775088384747505
[2025-03-22 18:08:58,201][model][INFO] - Training step 17520 loss 0.032382942736148834
[2025-03-22 18:10:18,990][model][INFO] - Training step 17680 loss 0.2615872025489807
[2025-03-22 18:11:37,369][model][INFO] - Training step 17840 loss 0.054563529789447784
[2025-03-22 18:12:54,155][model][INFO] - Training step 18000 loss 0.0326998196542263
[2025-03-22 18:14:13,783][model][INFO] - Training step 18160 loss 0.25549179315567017
[2025-03-22 18:15:34,331][model][INFO] - Training step 18320 loss 0.24909429252147675
[2025-03-22 18:16:54,511][model][INFO] - Training step 18480 loss 0.05217745155096054
[2025-03-22 18:18:14,806][model][INFO] - Training step 18640 loss 0.06363813579082489
[2025-03-22 18:19:36,085][model][INFO] - Training step 18800 loss 0.01606167107820511
[2025-03-22 18:20:56,034][model][INFO] - Training step 18960 loss 0.03743452578783035
[2025-03-22 18:22:15,425][model][INFO] - Training step 19120 loss 0.021052148193120956
[2025-03-22 18:23:35,260][model][INFO] - Training step 19280 loss 0.018480781465768814
[2025-03-22 18:24:55,304][model][INFO] - Training step 19440 loss 0.06940903514623642
[2025-03-22 18:26:17,120][model][INFO] - Training step 19600 loss 0.04476044327020645
[2025-03-22 18:27:36,299][model][INFO] - Training step 19760 loss 0.017522186040878296
[2025-03-22 18:28:53,940][model][INFO] - Training step 19920 loss 0.051522694528102875
[2025-03-22 18:30:12,672][model][INFO] - Training step 20080 loss 0.04846971482038498
[2025-03-22 18:31:30,142][model][INFO] - Training step 20240 loss 0.024694351479411125
[2025-03-22 18:32:51,338][model][INFO] - Training step 20400 loss 0.14764538407325745
[2025-03-22 18:34:10,850][model][INFO] - Training step 20560 loss 0.040987301617860794
[2025-03-22 18:35:28,696][model][INFO] - Training step 20720 loss 0.25074538588523865
[2025-03-22 18:36:49,378][model][INFO] - Training step 20880 loss 0.03530646115541458
[2025-03-22 18:38:08,412][model][INFO] - Training step 21040 loss 0.3042943477630615
[2025-03-22 18:39:26,831][model][INFO] - Training step 21200 loss 0.2332879602909088
[2025-03-22 18:40:45,316][model][INFO] - Training step 21360 loss 0.24215221405029297
[2025-03-22 18:42:04,784][model][INFO] - Training step 21520 loss 0.03122382052242756
[2025-03-22 18:43:23,620][model][INFO] - Training step 21680 loss 0.1565713882446289
[2025-03-22 18:44:44,081][model][INFO] - Training step 21840 loss 0.25252246856689453
[2025-03-22 18:46:00,750][model][INFO] - Training step 22000 loss 0.24256691336631775
[2025-03-22 18:47:18,908][model][INFO] - Training step 22160 loss 0.039761174470186234
[2025-03-22 18:48:40,401][model][INFO] - Training step 22320 loss 0.1068888008594513
[2025-03-22 18:49:59,892][model][INFO] - Training step 22480 loss 0.2416372001171112
[2025-03-22 18:51:19,052][model][INFO] - Training step 22640 loss 0.2488241046667099
[2025-03-22 18:52:36,651][model][INFO] - Training step 22800 loss 0.02774009108543396
[2025-03-22 18:53:57,199][model][INFO] - Training step 22960 loss 0.03214917704463005
[2025-03-22 18:55:16,135][model][INFO] - Training step 23120 loss 0.006375565659254789
[2025-03-22 18:56:37,567][model][INFO] - Training step 23280 loss 0.03751698136329651
[2025-03-22 18:57:57,448][model][INFO] - Training step 23440 loss 0.024623684585094452
[2025-03-22 18:59:16,031][model][INFO] - Training step 23600 loss 0.34425440430641174
[2025-03-22 19:00:35,591][model][INFO] - Training step 23760 loss 0.08690543472766876
[2025-03-22 19:01:55,993][model][INFO] - Training step 23920 loss 0.24265655875205994
[2025-03-22 19:03:15,050][model][INFO] - Training step 24080 loss 0.07511791586875916
[2025-03-22 19:04:33,708][model][INFO] - Training step 24240 loss 0.021946940571069717
[2025-03-22 19:05:50,582][model][INFO] - Training step 24400 loss 0.22645138204097748
[2025-03-22 19:07:07,995][model][INFO] - Training step 24560 loss 0.07281039655208588
[2025-03-22 19:08:25,722][model][INFO] - Training step 24720 loss 0.026644235476851463
[2025-03-22 19:09:44,580][model][INFO] - Training step 24880 loss 0.2783123850822449
[2025-03-22 19:11:01,832][model][INFO] - Training step 25040 loss 0.03807657212018967
[2025-03-22 19:12:21,840][model][INFO] - Training step 25200 loss 0.021269138902425766
[2025-03-22 19:13:40,878][model][INFO] - Training step 25360 loss 0.13061144948005676
[2025-03-22 19:14:58,792][model][INFO] - Training step 25520 loss 0.03886724263429642
[2025-03-22 19:16:17,902][model][INFO] - Training step 25680 loss 0.039847563952207565
[2025-03-22 19:17:36,104][model][INFO] - Training step 25840 loss 0.04255175590515137
[2025-03-22 19:18:57,383][model][INFO] - Training step 26000 loss 0.2828112244606018
[2025-03-22 19:20:19,055][model][INFO] - Training step 26160 loss 0.255033403635025
[2025-03-22 19:21:39,856][model][INFO] - Training step 26320 loss 0.16921444237232208
[2025-03-22 19:23:02,110][model][INFO] - Training step 26480 loss 0.039956606924533844
[2025-03-22 19:24:23,816][model][INFO] - Training step 26640 loss 0.029556533321738243
[2025-03-22 19:25:43,471][model][INFO] - Training step 26800 loss 0.040780168026685715
[2025-03-22 19:27:03,562][model][INFO] - Training step 26960 loss 0.024986036121845245
[2025-03-22 19:28:23,239][model][INFO] - Training step 27120 loss 0.04727867990732193
[2025-03-22 19:29:44,220][model][INFO] - Training step 27280 loss 0.008689271286129951
[2025-03-22 19:31:01,566][model][INFO] - Training step 27440 loss 0.2775806784629822
[2025-03-22 19:32:21,616][model][INFO] - Training step 27600 loss 0.2539932131767273
[2025-03-22 19:33:36,274][model][INFO] - Training step 27760 loss 0.06881137192249298
[2025-03-22 19:34:55,303][model][INFO] - Training step 27920 loss 0.03225090354681015
[2025-03-22 19:36:15,626][model][INFO] - Training step 28080 loss 0.006461947225034237
[2025-03-22 19:37:33,414][model][INFO] - Training step 28240 loss 0.046053677797317505
[2025-03-22 19:38:50,962][model][INFO] - Training step 28400 loss 0.05527520924806595
[2025-03-22 19:40:12,454][model][INFO] - Training step 28560 loss 0.004273105412721634
[2025-03-22 19:41:27,869][model][INFO] - Training step 28720 loss 0.254511296749115
[2025-03-22 19:42:48,909][model][INFO] - Training step 28880 loss 0.02104683220386505
[2025-03-22 19:44:08,128][model][INFO] - Training step 29040 loss 0.026596225798130035
[2025-03-22 19:45:28,360][model][INFO] - Training step 29200 loss 0.014664977788925171
[2025-03-22 19:46:45,776][model][INFO] - Training step 29360 loss 0.008939428254961967
[2025-03-22 19:48:02,660][model][INFO] - Training step 29520 loss 0.03579724580049515
[2025-03-22 19:49:24,694][model][INFO] - Training step 29680 loss 0.006493659690022469
[2025-03-22 19:50:42,930][model][INFO] - Training step 29840 loss 0.046793825924396515
[2025-03-22 19:52:03,371][model][INFO] - Training step 30000 loss 0.016282176598906517
[2025-03-22 19:53:24,070][model][INFO] - Training step 30160 loss 0.03858303651213646
[2025-03-22 19:54:45,935][model][INFO] - Training step 30320 loss 0.004977538250386715
[2025-03-22 19:56:03,696][model][INFO] - Training step 30480 loss 0.018076952546834946
[2025-03-22 19:57:18,006][model][INFO] - Training step 30640 loss 0.025733772665262222
[2025-03-22 19:58:35,222][model][INFO] - Training step 30800 loss 0.08215610682964325
[2025-03-22 19:59:53,442][model][INFO] - Training step 30960 loss 0.024763748049736023
[2025-03-22 20:01:11,692][model][INFO] - Training step 31120 loss 0.035904910415410995
[2025-03-22 20:02:30,161][model][INFO] - Training step 31280 loss 0.24665017426013947
[2025-03-22 20:03:49,626][model][INFO] - Training step 31440 loss 0.06063807010650635
[2025-03-22 20:05:07,620][model][INFO] - Training step 31600 loss 0.03705909103155136
[2025-03-22 20:06:25,083][model][INFO] - Training step 31760 loss 0.055757105350494385
[2025-03-22 20:07:45,445][model][INFO] - Training step 31920 loss 0.03615801781415939
[2025-03-22 20:09:04,353][model][INFO] - Training step 32080 loss 0.040966473519802094
[2025-03-22 20:10:25,695][model][INFO] - Training step 32240 loss 0.01632646843791008
[2025-03-22 20:11:46,005][model][INFO] - Training step 32400 loss 0.025390509516000748
[2025-03-22 20:13:05,761][model][INFO] - Training step 32560 loss 0.23885229229927063
[2025-03-22 20:14:27,370][model][INFO] - Training step 32720 loss 0.019466852769255638
[2025-03-22 20:15:47,694][model][INFO] - Training step 32880 loss 0.028893321752548218
[2025-03-22 20:17:07,564][model][INFO] - Training step 33040 loss 0.2551001310348511
[2025-03-22 20:18:26,460][model][INFO] - Training step 33200 loss 0.24090465903282166
[2025-03-22 20:19:44,783][model][INFO] - Training step 33360 loss 0.03155398741364479
[2025-03-22 20:21:03,587][model][INFO] - Training step 33520 loss 0.043078288435935974
[2025-03-22 20:22:23,022][model][INFO] - Training step 33680 loss 0.02045445144176483
[2025-03-22 20:23:41,843][model][INFO] - Training step 33840 loss 0.25237947702407837
[2025-03-22 20:24:59,200][model][INFO] - Training step 34000 loss 0.26264488697052
[2025-03-22 20:26:20,994][model][INFO] - Training step 34160 loss 0.054054707288742065
[2025-03-22 20:27:39,284][model][INFO] - Training step 34320 loss 0.004865058232098818
[2025-03-22 20:28:57,012][model][INFO] - Training step 34480 loss 0.12367189675569534
[2025-03-22 20:30:15,411][model][INFO] - Training step 34640 loss 0.031251341104507446
[2025-03-22 20:31:33,400][model][INFO] - Training step 34800 loss 0.031258903443813324
[2025-03-22 20:32:53,347][model][INFO] - Training step 34960 loss 0.02655702643096447
[2025-03-22 20:34:13,926][model][INFO] - Training step 35120 loss 0.005578935146331787
[2025-03-22 20:35:32,049][model][INFO] - Training step 35280 loss 0.026547804474830627
[2025-03-22 20:36:52,668][model][INFO] - Training step 35440 loss 0.008642233908176422
[2025-03-22 20:38:12,973][model][INFO] - Training step 35600 loss 0.03618595376610756
[2025-03-22 20:39:32,803][model][INFO] - Training step 35760 loss 0.001865471014752984
[2025-03-22 20:40:49,330][model][INFO] - Training step 35920 loss 0.03367365151643753
[2025-03-22 20:42:10,077][model][INFO] - Training step 36080 loss 0.006929502822458744
[2025-03-22 20:43:29,390][model][INFO] - Training step 36240 loss 0.030675474554300308
[2025-03-22 20:44:50,116][model][INFO] - Training step 36400 loss 0.023308753967285156
[2025-03-22 20:46:12,037][model][INFO] - Training step 36560 loss 0.2279307097196579
[2025-03-22 20:47:31,073][model][INFO] - Training step 36720 loss 0.008796160109341145
[2025-03-22 20:48:51,149][model][INFO] - Training step 36880 loss 0.08753511309623718
[2025-03-22 20:50:11,244][model][INFO] - Training step 37040 loss 0.00608420604839921
[2025-03-22 20:51:29,773][model][INFO] - Training step 37200 loss 0.0784284919500351
[2025-03-22 20:52:52,418][model][INFO] - Training step 37360 loss 0.06105082482099533
[2025-03-22 20:54:13,274][model][INFO] - Training step 37520 loss 0.01267528347671032
[2025-03-22 20:55:31,028][model][INFO] - Training step 37680 loss 0.024346627295017242
[2025-03-22 20:56:48,241][model][INFO] - Training step 37840 loss 0.10050699859857559
[2025-03-22 20:58:06,217][model][INFO] - Training step 38000 loss 0.024416344240307808
[2025-03-22 20:59:25,664][model][INFO] - Training step 38160 loss 0.020984452217817307
[2025-03-22 21:00:46,064][model][INFO] - Training step 38320 loss 0.05117582157254219
[2025-03-22 21:02:06,757][model][INFO] - Training step 38480 loss 0.044968899339437485
[2025-03-22 21:03:23,915][model][INFO] - Training step 38640 loss 0.02700628712773323
[2025-03-22 21:04:42,142][model][INFO] - Training step 38800 loss 0.031807318329811096
[2025-03-22 21:06:03,588][model][INFO] - Training step 38960 loss 0.025028299540281296
[2025-03-22 21:07:20,622][model][INFO] - Training step 39120 loss 0.0338827520608902
[2025-03-22 21:08:39,337][model][INFO] - Training step 39280 loss 0.05901557207107544
[2025-03-22 21:09:58,001][model][INFO] - Training step 39440 loss 0.06785579025745392
[2025-03-22 21:11:17,956][model][INFO] - Training step 39600 loss 0.03323446959257126
[2025-03-22 21:12:33,743][model][INFO] - Training step 39760 loss 0.02445162832736969
[2025-03-22 21:13:54,000][model][INFO] - Training step 39920 loss 0.0551019124686718
[2025-03-22 21:15:11,589][model][INFO] - Training step 40080 loss 0.06800279766321182
[2025-03-22 21:16:33,635][model][INFO] - Training step 40240 loss 0.20661719143390656
[2025-03-22 21:17:56,283][model][INFO] - Training step 40400 loss 0.006941816303879023
[2025-03-22 21:19:19,000][model][INFO] - Training step 40560 loss 0.14138275384902954
[2025-03-22 21:20:37,372][model][INFO] - Training step 40720 loss 0.03599117696285248
[2025-03-22 21:21:56,704][model][INFO] - Training step 40880 loss 0.05505673587322235
[2025-03-22 21:23:12,680][model][INFO] - Training step 41040 loss 0.2276490330696106
[2025-03-22 21:24:31,103][model][INFO] - Training step 41200 loss 0.027325395494699478
[2025-03-22 21:25:51,182][model][INFO] - Training step 41360 loss 0.014142779633402824
[2025-03-22 21:27:08,129][model][INFO] - Training step 41520 loss 0.03928849846124649
[2025-03-22 21:28:30,008][model][INFO] - Training step 41680 loss 0.007210949435830116
[2025-03-22 21:29:51,327][model][INFO] - Training step 41840 loss 0.004865090362727642
[2025-03-22 21:31:10,941][model][INFO] - Training step 42000 loss 0.04056255519390106
[2025-03-22 21:32:27,794][model][INFO] - Training step 42160 loss 0.028694596141576767
[2025-03-22 21:33:45,969][model][INFO] - Training step 42320 loss 0.06090810149908066
[2025-03-22 21:35:05,866][model][INFO] - Training step 42480 loss 0.02504611946642399
[2025-03-22 21:36:26,623][model][INFO] - Training step 42640 loss 0.004163593519479036
[2025-03-22 21:37:45,736][model][INFO] - Training step 42800 loss 0.25359997153282166
[2025-03-22 21:39:05,134][model][INFO] - Training step 42960 loss 0.024625275284051895
[2025-03-22 21:40:23,232][model][INFO] - Training step 43120 loss 0.043843820691108704
[2025-03-22 21:41:40,715][model][INFO] - Training step 43280 loss 0.044586725533008575
[2025-03-22 21:43:02,909][model][INFO] - Training step 43440 loss 0.13462930917739868
[2025-03-22 21:44:22,823][model][INFO] - Training step 43600 loss 0.0133280698210001
[2025-03-22 21:45:43,015][model][INFO] - Training step 43760 loss 0.23331570625305176
[2025-03-22 21:47:02,379][model][INFO] - Training step 43920 loss 0.26568758487701416
[2025-03-22 21:48:24,472][model][INFO] - Training step 44080 loss 0.03270267695188522
[2025-03-22 21:49:42,895][model][INFO] - Training step 44240 loss 0.026910724118351936
[2025-03-22 21:51:03,322][model][INFO] - Training step 44400 loss 0.10918933153152466
[2025-03-22 21:52:23,062][model][INFO] - Training step 44560 loss 0.25735363364219666
[2025-03-22 21:53:42,680][model][INFO] - Training step 44720 loss 0.023676451295614243
[2025-03-22 21:54:57,899][model][INFO] - Training step 44880 loss 0.07512898743152618
[2025-03-22 21:56:20,113][model][INFO] - Training step 45040 loss 0.03051947057247162
[2025-03-22 21:57:37,539][model][INFO] - Training step 45200 loss 0.013531556352972984
[2025-03-22 21:58:55,022][model][INFO] - Training step 45360 loss 0.07917408645153046
[2025-03-22 22:00:15,751][model][INFO] - Training step 45520 loss 0.03019225224852562
[2025-03-22 22:01:38,526][model][INFO] - Training step 45680 loss 0.011494521051645279
[2025-03-22 22:02:57,214][model][INFO] - Training step 45840 loss 0.2656397819519043
[2025-03-22 22:04:12,508][model][INFO] - Training step 46000 loss 0.04432300478219986
[2025-03-22 22:05:33,488][model][INFO] - Training step 46160 loss 0.03647018224000931
[2025-03-22 22:06:53,471][model][INFO] - Training step 46320 loss 0.02281331457197666
[2025-03-22 22:08:09,702][model][INFO] - Training step 46480 loss 0.24949994683265686
[2025-03-22 22:09:30,109][model][INFO] - Training step 46640 loss 0.007491378113627434
[2025-03-22 22:10:50,463][model][INFO] - Training step 46800 loss 0.03363332897424698
[2025-03-22 22:12:10,350][model][INFO] - Training step 46960 loss 0.07551434636116028
[2025-03-22 22:13:27,180][model][INFO] - Training step 47120 loss 0.26593828201293945
[2025-03-22 22:14:45,018][model][INFO] - Training step 47280 loss 0.0050155241042375565
[2025-03-22 22:16:03,206][model][INFO] - Training step 47440 loss 0.0501953661441803
[2025-03-22 22:17:22,984][model][INFO] - Training step 47600 loss 0.24780185520648956
[2025-03-22 22:18:44,064][model][INFO] - Training step 47760 loss 0.03861977905035019
[2025-03-22 22:20:04,929][model][INFO] - Training step 47920 loss 0.033216603100299835
[2025-03-22 22:21:25,309][model][INFO] - Training step 48080 loss 0.05927076190710068
[2025-03-22 22:22:41,718][model][INFO] - Training step 48240 loss 0.03791879862546921
[2025-03-22 22:24:00,290][model][INFO] - Training step 48400 loss 0.03957702964544296
[2025-03-22 22:25:18,109][model][INFO] - Training step 48560 loss 0.005502498708665371
[2025-03-22 22:26:39,775][model][INFO] - Training step 48720 loss 0.04469657689332962
[2025-03-22 22:27:58,329][model][INFO] - Training step 48880 loss 0.004223976284265518
[2025-03-22 22:29:16,540][model][INFO] - Training step 49040 loss 0.24441364407539368
[2025-03-22 22:30:41,071][model][INFO] - Training step 49200 loss 0.017959918826818466
[2025-03-22 22:32:00,996][model][INFO] - Training step 49360 loss 0.02890157327055931
[2025-03-22 22:33:17,979][model][INFO] - Training step 49520 loss 0.03655937686562538
[2025-03-22 22:34:35,784][model][INFO] - Training step 49680 loss 0.03488403931260109
[2025-03-22 22:35:54,939][model][INFO] - Training step 49840 loss 0.2844395935535431
[2025-03-22 22:37:13,975][model][INFO] - Training step 50000 loss 0.11248122155666351
[2025-03-22 22:38:33,349][model][INFO] - Training step 50160 loss 0.029883306473493576
[2025-03-22 22:39:51,170][model][INFO] - Training step 50320 loss 0.024004187434911728
[2025-03-22 22:41:08,420][model][INFO] - Training step 50480 loss 0.039518699049949646
[2025-03-22 22:42:26,816][model][INFO] - Training step 50640 loss 0.017114030197262764
[2025-03-22 22:52:01,161][model][INFO] - Training step 0 loss 0.018271589651703835
[2025-03-22 22:53:23,618][model][INFO] - Training step 160 loss 0.004752997308969498
[2025-03-22 22:54:42,747][model][INFO] - Training step 320 loss 0.039770737290382385
[2025-03-22 22:56:03,298][model][INFO] - Training step 480 loss 0.04570336639881134
[2025-03-22 22:57:19,801][model][INFO] - Training step 640 loss 0.18746642768383026
[2025-03-22 22:58:37,559][model][INFO] - Training step 800 loss 0.031595051288604736
[2025-03-22 22:59:58,030][model][INFO] - Training step 960 loss 0.24781399965286255
[2025-03-22 23:01:16,043][model][INFO] - Training step 1120 loss 0.049821145832538605
[2025-03-22 23:02:36,946][model][INFO] - Training step 1280 loss 0.2509996294975281
[2025-03-22 23:03:56,904][model][INFO] - Training step 1440 loss 0.04686186462640762
[2025-03-22 23:05:14,783][model][INFO] - Training step 1600 loss 0.06573981046676636
[2025-03-22 23:06:34,814][model][INFO] - Training step 1760 loss 0.032589223235845566
[2025-03-22 23:07:53,764][model][INFO] - Training step 1920 loss 0.01957884058356285
[2025-03-22 23:09:12,948][model][INFO] - Training step 2080 loss 0.026552697643637657
[2025-03-22 23:10:35,246][model][INFO] - Training step 2240 loss 0.0789087563753128
[2025-03-22 23:11:54,373][model][INFO] - Training step 2400 loss 0.01744607649743557
[2025-03-22 23:13:15,540][model][INFO] - Training step 2560 loss 0.053451161831617355
[2025-03-22 23:14:33,712][model][INFO] - Training step 2720 loss 0.020308539271354675
[2025-03-22 23:15:50,383][model][INFO] - Training step 2880 loss 0.010304221883416176
[2025-03-22 23:17:12,786][model][INFO] - Training step 3040 loss 0.147365540266037
[2025-03-22 23:18:33,774][model][INFO] - Training step 3200 loss 0.09974309802055359
[2025-03-22 23:19:52,104][model][INFO] - Training step 3360 loss 0.008392066694796085
[2025-03-22 23:21:09,890][model][INFO] - Training step 3520 loss 0.15577110648155212
[2025-03-22 23:22:29,621][model][INFO] - Training step 3680 loss 0.24606233835220337
[2025-03-22 23:23:47,788][model][INFO] - Training step 3840 loss 0.2299540638923645
[2025-03-22 23:25:07,834][model][INFO] - Training step 4000 loss 0.25843340158462524
[2025-03-22 23:26:28,305][model][INFO] - Training step 4160 loss 0.256955087184906
[2025-03-22 23:27:47,193][model][INFO] - Training step 4320 loss 0.25539731979370117
[2025-03-22 23:29:04,722][model][INFO] - Training step 4480 loss 0.030350608751177788
[2025-03-22 23:30:24,764][model][INFO] - Training step 4640 loss 0.03386449068784714
[2025-03-22 23:31:42,991][model][INFO] - Training step 4800 loss 0.031674016267061234
[2025-03-22 23:32:59,387][model][INFO] - Training step 4960 loss 0.003285636892542243
[2025-03-22 23:34:19,626][model][INFO] - Training step 5120 loss 0.07759127020835876
[2025-03-22 23:35:40,487][model][INFO] - Training step 5280 loss 0.22219206392765045
[2025-03-22 23:36:58,138][model][INFO] - Training step 5440 loss 0.0455603301525116
[2025-03-22 23:38:17,399][model][INFO] - Training step 5600 loss 0.009452502243220806
[2025-03-22 23:39:37,594][model][INFO] - Training step 5760 loss 0.008943493478000164
[2025-03-22 23:40:56,692][model][INFO] - Training step 5920 loss 0.0228114053606987
[2025-03-22 23:42:14,472][model][INFO] - Training step 6080 loss 0.256012499332428
[2025-03-22 23:43:31,200][model][INFO] - Training step 6240 loss 0.005462830886244774
[2025-03-22 23:44:54,052][model][INFO] - Training step 6400 loss 0.2532910108566284
[2025-03-22 23:46:12,855][model][INFO] - Training step 6560 loss 0.028059912845492363
[2025-03-22 23:47:36,618][model][INFO] - Training step 6720 loss 0.2933414578437805
[2025-03-22 23:48:55,744][model][INFO] - Training step 6880 loss 0.04875580593943596
[2025-03-22 23:50:16,331][model][INFO] - Training step 7040 loss 0.011482493951916695
[2025-03-22 23:51:36,572][model][INFO] - Training step 7200 loss 0.0029145823791623116
[2025-03-22 23:52:58,198][model][INFO] - Training step 7360 loss 0.05323077365756035
[2025-03-22 23:54:15,964][model][INFO] - Training step 7520 loss 0.04148278012871742
[2025-03-22 23:55:35,027][model][INFO] - Training step 7680 loss 0.028024183586239815
[2025-03-22 23:56:53,947][model][INFO] - Training step 7840 loss 0.0344298779964447
[2025-03-22 23:58:14,237][model][INFO] - Training step 8000 loss 0.004000201355665922
[2025-03-22 23:59:34,523][model][INFO] - Training step 8160 loss 0.039771780371665955
[2025-03-23 00:00:53,831][model][INFO] - Training step 8320 loss 0.23697085678577423
[2025-03-23 00:02:12,488][model][INFO] - Training step 8480 loss 0.07136572897434235
[2025-03-23 00:03:32,966][model][INFO] - Training step 8640 loss 0.017459608614444733
[2025-03-23 00:04:51,935][model][INFO] - Training step 8800 loss 0.25305914878845215
[2025-03-23 00:06:09,917][model][INFO] - Training step 8960 loss 0.6486670970916748
[2025-03-23 00:07:28,761][model][INFO] - Training step 9120 loss 0.03197420388460159
[2025-03-23 00:08:46,788][model][INFO] - Training step 9280 loss 0.2495424747467041
[2025-03-23 00:10:05,316][model][INFO] - Training step 9440 loss 0.2423689067363739
[2025-03-23 00:11:24,818][model][INFO] - Training step 9600 loss 0.035536207258701324
[2025-03-23 00:12:46,064][model][INFO] - Training step 9760 loss 0.018898529931902885
[2025-03-23 00:14:05,786][model][INFO] - Training step 9920 loss 0.022503584623336792
[2025-03-23 00:15:27,500][model][INFO] - Training step 10080 loss 0.0034411849919706583
[2025-03-23 00:16:44,958][model][INFO] - Training step 10240 loss 0.01533181220293045
[2025-03-23 00:18:03,198][model][INFO] - Training step 10400 loss 0.03636433929204941
[2025-03-23 00:19:19,644][model][INFO] - Training step 10560 loss 0.23719385266304016
[2025-03-23 00:20:37,471][model][INFO] - Training step 10720 loss 0.056579411029815674
[2025-03-23 00:21:57,279][model][INFO] - Training step 10880 loss 0.25598394870758057
[2025-03-23 00:23:13,742][model][INFO] - Training step 11040 loss 0.03275119513273239
[2025-03-23 00:24:31,874][model][INFO] - Training step 11200 loss 0.03996984660625458
[2025-03-23 00:25:51,308][model][INFO] - Training step 11360 loss 0.02529880404472351
[2025-03-23 00:27:07,143][model][INFO] - Training step 11520 loss 0.007231440395116806
[2025-03-23 00:28:26,730][model][INFO] - Training step 11680 loss 0.0048774247989058495
[2025-03-23 00:29:43,479][model][INFO] - Training step 11840 loss 0.024886388331651688
[2025-03-23 00:30:58,990][model][INFO] - Training step 12000 loss 0.04135614633560181
[2025-03-23 00:32:19,172][model][INFO] - Training step 12160 loss 0.033024862408638
[2025-03-23 00:33:35,487][model][INFO] - Training step 12320 loss 0.24852105975151062
[2025-03-23 00:34:56,806][model][INFO] - Training step 12480 loss 0.2515781819820404
[2025-03-23 00:36:16,527][model][INFO] - Training step 12640 loss 0.026265420019626617
[2025-03-23 00:37:36,291][model][INFO] - Training step 12800 loss 0.0017901200335472822
[2025-03-23 00:38:55,750][model][INFO] - Training step 12960 loss 0.016139190644025803
[2025-03-23 00:40:18,275][model][INFO] - Training step 13120 loss 0.25429388880729675
[2025-03-23 00:41:36,083][model][INFO] - Training step 13280 loss 0.0111470315605402
[2025-03-23 00:42:52,819][model][INFO] - Training step 13440 loss 0.049097105860710144
[2025-03-23 00:44:13,728][model][INFO] - Training step 13600 loss 0.024517381563782692
[2025-03-23 00:45:33,431][model][INFO] - Training step 13760 loss 0.02815314196050167
[2025-03-23 00:46:52,908][model][INFO] - Training step 13920 loss 0.05643713101744652
[2025-03-23 00:48:11,327][model][INFO] - Training step 14080 loss 0.004291104152798653
[2025-03-23 00:49:28,998][model][INFO] - Training step 14240 loss 0.2180611789226532
[2025-03-23 00:50:48,887][model][INFO] - Training step 14400 loss 0.016993720084428787
[2025-03-23 00:52:09,262][model][INFO] - Training step 14560 loss 0.026618897914886475
[2025-03-23 00:53:31,237][model][INFO] - Training step 14720 loss 0.0341576412320137
[2025-03-23 00:54:47,595][model][INFO] - Training step 14880 loss 0.03151295334100723
[2025-03-23 00:56:07,223][model][INFO] - Training step 15040 loss 0.33841297030448914
[2025-03-23 00:57:29,104][model][INFO] - Training step 15200 loss 0.06537593901157379
[2025-03-23 00:58:48,090][model][INFO] - Training step 15360 loss 0.009317276999354362
[2025-03-23 01:00:07,798][model][INFO] - Training step 15520 loss 0.015526274219155312
[2025-03-23 01:01:26,228][model][INFO] - Training step 15680 loss 0.029518764466047287
[2025-03-23 01:02:48,229][model][INFO] - Training step 15840 loss 0.10371998697519302
[2025-03-23 01:04:08,623][model][INFO] - Training step 16000 loss 0.035362452268600464
[2025-03-23 01:05:26,778][model][INFO] - Training step 16160 loss 0.017354585230350494
[2025-03-23 01:06:45,302][model][INFO] - Training step 16320 loss 0.027300208806991577
[2025-03-23 01:08:03,076][model][INFO] - Training step 16480 loss 0.04751328006386757
[2025-03-23 01:09:23,694][model][INFO] - Training step 16640 loss 0.02191154845058918
[2025-03-23 01:10:41,289][model][INFO] - Training step 16800 loss 0.2706976532936096
[2025-03-23 01:12:01,073][model][INFO] - Training step 16960 loss 0.03646101430058479
[2025-03-23 01:13:21,101][model][INFO] - Training step 17120 loss 0.06583979725837708
[2025-03-23 01:14:41,830][model][INFO] - Training step 17280 loss 0.013014263473451138
[2025-03-23 01:16:01,030][model][INFO] - Training step 17440 loss 0.004331808537244797
[2025-03-23 01:17:22,702][model][INFO] - Training step 17600 loss 0.030061278492212296
[2025-03-23 01:18:43,177][model][INFO] - Training step 17760 loss 0.03544499725103378
[2025-03-23 01:20:01,547][model][INFO] - Training step 17920 loss 0.006745979189872742
[2025-03-23 01:21:22,239][model][INFO] - Training step 18080 loss 0.026628077030181885
[2025-03-23 01:22:41,149][model][INFO] - Training step 18240 loss 0.03862323984503746
[2025-03-23 01:24:03,132][model][INFO] - Training step 18400 loss 0.05190470814704895
[2025-03-23 01:25:21,484][model][INFO] - Training step 18560 loss 0.033037684857845306
[2025-03-23 01:26:43,669][model][INFO] - Training step 18720 loss 0.03117850050330162
[2025-03-23 01:28:02,691][model][INFO] - Training step 18880 loss 0.022735049948096275
[2025-03-23 01:29:22,080][model][INFO] - Training step 19040 loss 0.03500938415527344
[2025-03-23 01:30:39,265][model][INFO] - Training step 19200 loss 0.060591086745262146
[2025-03-23 01:31:55,150][model][INFO] - Training step 19360 loss 0.03263435512781143
[2025-03-23 01:33:15,849][model][INFO] - Training step 19520 loss 0.05898010730743408
[2025-03-23 01:34:37,953][model][INFO] - Training step 19680 loss 0.03934112936258316
[2025-03-23 01:35:57,574][model][INFO] - Training step 19840 loss 0.026952028274536133
[2025-03-23 01:37:16,158][model][INFO] - Training step 20000 loss 0.06670768558979034
[2025-03-23 01:38:34,687][model][INFO] - Training step 20160 loss 0.031246762722730637
[2025-03-23 01:39:52,460][model][INFO] - Training step 20320 loss 0.038022637367248535
[2025-03-23 01:41:09,311][model][INFO] - Training step 20480 loss 0.03385248780250549
[2025-03-23 01:42:28,100][model][INFO] - Training step 20640 loss 0.029807481914758682
[2025-03-23 01:43:47,233][model][INFO] - Training step 20800 loss 0.03276059776544571
[2025-03-23 01:45:07,794][model][INFO] - Training step 20960 loss 0.0044427718967199326
[2025-03-23 01:46:29,444][model][INFO] - Training step 21120 loss 0.016621900722384453
[2025-03-23 01:47:49,178][model][INFO] - Training step 21280 loss 0.0220674816519022
[2025-03-23 01:49:07,044][model][INFO] - Training step 21440 loss 0.021871790289878845
[2025-03-23 01:50:30,323][model][INFO] - Training step 21600 loss 0.049796029925346375
[2025-03-23 01:51:50,752][model][INFO] - Training step 21760 loss 0.0311896875500679
[2025-03-23 01:53:07,289][model][INFO] - Training step 21920 loss 0.020475046709179878
[2025-03-23 01:54:25,649][model][INFO] - Training step 22080 loss 0.07056066393852234
[2025-03-23 01:55:46,449][model][INFO] - Training step 22240 loss 0.031072141602635384
[2025-03-23 01:57:06,459][model][INFO] - Training step 22400 loss 0.029162589460611343
[2025-03-23 01:58:27,253][model][INFO] - Training step 22560 loss 0.20999787747859955
[2025-03-23 01:59:46,411][model][INFO] - Training step 22720 loss 0.028353296220302582
[2025-03-23 02:01:03,434][model][INFO] - Training step 22880 loss 0.03242689371109009
[2025-03-23 02:02:22,244][model][INFO] - Training step 23040 loss 0.09790822863578796
[2025-03-23 02:03:42,532][model][INFO] - Training step 23200 loss 0.11731639504432678
[2025-03-23 02:05:02,756][model][INFO] - Training step 23360 loss 0.03224952891469002
[2025-03-23 02:06:21,690][model][INFO] - Training step 23520 loss 0.02268236130475998
[2025-03-23 02:07:38,271][model][INFO] - Training step 23680 loss 0.05643512308597565
[2025-03-23 02:08:57,631][model][INFO] - Training step 23840 loss 0.028505824506282806
[2025-03-23 02:10:15,481][model][INFO] - Training step 24000 loss 0.05151946842670441
[2025-03-23 02:11:32,297][model][INFO] - Training step 24160 loss 0.012339171022176743
[2025-03-23 02:12:52,292][model][INFO] - Training step 24320 loss 0.06669984757900238
[2025-03-23 02:14:12,406][model][INFO] - Training step 24480 loss 0.06508826464414597
[2025-03-23 02:15:31,018][model][INFO] - Training step 24640 loss 0.05714266002178192
[2025-03-23 02:16:48,899][model][INFO] - Training step 24800 loss 0.1540890336036682
[2025-03-23 02:18:08,116][model][INFO] - Training step 24960 loss 0.2661575675010681
[2025-03-23 02:19:29,275][model][INFO] - Training step 25120 loss 0.05829720199108124
[2025-03-23 02:20:47,567][model][INFO] - Training step 25280 loss 0.01661677286028862
[2025-03-23 02:22:04,408][model][INFO] - Training step 25440 loss 0.01786518469452858
[2025-03-23 02:23:22,718][model][INFO] - Training step 25600 loss 0.30483126640319824
[2025-03-23 02:24:39,771][model][INFO] - Training step 25760 loss 0.04571868106722832
[2025-03-23 02:26:01,466][model][INFO] - Training step 25920 loss 0.2171117067337036
[2025-03-23 02:27:19,565][model][INFO] - Training step 26080 loss 0.04732314497232437
[2025-03-23 02:28:38,166][model][INFO] - Training step 26240 loss 0.05068156123161316
[2025-03-23 02:29:56,282][model][INFO] - Training step 26400 loss 0.0845661461353302
[2025-03-23 02:31:16,725][model][INFO] - Training step 26560 loss 0.14359629154205322
[2025-03-23 02:32:36,414][model][INFO] - Training step 26720 loss 0.019040070474147797
[2025-03-23 02:33:56,362][model][INFO] - Training step 26880 loss 0.0067234039306640625
[2025-03-23 02:35:12,689][model][INFO] - Training step 27040 loss 0.2599167227745056
[2025-03-23 02:36:32,674][model][INFO] - Training step 27200 loss 0.2524590492248535
[2025-03-23 02:37:54,409][model][INFO] - Training step 27360 loss 0.031069032847881317
[2025-03-23 02:39:10,776][model][INFO] - Training step 27520 loss 0.07380993664264679
[2025-03-23 02:40:31,246][model][INFO] - Training step 27680 loss 0.1269303560256958
[2025-03-23 02:41:52,104][model][INFO] - Training step 27840 loss 0.04391701519489288
[2025-03-23 02:43:11,187][model][INFO] - Training step 28000 loss 0.004155621863901615
[2025-03-23 02:44:30,485][model][INFO] - Training step 28160 loss 0.043305858969688416
[2025-03-23 02:45:52,283][model][INFO] - Training step 28320 loss 0.026076145470142365
[2025-03-23 02:47:10,939][model][INFO] - Training step 28480 loss 0.07822345197200775
[2025-03-23 02:48:31,194][model][INFO] - Training step 28640 loss 0.05340436100959778
[2025-03-23 02:49:50,860][model][INFO] - Training step 28800 loss 0.10958297550678253
[2025-03-23 02:51:12,330][model][INFO] - Training step 28960 loss 0.003761819563806057
[2025-03-23 02:52:29,859][model][INFO] - Training step 29120 loss 0.08900099992752075
[2025-03-23 02:53:51,637][model][INFO] - Training step 29280 loss 0.03760584816336632
[2025-03-23 02:55:11,396][model][INFO] - Training step 29440 loss 0.31348830461502075
[2025-03-23 02:56:29,066][model][INFO] - Training step 29600 loss 0.10519534349441528
[2025-03-23 02:57:47,691][model][INFO] - Training step 29760 loss 0.24991026520729065
[2025-03-23 02:59:05,451][model][INFO] - Training step 29920 loss 0.187712162733078
[2025-03-23 03:00:25,940][model][INFO] - Training step 30080 loss 0.01673968881368637
[2025-03-23 03:01:43,574][model][INFO] - Training step 30240 loss 0.03233813866972923
[2025-03-23 03:03:02,418][model][INFO] - Training step 30400 loss 0.037183985114097595
[2025-03-23 03:04:22,486][model][INFO] - Training step 30560 loss 0.1830049753189087
[2025-03-23 03:05:38,223][model][INFO] - Training step 30720 loss 0.015279984101653099
[2025-03-23 03:06:54,331][model][INFO] - Training step 30880 loss 0.022676989436149597
[2025-03-23 03:08:13,708][model][INFO] - Training step 31040 loss 0.023534346371889114
[2025-03-23 03:09:31,985][model][INFO] - Training step 31200 loss 0.05866662412881851
[2025-03-23 03:10:52,131][model][INFO] - Training step 31360 loss 0.025424188002943993
[2025-03-23 03:12:12,740][model][INFO] - Training step 31520 loss 0.0650409609079361
[2025-03-23 03:13:34,383][model][INFO] - Training step 31680 loss 0.25927767157554626
[2025-03-23 03:14:52,666][model][INFO] - Training step 31840 loss 0.006419703830033541
[2025-03-23 03:16:11,702][model][INFO] - Training step 32000 loss 0.03171171247959137
[2025-03-23 03:17:30,741][model][INFO] - Training step 32160 loss 0.0742049515247345
[2025-03-23 03:18:52,477][model][INFO] - Training step 32320 loss 0.01865299418568611
[2025-03-23 03:20:12,007][model][INFO] - Training step 32480 loss 0.06494991481304169
[2025-03-23 03:21:30,447][model][INFO] - Training step 32640 loss 0.033023297786712646
[2025-03-23 03:22:50,812][model][INFO] - Training step 32800 loss 0.2487812042236328
[2025-03-23 03:24:12,846][model][INFO] - Training step 32960 loss 0.025789909064769745
[2025-03-23 03:25:30,940][model][INFO] - Training step 33120 loss 0.03158719465136528
[2025-03-23 03:26:48,394][model][INFO] - Training step 33280 loss 0.06561674177646637
[2025-03-23 03:28:06,283][model][INFO] - Training step 33440 loss 0.027618248015642166
[2025-03-23 03:29:25,054][model][INFO] - Training step 33600 loss 0.033095963299274445
[2025-03-23 03:30:45,237][model][INFO] - Training step 33760 loss 0.18519480526447296
[2025-03-23 03:32:04,677][model][INFO] - Training step 33920 loss 0.25355982780456543
[2025-03-23 03:33:24,200][model][INFO] - Training step 34080 loss 0.07550742477178574
[2025-03-23 03:34:47,271][model][INFO] - Training step 34240 loss 0.04981263726949692
[2025-03-23 03:36:07,606][model][INFO] - Training step 34400 loss 0.007191908545792103
[2025-03-23 03:37:27,622][model][INFO] - Training step 34560 loss 0.107367604970932
[2025-03-23 03:38:47,614][model][INFO] - Training step 34720 loss 0.036943696439266205
[2025-03-23 03:40:06,507][model][INFO] - Training step 34880 loss 0.02057645097374916
[2025-03-23 03:41:28,308][model][INFO] - Training step 35040 loss 0.24367880821228027
[2025-03-23 03:42:45,186][model][INFO] - Training step 35200 loss 0.2582414448261261
[2025-03-23 03:44:05,777][model][INFO] - Training step 35360 loss 0.02236340194940567
[2025-03-23 03:45:24,608][model][INFO] - Training step 35520 loss 0.046262044459581375
[2025-03-23 03:46:42,076][model][INFO] - Training step 35680 loss 0.02008884772658348
[2025-03-23 03:47:58,785][model][INFO] - Training step 35840 loss 0.03052499331533909
[2025-03-23 03:49:17,833][model][INFO] - Training step 36000 loss 0.07620662450790405
[2025-03-23 03:50:36,075][model][INFO] - Training step 36160 loss 0.03435928001999855
[2025-03-23 03:51:55,353][model][INFO] - Training step 36320 loss 0.11832626163959503
[2025-03-23 03:53:13,889][model][INFO] - Training step 36480 loss 0.0450749509036541
[2025-03-23 03:54:34,074][model][INFO] - Training step 36640 loss 0.02569170668721199
[2025-03-23 03:55:55,907][model][INFO] - Training step 36800 loss 0.04537715017795563
[2025-03-23 03:57:14,696][model][INFO] - Training step 36960 loss 0.019111769273877144
[2025-03-23 03:58:35,162][model][INFO] - Training step 37120 loss 0.005081196315586567
[2025-03-23 03:59:53,236][model][INFO] - Training step 37280 loss 0.24729017913341522
[2025-03-23 04:01:12,354][model][INFO] - Training step 37440 loss 0.06539295613765717
[2025-03-23 04:02:28,293][model][INFO] - Training step 37600 loss 0.026387035846710205
[2025-03-23 04:03:46,262][model][INFO] - Training step 37760 loss 0.06011117249727249
[2025-03-23 04:05:07,133][model][INFO] - Training step 37920 loss 0.006904833018779755
[2025-03-23 04:06:25,745][model][INFO] - Training step 38080 loss 0.0754612386226654
[2025-03-23 04:07:45,527][model][INFO] - Training step 38240 loss 0.0058573102578520775
[2025-03-23 04:09:04,975][model][INFO] - Training step 38400 loss 0.05705346167087555
[2025-03-23 04:10:24,579][model][INFO] - Training step 38560 loss 0.024206312373280525
[2025-03-23 04:11:44,574][model][INFO] - Training step 38720 loss 0.03863242268562317
[2025-03-23 04:13:05,989][model][INFO] - Training step 38880 loss 0.030728021636605263
[2025-03-23 04:14:26,773][model][INFO] - Training step 39040 loss 0.008963041007518768
[2025-03-23 04:15:45,001][model][INFO] - Training step 39200 loss 0.03523700684309006
[2025-03-23 04:17:04,862][model][INFO] - Training step 39360 loss 0.26636266708374023
[2025-03-23 04:18:25,477][model][INFO] - Training step 39520 loss 0.026825981214642525
[2025-03-23 04:19:43,505][model][INFO] - Training step 39680 loss 0.017143025994300842
[2025-03-23 04:21:03,346][model][INFO] - Training step 39840 loss 0.029909256845712662
[2025-03-23 04:22:23,951][model][INFO] - Training step 40000 loss 0.026359109207987785
[2025-03-23 04:23:45,844][model][INFO] - Training step 40160 loss 0.03758595883846283
[2025-03-23 04:25:07,071][model][INFO] - Training step 40320 loss 0.02517598122358322
[2025-03-23 04:26:26,860][model][INFO] - Training step 40480 loss 0.049254268407821655
[2025-03-23 04:27:49,421][model][INFO] - Training step 40640 loss 0.004945723805576563
[2025-03-23 04:29:08,576][model][INFO] - Training step 40800 loss 0.0047374628484249115
[2025-03-23 04:30:27,062][model][INFO] - Training step 40960 loss 0.036986734718084335
[2025-03-23 04:31:47,483][model][INFO] - Training step 41120 loss 0.010224887169897556
[2025-03-23 04:33:08,503][model][INFO] - Training step 41280 loss 0.02767699584364891
[2025-03-23 04:34:27,327][model][INFO] - Training step 41440 loss 0.11085377633571625
[2025-03-23 04:35:45,839][model][INFO] - Training step 41600 loss 0.031528864055871964
[2025-03-23 04:37:08,501][model][INFO] - Training step 41760 loss 0.017217734828591347
[2025-03-23 04:38:27,324][model][INFO] - Training step 41920 loss 0.022531772032380104
[2025-03-23 04:39:45,841][model][INFO] - Training step 42080 loss 0.24237613379955292
[2025-03-23 04:41:05,120][model][INFO] - Training step 42240 loss 0.003775285091251135
[2025-03-23 04:42:22,902][model][INFO] - Training step 42400 loss 0.016238156706094742
[2025-03-23 04:43:42,771][model][INFO] - Training step 42560 loss 0.011618558317422867
[2025-03-23 04:45:03,446][model][INFO] - Training step 42720 loss 0.0155907291918993
[2025-03-23 04:46:20,517][model][INFO] - Training step 42880 loss 0.17236602306365967
[2025-03-23 04:47:40,246][model][INFO] - Training step 43040 loss 0.025940705090761185
[2025-03-23 04:49:00,042][model][INFO] - Training step 43200 loss 0.030799012631177902
[2025-03-23 04:50:18,657][model][INFO] - Training step 43360 loss 0.052480682730674744
[2025-03-23 04:51:38,428][model][INFO] - Training step 43520 loss 0.02231149934232235
[2025-03-23 04:52:58,129][model][INFO] - Training step 43680 loss 0.2555404305458069
[2025-03-23 04:54:21,052][model][INFO] - Training step 43840 loss 0.027473919093608856
[2025-03-23 04:55:41,101][model][INFO] - Training step 44000 loss 0.2518411874771118
[2025-03-23 04:57:02,707][model][INFO] - Training step 44160 loss 0.014419080689549446
[2025-03-23 04:58:25,176][model][INFO] - Training step 44320 loss 0.017430249601602554
[2025-03-23 04:59:46,000][model][INFO] - Training step 44480 loss 0.01080833375453949
[2025-03-23 05:01:03,199][model][INFO] - Training step 44640 loss 0.02619830146431923
[2025-03-23 05:02:26,077][model][INFO] - Training step 44800 loss 0.019919713959097862
[2025-03-23 05:03:44,582][model][INFO] - Training step 44960 loss 0.05861467868089676
[2025-03-23 05:05:01,964][model][INFO] - Training step 45120 loss 0.24181504547595978
[2025-03-23 05:06:18,578][model][INFO] - Training step 45280 loss 0.020747676491737366
[2025-03-23 05:07:38,654][model][INFO] - Training step 45440 loss 0.016299646347761154
[2025-03-23 05:08:58,051][model][INFO] - Training step 45600 loss 0.030284106731414795
[2025-03-23 05:10:18,336][model][INFO] - Training step 45760 loss 0.032138679176568985
[2025-03-23 05:11:38,652][model][INFO] - Training step 45920 loss 0.0036292579025030136
[2025-03-23 05:12:57,275][model][INFO] - Training step 46080 loss 0.027731450274586678
[2025-03-23 05:14:18,339][model][INFO] - Training step 46240 loss 0.25438928604125977
[2025-03-23 05:15:39,602][model][INFO] - Training step 46400 loss 0.01101270318031311
[2025-03-23 05:16:56,222][model][INFO] - Training step 46560 loss 0.24894696474075317
[2025-03-23 05:18:14,469][model][INFO] - Training step 46720 loss 0.03155359625816345
[2025-03-23 05:19:33,126][model][INFO] - Training step 46880 loss 0.03266804665327072
[2025-03-23 05:20:53,630][model][INFO] - Training step 47040 loss 0.2593227028846741
[2025-03-23 05:22:11,559][model][INFO] - Training step 47200 loss 0.006738306954503059
[2025-03-23 05:23:31,145][model][INFO] - Training step 47360 loss 0.033128008246421814
[2025-03-23 05:24:53,104][model][INFO] - Training step 47520 loss 0.016953377053141594
[2025-03-23 05:26:13,802][model][INFO] - Training step 47680 loss 0.03697340935468674
[2025-03-23 05:27:31,755][model][INFO] - Training step 47840 loss 0.0752018466591835
[2025-03-23 05:28:52,045][model][INFO] - Training step 48000 loss 0.04736291617155075
[2025-03-23 05:30:13,120][model][INFO] - Training step 48160 loss 0.026477359235286713
[2025-03-23 05:31:32,005][model][INFO] - Training step 48320 loss 0.024137895554304123
[2025-03-23 05:32:46,944][model][INFO] - Training step 48480 loss 0.25331175327301025
[2025-03-23 05:34:05,398][model][INFO] - Training step 48640 loss 0.023457493633031845
[2025-03-23 05:35:26,091][model][INFO] - Training step 48800 loss 0.1632533073425293
[2025-03-23 05:36:45,375][model][INFO] - Training step 48960 loss 0.015739932656288147
[2025-03-23 05:38:06,092][model][INFO] - Training step 49120 loss 0.01902463473379612
[2025-03-23 05:39:27,587][model][INFO] - Training step 49280 loss 0.024311019107699394
[2025-03-23 05:40:45,042][model][INFO] - Training step 49440 loss 0.02383248321712017
[2025-03-23 05:42:04,516][model][INFO] - Training step 49600 loss 0.02879391610622406
[2025-03-23 05:43:25,327][model][INFO] - Training step 49760 loss 0.04530366510152817
[2025-03-23 05:44:44,525][model][INFO] - Training step 49920 loss 0.021042848005890846
[2025-03-23 05:46:01,851][model][INFO] - Training step 50080 loss 0.020890988409519196
[2025-03-23 05:47:21,033][model][INFO] - Training step 50240 loss 0.018660366535186768
[2025-03-23 05:48:37,453][model][INFO] - Training step 50400 loss 0.02470356598496437
[2025-03-23 05:49:55,840][model][INFO] - Training step 50560 loss 0.019967440515756607
[2025-03-23 05:51:11,773][model][INFO] - Training step 50720 loss 0.038951434195041656
[2025-03-23 06:00:44,716][model][INFO] - Training step 80 loss 0.04344195872545242
[2025-03-23 06:02:04,668][model][INFO] - Training step 240 loss 0.2473665177822113
[2025-03-23 06:03:23,387][model][INFO] - Training step 400 loss 0.004029623232781887
[2025-03-23 06:04:42,716][model][INFO] - Training step 560 loss 0.027156006544828415
[2025-03-23 06:06:00,686][model][INFO] - Training step 720 loss 0.10617299377918243
[2025-03-23 06:07:19,929][model][INFO] - Training step 880 loss 0.026660697534680367
[2025-03-23 06:08:39,669][model][INFO] - Training step 1040 loss 0.036023739725351334
[2025-03-23 06:10:01,195][model][INFO] - Training step 1200 loss 0.12027890235185623
[2025-03-23 06:11:22,458][model][INFO] - Training step 1360 loss 0.03996853902935982
[2025-03-23 06:12:39,322][model][INFO] - Training step 1520 loss 0.03512640297412872
[2025-03-23 06:13:57,571][model][INFO] - Training step 1680 loss 0.2571779489517212
[2025-03-23 06:15:15,445][model][INFO] - Training step 1840 loss 0.20215219259262085
[2025-03-23 06:16:34,395][model][INFO] - Training step 2000 loss 0.2090943455696106
[2025-03-23 06:17:52,823][model][INFO] - Training step 2160 loss 0.2384500950574875
[2025-03-23 06:19:10,106][model][INFO] - Training step 2320 loss 0.01931445114314556
[2025-03-23 06:20:28,110][model][INFO] - Training step 2480 loss 0.005266024265438318
[2025-03-23 06:21:46,809][model][INFO] - Training step 2640 loss 0.02106548845767975
[2025-03-23 06:23:05,931][model][INFO] - Training step 2800 loss 0.25253182649612427
[2025-03-23 06:24:24,393][model][INFO] - Training step 2960 loss 0.252108633518219
[2025-03-23 06:25:44,242][model][INFO] - Training step 3120 loss 0.06048716604709625
[2025-03-23 06:27:01,894][model][INFO] - Training step 3280 loss 0.03141648694872856
[2025-03-23 06:28:21,590][model][INFO] - Training step 3440 loss 0.24286654591560364
[2025-03-23 06:29:39,860][model][INFO] - Training step 3600 loss 0.2468562126159668
[2025-03-23 06:30:59,678][model][INFO] - Training step 3760 loss 0.01907024346292019
[2025-03-23 06:32:22,082][model][INFO] - Training step 3920 loss 0.027019837871193886
[2025-03-23 06:33:41,246][model][INFO] - Training step 4080 loss 0.12173430621623993
[2025-03-23 06:34:59,414][model][INFO] - Training step 4240 loss 0.033118948340415955
[2025-03-23 06:36:18,615][model][INFO] - Training step 4400 loss 0.009059170261025429
[2025-03-23 06:37:37,989][model][INFO] - Training step 4560 loss 0.035243451595306396
[2025-03-23 06:38:59,105][model][INFO] - Training step 4720 loss 0.02319495752453804
[2025-03-23 06:40:16,224][model][INFO] - Training step 4880 loss 0.013017049059271812
[2025-03-23 06:41:32,373][model][INFO] - Training step 5040 loss 0.032682113349437714
[2025-03-23 06:42:54,375][model][INFO] - Training step 5200 loss 0.07875686883926392
[2025-03-23 06:44:15,448][model][INFO] - Training step 5360 loss 0.006455224938690662
[2025-03-23 06:45:35,946][model][INFO] - Training step 5520 loss 0.07282672077417374
[2025-03-23 06:46:55,690][model][INFO] - Training step 5680 loss 0.015962228178977966
[2025-03-23 06:48:14,961][model][INFO] - Training step 5840 loss 0.2522578835487366
[2025-03-23 06:49:36,634][model][INFO] - Training step 6000 loss 0.013370133005082607
[2025-03-23 06:50:57,833][model][INFO] - Training step 6160 loss 0.020301420241594315
[2025-03-23 06:52:21,163][model][INFO] - Training step 6320 loss 0.04483318701386452
[2025-03-23 06:53:43,284][model][INFO] - Training step 6480 loss 0.19405803084373474
[2025-03-23 06:55:03,083][model][INFO] - Training step 6640 loss 0.10193042457103729
[2025-03-23 06:56:20,978][model][INFO] - Training step 6800 loss 0.005717356223613024
[2025-03-23 06:57:41,194][model][INFO] - Training step 6960 loss 0.028679970651865005
[2025-03-23 06:59:01,670][model][INFO] - Training step 7120 loss 0.0717800110578537
[2025-03-23 07:00:22,907][model][INFO] - Training step 7280 loss 0.013810505159199238
[2025-03-23 07:01:38,475][model][INFO] - Training step 7440 loss 0.016469137743115425
[2025-03-23 07:02:57,780][model][INFO] - Training step 7600 loss 0.032187189906835556
[2025-03-23 07:04:17,369][model][INFO] - Training step 7760 loss 0.03726871311664581
[2025-03-23 07:05:36,829][model][INFO] - Training step 7920 loss 0.04391494393348694
[2025-03-23 07:06:56,159][model][INFO] - Training step 8080 loss 0.02537369914352894
[2025-03-23 07:08:14,746][model][INFO] - Training step 8240 loss 0.25369691848754883
[2025-03-23 07:09:31,684][model][INFO] - Training step 8400 loss 0.06261368095874786
[2025-03-23 07:10:50,119][model][INFO] - Training step 8560 loss 0.07854864001274109
[2025-03-23 07:12:07,903][model][INFO] - Training step 8720 loss 0.026819493621587753
[2025-03-23 07:13:28,431][model][INFO] - Training step 8880 loss 0.04033336788415909
[2025-03-23 07:14:45,346][model][INFO] - Training step 9040 loss 0.2519422471523285
[2025-03-23 07:16:03,049][model][INFO] - Training step 9200 loss 0.02488945797085762
[2025-03-23 07:17:22,161][model][INFO] - Training step 9360 loss 0.04126647114753723
[2025-03-23 07:18:40,412][model][INFO] - Training step 9520 loss 0.014396242797374725
[2025-03-23 07:19:59,789][model][INFO] - Training step 9680 loss 0.1526598185300827
[2025-03-23 07:21:19,957][model][INFO] - Training step 9840 loss 0.043028704822063446
[2025-03-23 07:22:40,660][model][INFO] - Training step 10000 loss 0.01971461996436119
[2025-03-23 07:23:59,931][model][INFO] - Training step 10160 loss 0.018430273979902267
[2025-03-23 07:25:17,566][model][INFO] - Training step 10320 loss 0.0272684246301651
[2025-03-23 07:26:39,028][model][INFO] - Training step 10480 loss 0.02501474879682064
[2025-03-23 07:28:00,721][model][INFO] - Training step 10640 loss 0.031055433675646782
[2025-03-23 07:29:16,903][model][INFO] - Training step 10800 loss 0.033832281827926636
[2025-03-23 07:30:32,935][model][INFO] - Training step 10960 loss 0.2553675174713135
[2025-03-23 07:31:51,452][model][INFO] - Training step 11120 loss 0.021070033311843872
[2025-03-23 07:33:07,355][model][INFO] - Training step 11280 loss 0.263961523771286
[2025-03-23 07:34:27,250][model][INFO] - Training step 11440 loss 0.27412861585617065
[2025-03-23 07:35:47,604][model][INFO] - Training step 11600 loss 0.013879885897040367
[2025-03-23 07:37:07,293][model][INFO] - Training step 11760 loss 0.06704171746969223
[2025-03-23 07:38:24,658][model][INFO] - Training step 11920 loss 0.06645013391971588
[2025-03-23 07:39:43,777][model][INFO] - Training step 12080 loss 0.05649736523628235
[2025-03-23 07:41:03,082][model][INFO] - Training step 12240 loss 0.2517254650592804
[2025-03-23 07:42:22,813][model][INFO] - Training step 12400 loss 0.024453910067677498
[2025-03-23 07:43:43,248][model][INFO] - Training step 12560 loss 0.00389894493855536
[2025-03-23 07:45:02,562][model][INFO] - Training step 12720 loss 0.03160581737756729
[2025-03-23 07:46:21,224][model][INFO] - Training step 12880 loss 0.22367507219314575
[2025-03-23 07:47:42,549][model][INFO] - Training step 13040 loss 0.044975489377975464
[2025-03-23 07:49:01,221][model][INFO] - Training step 13200 loss 0.11909164488315582
[2025-03-23 07:50:19,912][model][INFO] - Training step 13360 loss 0.050012942403554916
[2025-03-23 07:51:40,659][model][INFO] - Training step 13520 loss 0.06357027590274811
[2025-03-23 07:53:00,486][model][INFO] - Training step 13680 loss 0.020760733634233475
[2025-03-23 07:54:19,800][model][INFO] - Training step 13840 loss 0.023215077817440033
[2025-03-23 07:55:39,049][model][INFO] - Training step 14000 loss 0.020127447322010994
[2025-03-23 07:56:57,207][model][INFO] - Training step 14160 loss 0.25674909353256226
[2025-03-23 07:58:14,558][model][INFO] - Training step 14320 loss 0.0262399073690176
[2025-03-23 07:59:35,005][model][INFO] - Training step 14480 loss 0.06681415438652039
[2025-03-23 08:00:55,926][model][INFO] - Training step 14640 loss 0.23465566337108612
[2025-03-23 08:02:15,090][model][INFO] - Training step 14800 loss 0.0428168885409832
[2025-03-23 08:03:32,696][model][INFO] - Training step 14960 loss 0.005214851349592209
[2025-03-23 08:04:51,605][model][INFO] - Training step 15120 loss 0.025656336918473244
[2025-03-23 08:06:10,433][model][INFO] - Training step 15280 loss 0.028638632968068123
[2025-03-23 08:07:30,084][model][INFO] - Training step 15440 loss 0.03845145180821419
[2025-03-23 08:08:48,484][model][INFO] - Training step 15600 loss 0.054102517664432526
[2025-03-23 08:10:06,249][model][INFO] - Training step 15760 loss 0.04191722720861435
[2025-03-23 08:11:26,292][model][INFO] - Training step 15920 loss 0.24546615779399872
[2025-03-23 08:12:43,645][model][INFO] - Training step 16080 loss 0.248520165681839
[2025-03-23 08:14:01,774][model][INFO] - Training step 16240 loss 0.03584226965904236
[2025-03-23 08:15:17,430][model][INFO] - Training step 16400 loss 0.2610476016998291
[2025-03-23 08:16:37,775][model][INFO] - Training step 16560 loss 0.007480621803551912
[2025-03-23 08:17:55,367][model][INFO] - Training step 16720 loss 0.034306056797504425
[2025-03-23 08:19:13,838][model][INFO] - Training step 16880 loss 0.042324475944042206
[2025-03-23 08:20:34,463][model][INFO] - Training step 17040 loss 0.08032134920358658
[2025-03-23 08:21:54,310][model][INFO] - Training step 17200 loss 0.08578663319349289
[2025-03-23 08:23:13,221][model][INFO] - Training step 17360 loss 0.0013014115393161774
[2025-03-23 08:24:31,493][model][INFO] - Training step 17520 loss 0.03594455122947693
[2025-03-23 08:25:51,110][model][INFO] - Training step 17680 loss 0.043951258063316345
[2025-03-23 08:27:05,163][model][INFO] - Training step 17840 loss 0.03195100277662277
[2025-03-23 08:28:22,347][model][INFO] - Training step 18000 loss 0.035959355533123016
[2025-03-23 08:29:40,457][model][INFO] - Training step 18160 loss 0.2571451663970947
[2025-03-23 08:30:57,501][model][INFO] - Training step 18320 loss 0.030927591025829315
[2025-03-23 08:32:21,951][model][INFO] - Training step 18480 loss 0.2885788083076477
[2025-03-23 08:33:41,834][model][INFO] - Training step 18640 loss 0.041472382843494415
[2025-03-23 08:34:59,487][model][INFO] - Training step 18800 loss 0.2664521038532257
[2025-03-23 08:36:17,892][model][INFO] - Training step 18960 loss 0.03237181156873703
[2025-03-23 08:37:35,140][model][INFO] - Training step 19120 loss 0.022947033867239952
[2025-03-23 08:38:52,669][model][INFO] - Training step 19280 loss 0.04807715117931366
[2025-03-23 08:40:12,937][model][INFO] - Training step 19440 loss 0.006884211674332619
[2025-03-23 08:41:35,990][model][INFO] - Training step 19600 loss 0.03357382118701935
[2025-03-23 08:42:54,378][model][INFO] - Training step 19760 loss 0.004781350493431091
[2025-03-23 08:44:13,519][model][INFO] - Training step 19920 loss 0.04626837372779846
[2025-03-23 08:45:32,873][model][INFO] - Training step 20080 loss 0.05466970056295395
[2025-03-23 08:46:53,545][model][INFO] - Training step 20240 loss 0.02168859913945198
[2025-03-23 08:48:14,279][model][INFO] - Training step 20400 loss 0.17528995871543884
[2025-03-23 08:49:34,901][model][INFO] - Training step 20560 loss 0.02378556691110134
[2025-03-23 08:50:54,810][model][INFO] - Training step 20720 loss 0.03968166187405586
[2025-03-23 08:52:15,370][model][INFO] - Training step 20880 loss 0.027037132531404495
[2025-03-23 08:53:35,923][model][INFO] - Training step 21040 loss 0.14364731311798096
[2025-03-23 08:54:57,677][model][INFO] - Training step 21200 loss 0.0289660282433033
[2025-03-23 08:56:18,919][model][INFO] - Training step 21360 loss 0.07231160253286362
[2025-03-23 08:57:35,231][model][INFO] - Training step 21520 loss 0.24860623478889465
[2025-03-23 08:58:55,767][model][INFO] - Training step 21680 loss 0.2453855574131012
[2025-03-23 09:00:14,344][model][INFO] - Training step 21840 loss 0.2683994174003601
[2025-03-23 09:01:31,871][model][INFO] - Training step 22000 loss 0.035337381064891815
[2025-03-23 09:02:48,166][model][INFO] - Training step 22160 loss 0.1540471762418747
[2025-03-23 09:04:09,754][model][INFO] - Training step 22320 loss 0.03169380873441696
[2025-03-23 09:05:27,793][model][INFO] - Training step 22480 loss 0.012381463311612606
[2025-03-23 09:06:49,152][model][INFO] - Training step 22640 loss 0.024067899212241173
[2025-03-23 09:08:06,008][model][INFO] - Training step 22800 loss 0.028193101286888123
[2025-03-23 09:09:24,943][model][INFO] - Training step 22960 loss 0.025521425530314445
[2025-03-23 09:10:45,217][model][INFO] - Training step 23120 loss 0.02526136301457882
[2025-03-23 09:12:04,953][model][INFO] - Training step 23280 loss 0.02145136520266533
[2025-03-23 09:13:23,900][model][INFO] - Training step 23440 loss 0.025546947494149208
[2025-03-23 09:14:41,032][model][INFO] - Training step 23600 loss 0.3486921489238739
[2025-03-23 09:16:00,901][model][INFO] - Training step 23760 loss 0.0343952514231205
[2025-03-23 09:17:19,945][model][INFO] - Training step 23920 loss 0.028887931257486343
[2025-03-23 09:18:38,955][model][INFO] - Training step 24080 loss 0.06267745792865753
[2025-03-23 09:19:59,173][model][INFO] - Training step 24240 loss 0.025582723319530487
[2025-03-23 09:21:18,777][model][INFO] - Training step 24400 loss 0.1314612329006195
[2025-03-23 09:22:37,193][model][INFO] - Training step 24560 loss 0.07164178043603897
[2025-03-23 09:23:55,247][model][INFO] - Training step 24720 loss 0.25541943311691284
[2025-03-23 09:25:14,623][model][INFO] - Training step 24880 loss 0.03059546835720539
[2025-03-23 09:26:38,116][model][INFO] - Training step 25040 loss 0.034057989716529846
[2025-03-23 09:27:55,550][model][INFO] - Training step 25200 loss 0.2423531413078308
[2025-03-23 09:29:11,685][model][INFO] - Training step 25360 loss 0.09033772349357605
[2025-03-23 09:30:29,760][model][INFO] - Training step 25520 loss 0.08099812269210815
[2025-03-23 09:31:50,114][model][INFO] - Training step 25680 loss 0.2581031024456024
[2025-03-23 09:33:06,107][model][INFO] - Training step 25840 loss 0.04438813775777817
[2025-03-23 09:34:22,865][model][INFO] - Training step 26000 loss 0.145206481218338
[2025-03-23 09:35:42,489][model][INFO] - Training step 26160 loss 0.026421377435326576
[2025-03-23 09:37:03,564][model][INFO] - Training step 26320 loss 0.025836877524852753
[2025-03-23 09:38:24,784][model][INFO] - Training step 26480 loss 0.026164811104536057
[2025-03-23 09:39:46,308][model][INFO] - Training step 26640 loss 0.03273478150367737
[2025-03-23 09:41:06,236][model][INFO] - Training step 26800 loss 0.01830693893134594
[2025-03-23 09:42:24,658][model][INFO] - Training step 26960 loss 0.028227772563695908
[2025-03-23 09:43:43,975][model][INFO] - Training step 27120 loss 0.024179335683584213
[2025-03-23 09:45:03,977][model][INFO] - Training step 27280 loss 0.03558730334043503
[2025-03-23 09:46:22,438][model][INFO] - Training step 27440 loss 0.03351693972945213
[2025-03-23 09:47:39,963][model][INFO] - Training step 27600 loss 0.050022244453430176
[2025-03-23 09:48:58,869][model][INFO] - Training step 27760 loss 0.061918385326862335
[2025-03-23 09:50:15,365][model][INFO] - Training step 27920 loss 0.02161869965493679
[2025-03-23 09:51:36,498][model][INFO] - Training step 28080 loss 0.006691841408610344
[2025-03-23 09:52:53,187][model][INFO] - Training step 28240 loss 0.2548035681247711
[2025-03-23 09:54:13,045][model][INFO] - Training step 28400 loss 0.2500322759151459
[2025-03-23 09:55:31,351][model][INFO] - Training step 28560 loss 0.028072744607925415
[2025-03-23 09:56:49,177][model][INFO] - Training step 28720 loss 0.028475157916545868
[2025-03-23 09:58:07,329][model][INFO] - Training step 28880 loss 0.010297410190105438
[2025-03-23 09:59:27,879][model][INFO] - Training step 29040 loss 0.024764850735664368
[2025-03-23 10:00:48,598][model][INFO] - Training step 29200 loss 0.12127527594566345
[2025-03-23 10:02:08,485][model][INFO] - Training step 29360 loss 0.007772454991936684
[2025-03-23 10:03:29,223][model][INFO] - Training step 29520 loss 0.04046396166086197
[2025-03-23 10:04:48,896][model][INFO] - Training step 29680 loss 0.2469734102487564
[2025-03-23 10:06:10,650][model][INFO] - Training step 29840 loss 0.2671665847301483
[2025-03-23 10:07:28,102][model][INFO] - Training step 30000 loss 0.036297332495450974
[2025-03-23 10:08:46,093][model][INFO] - Training step 30160 loss 0.2557692527770996
[2025-03-23 10:10:08,314][model][INFO] - Training step 30320 loss 0.04065186157822609
[2025-03-23 10:11:26,800][model][INFO] - Training step 30480 loss 0.02976437658071518
[2025-03-23 10:12:43,796][model][INFO] - Training step 30640 loss 0.2372780740261078
[2025-03-23 10:14:00,018][model][INFO] - Training step 30800 loss 0.03984761983156204
[2025-03-23 10:15:19,405][model][INFO] - Training step 30960 loss 0.013498358428478241
[2025-03-23 10:16:37,675][model][INFO] - Training step 31120 loss 0.04099458456039429
[2025-03-23 10:17:56,275][model][INFO] - Training step 31280 loss 0.03570619598031044
[2025-03-23 10:19:16,368][model][INFO] - Training step 31440 loss 0.034533094614744186
[2025-03-23 10:20:32,816][model][INFO] - Training step 31600 loss 0.054940879344940186
[2025-03-23 10:21:54,451][model][INFO] - Training step 31760 loss 0.0030656256712973118
[2025-03-23 10:23:12,376][model][INFO] - Training step 31920 loss 0.028309645131230354
[2025-03-23 10:24:29,120][model][INFO] - Training step 32080 loss 0.020767658948898315
[2025-03-23 10:25:47,361][model][INFO] - Training step 32240 loss 0.07715493440628052
[2025-03-23 10:27:08,617][model][INFO] - Training step 32400 loss 0.02451179549098015
[2025-03-23 10:28:27,606][model][INFO] - Training step 32560 loss 0.2534882426261902
[2025-03-23 10:29:46,820][model][INFO] - Training step 32720 loss 0.2505289912223816
[2025-03-23 10:31:10,520][model][INFO] - Training step 32880 loss 0.028485914692282677
[2025-03-23 10:32:28,714][model][INFO] - Training step 33040 loss 0.03557964041829109
[2025-03-23 10:33:48,930][model][INFO] - Training step 33200 loss 0.09524630010128021
[2025-03-23 10:35:06,920][model][INFO] - Training step 33360 loss 0.02281792461872101
[2025-03-23 10:36:27,197][model][INFO] - Training step 33520 loss 0.04931333661079407
[2025-03-23 10:37:45,541][model][INFO] - Training step 33680 loss 0.011601870879530907
[2025-03-23 10:39:05,989][model][INFO] - Training step 33840 loss 0.02324019744992256
[2025-03-23 10:40:26,918][model][INFO] - Training step 34000 loss 0.2566969692707062
[2025-03-23 10:41:48,683][model][INFO] - Training step 34160 loss 0.052365317940711975
[2025-03-23 10:43:08,171][model][INFO] - Training step 34320 loss 0.048813581466674805
[2025-03-23 10:44:27,846][model][INFO] - Training step 34480 loss 0.04960888624191284
[2025-03-23 10:45:44,807][model][INFO] - Training step 34640 loss 0.03666221350431442
[2025-03-23 10:47:04,887][model][INFO] - Training step 34800 loss 0.022594664245843887
[2025-03-23 10:48:24,321][model][INFO] - Training step 34960 loss 0.048039644956588745
[2025-03-23 10:49:42,769][model][INFO] - Training step 35120 loss 0.029634885489940643
[2025-03-23 10:51:04,615][model][INFO] - Training step 35280 loss 0.028316974639892578
[2025-03-23 10:52:22,422][model][INFO] - Training step 35440 loss 0.014572042971849442
[2025-03-23 10:53:42,821][model][INFO] - Training step 35600 loss 0.045996226370334625
[2025-03-23 10:55:02,314][model][INFO] - Training step 35760 loss 0.0241354089230299
[2025-03-23 10:56:17,400][model][INFO] - Training step 35920 loss 0.035696350038051605
[2025-03-23 10:57:37,707][model][INFO] - Training step 36080 loss 0.053548090159893036
[2025-03-23 10:58:55,487][model][INFO] - Training step 36240 loss 0.09752394258975983
[2025-03-23 11:00:12,393][model][INFO] - Training step 36400 loss 0.0891634076833725
[2025-03-23 11:01:33,596][model][INFO] - Training step 36560 loss 0.20075751841068268
[2025-03-23 11:02:56,208][model][INFO] - Training step 36720 loss 0.2516440749168396
[2025-03-23 11:04:17,955][model][INFO] - Training step 36880 loss 0.06692852079868317
[2025-03-23 11:05:35,780][model][INFO] - Training step 37040 loss 0.03539126366376877
[2025-03-23 11:06:55,734][model][INFO] - Training step 37200 loss 0.25081315636634827
[2025-03-23 11:08:14,884][model][INFO] - Training step 37360 loss 0.026294559240341187
[2025-03-23 11:09:37,113][model][INFO] - Training step 37520 loss 0.007789447903633118
[2025-03-23 11:10:58,269][model][INFO] - Training step 37680 loss 0.03891342878341675
[2025-03-23 11:12:16,392][model][INFO] - Training step 37840 loss 0.010342255234718323
[2025-03-23 11:13:35,408][model][INFO] - Training step 38000 loss 0.010815850459039211
[2025-03-23 11:14:54,240][model][INFO] - Training step 38160 loss 0.005101908929646015
[2025-03-23 11:16:13,665][model][INFO] - Training step 38320 loss 0.038041651248931885
[2025-03-23 11:17:33,017][model][INFO] - Training step 38480 loss 0.03039497695863247
[2025-03-23 11:18:51,147][model][INFO] - Training step 38640 loss 0.005787216126918793
[2025-03-23 11:20:08,331][model][INFO] - Training step 38800 loss 0.01367834210395813
[2025-03-23 11:21:26,962][model][INFO] - Training step 38960 loss 0.2522329092025757
[2025-03-23 11:22:44,964][model][INFO] - Training step 39120 loss 0.04770735278725624
[2025-03-23 11:24:02,802][model][INFO] - Training step 39280 loss 0.005521835759282112
[2025-03-23 11:25:24,818][model][INFO] - Training step 39440 loss 0.028090503066778183
[2025-03-23 11:26:43,737][model][INFO] - Training step 39600 loss 0.02446851134300232
[2025-03-23 11:28:02,473][model][INFO] - Training step 39760 loss 0.24942365288734436
[2025-03-23 11:29:23,638][model][INFO] - Training step 39920 loss 0.019459620118141174
[2025-03-23 11:30:42,973][model][INFO] - Training step 40080 loss 0.015956122428178787
[2025-03-23 11:32:01,251][model][INFO] - Training step 40240 loss 0.02895388752222061
[2025-03-23 11:33:20,554][model][INFO] - Training step 40400 loss 0.004519049543887377
[2025-03-23 11:34:40,628][model][INFO] - Training step 40560 loss 0.11032145470380783
[2025-03-23 11:35:59,964][model][INFO] - Training step 40720 loss 0.041741013526916504
[2025-03-23 11:37:17,572][model][INFO] - Training step 40880 loss 0.2695940136909485
[2025-03-23 11:38:35,164][model][INFO] - Training step 41040 loss 0.02961580455303192
[2025-03-23 11:39:54,796][model][INFO] - Training step 41200 loss 0.013766184449195862
[2025-03-23 11:41:16,139][model][INFO] - Training step 41360 loss 0.013446573168039322
[2025-03-23 11:42:34,576][model][INFO] - Training step 41520 loss 0.04881772771477699
[2025-03-23 11:43:52,489][model][INFO] - Training step 41680 loss 0.1721089482307434
[2025-03-23 11:45:09,085][model][INFO] - Training step 41840 loss 0.1525757610797882
[2025-03-23 11:46:28,962][model][INFO] - Training step 42000 loss 0.04394760727882385
[2025-03-23 11:47:47,096][model][INFO] - Training step 42160 loss 0.034614935517311096
[2025-03-23 11:49:05,781][model][INFO] - Training step 42320 loss 0.2422610968351364
[2025-03-23 11:50:26,115][model][INFO] - Training step 42480 loss 0.02367435023188591
[2025-03-23 11:51:45,079][model][INFO] - Training step 42640 loss 0.06195461377501488
[2025-03-23 11:53:00,808][model][INFO] - Training step 42800 loss 0.018624719232320786
[2025-03-23 11:54:21,670][model][INFO] - Training step 42960 loss 0.017857521772384644
[2025-03-23 11:55:41,318][model][INFO] - Training step 43120 loss 0.0024699552450329065
[2025-03-23 11:57:03,107][model][INFO] - Training step 43280 loss 0.07068927586078644
[2025-03-23 11:58:23,948][model][INFO] - Training step 43440 loss 0.038014788180589676
[2025-03-23 11:59:42,971][model][INFO] - Training step 43600 loss 0.021256525069475174
[2025-03-23 12:01:01,917][model][INFO] - Training step 43760 loss 0.03727008402347565
[2025-03-23 12:02:21,220][model][INFO] - Training step 43920 loss 0.04607477784156799
[2025-03-23 12:03:37,422][model][INFO] - Training step 44080 loss 0.0291285440325737
[2025-03-23 12:04:58,075][model][INFO] - Training step 44240 loss 0.025661226361989975
[2025-03-23 12:06:18,583][model][INFO] - Training step 44400 loss 0.03449802100658417
[2025-03-23 12:07:38,281][model][INFO] - Training step 44560 loss 0.0270592849701643
[2025-03-23 12:08:56,058][model][INFO] - Training step 44720 loss 0.0331634096801281
[2025-03-23 12:10:14,235][model][INFO] - Training step 44880 loss 0.004561945330351591
[2025-03-23 12:11:34,937][model][INFO] - Training step 45040 loss 0.24681076407432556
[2025-03-23 12:12:53,676][model][INFO] - Training step 45200 loss 0.02201009728014469
[2025-03-23 12:14:14,194][model][INFO] - Training step 45360 loss 0.042981117963790894
[2025-03-23 12:15:34,463][model][INFO] - Training step 45520 loss 0.03820325434207916
[2025-03-23 12:16:55,997][model][INFO] - Training step 45680 loss 0.01021276693791151
[2025-03-23 12:18:13,952][model][INFO] - Training step 45840 loss 0.005934473127126694
[2025-03-23 12:19:31,803][model][INFO] - Training step 46000 loss 0.03821521997451782
[2025-03-23 12:20:48,987][model][INFO] - Training step 46160 loss 0.10281166434288025
[2025-03-23 12:22:09,753][model][INFO] - Training step 46320 loss 0.021267184987664223
[2025-03-23 12:23:30,179][model][INFO] - Training step 46480 loss 0.012974747456610203
[2025-03-23 12:24:47,135][model][INFO] - Training step 46640 loss 0.06342962384223938
[2025-03-23 12:26:05,389][model][INFO] - Training step 46800 loss 0.23800738155841827
[2025-03-23 12:27:26,711][model][INFO] - Training step 46960 loss 0.0030833533965051174
[2025-03-23 12:28:45,210][model][INFO] - Training step 47120 loss 0.05180257931351662
[2025-03-23 12:30:07,213][model][INFO] - Training step 47280 loss 0.017827371135354042
[2025-03-23 12:31:27,131][model][INFO] - Training step 47440 loss 0.00553465262055397
[2025-03-23 12:32:46,361][model][INFO] - Training step 47600 loss 0.24605318903923035
[2025-03-23 12:34:06,471][model][INFO] - Training step 47760 loss 0.20362216234207153
[2025-03-23 12:35:24,811][model][INFO] - Training step 47920 loss 0.25293776392936707
[2025-03-23 12:36:44,828][model][INFO] - Training step 48080 loss 0.030609281733632088
[2025-03-23 12:38:04,202][model][INFO] - Training step 48240 loss 0.0025260751135647297
[2025-03-23 12:39:23,292][model][INFO] - Training step 48400 loss 0.07557879388332367
[2025-03-23 12:40:40,836][model][INFO] - Training step 48560 loss 0.052530333399772644
[2025-03-23 12:41:59,823][model][INFO] - Training step 48720 loss 0.03884604573249817
[2025-03-23 12:43:23,510][model][INFO] - Training step 48880 loss 0.004129162989556789
[2025-03-23 12:44:42,046][model][INFO] - Training step 49040 loss 0.024400074034929276
[2025-03-23 12:46:00,662][model][INFO] - Training step 49200 loss 0.23633331060409546
[2025-03-23 12:47:19,896][model][INFO] - Training step 49360 loss 0.02983739972114563
[2025-03-23 12:48:40,263][model][INFO] - Training step 49520 loss 0.08698643743991852
[2025-03-23 12:49:58,137][model][INFO] - Training step 49680 loss 0.031937263906002045
[2025-03-23 12:51:16,091][model][INFO] - Training step 49840 loss 0.21199338138103485
[2025-03-23 12:52:38,693][model][INFO] - Training step 50000 loss 0.034236498177051544
[2025-03-23 12:53:59,701][model][INFO] - Training step 50160 loss 0.024031445384025574
[2025-03-23 12:55:19,062][model][INFO] - Training step 50320 loss 0.03769000619649887
[2025-03-23 12:56:36,585][model][INFO] - Training step 50480 loss 0.023279394954442978
[2025-03-23 12:57:55,162][model][INFO] - Training step 50640 loss 0.21346649527549744
[2025-03-23 13:07:27,510][model][INFO] - Training step 0 loss 0.042168233543634415
[2025-03-23 13:08:47,730][model][INFO] - Training step 160 loss 0.015485016629099846
[2025-03-23 13:10:09,725][model][INFO] - Training step 320 loss 0.024954847991466522
[2025-03-23 13:11:30,233][model][INFO] - Training step 480 loss 0.029076173901557922
[2025-03-23 13:12:49,795][model][INFO] - Training step 640 loss 0.007634465582668781
[2025-03-23 13:14:09,495][model][INFO] - Training step 800 loss 0.25432437658309937
[2025-03-23 13:15:30,545][model][INFO] - Training step 960 loss 0.2526058256626129
[2025-03-23 13:16:49,507][model][INFO] - Training step 1120 loss 0.05978819727897644
[2025-03-23 13:18:08,088][model][INFO] - Training step 1280 loss 0.06791672855615616
[2025-03-23 13:19:25,358][model][INFO] - Training step 1440 loss 0.13440737128257751
[2025-03-23 13:20:45,261][model][INFO] - Training step 1600 loss 0.010791527107357979
[2025-03-23 13:22:06,602][model][INFO] - Training step 1760 loss 0.26227372884750366
[2025-03-23 13:23:26,219][model][INFO] - Training step 1920 loss 0.021012049168348312
[2025-03-23 13:24:47,927][model][INFO] - Training step 2080 loss 0.24867963790893555
[2025-03-23 13:26:07,871][model][INFO] - Training step 2240 loss 0.02164936065673828
[2025-03-23 13:27:28,081][model][INFO] - Training step 2400 loss 0.018717966973781586
[2025-03-23 13:28:47,280][model][INFO] - Training step 2560 loss 0.010440920479595661
[2025-03-23 13:30:05,739][model][INFO] - Training step 2720 loss 0.0023780749179422855
[2025-03-23 13:31:24,448][model][INFO] - Training step 2880 loss 0.0211164727807045
[2025-03-23 13:32:44,804][model][INFO] - Training step 3040 loss 0.03234970569610596
[2025-03-23 13:34:04,596][model][INFO] - Training step 3200 loss 0.0032611144706606865
[2025-03-23 13:35:22,119][model][INFO] - Training step 3360 loss 0.006608609575778246
[2025-03-23 13:36:40,071][model][INFO] - Training step 3520 loss 0.008117564022541046
[2025-03-23 13:38:00,924][model][INFO] - Training step 3680 loss 0.03200036287307739
[2025-03-23 13:39:16,395][model][INFO] - Training step 3840 loss 0.08684124052524567
[2025-03-23 13:40:36,999][model][INFO] - Training step 4000 loss 0.2569493055343628
[2025-03-23 13:41:58,669][model][INFO] - Training step 4160 loss 0.0035628667101264
[2025-03-23 13:43:17,279][model][INFO] - Training step 4320 loss 0.025266006588935852
[2025-03-23 13:44:36,620][model][INFO] - Training step 4480 loss 0.033176012337207794
[2025-03-23 13:45:56,787][model][INFO] - Training step 4640 loss 0.2507040202617645
[2025-03-23 13:47:14,305][model][INFO] - Training step 4800 loss 0.06020371615886688
[2025-03-23 13:48:33,399][model][INFO] - Training step 4960 loss 0.012373402714729309
[2025-03-23 13:49:52,325][model][INFO] - Training step 5120 loss 0.6532942056655884
[2025-03-23 13:51:11,998][model][INFO] - Training step 5280 loss 0.23110708594322205
[2025-03-23 13:52:32,550][model][INFO] - Training step 5440 loss 0.056623607873916626
[2025-03-23 13:53:49,241][model][INFO] - Training step 5600 loss 0.048935309052467346
[2025-03-23 13:55:08,199][model][INFO] - Training step 5760 loss 0.019776202738285065
[2025-03-23 13:56:28,105][model][INFO] - Training step 5920 loss 0.0027997312135994434
[2025-03-23 13:57:45,586][model][INFO] - Training step 6080 loss 0.04893761873245239
[2025-03-23 13:59:08,310][model][INFO] - Training step 6240 loss 0.01898956298828125
[2025-03-23 14:00:28,730][model][INFO] - Training step 6400 loss 0.04703294485807419
[2025-03-23 14:01:45,468][model][INFO] - Training step 6560 loss 0.07216377556324005
[2025-03-23 14:03:05,223][model][INFO] - Training step 6720 loss 0.274014413356781
[2025-03-23 14:04:25,100][model][INFO] - Training step 6880 loss 0.10704547166824341
[2025-03-23 14:05:42,456][model][INFO] - Training step 7040 loss 0.039223283529281616
[2025-03-23 14:07:04,867][model][INFO] - Training step 7200 loss 0.24399679899215698
[2025-03-23 14:08:24,499][model][INFO] - Training step 7360 loss 0.036441653966903687
[2025-03-23 14:09:43,546][model][INFO] - Training step 7520 loss 0.031051769852638245
[2025-03-23 14:11:04,045][model][INFO] - Training step 7680 loss 0.004144697450101376
[2025-03-23 14:12:24,829][model][INFO] - Training step 7840 loss 0.022730886936187744
[2025-03-23 14:13:45,826][model][INFO] - Training step 8000 loss 0.03471793234348297
[2025-03-23 14:15:03,276][model][INFO] - Training step 8160 loss 0.09621681272983551
[2025-03-23 14:16:22,986][model][INFO] - Training step 8320 loss 0.004169455263763666
[2025-03-23 14:17:44,456][model][INFO] - Training step 8480 loss 0.0709870308637619
[2025-03-23 14:19:02,982][model][INFO] - Training step 8640 loss 0.005720253102481365
[2025-03-23 14:20:22,808][model][INFO] - Training step 8800 loss 0.026939552277326584
[2025-03-23 14:21:42,427][model][INFO] - Training step 8960 loss 0.03176048398017883
[2025-03-23 14:23:01,789][model][INFO] - Training step 9120 loss 0.028161101043224335
[2025-03-23 14:24:20,888][model][INFO] - Training step 9280 loss 0.027452785521745682
[2025-03-23 14:25:39,440][model][INFO] - Training step 9440 loss 0.02487196773290634
[2025-03-23 14:26:56,785][model][INFO] - Training step 9600 loss 0.03150065243244171
[2025-03-23 14:28:16,355][model][INFO] - Training step 9760 loss 0.0057709612883627415
[2025-03-23 14:29:34,364][model][INFO] - Training step 9920 loss 0.015835663303732872
[2025-03-23 14:30:54,715][model][INFO] - Training step 10080 loss 0.04201873019337654
[2025-03-23 14:32:11,632][model][INFO] - Training step 10240 loss 0.2426333725452423
[2025-03-23 14:33:30,072][model][INFO] - Training step 10400 loss 0.25998756289482117
[2025-03-23 14:34:50,764][model][INFO] - Training step 10560 loss 0.004655820317566395
[2025-03-23 14:36:07,031][model][INFO] - Training step 10720 loss 0.014634660445153713
[2025-03-23 14:37:26,246][model][INFO] - Training step 10880 loss 0.04150079935789108
[2025-03-23 14:38:43,727][model][INFO] - Training step 11040 loss 0.0034537999890744686
[2025-03-23 14:40:01,986][model][INFO] - Training step 11200 loss 0.02733217552304268
[2025-03-23 14:41:20,973][model][INFO] - Training step 11360 loss 0.0019064086955040693
[2025-03-23 14:42:40,284][model][INFO] - Training step 11520 loss 0.02090679481625557
[2025-03-23 14:43:57,565][model][INFO] - Training step 11680 loss 0.2482832968235016
[2025-03-23 14:45:16,366][model][INFO] - Training step 11840 loss 0.006631139200180769
[2025-03-23 14:46:32,568][model][INFO] - Training step 12000 loss 0.20941400527954102
[2025-03-23 14:47:50,247][model][INFO] - Training step 12160 loss 0.025624431669712067
[2025-03-23 14:49:08,097][model][INFO] - Training step 12320 loss 0.052673980593681335
[2025-03-23 14:50:25,767][model][INFO] - Training step 12480 loss 0.02218152955174446
[2025-03-23 14:51:45,533][model][INFO] - Training step 12640 loss 0.04415975883603096
[2025-03-23 14:53:08,423][model][INFO] - Training step 12800 loss 0.030761688947677612
[2025-03-23 14:54:24,686][model][INFO] - Training step 12960 loss 0.01849931851029396
[2025-03-23 14:55:42,447][model][INFO] - Training step 13120 loss 0.12032033503055573
[2025-03-23 14:57:00,311][model][INFO] - Training step 13280 loss 0.25602811574935913
[2025-03-23 14:58:16,508][model][INFO] - Training step 13440 loss 0.3131136894226074
[2025-03-23 14:59:36,316][model][INFO] - Training step 13600 loss 0.009388254955410957
[2025-03-23 15:00:58,383][model][INFO] - Training step 13760 loss 0.1299368143081665
[2025-03-23 15:02:18,680][model][INFO] - Training step 13920 loss 0.005512760486453772
[2025-03-23 15:03:38,714][model][INFO] - Training step 14080 loss 0.15013128519058228
[2025-03-23 15:05:00,117][model][INFO] - Training step 14240 loss 0.005803605541586876
[2025-03-23 15:06:19,571][model][INFO] - Training step 14400 loss 0.23319604992866516
[2025-03-23 15:07:38,921][model][INFO] - Training step 14560 loss 0.02495284005999565
[2025-03-23 15:08:59,861][model][INFO] - Training step 14720 loss 0.2515273690223694
[2025-03-23 15:10:19,798][model][INFO] - Training step 14880 loss 0.2307242751121521
[2025-03-23 15:11:37,139][model][INFO] - Training step 15040 loss 0.04439781606197357
[2025-03-23 15:12:58,005][model][INFO] - Training step 15200 loss 0.019913354888558388
[2025-03-23 15:14:15,948][model][INFO] - Training step 15360 loss 0.050758689641952515
[2025-03-23 15:15:35,169][model][INFO] - Training step 15520 loss 0.026813339442014694
[2025-03-23 15:16:51,538][model][INFO] - Training step 15680 loss 0.0032869891729205847
[2025-03-23 15:18:09,758][model][INFO] - Training step 15840 loss 0.03946864232420921
[2025-03-23 15:19:29,310][model][INFO] - Training step 16000 loss 0.03647950291633606
[2025-03-23 15:20:52,165][model][INFO] - Training step 16160 loss 0.04258940741419792
[2025-03-23 15:22:11,134][model][INFO] - Training step 16320 loss 0.029707979410886765
[2025-03-23 15:23:28,520][model][INFO] - Training step 16480 loss 0.02036859467625618
[2025-03-23 15:24:46,331][model][INFO] - Training step 16640 loss 0.02267962135374546
[2025-03-23 15:26:04,631][model][INFO] - Training step 16800 loss 0.027887295931577682
[2025-03-23 15:27:24,393][model][INFO] - Training step 16960 loss 0.03404860943555832
[2025-03-23 15:28:44,725][model][INFO] - Training step 17120 loss 0.0460490845143795
[2025-03-23 15:30:03,573][model][INFO] - Training step 17280 loss 0.23744650185108185
[2025-03-23 15:31:21,605][model][INFO] - Training step 17440 loss 0.036435894668102264
[2025-03-23 15:32:43,217][model][INFO] - Training step 17600 loss 0.03560981899499893
[2025-03-23 15:34:03,415][model][INFO] - Training step 17760 loss 0.05388876795768738
[2025-03-23 15:35:20,888][model][INFO] - Training step 17920 loss 0.05903906002640724
[2025-03-23 15:36:43,250][model][INFO] - Training step 18080 loss 0.006265586242079735
[2025-03-23 15:38:03,884][model][INFO] - Training step 18240 loss 0.03328800946474075
[2025-03-23 15:39:26,741][model][INFO] - Training step 18400 loss 0.03388960659503937
[2025-03-23 15:40:49,615][model][INFO] - Training step 18560 loss 0.26592326164245605
[2025-03-23 15:42:11,548][model][INFO] - Training step 18720 loss 0.03258350491523743
[2025-03-23 15:43:30,299][model][INFO] - Training step 18880 loss 0.25577327609062195
[2025-03-23 15:44:49,121][model][INFO] - Training step 19040 loss 0.14886018633842468
[2025-03-23 15:46:08,802][model][INFO] - Training step 19200 loss 0.02487921714782715
[2025-03-23 15:47:27,752][model][INFO] - Training step 19360 loss 0.028240425512194633
[2025-03-23 15:48:48,364][model][INFO] - Training step 19520 loss 0.059766076505184174
[2025-03-23 15:50:05,276][model][INFO] - Training step 19680 loss 0.030151018872857094
[2025-03-23 15:51:24,627][model][INFO] - Training step 19840 loss 0.025919344276189804
[2025-03-23 15:52:42,876][model][INFO] - Training step 20000 loss 0.17319084703922272
[2025-03-23 15:54:02,532][model][INFO] - Training step 20160 loss 0.02391173131763935
[2025-03-23 15:55:24,330][model][INFO] - Training step 20320 loss 0.030534062534570694
[2025-03-23 15:56:46,860][model][INFO] - Training step 20480 loss 0.252453088760376
[2025-03-23 15:58:04,444][model][INFO] - Training step 20640 loss 0.025939449667930603
[2025-03-23 15:59:24,822][model][INFO] - Training step 20800 loss 0.0037833410315215588
[2025-03-23 16:00:43,585][model][INFO] - Training step 20960 loss 0.0940079465508461
[2025-03-23 16:02:02,662][model][INFO] - Training step 21120 loss 0.09532437473535538
[2025-03-23 16:03:23,429][model][INFO] - Training step 21280 loss 0.24659249186515808
[2025-03-23 16:04:43,374][model][INFO] - Training step 21440 loss 0.24297745525836945
[2025-03-23 16:06:00,122][model][INFO] - Training step 21600 loss 0.03212135285139084
[2025-03-23 16:07:17,977][model][INFO] - Training step 21760 loss 0.24354879558086395
[2025-03-23 16:08:38,960][model][INFO] - Training step 21920 loss 0.06579708307981491
[2025-03-23 16:09:57,895][model][INFO] - Training step 22080 loss 0.08537621796131134
[2025-03-23 16:11:21,498][model][INFO] - Training step 22240 loss 0.01173088513314724
[2025-03-23 16:12:41,505][model][INFO] - Training step 22400 loss 0.03571750968694687
[2025-03-23 16:13:59,208][model][INFO] - Training step 22560 loss 0.24948792159557343
[2025-03-23 16:15:18,292][model][INFO] - Training step 22720 loss 0.026839088648557663
[2025-03-23 16:16:37,343][model][INFO] - Training step 22880 loss 0.015898732468485832
[2025-03-23 16:17:57,977][model][INFO] - Training step 23040 loss 0.11638779938220978
[2025-03-23 16:19:19,450][model][INFO] - Training step 23200 loss 0.0643867626786232
[2025-03-23 16:20:36,902][model][INFO] - Training step 23360 loss 0.05285485088825226
[2025-03-23 16:21:57,231][model][INFO] - Training step 23520 loss 0.022410552948713303
[2025-03-23 16:23:15,333][model][INFO] - Training step 23680 loss 0.0017509256722405553
[2025-03-23 16:24:35,205][model][INFO] - Training step 23840 loss 0.027756933122873306
[2025-03-23 16:25:52,381][model][INFO] - Training step 24000 loss 0.028621595352888107
[2025-03-23 16:27:10,061][model][INFO] - Training step 24160 loss 0.022408917546272278
[2025-03-23 16:28:28,781][model][INFO] - Training step 24320 loss 0.04030259698629379
[2025-03-23 16:29:47,297][model][INFO] - Training step 24480 loss 0.24634316563606262
[2025-03-23 16:31:06,932][model][INFO] - Training step 24640 loss 0.04329245537519455
[2025-03-23 16:32:26,564][model][INFO] - Training step 24800 loss 0.1611572504043579
[2025-03-23 16:33:48,234][model][INFO] - Training step 24960 loss 0.03304901719093323
[2025-03-23 16:35:11,460][model][INFO] - Training step 25120 loss 0.06374892592430115
[2025-03-23 16:36:31,091][model][INFO] - Training step 25280 loss 0.02122141420841217
[2025-03-23 16:37:48,709][model][INFO] - Training step 25440 loss 0.017847411334514618
[2025-03-23 16:39:07,444][model][INFO] - Training step 25600 loss 0.24183762073516846
[2025-03-23 16:40:26,200][model][INFO] - Training step 25760 loss 0.02785887010395527
[2025-03-23 16:41:48,115][model][INFO] - Training step 25920 loss 0.09202438592910767
[2025-03-23 16:43:06,458][model][INFO] - Training step 26080 loss 0.020652322098612785
[2025-03-23 16:44:27,036][model][INFO] - Training step 26240 loss 0.0822022557258606
[2025-03-23 16:45:44,838][model][INFO] - Training step 26400 loss 0.09264441579580307
[2025-03-23 16:47:04,412][model][INFO] - Training step 26560 loss 0.2619600296020508
[2025-03-23 16:48:22,163][model][INFO] - Training step 26720 loss 0.02236616238951683
[2025-03-23 16:49:42,488][model][INFO] - Training step 26880 loss 0.24873724579811096
[2025-03-23 16:51:02,302][model][INFO] - Training step 27040 loss 0.026842083781957626
[2025-03-23 16:52:22,637][model][INFO] - Training step 27200 loss 0.017241112887859344
[2025-03-23 16:53:42,687][model][INFO] - Training step 27360 loss 0.03293357044458389
[2025-03-23 16:55:00,796][model][INFO] - Training step 27520 loss 0.04871826246380806
[2025-03-23 16:56:18,539][model][INFO] - Training step 27680 loss 0.12906531989574432
[2025-03-23 16:57:38,270][model][INFO] - Training step 27840 loss 0.07780659198760986
[2025-03-23 16:58:56,482][model][INFO] - Training step 28000 loss 0.03420848399400711
[2025-03-23 17:00:20,735][model][INFO] - Training step 28160 loss 0.015667099505662918
[2025-03-23 17:01:41,574][model][INFO] - Training step 28320 loss 0.23657198250293732
[2025-03-23 17:03:00,112][model][INFO] - Training step 28480 loss 0.06899348646402359
[2025-03-23 17:04:20,535][model][INFO] - Training step 28640 loss 0.001513392897322774
[2025-03-23 17:05:35,902][model][INFO] - Training step 28800 loss 0.13764044642448425
[2025-03-23 17:06:55,163][model][INFO] - Training step 28960 loss 0.25892162322998047
[2025-03-23 17:08:15,757][model][INFO] - Training step 29120 loss 0.03126216679811478
[2025-03-23 17:09:35,629][model][INFO] - Training step 29280 loss 0.048722922801971436
[2025-03-23 17:10:54,521][model][INFO] - Training step 29440 loss 0.03844678774476051
[2025-03-23 17:12:15,802][model][INFO] - Training step 29600 loss 0.06793816387653351
[2025-03-23 17:13:35,453][model][INFO] - Training step 29760 loss 0.03610587120056152
[2025-03-23 17:14:55,101][model][INFO] - Training step 29920 loss 0.024424657225608826
[2025-03-23 17:16:12,927][model][INFO] - Training step 30080 loss 0.02001837268471718
[2025-03-23 17:17:30,278][model][INFO] - Training step 30240 loss 0.033195991069078445
[2025-03-23 17:18:50,917][model][INFO] - Training step 30400 loss 0.2417258769273758
[2025-03-23 17:20:06,456][model][INFO] - Training step 30560 loss 0.03139519691467285
[2025-03-23 17:21:21,219][model][INFO] - Training step 30720 loss 0.010395808145403862
[2025-03-23 17:22:35,311][model][INFO] - Training step 30880 loss 0.02629656344652176
[2025-03-23 17:23:56,000][model][INFO] - Training step 31040 loss 0.03132302686572075
[2025-03-23 17:25:13,590][model][INFO] - Training step 31200 loss 0.02005292847752571
[2025-03-23 17:26:32,055][model][INFO] - Training step 31360 loss 0.11129359155893326
[2025-03-23 17:27:51,825][model][INFO] - Training step 31520 loss 0.10256457328796387
[2025-03-23 17:29:10,945][model][INFO] - Training step 31680 loss 0.060783132910728455
[2025-03-23 17:30:28,945][model][INFO] - Training step 31840 loss 0.014641869813203812
[2025-03-23 17:31:49,731][model][INFO] - Training step 32000 loss 0.05652973800897598
[2025-03-23 17:33:11,121][model][INFO] - Training step 32160 loss 0.035653553903102875
[2025-03-23 17:34:33,301][model][INFO] - Training step 32320 loss 0.020767228677868843
[2025-03-23 17:35:54,450][model][INFO] - Training step 32480 loss 0.0337299108505249
[2025-03-23 17:37:15,234][model][INFO] - Training step 32640 loss 0.04156028479337692
[2025-03-23 17:38:35,277][model][INFO] - Training step 32800 loss 0.11325494945049286
[2025-03-23 17:40:00,136][model][INFO] - Training step 32960 loss 0.023846760392189026
[2025-03-23 17:41:18,029][model][INFO] - Training step 33120 loss 0.24725663661956787
[2025-03-23 17:42:40,331][model][INFO] - Training step 33280 loss 0.051033761352300644
[2025-03-23 17:44:01,051][model][INFO] - Training step 33440 loss 0.036299023777246475
[2025-03-23 17:45:22,489][model][INFO] - Training step 33600 loss 0.030351081863045692
[2025-03-23 17:46:41,782][model][INFO] - Training step 33760 loss 0.007897667586803436
[2025-03-23 17:48:04,329][model][INFO] - Training step 33920 loss 0.003080993890762329
[2025-03-23 17:49:22,739][model][INFO] - Training step 34080 loss 0.0050950562581419945
[2025-03-23 17:50:43,796][model][INFO] - Training step 34240 loss 0.025400664657354355
[2025-03-23 17:52:05,609][model][INFO] - Training step 34400 loss 0.24027714133262634
[2025-03-23 17:53:25,879][model][INFO] - Training step 34560 loss 0.033977389335632324
[2025-03-23 17:54:49,962][model][INFO] - Training step 34720 loss 0.020117204636335373
[2025-03-23 17:56:09,030][model][INFO] - Training step 34880 loss 0.27320390939712524
[2025-03-23 17:57:29,639][model][INFO] - Training step 35040 loss 0.037845999002456665
[2025-03-23 17:58:50,414][model][INFO] - Training step 35200 loss 0.029279129579663277
[2025-03-23 18:00:09,419][model][INFO] - Training step 35360 loss 0.25032755732536316
[2025-03-23 18:01:32,175][model][INFO] - Training step 35520 loss 0.02728450298309326
[2025-03-23 18:02:49,889][model][INFO] - Training step 35680 loss 0.0178305022418499
[2025-03-23 18:04:08,419][model][INFO] - Training step 35840 loss 0.01686626672744751
[2025-03-23 18:05:26,439][model][INFO] - Training step 36000 loss 0.025310523808002472
[2025-03-23 18:06:45,006][model][INFO] - Training step 36160 loss 0.15555687248706818
[2025-03-23 18:08:06,449][model][INFO] - Training step 36320 loss 0.283527672290802
[2025-03-23 18:09:27,247][model][INFO] - Training step 36480 loss 0.019768407568335533
[2025-03-23 18:10:47,886][model][INFO] - Training step 36640 loss 0.02444816753268242
[2025-03-23 18:12:05,730][model][INFO] - Training step 36800 loss 0.0032156212255358696
[2025-03-23 18:13:28,921][model][INFO] - Training step 36960 loss 0.01556432619690895
[2025-03-23 18:14:49,140][model][INFO] - Training step 37120 loss 0.0037174993194639683
[2025-03-23 18:16:11,495][model][INFO] - Training step 37280 loss 0.049638085067272186
[2025-03-23 18:17:33,793][model][INFO] - Training step 37440 loss 0.0708482414484024
[2025-03-23 18:18:51,463][model][INFO] - Training step 37600 loss 0.049886785447597504
[2025-03-23 18:20:08,871][model][INFO] - Training step 37760 loss 0.044318944215774536
[2025-03-23 18:21:27,873][model][INFO] - Training step 37920 loss 0.2483905553817749
[2025-03-23 18:22:44,421][model][INFO] - Training step 38080 loss 0.03314070403575897
[2025-03-23 18:24:04,471][model][INFO] - Training step 38240 loss 0.02041304111480713
[2025-03-23 18:25:23,276][model][INFO] - Training step 38400 loss 0.23511138558387756
[2025-03-23 18:26:41,527][model][INFO] - Training step 38560 loss 0.024177446961402893
[2025-03-23 18:28:00,513][model][INFO] - Training step 38720 loss 0.00812620297074318
[2025-03-23 18:29:21,273][model][INFO] - Training step 38880 loss 0.025400839745998383
[2025-03-23 18:30:39,072][model][INFO] - Training step 39040 loss 0.025474578142166138
[2025-03-23 18:31:57,700][model][INFO] - Training step 39200 loss 0.03950950503349304
[2025-03-23 18:33:15,930][model][INFO] - Training step 39360 loss 0.1618386209011078
[2025-03-23 18:34:35,813][model][INFO] - Training step 39520 loss 0.012506053782999516
[2025-03-23 18:35:52,438][model][INFO] - Training step 39680 loss 0.01560411136597395
[2025-03-23 18:37:16,770][model][INFO] - Training step 39840 loss 0.24293029308319092
[2025-03-23 18:38:38,191][model][INFO] - Training step 40000 loss 0.029019542038440704
[2025-03-23 18:39:58,651][model][INFO] - Training step 40160 loss 0.030000440776348114
[2025-03-23 18:41:17,359][model][INFO] - Training step 40320 loss 0.03822857141494751
[2025-03-23 18:42:37,354][model][INFO] - Training step 40480 loss 0.04746226221323013
[2025-03-23 18:43:58,586][model][INFO] - Training step 40640 loss 0.2360602617263794
[2025-03-23 18:45:16,344][model][INFO] - Training step 40800 loss 0.016045840457081795
[2025-03-23 18:46:36,872][model][INFO] - Training step 40960 loss 0.2557571530342102
[2025-03-23 18:47:58,830][model][INFO] - Training step 41120 loss 0.014330537989735603
[2025-03-23 18:49:18,961][model][INFO] - Training step 41280 loss 0.03248104453086853
[2025-03-23 18:50:36,960][model][INFO] - Training step 41440 loss 0.04244309291243553
[2025-03-23 18:51:59,384][model][INFO] - Training step 41600 loss 0.24959680438041687
[2025-03-23 18:53:20,921][model][INFO] - Training step 41760 loss 0.004913371056318283
[2025-03-23 18:54:43,083][model][INFO] - Training step 41920 loss 0.0713900476694107
[2025-03-23 18:55:57,233][model][INFO] - Training step 42080 loss 0.012816915288567543
[2025-03-23 18:57:14,962][model][INFO] - Training step 42240 loss 0.04240218549966812
[2025-03-23 18:58:30,525][model][INFO] - Training step 42400 loss 0.24932579696178436
[2025-03-23 18:59:51,352][model][INFO] - Training step 42560 loss 0.026883935555815697
[2025-03-23 19:01:11,515][model][INFO] - Training step 42720 loss 0.01277155801653862
[2025-03-23 19:02:29,087][model][INFO] - Training step 42880 loss 0.13187803328037262
[2025-03-23 19:03:50,072][model][INFO] - Training step 43040 loss 0.020339369773864746
[2025-03-23 19:05:08,301][model][INFO] - Training step 43200 loss 0.04982954263687134
[2025-03-23 19:06:29,334][model][INFO] - Training step 43360 loss 0.04097055643796921
[2025-03-23 19:07:50,746][model][INFO] - Training step 43520 loss 0.0291290245950222
[2025-03-23 19:09:11,264][model][INFO] - Training step 43680 loss 0.11079290509223938
[2025-03-23 19:10:32,064][model][INFO] - Training step 43840 loss 0.10602886974811554
[2025-03-23 19:11:53,108][model][INFO] - Training step 44000 loss 0.026199471205472946
[2025-03-23 19:13:16,846][model][INFO] - Training step 44160 loss 0.00678222207352519
[2025-03-23 19:14:36,559][model][INFO] - Training step 44320 loss 0.02675297111272812
[2025-03-23 19:15:57,633][model][INFO] - Training step 44480 loss 0.005197681020945311
[2025-03-23 19:17:15,428][model][INFO] - Training step 44640 loss 0.25714582204818726
[2025-03-23 19:18:35,562][model][INFO] - Training step 44800 loss 0.03843614459037781
[2025-03-23 19:19:53,857][model][INFO] - Training step 44960 loss 0.09691661596298218
[2025-03-23 19:21:14,474][model][INFO] - Training step 45120 loss 0.03792671114206314
[2025-03-23 19:22:35,522][model][INFO] - Training step 45280 loss 0.02388482540845871
[2025-03-23 19:23:58,089][model][INFO] - Training step 45440 loss 0.008659500628709793
[2025-03-23 19:25:18,459][model][INFO] - Training step 45600 loss 0.028085678815841675
[2025-03-23 19:26:39,770][model][INFO] - Training step 45760 loss 0.03986372798681259
[2025-03-23 19:27:57,151][model][INFO] - Training step 45920 loss 0.027526404708623886
[2025-03-23 19:29:19,518][model][INFO] - Training step 46080 loss 0.02957334741950035
[2025-03-23 19:30:39,451][model][INFO] - Training step 46240 loss 0.02065189555287361
[2025-03-23 19:32:00,166][model][INFO] - Training step 46400 loss 0.012371504679322243
[2025-03-23 19:33:18,542][model][INFO] - Training step 46560 loss 0.008124280720949173
[2025-03-23 19:34:38,531][model][INFO] - Training step 46720 loss 0.03528224304318428
[2025-03-23 19:35:56,229][model][INFO] - Training step 46880 loss 0.2795562744140625
[2025-03-23 19:37:16,708][model][INFO] - Training step 47040 loss 0.056464456021785736
[2025-03-23 19:38:34,058][model][INFO] - Training step 47200 loss 0.004851659759879112
[2025-03-23 19:39:53,716][model][INFO] - Training step 47360 loss 0.03477171063423157
[2025-03-23 19:41:10,532][model][INFO] - Training step 47520 loss 0.022134531289339066
[2025-03-23 19:42:35,593][model][INFO] - Training step 47680 loss 0.03259049355983734
[2025-03-23 19:43:55,211][model][INFO] - Training step 47840 loss 0.02166806161403656
[2025-03-23 19:45:15,210][model][INFO] - Training step 48000 loss 0.05686238408088684
[2025-03-23 19:46:36,386][model][INFO] - Training step 48160 loss 0.026274994015693665
[2025-03-23 19:47:55,188][model][INFO] - Training step 48320 loss 0.03239903599023819
[2025-03-23 19:49:15,044][model][INFO] - Training step 48480 loss 0.007221533916890621
[2025-03-23 19:50:34,174][model][INFO] - Training step 48640 loss 0.025127075612545013
[2025-03-23 19:51:53,677][model][INFO] - Training step 48800 loss 0.034738656133413315
[2025-03-23 19:53:11,908][model][INFO] - Training step 48960 loss 0.23678508400917053
[2025-03-23 19:54:32,306][model][INFO] - Training step 49120 loss 0.03793639689683914
[2025-03-23 19:55:52,001][model][INFO] - Training step 49280 loss 0.24527820944786072
[2025-03-23 19:57:11,537][model][INFO] - Training step 49440 loss 0.2520607113838196
[2025-03-23 19:58:30,655][model][INFO] - Training step 49600 loss 0.04833674430847168
[2025-03-23 19:59:52,610][model][INFO] - Training step 49760 loss 0.013763001188635826
[2025-03-23 20:01:12,691][model][INFO] - Training step 49920 loss 0.05506119877099991
[2025-03-23 20:02:30,694][model][INFO] - Training step 50080 loss 0.02049485221505165
[2025-03-23 20:03:51,750][model][INFO] - Training step 50240 loss 0.01174705009907484
[2025-03-23 20:05:09,412][model][INFO] - Training step 50400 loss 0.022576745599508286
[2025-03-23 20:06:29,473][model][INFO] - Training step 50560 loss 0.017373165115714073
[2025-03-23 20:07:50,969][model][INFO] - Training step 50720 loss 0.027288448065519333
[2025-03-23 20:17:28,870][model][INFO] - Training step 80 loss 0.25922322273254395
[2025-03-23 20:18:54,412][model][INFO] - Training step 240 loss 0.16816848516464233
[2025-03-23 20:20:14,208][model][INFO] - Training step 400 loss 0.1271103322505951
[2025-03-23 20:21:33,970][model][INFO] - Training step 560 loss 0.02209671586751938
[2025-03-23 20:22:55,620][model][INFO] - Training step 720 loss 0.24825792014598846
[2025-03-23 20:24:15,390][model][INFO] - Training step 880 loss 0.003374050371348858
[2025-03-23 20:25:35,724][model][INFO] - Training step 1040 loss 0.018239136785268784
[2025-03-23 20:26:55,217][model][INFO] - Training step 1200 loss 0.005675702355802059
[2025-03-23 20:28:13,971][model][INFO] - Training step 1360 loss 0.256756067276001
[2025-03-23 20:29:29,685][model][INFO] - Training step 1520 loss 0.03247474879026413
[2025-03-23 20:30:47,903][model][INFO] - Training step 1680 loss 0.018762610852718353
[2025-03-23 20:32:07,366][model][INFO] - Training step 1840 loss 0.25613778829574585
[2025-03-23 20:33:24,336][model][INFO] - Training step 2000 loss 0.06433509290218353
[2025-03-23 20:34:45,649][model][INFO] - Training step 2160 loss 0.055104948580265045
[2025-03-23 20:36:02,129][model][INFO] - Training step 2320 loss 0.10611192882061005
[2025-03-23 20:37:22,203][model][INFO] - Training step 2480 loss 0.009282858110964298
[2025-03-23 20:38:42,448][model][INFO] - Training step 2640 loss 0.024398665875196457
[2025-03-23 20:40:01,134][model][INFO] - Training step 2800 loss 0.03285958617925644
[2025-03-23 20:41:21,070][model][INFO] - Training step 2960 loss 0.2512732148170471
[2025-03-23 20:42:39,496][model][INFO] - Training step 3120 loss 0.2613702714443207
[2025-03-23 20:43:56,847][model][INFO] - Training step 3280 loss 0.19255812466144562
[2025-03-23 20:45:17,126][model][INFO] - Training step 3440 loss 0.22492732107639313
[2025-03-23 20:46:37,478][model][INFO] - Training step 3600 loss 0.2453872114419937
[2025-03-23 20:47:55,201][model][INFO] - Training step 3760 loss 0.055385343730449677
[2025-03-23 20:49:13,208][model][INFO] - Training step 3920 loss 0.0153705645352602
[2025-03-23 20:50:34,392][model][INFO] - Training step 4080 loss 0.0565156415104866
[2025-03-23 20:51:54,717][model][INFO] - Training step 4240 loss 0.036905113607645035
[2025-03-23 20:53:14,434][model][INFO] - Training step 4400 loss 0.023729372769594193
[2025-03-23 20:54:34,553][model][INFO] - Training step 4560 loss 0.025358207523822784
[2025-03-23 20:55:56,447][model][INFO] - Training step 4720 loss 0.021020393818616867
[2025-03-23 20:57:13,133][model][INFO] - Training step 4880 loss 0.0115277748554945
[2025-03-23 20:58:32,954][model][INFO] - Training step 5040 loss 0.0022850933019071817
[2025-03-23 20:59:50,454][model][INFO] - Training step 5200 loss 0.007161114364862442
[2025-03-23 21:01:08,339][model][INFO] - Training step 5360 loss 0.04334171116352081
[2025-03-23 21:02:29,598][model][INFO] - Training step 5520 loss 0.2641361951828003
[2025-03-23 21:03:50,749][model][INFO] - Training step 5680 loss 0.02272183448076248
[2025-03-23 21:05:08,859][model][INFO] - Training step 5840 loss 0.2506048381328583
[2025-03-23 21:06:29,027][model][INFO] - Training step 6000 loss 0.270910382270813
[2025-03-23 21:07:48,368][model][INFO] - Training step 6160 loss 0.019270703196525574
[2025-03-23 21:09:10,273][model][INFO] - Training step 6320 loss 0.2776663303375244
[2025-03-23 21:10:29,069][model][INFO] - Training step 6480 loss 0.043575603514909744
[2025-03-23 21:11:51,544][model][INFO] - Training step 6640 loss 0.26123616099357605
[2025-03-23 21:13:12,264][model][INFO] - Training step 6800 loss 0.016019528731703758
[2025-03-23 21:14:30,995][model][INFO] - Training step 6960 loss 0.024669058620929718
[2025-03-23 21:15:50,892][model][INFO] - Training step 7120 loss 0.048779651522636414
[2025-03-23 21:17:12,945][model][INFO] - Training step 7280 loss 0.2549486756324768
[2025-03-23 21:18:34,551][model][INFO] - Training step 7440 loss 0.24304692447185516
[2025-03-23 21:19:55,565][model][INFO] - Training step 7600 loss 0.024884022772312164
[2025-03-23 21:21:17,398][model][INFO] - Training step 7760 loss 0.028324484825134277
[2025-03-23 21:22:40,348][model][INFO] - Training step 7920 loss 0.03815257549285889
[2025-03-23 21:23:59,725][model][INFO] - Training step 8080 loss 0.0028225923888385296
[2025-03-23 21:25:19,369][model][INFO] - Training step 8240 loss 0.024179968982934952
[2025-03-23 21:26:37,843][model][INFO] - Training step 8400 loss 0.049921683967113495
[2025-03-23 21:27:55,997][model][INFO] - Training step 8560 loss 0.02473977580666542
[2025-03-23 21:29:16,513][model][INFO] - Training step 8720 loss 0.14016284048557281
[2025-03-23 21:30:40,294][model][INFO] - Training step 8880 loss 0.02040788345038891
[2025-03-23 21:32:01,184][model][INFO] - Training step 9040 loss 0.031672727316617966
[2025-03-23 21:33:19,989][model][INFO] - Training step 9200 loss 0.022677700966596603
[2025-03-23 21:34:38,147][model][INFO] - Training step 9360 loss 0.029066085815429688
[2025-03-23 21:35:56,825][model][INFO] - Training step 9520 loss 0.012987105175852776
[2025-03-23 21:37:17,496][model][INFO] - Training step 9680 loss 0.11301635950803757
[2025-03-23 21:38:37,269][model][INFO] - Training step 9840 loss 0.03939879685640335
[2025-03-23 21:39:59,887][model][INFO] - Training step 10000 loss 0.03610791265964508
[2025-03-23 21:41:19,406][model][INFO] - Training step 10160 loss 0.019988613203167915
[2025-03-23 21:42:37,325][model][INFO] - Training step 10320 loss 0.01745208352804184
[2025-03-23 21:43:56,045][model][INFO] - Training step 10480 loss 0.004783078096807003
[2025-03-23 21:45:16,528][model][INFO] - Training step 10640 loss 0.28256383538246155
[2025-03-23 21:46:35,443][model][INFO] - Training step 10800 loss 0.030487297102808952
[2025-03-23 21:47:57,551][model][INFO] - Training step 10960 loss 0.09231679141521454
[2025-03-23 21:49:18,333][model][INFO] - Training step 11120 loss 0.25736185908317566
[2025-03-23 21:50:36,800][model][INFO] - Training step 11280 loss 0.03833220154047012
[2025-03-23 21:51:54,876][model][INFO] - Training step 11440 loss 0.2604362368583679
[2025-03-23 21:53:11,894][model][INFO] - Training step 11600 loss 0.015685420483350754
[2025-03-23 21:54:34,256][model][INFO] - Training step 11760 loss 0.04850532114505768
[2025-03-23 21:55:51,275][model][INFO] - Training step 11920 loss 0.003756043268367648
[2025-03-23 21:57:13,959][model][INFO] - Training step 12080 loss 0.04021330177783966
[2025-03-23 21:58:36,845][model][INFO] - Training step 12240 loss 0.13374201953411102
[2025-03-23 21:59:57,647][model][INFO] - Training step 12400 loss 0.07358068227767944
[2025-03-23 22:01:15,404][model][INFO] - Training step 12560 loss 0.04565645009279251
[2025-03-23 22:02:33,587][model][INFO] - Training step 12720 loss 0.22040611505508423
[2025-03-23 22:03:51,944][model][INFO] - Training step 12880 loss 0.003478731494396925
[2025-03-23 22:05:10,813][model][INFO] - Training step 13040 loss 0.02755122259259224
[2025-03-23 22:06:30,649][model][INFO] - Training step 13200 loss 0.24784591794013977
[2025-03-23 22:07:52,614][model][INFO] - Training step 13360 loss 0.05403143912553787
[2025-03-23 22:09:12,211][model][INFO] - Training step 13520 loss 0.26842200756073
[2025-03-23 22:10:32,235][model][INFO] - Training step 13680 loss 0.01816195249557495
[2025-03-23 22:11:54,225][model][INFO] - Training step 13840 loss 0.1227526068687439
[2025-03-23 22:13:13,788][model][INFO] - Training step 14000 loss 0.02518671564757824
[2025-03-23 22:14:31,989][model][INFO] - Training step 14160 loss 0.032825812697410583
[2025-03-23 22:15:52,154][model][INFO] - Training step 14320 loss 0.018474601209163666
[2025-03-23 22:17:11,187][model][INFO] - Training step 14480 loss 0.00647894199937582
[2025-03-23 22:18:33,214][model][INFO] - Training step 14640 loss 0.01716403290629387
[2025-03-23 22:19:49,807][model][INFO] - Training step 14800 loss 0.0454479455947876
[2025-03-23 22:21:11,402][model][INFO] - Training step 14960 loss 0.016331061720848083
[2025-03-23 22:22:33,619][model][INFO] - Training step 15120 loss 0.01692444086074829
[2025-03-23 22:23:51,869][model][INFO] - Training step 15280 loss 0.0397874116897583
[2025-03-23 22:25:11,564][model][INFO] - Training step 15440 loss 0.016242429614067078
[2025-03-23 22:26:29,502][model][INFO] - Training step 15600 loss 0.11374763399362564
[2025-03-23 22:27:51,117][model][INFO] - Training step 15760 loss 0.007815998047590256
[2025-03-23 22:29:11,214][model][INFO] - Training step 15920 loss 0.03286447748541832
[2025-03-23 22:30:30,163][model][INFO] - Training step 16080 loss 0.2484445571899414
[2025-03-23 22:31:51,192][model][INFO] - Training step 16240 loss 0.07168232649564743
[2025-03-23 22:33:12,773][model][INFO] - Training step 16400 loss 0.0035140931140631437
[2025-03-23 22:34:31,256][model][INFO] - Training step 16560 loss 0.036296308040618896
[2025-03-23 22:35:48,434][model][INFO] - Training step 16720 loss 0.07415133714675903
[2025-03-23 22:37:11,408][model][INFO] - Training step 16880 loss 0.24984689056873322
[2025-03-23 22:38:31,017][model][INFO] - Training step 17040 loss 0.16981695592403412
[2025-03-23 22:39:53,358][model][INFO] - Training step 17200 loss 0.03902754932641983
[2025-03-23 22:41:12,188][model][INFO] - Training step 17360 loss 0.04633912071585655
[2025-03-23 22:42:31,111][model][INFO] - Training step 17520 loss 0.04679546877741814
[2025-03-23 22:43:52,788][model][INFO] - Training step 17680 loss 0.022365707904100418
[2025-03-23 22:45:11,419][model][INFO] - Training step 17840 loss 0.03311634063720703
[2025-03-23 22:46:32,885][model][INFO] - Training step 18000 loss 0.03628632426261902
[2025-03-23 22:47:51,812][model][INFO] - Training step 18160 loss 0.034602247178554535
[2025-03-23 22:49:13,978][model][INFO] - Training step 18320 loss 0.024035902693867683
[2025-03-23 22:50:36,005][model][INFO] - Training step 18480 loss 0.042253389954566956
[2025-03-23 22:52:00,390][model][INFO] - Training step 18640 loss 0.07787914574146271
[2025-03-23 22:53:18,055][model][INFO] - Training step 18800 loss 0.059176504611968994
[2025-03-23 22:54:36,078][model][INFO] - Training step 18960 loss 0.03992066532373428
[2025-03-23 22:55:54,134][model][INFO] - Training step 19120 loss 0.23257246613502502
[2025-03-23 22:57:11,387][model][INFO] - Training step 19280 loss 0.027523182332515717
[2025-03-23 22:58:31,519][model][INFO] - Training step 19440 loss 0.005091800354421139
[2025-03-23 22:59:55,516][model][INFO] - Training step 19600 loss 0.06736715137958527
[2025-03-23 23:01:13,097][model][INFO] - Training step 19760 loss 0.07834019511938095
[2025-03-23 23:02:34,031][model][INFO] - Training step 19920 loss 0.05062510818243027
[2025-03-23 23:03:55,521][model][INFO] - Training step 20080 loss 0.0381845161318779
[2025-03-23 23:05:15,354][model][INFO] - Training step 20240 loss 0.24201694130897522
[2025-03-23 23:06:35,427][model][INFO] - Training step 20400 loss 0.13913002610206604
[2025-03-23 23:07:53,772][model][INFO] - Training step 20560 loss 0.2546941041946411
[2025-03-23 23:09:17,323][model][INFO] - Training step 20720 loss 0.00566271785646677
[2025-03-23 23:10:36,164][model][INFO] - Training step 20880 loss 0.0986865982413292
[2025-03-23 23:11:56,147][model][INFO] - Training step 21040 loss 0.003228612942621112
[2025-03-23 23:13:18,916][model][INFO] - Training step 21200 loss 0.023661501705646515
[2025-03-23 23:14:41,692][model][INFO] - Training step 21360 loss 0.015586033463478088
[2025-03-23 23:16:03,076][model][INFO] - Training step 21520 loss 0.011875588446855545
[2025-03-23 23:17:21,132][model][INFO] - Training step 21680 loss 0.022891424596309662
[2025-03-23 23:18:45,130][model][INFO] - Training step 21840 loss 0.10915819555521011
[2025-03-23 23:20:05,236][model][INFO] - Training step 22000 loss 0.027880894020199776
[2025-03-23 23:21:25,322][model][INFO] - Training step 22160 loss 0.008358223363757133
[2025-03-23 23:22:46,929][model][INFO] - Training step 22320 loss 0.03164573386311531
[2025-03-23 23:24:05,171][model][INFO] - Training step 22480 loss 0.2481480836868286
[2025-03-23 23:25:25,461][model][INFO] - Training step 22640 loss 0.023878201842308044
[2025-03-23 23:26:45,426][model][INFO] - Training step 22800 loss 0.040247246623039246
[2025-03-23 23:28:06,685][model][INFO] - Training step 22960 loss 0.03350048512220383
[2025-03-23 23:29:26,337][model][INFO] - Training step 23120 loss 0.2631521224975586
[2025-03-23 23:30:48,133][model][INFO] - Training step 23280 loss 0.040986932814121246
[2025-03-23 23:32:08,687][model][INFO] - Training step 23440 loss 0.07136425375938416
[2025-03-23 23:33:26,407][model][INFO] - Training step 23600 loss 0.06950253248214722
[2025-03-23 23:34:44,102][model][INFO] - Training step 23760 loss 0.04932321235537529
[2025-03-23 23:36:03,509][model][INFO] - Training step 23920 loss 0.03766896203160286
[2025-03-23 23:37:22,682][model][INFO] - Training step 24080 loss 0.04012800753116608
[2025-03-23 23:38:39,557][model][INFO] - Training step 24240 loss 0.05575518310070038
[2025-03-23 23:39:58,787][model][INFO] - Training step 24400 loss 0.08037108182907104
[2025-03-23 23:41:17,238][model][INFO] - Training step 24560 loss 0.028852511197328568
[2025-03-23 23:42:37,404][model][INFO] - Training step 24720 loss 0.025802891701459885
[2025-03-23 23:43:58,480][model][INFO] - Training step 24880 loss 0.10852673649787903
[2025-03-23 23:45:16,178][model][INFO] - Training step 25040 loss 0.01411370187997818
[2025-03-23 23:46:33,733][model][INFO] - Training step 25200 loss 0.022557353600859642
[2025-03-23 23:47:51,805][model][INFO] - Training step 25360 loss 0.007862156257033348
[2025-03-23 23:49:09,644][model][INFO] - Training step 25520 loss 0.06988154351711273
[2025-03-23 23:50:27,371][model][INFO] - Training step 25680 loss 0.017701484262943268
[2025-03-23 23:51:45,143][model][INFO] - Training step 25840 loss 0.04355672001838684
[2025-03-23 23:53:06,785][model][INFO] - Training step 26000 loss 0.07914486527442932
[2025-03-23 23:54:26,988][model][INFO] - Training step 26160 loss 0.0372118279337883
[2025-03-23 23:55:47,351][model][INFO] - Training step 26320 loss 0.24688206613063812
[2025-03-23 23:57:08,099][model][INFO] - Training step 26480 loss 0.24422687292099
[2025-03-23 23:58:29,233][model][INFO] - Training step 26640 loss 0.03038937970995903
[2025-03-23 23:59:47,063][model][INFO] - Training step 26800 loss 0.010407032445073128
[2025-03-24 00:01:05,725][model][INFO] - Training step 26960 loss 0.029737532138824463
[2025-03-24 00:02:26,367][model][INFO] - Training step 27120 loss 0.2309453934431076
[2025-03-24 00:03:48,471][model][INFO] - Training step 27280 loss 0.005606587044894695
[2025-03-24 00:05:09,764][model][INFO] - Training step 27440 loss 0.0835118219256401
[2025-03-24 00:06:27,840][model][INFO] - Training step 27600 loss 0.05088002234697342
[2025-03-24 00:07:47,774][model][INFO] - Training step 27760 loss 0.2489941269159317
[2025-03-24 00:09:06,416][model][INFO] - Training step 27920 loss 0.003627147525548935
[2025-03-24 00:10:28,476][model][INFO] - Training step 28080 loss 0.03188806027173996
[2025-03-24 00:11:46,568][model][INFO] - Training step 28240 loss 0.11145617812871933
[2025-03-24 00:13:04,274][model][INFO] - Training step 28400 loss 0.1077929213643074
[2025-03-24 00:14:24,339][model][INFO] - Training step 28560 loss 0.003778603859245777
[2025-03-24 00:15:39,680][model][INFO] - Training step 28720 loss 0.2420741617679596
[2025-03-24 00:17:00,552][model][INFO] - Training step 28880 loss 0.016724763438105583
[2025-03-24 00:18:21,117][model][INFO] - Training step 29040 loss 0.02536199614405632
[2025-03-24 00:19:39,260][model][INFO] - Training step 29200 loss 0.030809476971626282
[2025-03-24 00:21:00,895][model][INFO] - Training step 29360 loss 0.00753022963181138
[2025-03-24 00:22:21,653][model][INFO] - Training step 29520 loss 0.006414065137505531
[2025-03-24 00:23:46,970][model][INFO] - Training step 29680 loss 0.028936980292201042
[2025-03-24 00:25:07,034][model][INFO] - Training step 29840 loss 0.03018636256456375
[2025-03-24 00:26:32,476][model][INFO] - Training step 30000 loss 0.02306213229894638
[2025-03-24 00:27:52,373][model][INFO] - Training step 30160 loss 0.25012660026550293
[2025-03-24 00:29:12,683][model][INFO] - Training step 30320 loss 0.020954683423042297
[2025-03-24 00:30:37,906][model][INFO] - Training step 30480 loss 0.02006492391228676
[2025-03-24 00:31:56,105][model][INFO] - Training step 30640 loss 0.02209566906094551
[2025-03-24 00:33:13,711][model][INFO] - Training step 30800 loss 0.04995659738779068
[2025-03-24 00:34:34,631][model][INFO] - Training step 30960 loss 0.02774742804467678
[2025-03-24 00:35:56,731][model][INFO] - Training step 31120 loss 0.2502358853816986
[2025-03-24 00:37:13,044][model][INFO] - Training step 31280 loss 0.05316232889890671
[2025-03-24 00:38:32,416][model][INFO] - Training step 31440 loss 0.033786624670028687
[2025-03-24 00:39:51,266][model][INFO] - Training step 31600 loss 0.042118944227695465
[2025-03-24 00:41:10,480][model][INFO] - Training step 31760 loss 0.10416201502084732
[2025-03-24 00:42:33,439][model][INFO] - Training step 31920 loss 0.02552781254053116
[2025-03-24 00:43:54,626][model][INFO] - Training step 32080 loss 0.0205159243196249
[2025-03-24 00:45:15,347][model][INFO] - Training step 32240 loss 0.01718199998140335
[2025-03-24 00:46:35,710][model][INFO] - Training step 32400 loss 0.08606430888175964
[2025-03-24 00:47:58,207][model][INFO] - Training step 32560 loss 0.07040978968143463
[2025-03-24 00:49:20,796][model][INFO] - Training step 32720 loss 0.03125613182783127
[2025-03-24 00:50:43,280][model][INFO] - Training step 32880 loss 0.030575741082429886
[2025-03-24 00:52:04,870][model][INFO] - Training step 33040 loss 0.05350527539849281
[2025-03-24 00:53:26,001][model][INFO] - Training step 33200 loss 0.08293888717889786
[2025-03-24 00:54:48,608][model][INFO] - Training step 33360 loss 0.008231399580836296
[2025-03-24 00:56:10,555][model][INFO] - Training step 33520 loss 0.03582419082522392
[2025-03-24 00:57:30,719][model][INFO] - Training step 33680 loss 0.01099557988345623
[2025-03-24 00:58:53,509][model][INFO] - Training step 33840 loss 0.05541708320379257
[2025-03-24 01:00:10,346][model][INFO] - Training step 34000 loss 0.023758772760629654
[2025-03-24 01:01:32,310][model][INFO] - Training step 34160 loss 0.26012715697288513
[2025-03-24 01:02:50,741][model][INFO] - Training step 34320 loss 0.10820841044187546
[2025-03-24 01:04:15,340][model][INFO] - Training step 34480 loss 0.1581977903842926
[2025-03-24 01:05:38,525][model][INFO] - Training step 34640 loss 0.03430210053920746
[2025-03-24 01:06:57,510][model][INFO] - Training step 34800 loss 0.25496309995651245
[2025-03-24 01:08:18,732][model][INFO] - Training step 34960 loss 0.044755369424819946
[2025-03-24 01:09:39,684][model][INFO] - Training step 35120 loss 0.012796793133020401
[2025-03-24 01:10:59,624][model][INFO] - Training step 35280 loss 0.04212753102183342
[2025-03-24 01:12:21,095][model][INFO] - Training step 35440 loss 0.013638822361826897
[2025-03-24 01:13:40,822][model][INFO] - Training step 35600 loss 0.26056262850761414
[2025-03-24 01:15:00,755][model][INFO] - Training step 35760 loss 0.021593943238258362
[2025-03-24 01:16:16,622][model][INFO] - Training step 35920 loss 0.2440975159406662
[2025-03-24 01:17:38,461][model][INFO] - Training step 36080 loss 0.006931855343282223
[2025-03-24 01:18:58,816][model][INFO] - Training step 36240 loss 0.019656561315059662
[2025-03-24 01:20:18,963][model][INFO] - Training step 36400 loss 0.009758674539625645
[2025-03-24 01:21:38,732][model][INFO] - Training step 36560 loss 0.02401452511548996
[2025-03-24 01:22:57,209][model][INFO] - Training step 36720 loss 0.024729706346988678
[2025-03-24 01:24:16,031][model][INFO] - Training step 36880 loss 0.1280391365289688
[2025-03-24 01:25:38,096][model][INFO] - Training step 37040 loss 0.009127325378358364
[2025-03-24 01:27:01,662][model][INFO] - Training step 37200 loss 0.008843975141644478
[2025-03-24 01:28:20,072][model][INFO] - Training step 37360 loss 0.010168490000069141
[2025-03-24 01:29:37,287][model][INFO] - Training step 37520 loss 0.013590591959655285
[2025-03-24 01:30:57,672][model][INFO] - Training step 37680 loss 0.023453418165445328
[2025-03-24 01:32:20,184][model][INFO] - Training step 37840 loss 0.005841548554599285
[2025-03-24 01:33:39,139][model][INFO] - Training step 38000 loss 0.010227940045297146
[2025-03-24 01:34:58,161][model][INFO] - Training step 38160 loss 0.02127934992313385
[2025-03-24 01:36:17,402][model][INFO] - Training step 38320 loss 0.2497108280658722
[2025-03-24 01:37:38,432][model][INFO] - Training step 38480 loss 0.045928359031677246
[2025-03-24 01:38:58,323][model][INFO] - Training step 38640 loss 0.0040618241764605045
[2025-03-24 01:40:17,932][model][INFO] - Training step 38800 loss 0.013488100841641426
[2025-03-24 01:41:38,509][model][INFO] - Training step 38960 loss 0.022616088390350342
[2025-03-24 01:42:56,255][model][INFO] - Training step 39120 loss 0.018871957436203957
[2025-03-24 01:44:17,820][model][INFO] - Training step 39280 loss 0.025281105190515518
[2025-03-24 01:45:38,451][model][INFO] - Training step 39440 loss 0.049248192459344864
[2025-03-24 01:46:55,985][model][INFO] - Training step 39600 loss 0.021913088858127594
[2025-03-24 01:48:14,559][model][INFO] - Training step 39760 loss 0.021693047136068344
[2025-03-24 01:49:34,083][model][INFO] - Training step 39920 loss 0.017981160432100296
[2025-03-24 01:50:55,105][model][INFO] - Training step 40080 loss 0.005177654325962067
[2025-03-24 01:52:13,944][model][INFO] - Training step 40240 loss 0.031266264617443085
[2025-03-24 01:53:36,087][model][INFO] - Training step 40400 loss 0.004831559956073761
[2025-03-24 01:54:54,066][model][INFO] - Training step 40560 loss 0.11800360679626465
[2025-03-24 01:56:12,726][model][INFO] - Training step 40720 loss 0.03926935791969299
[2025-03-24 01:57:29,282][model][INFO] - Training step 40880 loss 0.019341126084327698
[2025-03-24 01:58:47,764][model][INFO] - Training step 41040 loss 0.004670296795666218
[2025-03-24 02:00:08,255][model][INFO] - Training step 41200 loss 0.24046385288238525
[2025-03-24 02:01:28,967][model][INFO] - Training step 41360 loss 0.028836626559495926
[2025-03-24 02:02:47,540][model][INFO] - Training step 41520 loss 0.03397650271654129
[2025-03-24 02:04:08,726][model][INFO] - Training step 41680 loss 0.060259029269218445
[2025-03-24 02:05:30,519][model][INFO] - Training step 41840 loss 0.2569601535797119
[2025-03-24 02:06:50,520][model][INFO] - Training step 42000 loss 0.03918521851301193
[2025-03-24 02:08:10,663][model][INFO] - Training step 42160 loss 0.03112386167049408
[2025-03-24 02:09:26,269][model][INFO] - Training step 42320 loss 0.03643595427274704
[2025-03-24 02:10:48,098][model][INFO] - Training step 42480 loss 0.03157978132367134
[2025-03-24 02:12:06,988][model][INFO] - Training step 42640 loss 0.23594504594802856
[2025-03-24 02:13:27,487][model][INFO] - Training step 42800 loss 0.09618295729160309
[2025-03-24 02:14:45,505][model][INFO] - Training step 42960 loss 0.018415281549096107
[2025-03-24 02:16:05,225][model][INFO] - Training step 43120 loss 0.14332804083824158
[2025-03-24 02:17:27,171][model][INFO] - Training step 43280 loss 0.2541625499725342
[2025-03-24 02:18:46,211][model][INFO] - Training step 43440 loss 0.036751702427864075
[2025-03-24 02:20:04,549][model][INFO] - Training step 43600 loss 0.013057710602879524
[2025-03-24 02:21:25,655][model][INFO] - Training step 43760 loss 0.028528522700071335
[2025-03-24 02:22:44,151][model][INFO] - Training step 43920 loss 0.1266968548297882
[2025-03-24 02:24:03,490][model][INFO] - Training step 44080 loss 0.005326278042048216
[2025-03-24 02:25:25,041][model][INFO] - Training step 44240 loss 0.023106973618268967
[2025-03-24 02:26:44,950][model][INFO] - Training step 44400 loss 0.04002899304032326
[2025-03-24 02:28:03,108][model][INFO] - Training step 44560 loss 0.03023967519402504
[2025-03-24 02:29:25,980][model][INFO] - Training step 44720 loss 0.03832992911338806
[2025-03-24 02:30:43,372][model][INFO] - Training step 44880 loss 0.05827656015753746
[2025-03-24 02:32:03,006][model][INFO] - Training step 45040 loss 0.25094449520111084
[2025-03-24 02:33:22,767][model][INFO] - Training step 45200 loss 0.052577611058950424
[2025-03-24 02:34:43,962][model][INFO] - Training step 45360 loss 0.019565587863326073
[2025-03-24 02:36:01,205][model][INFO] - Training step 45520 loss 0.044882453978061676
[2025-03-24 02:37:21,631][model][INFO] - Training step 45680 loss 0.009791926480829716
[2025-03-24 02:38:41,570][model][INFO] - Training step 45840 loss 0.27048614621162415
[2025-03-24 02:40:01,720][model][INFO] - Training step 46000 loss 0.27219367027282715
[2025-03-24 02:41:22,083][model][INFO] - Training step 46160 loss 0.030862296000123024
[2025-03-24 02:42:44,652][model][INFO] - Training step 46320 loss 0.06409990787506104
[2025-03-24 02:44:03,882][model][INFO] - Training step 46480 loss 0.24973919987678528
[2025-03-24 02:45:23,352][model][INFO] - Training step 46640 loss 0.0997474193572998
[2025-03-24 02:46:42,552][model][INFO] - Training step 46800 loss 0.25266924500465393
[2025-03-24 02:48:03,168][model][INFO] - Training step 46960 loss 0.031196556985378265
[2025-03-24 02:49:20,041][model][INFO] - Training step 47120 loss 0.03813432157039642
[2025-03-24 02:50:39,611][model][INFO] - Training step 47280 loss 0.019297851249575615
[2025-03-24 02:51:58,618][model][INFO] - Training step 47440 loss 0.014724291861057281
[2025-03-24 02:53:19,177][model][INFO] - Training step 47600 loss 0.09518252313137054
[2025-03-24 02:54:42,086][model][INFO] - Training step 47760 loss 0.006342089269310236
[2025-03-24 02:55:59,225][model][INFO] - Training step 47920 loss 0.031121065840125084
[2025-03-24 02:57:20,231][model][INFO] - Training step 48080 loss 0.02816167101264
[2025-03-24 02:58:36,888][model][INFO] - Training step 48240 loss 0.020863639190793037
[2025-03-24 02:59:56,695][model][INFO] - Training step 48400 loss 0.06724005937576294
[2025-03-24 03:01:14,765][model][INFO] - Training step 48560 loss 0.036356523633003235
[2025-03-24 03:02:35,772][model][INFO] - Training step 48720 loss 0.02849370241165161
[2025-03-24 03:03:52,764][model][INFO] - Training step 48880 loss 0.018805798143148422
[2025-03-24 03:05:13,820][model][INFO] - Training step 49040 loss 0.25113794207572937
[2025-03-24 03:06:35,167][model][INFO] - Training step 49200 loss 0.03444264084100723
[2025-03-24 03:07:53,796][model][INFO] - Training step 49360 loss 0.029564090073108673
[2025-03-24 03:09:13,248][model][INFO] - Training step 49520 loss 0.03847673907876015
[2025-03-24 03:10:33,264][model][INFO] - Training step 49680 loss 0.004954509437084198
[2025-03-24 03:11:53,735][model][INFO] - Training step 49840 loss 0.005732300691306591
[2025-03-24 03:13:15,399][model][INFO] - Training step 50000 loss 0.02971780113875866
[2025-03-24 03:14:37,514][model][INFO] - Training step 50160 loss 0.02031223103404045
[2025-03-24 03:15:55,586][model][INFO] - Training step 50320 loss 0.24693521857261658
[2025-03-24 03:17:13,402][model][INFO] - Training step 50480 loss 0.02801656350493431
[2025-03-24 03:18:32,002][model][INFO] - Training step 50640 loss 0.019186723977327347
[2025-03-24 03:28:07,113][model][INFO] - Training step 0 loss 0.021439794450998306
[2025-03-24 03:29:29,471][model][INFO] - Training step 160 loss 0.013723605312407017
[2025-03-24 03:30:47,631][model][INFO] - Training step 320 loss 0.025897745043039322
[2025-03-24 03:32:08,117][model][INFO] - Training step 480 loss 0.21924450993537903
[2025-03-24 03:33:25,862][model][INFO] - Training step 640 loss 0.044903382658958435
[2025-03-24 03:34:46,395][model][INFO] - Training step 800 loss 0.030075691640377045
[2025-03-24 03:36:05,035][model][INFO] - Training step 960 loss 0.031633615493774414
[2025-03-24 03:37:22,505][model][INFO] - Training step 1120 loss 0.055475011467933655
[2025-03-24 03:38:44,092][model][INFO] - Training step 1280 loss 0.018859470263123512
[2025-03-24 03:40:03,216][model][INFO] - Training step 1440 loss 0.028299294412136078
[2025-03-24 03:41:20,252][model][INFO] - Training step 1600 loss 0.05210281163454056
[2025-03-24 03:42:40,850][model][INFO] - Training step 1760 loss 0.2372775673866272
[2025-03-24 03:44:00,531][model][INFO] - Training step 1920 loss 0.04299384355545044
[2025-03-24 03:45:18,013][model][INFO] - Training step 2080 loss 0.2513488531112671
[2025-03-24 03:46:35,983][model][INFO] - Training step 2240 loss 0.005195880774408579
[2025-03-24 03:47:55,918][model][INFO] - Training step 2400 loss 0.034864168614149094
[2025-03-24 03:49:14,052][model][INFO] - Training step 2560 loss 0.15464265644550323
[2025-03-24 03:50:34,067][model][INFO] - Training step 2720 loss 0.004361423198133707
[2025-03-24 03:51:52,579][model][INFO] - Training step 2880 loss 0.039857298135757446
[2025-03-24 03:53:13,830][model][INFO] - Training step 3040 loss 0.006710004061460495
[2025-03-24 03:54:34,862][model][INFO] - Training step 3200 loss 0.05062497779726982
[2025-03-24 03:55:51,445][model][INFO] - Training step 3360 loss 0.2763825058937073
[2025-03-24 03:57:09,468][model][INFO] - Training step 3520 loss 0.004740213043987751
[2025-03-24 03:58:27,518][model][INFO] - Training step 3680 loss 0.02781779319047928
[2025-03-24 03:59:47,061][model][INFO] - Training step 3840 loss 0.05680660530924797
[2025-03-24 04:01:06,281][model][INFO] - Training step 4000 loss 0.034704018384218216
[2025-03-24 04:02:28,078][model][INFO] - Training step 4160 loss 0.25385236740112305
[2025-03-24 04:03:44,965][model][INFO] - Training step 4320 loss 0.25607815384864807
[2025-03-24 04:05:05,100][model][INFO] - Training step 4480 loss 0.0021288807038217783
[2025-03-24 04:06:28,379][model][INFO] - Training step 4640 loss 0.0329180508852005
[2025-03-24 04:07:46,559][model][INFO] - Training step 4800 loss 0.030259259045124054
[2025-03-24 04:09:01,048][model][INFO] - Training step 4960 loss 0.018347609788179398
[2025-03-24 04:10:24,050][model][INFO] - Training step 5120 loss 0.12142305076122284
[2025-03-24 04:11:41,674][model][INFO] - Training step 5280 loss 0.028654906898736954
[2025-03-24 04:12:58,191][model][INFO] - Training step 5440 loss 0.042999785393476486
[2025-03-24 04:14:14,971][model][INFO] - Training step 5600 loss 0.022151771932840347
[2025-03-24 04:15:35,716][model][INFO] - Training step 5760 loss 0.025727320462465286
[2025-03-24 04:16:56,979][model][INFO] - Training step 5920 loss 0.02229941636323929
[2025-03-24 04:18:16,276][model][INFO] - Training step 6080 loss 0.004650555085390806
[2025-03-24 04:19:35,583][model][INFO] - Training step 6240 loss 0.08442854136228561
[2025-03-24 04:20:55,272][model][INFO] - Training step 6400 loss 0.02631940320134163
[2025-03-24 04:22:13,818][model][INFO] - Training step 6560 loss 0.10213323682546616
[2025-03-24 04:23:33,639][model][INFO] - Training step 6720 loss 0.015101789496839046
[2025-03-24 04:24:52,677][model][INFO] - Training step 6880 loss 0.08941242098808289
[2025-03-24 04:26:12,759][model][INFO] - Training step 7040 loss 0.026479721069335938
[2025-03-24 04:27:37,357][model][INFO] - Training step 7200 loss 0.019603148102760315
[2025-03-24 04:28:54,830][model][INFO] - Training step 7360 loss 0.025373002514243126
[2025-03-24 04:30:14,747][model][INFO] - Training step 7520 loss 0.2485349476337433
[2025-03-24 04:31:35,201][model][INFO] - Training step 7680 loss 0.10712634772062302
[2025-03-24 04:32:53,114][model][INFO] - Training step 7840 loss 0.027066674083471298
[2025-03-24 04:34:12,517][model][INFO] - Training step 8000 loss 0.03327763080596924
[2025-03-24 04:35:31,854][model][INFO] - Training step 8160 loss 0.015100063756108284
[2025-03-24 04:36:49,696][model][INFO] - Training step 8320 loss 0.0344124436378479
[2025-03-24 04:38:08,432][model][INFO] - Training step 8480 loss 0.07906155288219452
[2025-03-24 04:39:23,882][model][INFO] - Training step 8640 loss 0.2756234109401703
[2025-03-24 04:40:42,511][model][INFO] - Training step 8800 loss 0.004163756966590881
[2025-03-24 04:42:00,657][model][INFO] - Training step 8960 loss 0.0441260039806366
[2025-03-24 04:43:17,700][model][INFO] - Training step 9120 loss 0.0532277375459671
[2025-03-24 04:44:38,594][model][INFO] - Training step 9280 loss 0.03679526224732399
[2025-03-24 04:45:59,198][model][INFO] - Training step 9440 loss 0.014124855399131775
[2025-03-24 04:47:19,052][model][INFO] - Training step 9600 loss 0.0599898099899292
[2025-03-24 04:48:39,983][model][INFO] - Training step 9760 loss 0.005176130682229996
[2025-03-24 04:50:03,322][model][INFO] - Training step 9920 loss 0.10977961122989655
[2025-03-24 04:51:24,254][model][INFO] - Training step 10080 loss 0.00736392755061388
[2025-03-24 04:52:41,719][model][INFO] - Training step 10240 loss 0.2434130162000656
[2025-03-24 04:53:59,554][model][INFO] - Training step 10400 loss 0.05158350244164467
[2025-03-24 04:55:18,779][model][INFO] - Training step 10560 loss 0.11385052651166916
[2025-03-24 04:56:37,048][model][INFO] - Training step 10720 loss 0.0042982203885912895
[2025-03-24 04:57:54,553][model][INFO] - Training step 10880 loss 0.2563703656196594
[2025-03-24 04:59:14,976][model][INFO] - Training step 11040 loss 0.02761233225464821
[2025-03-24 05:00:33,627][model][INFO] - Training step 11200 loss 0.007167395204305649
[2025-03-24 05:01:53,097][model][INFO] - Training step 11360 loss 0.024278949946165085
[2025-03-24 05:03:11,334][model][INFO] - Training step 11520 loss 0.15159791707992554
[2025-03-24 05:04:29,537][model][INFO] - Training step 11680 loss 0.035786520689725876
[2025-03-24 05:05:50,338][model][INFO] - Training step 11840 loss 0.02155076339840889
[2025-03-24 05:07:10,935][model][INFO] - Training step 12000 loss 0.033086322247982025
[2025-03-24 05:08:31,353][model][INFO] - Training step 12160 loss 0.0754806399345398
[2025-03-24 05:09:49,244][model][INFO] - Training step 12320 loss 0.2481372058391571
[2025-03-24 05:11:09,178][model][INFO] - Training step 12480 loss 0.034260787069797516
[2025-03-24 05:12:27,273][model][INFO] - Training step 12640 loss 0.07151338458061218
[2025-03-24 05:13:46,853][model][INFO] - Training step 12800 loss 0.0022684575524181128
[2025-03-24 05:15:06,069][model][INFO] - Training step 12960 loss 0.046866368502378464
[2025-03-24 05:16:27,489][model][INFO] - Training step 13120 loss 0.017109543085098267
[2025-03-24 05:17:44,875][model][INFO] - Training step 13280 loss 0.012208754196763039
[2025-03-24 05:19:02,190][model][INFO] - Training step 13440 loss 0.03828249126672745
[2025-03-24 05:20:23,207][model][INFO] - Training step 13600 loss 0.024003546684980392
[2025-03-24 05:21:42,901][model][INFO] - Training step 13760 loss 0.02591700106859207
[2025-03-24 05:23:02,334][model][INFO] - Training step 13920 loss 0.12161564081907272
[2025-03-24 05:24:19,749][model][INFO] - Training step 14080 loss 0.05113938823342323
[2025-03-24 05:25:38,580][model][INFO] - Training step 14240 loss 0.5982831120491028
[2025-03-24 05:26:56,322][model][INFO] - Training step 14400 loss 0.2599525451660156
[2025-03-24 05:28:13,670][model][INFO] - Training step 14560 loss 0.03673773258924484
[2025-03-24 05:29:34,272][model][INFO] - Training step 14720 loss 0.2528366148471832
[2025-03-24 05:30:54,492][model][INFO] - Training step 14880 loss 0.04385298863053322
[2025-03-24 05:32:15,587][model][INFO] - Training step 15040 loss 0.06793473660945892
[2025-03-24 05:33:36,150][model][INFO] - Training step 15200 loss 0.03534679859876633
[2025-03-24 05:34:54,711][model][INFO] - Training step 15360 loss 0.030411135405302048
[2025-03-24 05:36:14,414][model][INFO] - Training step 15520 loss 0.015480647794902325
[2025-03-24 05:37:31,673][model][INFO] - Training step 15680 loss 0.01954563707113266
[2025-03-24 05:38:51,400][model][INFO] - Training step 15840 loss 0.034544602036476135
[2025-03-24 05:40:11,276][model][INFO] - Training step 16000 loss 0.2580340504646301
[2025-03-24 05:41:32,041][model][INFO] - Training step 16160 loss 0.05079600214958191
[2025-03-24 05:42:51,579][model][INFO] - Training step 16320 loss 0.006067377049475908
[2025-03-24 05:44:09,337][model][INFO] - Training step 16480 loss 0.024274423718452454
[2025-03-24 05:45:28,752][model][INFO] - Training step 16640 loss 0.010972539894282818
[2025-03-24 05:46:47,061][model][INFO] - Training step 16800 loss 0.045956823974847794
[2025-03-24 05:48:05,536][model][INFO] - Training step 16960 loss 0.029673952609300613
[2025-03-24 05:49:23,551][model][INFO] - Training step 17120 loss 0.06384022533893585
[2025-03-24 05:50:45,091][model][INFO] - Training step 17280 loss 0.029055988416075706
[2025-03-24 05:52:03,983][model][INFO] - Training step 17440 loss 0.029191959649324417
[2025-03-24 05:53:26,098][model][INFO] - Training step 17600 loss 0.027982892468571663
[2025-03-24 05:54:45,836][model][INFO] - Training step 17760 loss 0.005913021042943001
[2025-03-24 05:56:03,390][model][INFO] - Training step 17920 loss 0.26635703444480896
[2025-03-24 05:57:22,280][model][INFO] - Training step 18080 loss 0.05318039655685425
[2025-03-24 05:58:41,187][model][INFO] - Training step 18240 loss 0.05597493052482605
[2025-03-24 06:00:01,670][model][INFO] - Training step 18400 loss 0.15607857704162598
[2025-03-24 06:01:20,644][model][INFO] - Training step 18560 loss 0.06194138526916504
[2025-03-24 06:02:41,042][model][INFO] - Training step 18720 loss 0.02283274009823799
[2025-03-24 06:03:58,798][model][INFO] - Training step 18880 loss 0.004836144857108593
[2025-03-24 06:05:14,594][model][INFO] - Training step 19040 loss 0.004011520184576511
[2025-03-24 06:06:32,680][model][INFO] - Training step 19200 loss 0.14391009509563446
[2025-03-24 06:07:49,822][model][INFO] - Training step 19360 loss 0.10177990794181824
[2025-03-24 06:09:10,680][model][INFO] - Training step 19520 loss 0.2275339961051941
[2025-03-24 06:10:32,642][model][INFO] - Training step 19680 loss 0.02819763496518135
[2025-03-24 06:11:51,346][model][INFO] - Training step 19840 loss 0.02231152355670929
[2025-03-24 06:13:13,115][model][INFO] - Training step 20000 loss 0.11619190871715546
[2025-03-24 06:14:33,365][model][INFO] - Training step 20160 loss 0.03942461311817169
[2025-03-24 06:15:52,473][model][INFO] - Training step 20320 loss 0.040301185101270676
[2025-03-24 06:17:10,104][model][INFO] - Training step 20480 loss 0.031301405280828476
[2025-03-24 06:18:30,049][model][INFO] - Training step 20640 loss 0.02560008503496647
[2025-03-24 06:19:49,100][model][INFO] - Training step 20800 loss 0.04851038008928299
[2025-03-24 06:21:11,003][model][INFO] - Training step 20960 loss 0.02887110598385334
[2025-03-24 06:22:30,340][model][INFO] - Training step 21120 loss 0.3538731336593628
[2025-03-24 06:23:51,313][model][INFO] - Training step 21280 loss 0.016306694597005844
[2025-03-24 06:25:10,134][model][INFO] - Training step 21440 loss 0.008982287719845772
[2025-03-24 06:26:28,047][model][INFO] - Training step 21600 loss 0.25522953271865845
[2025-03-24 06:27:47,746][model][INFO] - Training step 21760 loss 0.25601840019226074
[2025-03-24 06:29:07,940][model][INFO] - Training step 21920 loss 0.02279883809387684
[2025-03-24 06:30:30,102][model][INFO] - Training step 22080 loss 0.09087848663330078
[2025-03-24 06:31:49,800][model][INFO] - Training step 22240 loss 0.026544006541371346
[2025-03-24 06:33:08,954][model][INFO] - Training step 22400 loss 0.02881469577550888
[2025-03-24 06:34:27,106][model][INFO] - Training step 22560 loss 0.036871545016765594
[2025-03-24 06:35:50,386][model][INFO] - Training step 22720 loss 0.009519883431494236
[2025-03-24 06:37:06,891][model][INFO] - Training step 22880 loss 0.03173521161079407
[2025-03-24 06:38:26,548][model][INFO] - Training step 23040 loss 0.005371403880417347
[2025-03-24 06:39:45,608][model][INFO] - Training step 23200 loss 0.04241064190864563
[2025-03-24 06:41:05,690][model][INFO] - Training step 23360 loss 0.003466373775154352
[2025-03-24 06:42:25,169][model][INFO] - Training step 23520 loss 0.255618155002594
[2025-03-24 06:43:46,847][model][INFO] - Training step 23680 loss 0.002387578599154949
[2025-03-24 06:45:05,738][model][INFO] - Training step 23840 loss 0.25023719668388367
[2025-03-24 06:46:22,615][model][INFO] - Training step 24000 loss 0.02840130403637886
[2025-03-24 06:47:46,178][model][INFO] - Training step 24160 loss 0.029092172160744667
[2025-03-24 06:49:04,953][model][INFO] - Training step 24320 loss 0.024033915251493454
[2025-03-24 06:50:24,607][model][INFO] - Training step 24480 loss 0.004517893306910992
[2025-03-24 06:51:43,367][model][INFO] - Training step 24640 loss 0.2541194558143616
[2025-03-24 06:53:01,601][model][INFO] - Training step 24800 loss 0.04538869112730026
[2025-03-24 06:54:23,764][model][INFO] - Training step 24960 loss 0.08689159154891968
[2025-03-24 06:55:43,063][model][INFO] - Training step 25120 loss 0.33421164751052856
[2025-03-24 06:57:02,207][model][INFO] - Training step 25280 loss 0.01939591020345688
[2025-03-24 06:58:19,893][model][INFO] - Training step 25440 loss 0.03355094790458679
[2025-03-24 06:59:38,016][model][INFO] - Training step 25600 loss 0.2975981533527374
[2025-03-24 07:00:51,586][model][INFO] - Training step 25760 loss 0.020872056484222412
[2025-03-24 07:02:10,766][model][INFO] - Training step 25920 loss 0.01991475746035576
[2025-03-24 07:03:29,214][model][INFO] - Training step 26080 loss 0.021791528910398483
[2025-03-24 07:04:49,223][model][INFO] - Training step 26240 loss 0.021738145500421524
[2025-03-24 07:06:07,117][model][INFO] - Training step 26400 loss 0.25158464908599854
[2025-03-24 07:07:26,280][model][INFO] - Training step 26560 loss 0.25221848487854004
[2025-03-24 07:08:46,770][model][INFO] - Training step 26720 loss 0.017206352204084396
[2025-03-24 07:10:04,199][model][INFO] - Training step 26880 loss 0.004655103199183941
[2025-03-24 07:11:22,183][model][INFO] - Training step 27040 loss 0.27286434173583984
[2025-03-24 07:12:40,627][model][INFO] - Training step 27200 loss 0.01887122541666031
[2025-03-24 07:13:59,014][model][INFO] - Training step 27360 loss 0.0033162140753120184
[2025-03-24 07:15:21,446][model][INFO] - Training step 27520 loss 0.0034279979299753904
[2025-03-24 07:16:41,239][model][INFO] - Training step 27680 loss 0.018388520926237106
[2025-03-24 07:18:00,265][model][INFO] - Training step 27840 loss 0.024466458708047867
[2025-03-24 07:19:19,302][model][INFO] - Training step 28000 loss 0.0269925519824028
[2025-03-24 07:20:38,008][model][INFO] - Training step 28160 loss 0.01860598661005497
[2025-03-24 07:21:56,444][model][INFO] - Training step 28320 loss 0.23508983850479126
[2025-03-24 07:23:15,080][model][INFO] - Training step 28480 loss 0.008196849375963211
[2025-03-24 07:24:33,951][model][INFO] - Training step 28640 loss 0.03466762602329254
[2025-03-24 07:25:49,623][model][INFO] - Training step 28800 loss 0.0684685930609703
[2025-03-24 07:27:09,778][model][INFO] - Training step 28960 loss 0.007402186281979084
[2025-03-24 07:28:29,960][model][INFO] - Training step 29120 loss 0.03583972156047821
[2025-03-24 07:29:49,278][model][INFO] - Training step 29280 loss 0.04779040068387985
[2025-03-24 07:31:07,501][model][INFO] - Training step 29440 loss 0.05903603509068489
[2025-03-24 07:32:24,623][model][INFO] - Training step 29600 loss 0.057058997452259064
[2025-03-24 07:33:45,340][model][INFO] - Training step 29760 loss 0.2502603530883789
[2025-03-24 07:35:08,178][model][INFO] - Training step 29920 loss 0.03723131865262985
[2025-03-24 07:36:26,582][model][INFO] - Training step 30080 loss 0.0047085825353860855
[2025-03-24 07:37:42,826][model][INFO] - Training step 30240 loss 0.028691092506051064
[2025-03-24 07:39:05,100][model][INFO] - Training step 30400 loss 0.0026615867391228676
[2025-03-24 07:40:22,604][model][INFO] - Training step 30560 loss 0.0535869337618351
[2025-03-24 07:41:38,126][model][INFO] - Training step 30720 loss 0.015562532469630241
[2025-03-24 07:42:54,400][model][INFO] - Training step 30880 loss 0.0053185331635177135
[2025-03-24 07:44:17,476][model][INFO] - Training step 31040 loss 0.06760795414447784
[2025-03-24 07:45:33,947][model][INFO] - Training step 31200 loss 0.023674430325627327
[2025-03-24 07:46:52,140][model][INFO] - Training step 31360 loss 0.023371122777462006
[2025-03-24 07:48:12,306][model][INFO] - Training step 31520 loss 0.0721174031496048
[2025-03-24 07:49:31,788][model][INFO] - Training step 31680 loss 0.03644971549510956
[2025-03-24 07:50:50,285][model][INFO] - Training step 31840 loss 0.0033483575098216534
[2025-03-24 07:52:07,839][model][INFO] - Training step 32000 loss 0.03788578510284424
[2025-03-24 07:53:27,912][model][INFO] - Training step 32160 loss 0.04426330700516701
[2025-03-24 07:54:47,954][model][INFO] - Training step 32320 loss 0.020270846784114838
[2025-03-24 07:56:06,192][model][INFO] - Training step 32480 loss 0.007440727204084396
[2025-03-24 07:57:27,495][model][INFO] - Training step 32640 loss 0.1128399521112442
[2025-03-24 07:58:48,168][model][INFO] - Training step 32800 loss 0.033206693828105927
[2025-03-24 08:00:06,804][model][INFO] - Training step 32960 loss 0.2526172399520874
[2025-03-24 08:01:26,664][model][INFO] - Training step 33120 loss 0.008701901882886887
[2025-03-24 08:02:47,512][model][INFO] - Training step 33280 loss 0.09152153134346008
[2025-03-24 08:04:07,344][model][INFO] - Training step 33440 loss 0.005435410887002945
[2025-03-24 08:05:26,509][model][INFO] - Training step 33600 loss 0.025183450430631638
[2025-03-24 08:06:46,985][model][INFO] - Training step 33760 loss 0.24723047018051147
[2025-03-24 08:08:05,481][model][INFO] - Training step 33920 loss 0.14484193921089172
[2025-03-24 08:09:22,678][model][INFO] - Training step 34080 loss 0.016990039497613907
[2025-03-24 08:10:43,117][model][INFO] - Training step 34240 loss 0.027116548269987106
[2025-03-24 08:12:04,639][model][INFO] - Training step 34400 loss 0.03729161620140076
[2025-03-24 08:13:23,017][model][INFO] - Training step 34560 loss 0.040659062564373016
[2025-03-24 08:14:41,101][model][INFO] - Training step 34720 loss 0.2568530738353729
[2025-03-24 08:16:00,538][model][INFO] - Training step 34880 loss 0.02499435842037201
[2025-03-24 08:17:19,410][model][INFO] - Training step 35040 loss 0.036088086664676666
[2025-03-24 08:18:40,482][model][INFO] - Training step 35200 loss 0.23028923571109772
[2025-03-24 08:19:59,895][model][INFO] - Training step 35360 loss 0.0224319901317358
[2025-03-24 08:21:19,941][model][INFO] - Training step 35520 loss 0.028071220964193344
[2025-03-24 08:22:38,721][model][INFO] - Training step 35680 loss 0.019133735448122025
[2025-03-24 08:23:56,702][model][INFO] - Training step 35840 loss 0.011776916682720184
[2025-03-24 08:25:17,304][model][INFO] - Training step 36000 loss 0.0015778085216879845
[2025-03-24 08:26:38,002][model][INFO] - Training step 36160 loss 0.0017752919811755419
[2025-03-24 08:27:57,528][model][INFO] - Training step 36320 loss 0.012298425659537315
[2025-03-24 08:29:18,630][model][INFO] - Training step 36480 loss 0.023856883868575096
[2025-03-24 08:30:38,974][model][INFO] - Training step 36640 loss 0.028227701783180237
[2025-03-24 08:31:58,906][model][INFO] - Training step 36800 loss 0.0034858067519962788
[2025-03-24 08:33:15,762][model][INFO] - Training step 36960 loss 0.013841177336871624
[2025-03-24 08:34:37,077][model][INFO] - Training step 37120 loss 0.02219432219862938
[2025-03-24 08:35:59,082][model][INFO] - Training step 37280 loss 0.050535064190626144
[2025-03-24 08:37:21,184][model][INFO] - Training step 37440 loss 0.0055986144579946995
[2025-03-24 08:38:39,580][model][INFO] - Training step 37600 loss 0.04568114131689072
[2025-03-24 08:39:57,312][model][INFO] - Training step 37760 loss 0.03231101855635643
[2025-03-24 08:41:15,897][model][INFO] - Training step 37920 loss 0.018636459484696388
[2025-03-24 08:42:34,152][model][INFO] - Training step 38080 loss 0.2491362988948822
[2025-03-24 08:43:56,398][model][INFO] - Training step 38240 loss 0.2540755569934845
[2025-03-24 08:45:18,015][model][INFO] - Training step 38400 loss 0.03019324317574501
[2025-03-24 08:46:35,421][model][INFO] - Training step 38560 loss 0.024740027263760567
[2025-03-24 08:47:55,116][model][INFO] - Training step 38720 loss 0.25539126992225647
[2025-03-24 08:49:13,211][model][INFO] - Training step 38880 loss 0.0374971441924572
[2025-03-24 08:50:35,701][model][INFO] - Training step 39040 loss 0.004479912109673023
[2025-03-24 08:51:55,523][model][INFO] - Training step 39200 loss 0.19980840384960175
[2025-03-24 08:53:17,002][model][INFO] - Training step 39360 loss 0.020363513380289078
[2025-03-24 08:54:35,143][model][INFO] - Training step 39520 loss 0.023282093927264214
[2025-03-24 08:55:54,540][model][INFO] - Training step 39680 loss 0.2786751687526703
[2025-03-24 08:57:13,349][model][INFO] - Training step 39840 loss 0.028742047026753426
[2025-03-24 08:58:34,177][model][INFO] - Training step 40000 loss 0.0043893721885979176
[2025-03-24 08:59:53,265][model][INFO] - Training step 40160 loss 0.03131800889968872
[2025-03-24 09:01:12,932][model][INFO] - Training step 40320 loss 0.00640482222661376
[2025-03-24 09:02:30,863][model][INFO] - Training step 40480 loss 0.00836633238941431
[2025-03-24 09:03:49,700][model][INFO] - Training step 40640 loss 0.05409318581223488
[2025-03-24 09:05:05,718][model][INFO] - Training step 40800 loss 0.19583666324615479
[2025-03-24 09:06:22,442][model][INFO] - Training step 40960 loss 0.023235922679305077
[2025-03-24 09:07:42,136][model][INFO] - Training step 41120 loss 0.008936915546655655
[2025-03-24 09:09:01,036][model][INFO] - Training step 41280 loss 0.06697791814804077
[2025-03-24 09:10:20,997][model][INFO] - Training step 41440 loss 0.04636242985725403
[2025-03-24 09:11:41,291][model][INFO] - Training step 41600 loss 0.00561184948310256
[2025-03-24 09:12:58,319][model][INFO] - Training step 41760 loss 0.015973903238773346
[2025-03-24 09:14:19,001][model][INFO] - Training step 41920 loss 0.03183542191982269
[2025-03-24 09:15:42,508][model][INFO] - Training step 42080 loss 0.004529766738414764
[2025-03-24 09:17:02,248][model][INFO] - Training step 42240 loss 0.025741714984178543
[2025-03-24 09:18:22,768][model][INFO] - Training step 42400 loss 0.2534150183200836
[2025-03-24 09:19:44,162][model][INFO] - Training step 42560 loss 0.021694181486964226
[2025-03-24 09:21:03,839][model][INFO] - Training step 42720 loss 0.0424547977745533
[2025-03-24 09:22:21,833][model][INFO] - Training step 42880 loss 0.009584158658981323
[2025-03-24 09:23:42,618][model][INFO] - Training step 43040 loss 0.10769481211900711
[2025-03-24 09:25:01,561][model][INFO] - Training step 43200 loss 0.036428265273571014
[2025-03-24 09:26:24,097][model][INFO] - Training step 43360 loss 0.0373811200261116
[2025-03-24 09:27:43,940][model][INFO] - Training step 43520 loss 0.02094264142215252
[2025-03-24 09:29:03,718][model][INFO] - Training step 43680 loss 0.02409256249666214
[2025-03-24 09:30:24,670][model][INFO] - Training step 43840 loss 0.02636961080133915
[2025-03-24 09:31:45,380][model][INFO] - Training step 44000 loss 0.005282926373183727
[2025-03-24 09:33:04,088][model][INFO] - Training step 44160 loss 0.012099791318178177
[2025-03-24 09:34:23,666][model][INFO] - Training step 44320 loss 0.019875342026352882
[2025-03-24 09:35:44,818][model][INFO] - Training step 44480 loss 0.007226865738630295
[2025-03-24 09:37:02,186][model][INFO] - Training step 44640 loss 0.002076702192425728
[2025-03-24 09:38:24,084][model][INFO] - Training step 44800 loss 0.051638297736644745
[2025-03-24 09:39:42,920][model][INFO] - Training step 44960 loss 0.043958522379398346
[2025-03-24 09:41:02,622][model][INFO] - Training step 45120 loss 0.03851420059800148
[2025-03-24 09:42:21,966][model][INFO] - Training step 45280 loss 0.02307073585689068
[2025-03-24 09:43:41,965][model][INFO] - Training step 45440 loss 0.0069823781959712505
[2025-03-24 09:45:01,599][model][INFO] - Training step 45600 loss 0.05848131328821182
[2025-03-24 09:46:23,171][model][INFO] - Training step 45760 loss 0.0282834954559803
[2025-03-24 09:47:42,484][model][INFO] - Training step 45920 loss 0.030592460185289383
[2025-03-24 09:49:00,381][model][INFO] - Training step 46080 loss 0.03476106375455856
[2025-03-24 09:50:18,343][model][INFO] - Training step 46240 loss 0.016677938401699066
[2025-03-24 09:51:38,679][model][INFO] - Training step 46400 loss 0.007927896454930305
[2025-03-24 09:52:55,288][model][INFO] - Training step 46560 loss 0.011651432141661644
[2025-03-24 09:54:12,677][model][INFO] - Training step 46720 loss 0.02797684259712696
[2025-03-24 09:55:32,921][model][INFO] - Training step 46880 loss 0.032752059400081635
[2025-03-24 09:56:50,668][model][INFO] - Training step 47040 loss 0.04294753074645996
[2025-03-24 09:58:09,423][model][INFO] - Training step 47200 loss 0.018293624743819237
[2025-03-24 09:59:29,574][model][INFO] - Training step 47360 loss 0.02515103667974472
[2025-03-24 10:00:48,483][model][INFO] - Training step 47520 loss 0.046891432255506516
[2025-03-24 10:02:06,982][model][INFO] - Training step 47680 loss 0.03390797972679138
[2025-03-24 10:03:25,206][model][INFO] - Training step 47840 loss 0.017465390264987946
[2025-03-24 10:04:44,767][model][INFO] - Training step 48000 loss 0.25610339641571045
[2025-03-24 10:06:04,438][model][INFO] - Training step 48160 loss 0.01954745128750801
[2025-03-24 10:07:21,513][model][INFO] - Training step 48320 loss 0.021108554676175117
[2025-03-24 10:08:37,303][model][INFO] - Training step 48480 loss 0.02039378136396408
[2025-03-24 10:09:54,780][model][INFO] - Training step 48640 loss 0.023631853982806206
[2025-03-24 10:11:15,240][model][INFO] - Training step 48800 loss 0.2607913017272949
[2025-03-24 10:12:36,355][model][INFO] - Training step 48960 loss 0.01532185822725296
[2025-03-24 10:13:57,150][model][INFO] - Training step 49120 loss 0.019335709512233734
[2025-03-24 10:15:17,086][model][INFO] - Training step 49280 loss 0.029825421050190926
[2025-03-24 10:16:37,666][model][INFO] - Training step 49440 loss 0.0026043893303722143
[2025-03-24 10:17:57,782][model][INFO] - Training step 49600 loss 0.04123123735189438
[2025-03-24 10:19:16,180][model][INFO] - Training step 49760 loss 0.005755101330578327
[2025-03-24 10:20:37,735][model][INFO] - Training step 49920 loss 0.016019223257899284
[2025-03-24 10:21:57,204][model][INFO] - Training step 50080 loss 0.24828535318374634
[2025-03-24 10:23:15,902][model][INFO] - Training step 50240 loss 0.012470860034227371
[2025-03-24 10:24:32,861][model][INFO] - Training step 50400 loss 0.007824503816664219
[2025-03-24 10:25:50,291][model][INFO] - Training step 50560 loss 0.008112309500575066
[2025-03-24 10:27:08,535][model][INFO] - Training step 50720 loss 0.023016616702079773
[2025-03-24 10:36:45,270][model][INFO] - Training step 80 loss 0.038717810064554214
[2025-03-24 10:38:08,326][model][INFO] - Training step 240 loss 0.024980051442980766
[2025-03-24 10:39:28,004][model][INFO] - Training step 400 loss 0.025206085294485092
[2025-03-24 10:40:47,156][model][INFO] - Training step 560 loss 0.043653953820466995
[2025-03-24 10:42:07,463][model][INFO] - Training step 720 loss 0.02719765156507492
[2025-03-24 10:43:26,311][model][INFO] - Training step 880 loss 0.13729089498519897
[2025-03-24 10:44:45,989][model][INFO] - Training step 1040 loss 0.24228009581565857
[2025-03-24 10:46:07,444][model][INFO] - Training step 1200 loss 0.004462908022105694
[2025-03-24 10:47:27,493][model][INFO] - Training step 1360 loss 0.060419149696826935
[2025-03-24 10:48:44,448][model][INFO] - Training step 1520 loss 0.030456429347395897
[2025-03-24 10:50:03,025][model][INFO] - Training step 1680 loss 0.021067054942250252
[2025-03-24 10:51:23,215][model][INFO] - Training step 1840 loss 0.20157061517238617
[2025-03-24 10:52:41,981][model][INFO] - Training step 2000 loss 0.15716847777366638
[2025-03-24 10:53:58,376][model][INFO] - Training step 2160 loss 0.00468742661178112
[2025-03-24 10:55:15,862][model][INFO] - Training step 2320 loss 0.2783527374267578
[2025-03-24 10:56:38,432][model][INFO] - Training step 2480 loss 0.004196832422167063
[2025-03-24 10:57:56,041][model][INFO] - Training step 2640 loss 0.032736144959926605
[2025-03-24 10:59:15,071][model][INFO] - Training step 2800 loss 0.2500714063644409
[2025-03-24 11:00:36,201][model][INFO] - Training step 2960 loss 0.035643570125103
[2025-03-24 11:01:54,190][model][INFO] - Training step 3120 loss 0.3691759705543518
[2025-03-24 11:03:14,141][model][INFO] - Training step 3280 loss 0.03616512566804886
[2025-03-24 11:04:32,361][model][INFO] - Training step 3440 loss 0.023772481828927994
[2025-03-24 11:05:50,534][model][INFO] - Training step 3600 loss 0.017136145383119583
[2025-03-24 11:07:07,780][model][INFO] - Training step 3760 loss 0.01972087286412716
[2025-03-24 11:08:27,513][model][INFO] - Training step 3920 loss 0.015492730773985386
[2025-03-24 11:09:48,217][model][INFO] - Training step 4080 loss 0.030726999044418335
[2025-03-24 11:11:07,658][model][INFO] - Training step 4240 loss 0.2512696087360382
[2025-03-24 11:12:27,679][model][INFO] - Training step 4400 loss 0.018575873225927353
[2025-03-24 11:13:51,750][model][INFO] - Training step 4560 loss 0.024041704833507538
[2025-03-24 11:15:11,841][model][INFO] - Training step 4720 loss 0.037675052881240845
[2025-03-24 11:16:29,141][model][INFO] - Training step 4880 loss 0.03972353786230087
[2025-03-24 11:17:47,676][model][INFO] - Training step 5040 loss 0.036440733820199966
[2025-03-24 11:19:07,548][model][INFO] - Training step 5200 loss 0.020548172295093536
[2025-03-24 11:20:27,701][model][INFO] - Training step 5360 loss 0.06454792618751526
[2025-03-24 11:21:47,015][model][INFO] - Training step 5520 loss 0.2566053867340088
[2025-03-24 11:23:05,721][model][INFO] - Training step 5680 loss 0.15495117008686066
[2025-03-24 11:24:25,108][model][INFO] - Training step 5840 loss 0.07522887736558914
[2025-03-24 11:25:45,452][model][INFO] - Training step 6000 loss 0.24898622930049896
[2025-03-24 11:27:03,219][model][INFO] - Training step 6160 loss 0.027199778705835342
[2025-03-24 11:28:23,206][model][INFO] - Training step 6320 loss 0.026371922343969345
[2025-03-24 11:29:43,585][model][INFO] - Training step 6480 loss 0.041945163160562515
[2025-03-24 11:31:00,841][model][INFO] - Training step 6640 loss 0.007936447858810425
[2025-03-24 11:32:21,545][model][INFO] - Training step 6800 loss 0.02485189214348793
[2025-03-24 11:33:39,255][model][INFO] - Training step 6960 loss 0.10775365680456161
[2025-03-24 11:34:58,265][model][INFO] - Training step 7120 loss 0.052753105759620667
[2025-03-24 11:36:19,397][model][INFO] - Training step 7280 loss 0.015485437586903572
[2025-03-24 11:37:38,851][model][INFO] - Training step 7440 loss 0.016186974942684174
[2025-03-24 11:38:57,019][model][INFO] - Training step 7600 loss 0.0305451862514019
[2025-03-24 11:40:17,970][model][INFO] - Training step 7760 loss 0.055917151272296906
[2025-03-24 11:41:37,310][model][INFO] - Training step 7920 loss 0.25263577699661255
[2025-03-24 11:42:54,829][model][INFO] - Training step 8080 loss 0.050661176443099976
[2025-03-24 11:44:11,877][model][INFO] - Training step 8240 loss 0.05905914306640625
[2025-03-24 11:45:31,729][model][INFO] - Training step 8400 loss 0.03337843716144562
[2025-03-24 11:46:51,864][model][INFO] - Training step 8560 loss 0.02072444185614586
[2025-03-24 11:48:09,595][model][INFO] - Training step 8720 loss 0.02814127318561077
[2025-03-24 11:49:30,635][model][INFO] - Training step 8880 loss 0.018241293728351593
[2025-03-24 11:50:48,808][model][INFO] - Training step 9040 loss 0.012633707374334335
[2025-03-24 11:52:06,843][model][INFO] - Training step 9200 loss 0.249688982963562
[2025-03-24 11:53:25,957][model][INFO] - Training step 9360 loss 0.027261268347501755
[2025-03-24 11:54:47,324][model][INFO] - Training step 9520 loss 0.159807950258255
[2025-03-24 11:56:06,808][model][INFO] - Training step 9680 loss 0.25479042530059814
[2025-03-24 11:57:29,761][model][INFO] - Training step 9840 loss 0.04201817512512207
[2025-03-24 11:58:48,937][model][INFO] - Training step 10000 loss 0.26791781187057495
[2025-03-24 12:00:08,501][model][INFO] - Training step 10160 loss 0.24949878454208374
[2025-03-24 12:01:27,667][model][INFO] - Training step 10320 loss 0.020017847418785095
[2025-03-24 12:02:45,894][model][INFO] - Training step 10480 loss 0.031186550855636597
[2025-03-24 12:04:04,718][model][INFO] - Training step 10640 loss 0.028123199939727783
[2025-03-24 12:05:22,983][model][INFO] - Training step 10800 loss 0.03632087633013725
[2025-03-24 12:06:44,010][model][INFO] - Training step 10960 loss 0.04938560724258423
[2025-03-24 12:08:03,065][model][INFO] - Training step 11120 loss 0.005119020119309425
[2025-03-24 12:09:20,519][model][INFO] - Training step 11280 loss 0.03866603597998619
[2025-03-24 12:10:40,435][model][INFO] - Training step 11440 loss 0.02320772409439087
[2025-03-24 12:11:56,468][model][INFO] - Training step 11600 loss 0.25229015946388245
[2025-03-24 12:13:18,555][model][INFO] - Training step 11760 loss 0.04943517968058586
[2025-03-24 12:14:34,652][model][INFO] - Training step 11920 loss 0.24611932039260864
[2025-03-24 12:15:54,313][model][INFO] - Training step 12080 loss 0.03854402154684067
[2025-03-24 12:17:12,338][model][INFO] - Training step 12240 loss 0.05346957594156265
[2025-03-24 12:18:28,900][model][INFO] - Training step 12400 loss 0.024969469755887985
[2025-03-24 12:19:48,224][model][INFO] - Training step 12560 loss 0.025244027376174927
[2025-03-24 12:21:06,660][model][INFO] - Training step 12720 loss 0.032874323427677155
[2025-03-24 12:22:26,554][model][INFO] - Training step 12880 loss 0.24763920903205872
[2025-03-24 12:23:44,370][model][INFO] - Training step 13040 loss 0.1255846917629242
[2025-03-24 12:25:03,279][model][INFO] - Training step 13200 loss 0.04125640541315079
[2025-03-24 12:26:24,733][model][INFO] - Training step 13360 loss 0.04458445683121681
[2025-03-24 12:27:42,819][model][INFO] - Training step 13520 loss 0.029911765828728676
[2025-03-24 12:29:04,024][model][INFO] - Training step 13680 loss 0.005890296306461096
[2025-03-24 12:30:21,934][model][INFO] - Training step 13840 loss 0.028352202847599983
[2025-03-24 12:31:44,588][model][INFO] - Training step 14000 loss 0.029003921896219254
[2025-03-24 12:33:03,478][model][INFO] - Training step 14160 loss 0.2546153664588928
[2025-03-24 12:34:19,671][model][INFO] - Training step 14320 loss 0.03374314680695534
[2025-03-24 12:35:36,715][model][INFO] - Training step 14480 loss 0.13083961606025696
[2025-03-24 12:36:57,732][model][INFO] - Training step 14640 loss 0.003222636179998517
[2025-03-24 12:38:18,388][model][INFO] - Training step 14800 loss 0.2476481944322586
[2025-03-24 12:39:37,840][model][INFO] - Training step 14960 loss 0.0719107836484909
[2025-03-24 12:41:00,514][model][INFO] - Training step 15120 loss 0.01580563560128212
[2025-03-24 12:42:20,798][model][INFO] - Training step 15280 loss 0.004744465462863445
[2025-03-24 12:43:40,132][model][INFO] - Training step 15440 loss 0.019346021115779877
[2025-03-24 12:44:59,170][model][INFO] - Training step 15600 loss 0.25555211305618286
[2025-03-24 12:46:20,414][model][INFO] - Training step 15760 loss 0.003373271320015192
[2025-03-24 12:47:38,146][model][INFO] - Training step 15920 loss 0.03232543170452118
[2025-03-24 12:48:54,846][model][INFO] - Training step 16080 loss 0.01687830314040184
[2025-03-24 12:50:13,877][model][INFO] - Training step 16240 loss 0.24850919842720032
[2025-03-24 12:51:37,510][model][INFO] - Training step 16400 loss 0.06810393929481506
[2025-03-24 12:52:56,888][model][INFO] - Training step 16560 loss 0.04180010035634041
[2025-03-24 12:54:14,184][model][INFO] - Training step 16720 loss 0.25635647773742676
[2025-03-24 12:55:34,498][model][INFO] - Training step 16880 loss 0.24988065659999847
[2025-03-24 12:56:55,743][model][INFO] - Training step 17040 loss 0.14200207591056824
[2025-03-24 12:58:15,291][model][INFO] - Training step 17200 loss 0.005317213945090771
[2025-03-24 12:59:36,812][model][INFO] - Training step 17360 loss 0.03348061442375183
[2025-03-24 13:00:58,336][model][INFO] - Training step 17520 loss 0.04326925799250603
[2025-03-24 13:02:22,312][model][INFO] - Training step 17680 loss 0.053610868752002716
[2025-03-24 13:03:38,397][model][INFO] - Training step 17840 loss 0.05606623366475105
[2025-03-24 13:04:57,084][model][INFO] - Training step 18000 loss 0.030084002763032913
[2025-03-24 13:06:15,456][model][INFO] - Training step 18160 loss 0.03347992151975632
[2025-03-24 13:07:34,966][model][INFO] - Training step 18320 loss 0.025963496416807175
[2025-03-24 13:08:55,679][model][INFO] - Training step 18480 loss 0.02664780244231224
[2025-03-24 13:10:14,997][model][INFO] - Training step 18640 loss 0.027809232473373413
[2025-03-24 13:11:37,764][model][INFO] - Training step 18800 loss 0.030219759792089462
[2025-03-24 13:12:55,859][model][INFO] - Training step 18960 loss 0.060708194971084595
[2025-03-24 13:14:15,001][model][INFO] - Training step 19120 loss 0.019491570070385933
[2025-03-24 13:15:36,005][model][INFO] - Training step 19280 loss 0.05150953680276871
[2025-03-24 13:16:58,182][model][INFO] - Training step 19440 loss 0.007563861086964607
[2025-03-24 13:18:18,335][model][INFO] - Training step 19600 loss 0.04488327354192734
[2025-03-24 13:19:36,108][model][INFO] - Training step 19760 loss 0.2583622336387634
[2025-03-24 13:20:56,637][model][INFO] - Training step 19920 loss 0.05444536358118057
[2025-03-24 13:22:20,161][model][INFO] - Training step 20080 loss 0.0443655326962471
[2025-03-24 13:23:40,821][model][INFO] - Training step 20240 loss 0.030902758240699768
[2025-03-24 13:25:02,231][model][INFO] - Training step 20400 loss 0.05174221470952034
[2025-03-24 13:26:21,708][model][INFO] - Training step 20560 loss 0.0200535599142313
[2025-03-24 13:27:46,702][model][INFO] - Training step 20720 loss 0.003800160251557827
[2025-03-24 13:29:09,527][model][INFO] - Training step 20880 loss 0.007511422969400883
[2025-03-24 13:30:30,364][model][INFO] - Training step 21040 loss 0.2323520928621292
[2025-03-24 13:31:50,609][model][INFO] - Training step 21200 loss 0.030478600412607193
[2025-03-24 13:33:06,856][model][INFO] - Training step 21360 loss 0.04528200626373291
[2025-03-24 13:34:23,432][model][INFO] - Training step 21520 loss 0.030798984691500664
[2025-03-24 13:35:43,557][model][INFO] - Training step 21680 loss 0.04039986431598663
[2025-03-24 13:37:01,622][model][INFO] - Training step 21840 loss 0.02465774118900299
[2025-03-24 13:38:22,803][model][INFO] - Training step 22000 loss 0.03993353247642517
[2025-03-24 13:39:39,656][model][INFO] - Training step 22160 loss 0.03296776860952377
[2025-03-24 13:40:58,998][model][INFO] - Training step 22320 loss 0.03165664151310921
[2025-03-24 13:42:18,693][model][INFO] - Training step 22480 loss 0.09150002896785736
[2025-03-24 13:43:39,042][model][INFO] - Training step 22640 loss 0.02047259733080864
[2025-03-24 13:45:02,128][model][INFO] - Training step 22800 loss 0.003963063005357981
[2025-03-24 13:46:24,639][model][INFO] - Training step 22960 loss 0.004736597649753094
[2025-03-24 13:47:40,385][model][INFO] - Training step 23120 loss 0.022631779313087463
[2025-03-24 13:49:04,382][model][INFO] - Training step 23280 loss 0.021478157490491867
[2025-03-24 13:50:26,505][model][INFO] - Training step 23440 loss 0.005187481641769409
[2025-03-24 13:51:44,704][model][INFO] - Training step 23600 loss 0.0416850671172142
[2025-03-24 13:53:01,838][model][INFO] - Training step 23760 loss 0.04118506610393524
[2025-03-24 13:54:20,780][model][INFO] - Training step 23920 loss 0.09880828112363815
[2025-03-24 13:55:37,489][model][INFO] - Training step 24080 loss 0.24504920840263367
[2025-03-24 13:56:55,208][model][INFO] - Training step 24240 loss 0.023950498551130295
[2025-03-24 13:58:13,160][model][INFO] - Training step 24400 loss 0.02732309140264988
[2025-03-24 13:59:33,284][model][INFO] - Training step 24560 loss 0.24493080377578735
[2025-03-24 14:00:55,114][model][INFO] - Training step 24720 loss 0.17887651920318604
[2025-03-24 14:02:15,986][model][INFO] - Training step 24880 loss 0.04071186110377312
[2025-03-24 14:03:34,885][model][INFO] - Training step 25040 loss 0.026846732944250107
[2025-03-24 14:04:55,806][model][INFO] - Training step 25200 loss 0.24488216638565063
[2025-03-24 14:06:17,030][model][INFO] - Training step 25360 loss 0.03371454030275345
[2025-03-24 14:07:36,192][model][INFO] - Training step 25520 loss 0.034049101173877716
[2025-03-24 14:08:58,317][model][INFO] - Training step 25680 loss 0.02453083172440529
[2025-03-24 14:10:15,978][model][INFO] - Training step 25840 loss 0.0481262281537056
[2025-03-24 14:11:35,367][model][INFO] - Training step 26000 loss 0.0043114786967635155
[2025-03-24 14:12:56,445][model][INFO] - Training step 26160 loss 0.028345869854092598
[2025-03-24 14:14:15,272][model][INFO] - Training step 26320 loss 0.15811604261398315
[2025-03-24 14:15:33,666][model][INFO] - Training step 26480 loss 0.04034392535686493
[2025-03-24 14:16:53,904][model][INFO] - Training step 26640 loss 0.006223781034350395
[2025-03-24 14:18:11,442][model][INFO] - Training step 26800 loss 0.009406132623553276
[2025-03-24 14:19:32,662][model][INFO] - Training step 26960 loss 0.01947931945323944
[2025-03-24 14:20:49,873][model][INFO] - Training step 27120 loss 0.24245867133140564
[2025-03-24 14:22:10,223][model][INFO] - Training step 27280 loss 0.0392322912812233
[2025-03-24 14:23:27,646][model][INFO] - Training step 27440 loss 0.0302504263818264
[2025-03-24 14:24:46,507][model][INFO] - Training step 27600 loss 0.1385507881641388
[2025-03-24 14:26:08,254][model][INFO] - Training step 27760 loss 0.06690849363803864
[2025-03-24 14:27:26,105][model][INFO] - Training step 27920 loss 0.037545498460531235
[2025-03-24 14:28:46,897][model][INFO] - Training step 28080 loss 0.003195076482370496
[2025-03-24 14:30:07,636][model][INFO] - Training step 28240 loss 0.05313429236412048
[2025-03-24 14:31:26,516][model][INFO] - Training step 28400 loss 0.04907996207475662
[2025-03-24 14:32:45,945][model][INFO] - Training step 28560 loss 0.026543188840150833
[2025-03-24 14:34:03,166][model][INFO] - Training step 28720 loss 0.014685867354273796
[2025-03-24 14:35:24,534][model][INFO] - Training step 28880 loss 0.23808670043945312
[2025-03-24 14:36:46,903][model][INFO] - Training step 29040 loss 0.021079279482364655
[2025-03-24 14:38:07,768][model][INFO] - Training step 29200 loss 0.014141151681542397
[2025-03-24 14:39:28,944][model][INFO] - Training step 29360 loss 0.007325245067477226
[2025-03-24 14:40:48,589][model][INFO] - Training step 29520 loss 0.2573731541633606
[2025-03-24 14:42:09,057][model][INFO] - Training step 29680 loss 0.03170260787010193
[2025-03-24 14:43:30,322][model][INFO] - Training step 29840 loss 0.042890697717666626
[2025-03-24 14:44:49,882][model][INFO] - Training step 30000 loss 0.004675181582570076
[2025-03-24 14:46:10,066][model][INFO] - Training step 30160 loss 0.2510477602481842
[2025-03-24 14:47:29,219][model][INFO] - Training step 30320 loss 0.02147173509001732
[2025-03-24 14:48:48,568][model][INFO] - Training step 30480 loss 0.027808532118797302
[2025-03-24 14:50:06,170][model][INFO] - Training step 30640 loss 0.021665018051862717
[2025-03-24 14:51:22,277][model][INFO] - Training step 30800 loss 0.0362367108464241
[2025-03-24 14:52:43,761][model][INFO] - Training step 30960 loss 0.027698881924152374
[2025-03-24 14:54:05,415][model][INFO] - Training step 31120 loss 0.05925781652331352
[2025-03-24 14:55:24,339][model][INFO] - Training step 31280 loss 0.033509477972984314
[2025-03-24 14:56:44,915][model][INFO] - Training step 31440 loss 0.2065449357032776
[2025-03-24 14:58:03,617][model][INFO] - Training step 31600 loss 0.02589724399149418
[2025-03-24 14:59:22,512][model][INFO] - Training step 31760 loss 0.05859345197677612
[2025-03-24 15:00:43,607][model][INFO] - Training step 31920 loss 0.02709733508527279
[2025-03-24 15:02:02,793][model][INFO] - Training step 32080 loss 0.022136278450489044
[2025-03-24 15:03:24,662][model][INFO] - Training step 32240 loss 0.2487122118473053
[2025-03-24 15:04:44,700][model][INFO] - Training step 32400 loss 0.00270933099091053
[2025-03-24 15:06:07,455][model][INFO] - Training step 32560 loss 0.03590347617864609
[2025-03-24 15:07:27,023][model][INFO] - Training step 32720 loss 0.018102223053574562
[2025-03-24 15:08:50,970][model][INFO] - Training step 32880 loss 0.027273688465356827
[2025-03-24 15:10:10,018][model][INFO] - Training step 33040 loss 0.024995211511850357
[2025-03-24 15:11:29,236][model][INFO] - Training step 33200 loss 0.10695405304431915
[2025-03-24 15:12:52,391][model][INFO] - Training step 33360 loss 0.019849766045808792
[2025-03-24 15:14:18,662][model][INFO] - Training step 33520 loss 0.2529201805591583
[2025-03-24 15:15:37,823][model][INFO] - Training step 33680 loss 0.01101610902696848
[2025-03-24 15:16:58,946][model][INFO] - Training step 33840 loss 0.08971170336008072
[2025-03-24 15:18:18,059][model][INFO] - Training step 34000 loss 0.022776233032345772
[2025-03-24 15:19:42,126][model][INFO] - Training step 34160 loss 0.2791491150856018
[2025-03-24 15:21:02,286][model][INFO] - Training step 34320 loss 0.28907012939453125
[2025-03-24 15:22:23,964][model][INFO] - Training step 34480 loss 0.03484145179390907
[2025-03-24 15:23:42,007][model][INFO] - Training step 34640 loss 0.04469791054725647
[2025-03-24 15:25:01,179][model][INFO] - Training step 34800 loss 0.033166058361530304
[2025-03-24 15:26:23,140][model][INFO] - Training step 34960 loss 0.030696317553520203
[2025-03-24 15:27:40,610][model][INFO] - Training step 35120 loss 0.007600502111017704
[2025-03-24 15:29:08,479][model][INFO] - Training step 35280 loss 0.022183693945407867
[2025-03-24 15:30:31,100][model][INFO] - Training step 35440 loss 0.013578435406088829
[2025-03-24 15:31:52,038][model][INFO] - Training step 35600 loss 0.03284309059381485
[2025-03-24 15:33:14,723][model][INFO] - Training step 35760 loss 0.03155158832669258
[2025-03-24 15:34:32,830][model][INFO] - Training step 35920 loss 0.02731063961982727
[2025-03-24 15:35:53,797][model][INFO] - Training step 36080 loss 0.03834693133831024
[2025-03-24 15:37:16,588][model][INFO] - Training step 36240 loss 0.0030969807412475348
[2025-03-24 15:38:37,650][model][INFO] - Training step 36400 loss 0.021796390414237976
[2025-03-24 15:39:58,835][model][INFO] - Training step 36560 loss 0.006299917120486498
[2025-03-24 15:41:21,209][model][INFO] - Training step 36720 loss 0.25258558988571167
[2025-03-24 15:42:44,423][model][INFO] - Training step 36880 loss 0.0357624776661396
[2025-03-24 15:44:07,623][model][INFO] - Training step 37040 loss 0.01665164902806282
[2025-03-24 15:45:27,150][model][INFO] - Training step 37200 loss 0.08346453309059143
[2025-03-24 15:46:46,678][model][INFO] - Training step 37360 loss 0.03767339140176773
[2025-03-24 15:48:06,307][model][INFO] - Training step 37520 loss 0.01635502651333809
[2025-03-24 15:49:26,760][model][INFO] - Training step 37680 loss 0.2523457407951355
[2025-03-24 15:50:45,856][model][INFO] - Training step 37840 loss 0.04099353402853012
[2025-03-24 15:52:06,336][model][INFO] - Training step 38000 loss 0.010401875711977482
[2025-03-24 15:53:29,194][model][INFO] - Training step 38160 loss 0.019079379737377167
[2025-03-24 15:54:51,703][model][INFO] - Training step 38320 loss 0.049696967005729675
[2025-03-24 15:56:10,951][model][INFO] - Training step 38480 loss 0.27733114361763
[2025-03-24 15:57:31,564][model][INFO] - Training step 38640 loss 0.023847386240959167
[2025-03-24 15:58:49,772][model][INFO] - Training step 38800 loss 0.03770717978477478
[2025-03-24 16:00:10,086][model][INFO] - Training step 38960 loss 0.02109706588089466
[2025-03-24 16:01:26,936][model][INFO] - Training step 39120 loss 0.155301034450531
[2025-03-24 16:02:47,298][model][INFO] - Training step 39280 loss 0.035576242953538895
[2025-03-24 16:04:07,282][model][INFO] - Training step 39440 loss 0.019256673753261566
[2025-03-24 16:05:27,699][model][INFO] - Training step 39600 loss 0.006099258083850145
[2025-03-24 16:06:47,668][model][INFO] - Training step 39760 loss 0.2528972625732422
[2025-03-24 16:08:06,644][model][INFO] - Training step 39920 loss 0.019067637622356415
[2025-03-24 16:09:26,933][model][INFO] - Training step 40080 loss 0.018176965415477753
[2025-03-24 16:10:46,754][model][INFO] - Training step 40240 loss 0.005759538616985083
[2025-03-24 16:12:04,453][model][INFO] - Training step 40400 loss 0.02841242216527462
[2025-03-24 16:13:26,421][model][INFO] - Training step 40560 loss 0.07166220247745514
[2025-03-24 16:14:47,472][model][INFO] - Training step 40720 loss 0.03471452370285988
[2025-03-24 16:16:07,430][model][INFO] - Training step 40880 loss 0.020401785150170326
[2025-03-24 16:17:26,148][model][INFO] - Training step 41040 loss 0.03252570703625679
[2025-03-24 16:18:44,026][model][INFO] - Training step 41200 loss 0.013815008103847504
[2025-03-24 16:20:06,601][model][INFO] - Training step 41360 loss 0.01198909617960453
[2025-03-24 16:21:26,687][model][INFO] - Training step 41520 loss 0.03523831069469452
[2025-03-24 16:22:47,162][model][INFO] - Training step 41680 loss 0.2756556272506714
[2025-03-24 16:24:06,488][model][INFO] - Training step 41840 loss 0.015505354851484299
[2025-03-24 16:25:27,875][model][INFO] - Training step 42000 loss 0.0427577905356884
[2025-03-24 16:26:47,808][model][INFO] - Training step 42160 loss 0.03917761147022247
[2025-03-24 16:28:06,571][model][INFO] - Training step 42320 loss 0.021900653839111328
[2025-03-24 16:29:25,100][model][INFO] - Training step 42480 loss 0.19890308380126953
[2025-03-24 16:30:42,118][model][INFO] - Training step 42640 loss 0.027529999613761902
[2025-03-24 16:31:58,725][model][INFO] - Training step 42800 loss 0.018934648483991623
[2025-03-24 16:33:19,102][model][INFO] - Training step 42960 loss 0.00967084988951683
[2025-03-24 16:34:39,548][model][INFO] - Training step 43120 loss 0.2510315179824829
[2025-03-24 16:35:59,830][model][INFO] - Training step 43280 loss 0.04710916057229042
[2025-03-24 16:37:20,488][model][INFO] - Training step 43440 loss 0.16761957108974457
[2025-03-24 16:38:39,999][model][INFO] - Training step 43600 loss 0.007333557121455669
[2025-03-24 16:40:03,168][model][INFO] - Training step 43760 loss 0.007275369018316269
[2025-03-24 16:41:21,990][model][INFO] - Training step 43920 loss 0.044536903500556946
[2025-03-24 16:42:42,186][model][INFO] - Training step 44080 loss 0.028305936604738235
[2025-03-24 16:44:06,440][model][INFO] - Training step 44240 loss 0.02440130151808262
[2025-03-24 16:45:26,267][model][INFO] - Training step 44400 loss 0.033243536949157715
[2025-03-24 16:46:43,359][model][INFO] - Training step 44560 loss 0.0024039926938712597
[2025-03-24 16:48:03,269][model][INFO] - Training step 44720 loss 0.03880853205919266
[2025-03-24 16:49:22,183][model][INFO] - Training step 44880 loss 0.008469341322779655
[2025-03-24 16:50:42,546][model][INFO] - Training step 45040 loss 0.046260349452495575
[2025-03-24 16:52:01,622][model][INFO] - Training step 45200 loss 0.2173585742712021
[2025-03-24 16:53:21,390][model][INFO] - Training step 45360 loss 0.03166511654853821
[2025-03-24 16:54:42,291][model][INFO] - Training step 45520 loss 0.14742588996887207
[2025-03-24 16:56:04,410][model][INFO] - Training step 45680 loss 0.02436942048370838
[2025-03-24 16:57:25,292][model][INFO] - Training step 45840 loss 0.00469685485586524
[2025-03-24 16:58:46,554][model][INFO] - Training step 46000 loss 0.044238656759262085
[2025-03-24 17:00:06,319][model][INFO] - Training step 46160 loss 0.08193893730640411
[2025-03-24 17:01:24,902][model][INFO] - Training step 46320 loss 0.020918570458889008
[2025-03-24 17:02:41,526][model][INFO] - Training step 46480 loss 0.24510802328586578
[2025-03-24 17:03:59,637][model][INFO] - Training step 46640 loss 0.03548505902290344
[2025-03-24 17:05:18,162][model][INFO] - Training step 46800 loss 0.057379089295864105
[2025-03-24 17:06:39,004][model][INFO] - Training step 46960 loss 0.03897840529680252
[2025-03-24 17:07:59,068][model][INFO] - Training step 47120 loss 0.041400451213121414
[2025-03-24 17:09:20,883][model][INFO] - Training step 47280 loss 0.014846934005618095
[2025-03-24 17:10:40,939][model][INFO] - Training step 47440 loss 0.03726759925484657
[2025-03-24 17:12:02,216][model][INFO] - Training step 47600 loss 0.2473432421684265
[2025-03-24 17:13:20,980][model][INFO] - Training step 47760 loss 0.2453266978263855
[2025-03-24 17:14:39,965][model][INFO] - Training step 47920 loss 0.03758126497268677
[2025-03-24 17:16:00,945][model][INFO] - Training step 48080 loss 0.06984835863113403
[2025-03-24 17:17:18,796][model][INFO] - Training step 48240 loss 0.006923663429915905
[2025-03-24 17:18:36,805][model][INFO] - Training step 48400 loss 0.2646845579147339
[2025-03-24 17:19:55,600][model][INFO] - Training step 48560 loss 0.030675765126943588
[2025-03-24 17:21:16,356][model][INFO] - Training step 48720 loss 0.15979287028312683
[2025-03-24 17:22:36,340][model][INFO] - Training step 48880 loss 0.03015798330307007
[2025-03-24 17:23:54,125][model][INFO] - Training step 49040 loss 0.006856183521449566
[2025-03-24 17:25:14,056][model][INFO] - Training step 49200 loss 0.2700206935405731
[2025-03-24 17:26:32,649][model][INFO] - Training step 49360 loss 0.024987397715449333
[2025-03-24 17:27:50,796][model][INFO] - Training step 49520 loss 0.03874902054667473
[2025-03-24 17:29:10,733][model][INFO] - Training step 49680 loss 0.0051825447008013725
[2025-03-24 17:30:27,555][model][INFO] - Training step 49840 loss 0.042381275445222855
[2025-03-24 17:31:49,899][model][INFO] - Training step 50000 loss 0.0032736710272729397
[2025-03-24 17:33:08,670][model][INFO] - Training step 50160 loss 0.24795512855052948
[2025-03-24 17:34:27,899][model][INFO] - Training step 50320 loss 0.018888099119067192
[2025-03-24 17:35:45,551][model][INFO] - Training step 50480 loss 0.03032618574798107
[2025-03-24 17:37:05,018][model][INFO] - Training step 50640 loss 0.013493264093995094
[2025-03-24 17:46:55,835][model][INFO] - Training step 0 loss 0.022762088105082512
[2025-03-24 17:48:16,339][model][INFO] - Training step 160 loss 0.033678214997053146
[2025-03-24 17:49:38,805][model][INFO] - Training step 320 loss 0.05451691150665283
[2025-03-24 17:50:59,871][model][INFO] - Training step 480 loss 0.026510166004300117
[2025-03-24 17:52:19,028][model][INFO] - Training step 640 loss 0.06571981310844421
[2025-03-24 17:53:39,463][model][INFO] - Training step 800 loss 0.024117454886436462
[2025-03-24 17:54:58,538][model][INFO] - Training step 960 loss 0.016081124544143677
[2025-03-24 17:56:17,732][model][INFO] - Training step 1120 loss 0.054521527141332626
[2025-03-24 17:57:37,767][model][INFO] - Training step 1280 loss 0.021732164546847343
[2025-03-24 17:58:55,730][model][INFO] - Training step 1440 loss 0.02712537720799446
[2025-03-24 18:00:15,971][model][INFO] - Training step 1600 loss 0.085335373878479
[2025-03-24 18:01:38,587][model][INFO] - Training step 1760 loss 0.006618424318730831
[2025-03-24 18:02:59,897][model][INFO] - Training step 1920 loss 0.00703512504696846
[2025-03-24 18:04:22,116][model][INFO] - Training step 2080 loss 0.023269709199666977
[2025-03-24 18:05:41,585][model][INFO] - Training step 2240 loss 0.2593284249305725
[2025-03-24 18:07:00,800][model][INFO] - Training step 2400 loss 0.06941536068916321
[2025-03-24 18:08:18,798][model][INFO] - Training step 2560 loss 0.026598352938890457
[2025-03-24 18:09:37,408][model][INFO] - Training step 2720 loss 0.004073339980095625
[2025-03-24 18:10:56,857][model][INFO] - Training step 2880 loss 0.017875995486974716
[2025-03-24 18:12:17,949][model][INFO] - Training step 3040 loss 0.006404011510312557
[2025-03-24 18:13:37,040][model][INFO] - Training step 3200 loss 0.012393565848469734
[2025-03-24 18:14:59,198][model][INFO] - Training step 3360 loss 0.009910151362419128
[2025-03-24 18:16:19,840][model][INFO] - Training step 3520 loss 0.034598879516124725
[2025-03-24 18:17:38,693][model][INFO] - Training step 3680 loss 0.036255210638046265
[2025-03-24 18:18:55,546][model][INFO] - Training step 3840 loss 0.11163489520549774
[2025-03-24 18:20:16,082][model][INFO] - Training step 4000 loss 0.03743169456720352
[2025-03-24 18:21:36,089][model][INFO] - Training step 4160 loss 0.022774282842874527
[2025-03-24 18:22:57,539][model][INFO] - Training step 4320 loss 0.02831590175628662
[2025-03-24 18:24:18,365][model][INFO] - Training step 4480 loss 0.2526826858520508
[2025-03-24 18:25:38,195][model][INFO] - Training step 4640 loss 0.056430231779813766
[2025-03-24 18:26:59,176][model][INFO] - Training step 4800 loss 0.0446842722594738
[2025-03-24 18:28:17,306][model][INFO] - Training step 4960 loss 0.01099473237991333
[2025-03-24 18:29:35,383][model][INFO] - Training step 5120 loss 0.08425182849168777
[2025-03-24 18:30:57,656][model][INFO] - Training step 5280 loss 0.02132386341691017
[2025-03-24 18:32:17,039][model][INFO] - Training step 5440 loss 0.2512141466140747
[2025-03-24 18:33:33,557][model][INFO] - Training step 5600 loss 0.017890289425849915
[2025-03-24 18:34:52,765][model][INFO] - Training step 5760 loss 0.028458328917622566
[2025-03-24 18:36:12,295][model][INFO] - Training step 5920 loss 0.025495756417512894
[2025-03-24 18:37:31,535][model][INFO] - Training step 6080 loss 0.053056810051202774
[2025-03-24 18:38:51,952][model][INFO] - Training step 6240 loss 0.010249663144350052
[2025-03-24 18:40:12,606][model][INFO] - Training step 6400 loss 0.0929800271987915
[2025-03-24 18:41:32,151][model][INFO] - Training step 6560 loss 0.2419564425945282
[2025-03-24 18:42:52,428][model][INFO] - Training step 6720 loss 0.0041292752139270306
[2025-03-24 18:44:13,536][model][INFO] - Training step 6880 loss 0.046945493668317795
[2025-03-24 18:45:32,139][model][INFO] - Training step 7040 loss 0.014571882784366608
[2025-03-24 18:46:54,437][model][INFO] - Training step 7200 loss 0.014807065948843956
[2025-03-24 18:48:14,553][model][INFO] - Training step 7360 loss 0.24785038828849792
[2025-03-24 18:49:33,785][model][INFO] - Training step 7520 loss 0.003417850472033024
[2025-03-24 18:50:54,358][model][INFO] - Training step 7680 loss 0.004571852274239063
[2025-03-24 18:52:13,178][model][INFO] - Training step 7840 loss 0.024139270186424255
[2025-03-24 18:53:35,949][model][INFO] - Training step 8000 loss 0.007321466691792011
[2025-03-24 18:54:54,929][model][INFO] - Training step 8160 loss 0.0033365145791321993
[2025-03-24 18:56:13,304][model][INFO] - Training step 8320 loss 0.056974656879901886
[2025-03-24 18:57:33,651][model][INFO] - Training step 8480 loss 0.22994178533554077
[2025-03-24 18:58:54,827][model][INFO] - Training step 8640 loss 0.029575172811746597
[2025-03-24 19:00:12,731][model][INFO] - Training step 8800 loss 0.027186620980501175
[2025-03-24 19:01:32,814][model][INFO] - Training step 8960 loss 0.027222560718655586
[2025-03-24 19:02:50,329][model][INFO] - Training step 9120 loss 0.029630213975906372
[2025-03-24 19:04:07,584][model][INFO] - Training step 9280 loss 0.013129363767802715
[2025-03-24 19:05:28,020][model][INFO] - Training step 9440 loss 0.013613110408186913
[2025-03-24 19:06:48,536][model][INFO] - Training step 9600 loss 0.02083236165344715
[2025-03-24 19:08:08,837][model][INFO] - Training step 9760 loss 0.002039126353338361
[2025-03-24 19:09:29,153][model][INFO] - Training step 9920 loss 0.016130514442920685
[2025-03-24 19:10:52,575][model][INFO] - Training step 10080 loss 0.02055295929312706
[2025-03-24 19:12:08,854][model][INFO] - Training step 10240 loss 0.25217103958129883
[2025-03-24 19:13:28,384][model][INFO] - Training step 10400 loss 0.054140035063028336
[2025-03-24 19:14:47,819][model][INFO] - Training step 10560 loss 0.30193158984184265
[2025-03-24 19:16:04,071][model][INFO] - Training step 10720 loss 0.01624326966702938
[2025-03-24 19:17:24,805][model][INFO] - Training step 10880 loss 0.034131795167922974
[2025-03-24 19:18:46,976][model][INFO] - Training step 11040 loss 0.023706942796707153
[2025-03-24 19:20:05,897][model][INFO] - Training step 11200 loss 0.22655948996543884
[2025-03-24 19:21:22,791][model][INFO] - Training step 11360 loss 0.020559601485729218
[2025-03-24 19:22:42,456][model][INFO] - Training step 11520 loss 0.056309737265110016
[2025-03-24 19:24:01,409][model][INFO] - Training step 11680 loss 0.2298697531223297
[2025-03-24 19:25:20,401][model][INFO] - Training step 11840 loss 0.07013688236474991
[2025-03-24 19:26:39,838][model][INFO] - Training step 12000 loss 0.04255721718072891
[2025-03-24 19:28:00,815][model][INFO] - Training step 12160 loss 0.03137419745326042
[2025-03-24 19:29:18,385][model][INFO] - Training step 12320 loss 0.0027465634047985077
[2025-03-24 19:30:38,236][model][INFO] - Training step 12480 loss 0.06487921625375748
[2025-03-24 19:31:56,738][model][INFO] - Training step 12640 loss 0.02832755446434021
[2025-03-24 19:33:17,722][model][INFO] - Training step 12800 loss 0.024765316396951675
[2025-03-24 19:34:34,893][model][INFO] - Training step 12960 loss 0.016242973506450653
[2025-03-24 19:35:53,123][model][INFO] - Training step 13120 loss 0.023524748161435127
[2025-03-24 19:37:14,714][model][INFO] - Training step 13280 loss 0.015418723225593567
[2025-03-24 19:38:31,232][model][INFO] - Training step 13440 loss 0.10244685411453247
[2025-03-24 19:39:52,037][model][INFO] - Training step 13600 loss 0.02442082390189171
[2025-03-24 19:41:11,059][model][INFO] - Training step 13760 loss 0.21727952361106873
[2025-03-24 19:42:30,767][model][INFO] - Training step 13920 loss 0.26829326152801514
[2025-03-24 19:43:49,254][model][INFO] - Training step 14080 loss 0.03444741666316986
[2025-03-24 19:45:08,642][model][INFO] - Training step 14240 loss 0.059219636023044586
[2025-03-24 19:46:26,135][model][INFO] - Training step 14400 loss 0.2332734316587448
[2025-03-24 19:47:46,653][model][INFO] - Training step 14560 loss 0.00803499948233366
[2025-03-24 19:49:04,841][model][INFO] - Training step 14720 loss 0.005539108999073505
[2025-03-24 19:50:22,082][model][INFO] - Training step 14880 loss 0.030656149610877037
[2025-03-24 19:51:43,475][model][INFO] - Training step 15040 loss 0.22114016115665436
[2025-03-24 19:53:03,671][model][INFO] - Training step 15200 loss 0.0033516164403408766
[2025-03-24 19:54:23,679][model][INFO] - Training step 15360 loss 0.015227162279188633
[2025-03-24 19:55:45,399][model][INFO] - Training step 15520 loss 0.04708206653594971
[2025-03-24 19:57:06,198][model][INFO] - Training step 15680 loss 0.0466017872095108
[2025-03-24 19:58:25,145][model][INFO] - Training step 15840 loss 0.03986279293894768
[2025-03-24 19:59:45,127][model][INFO] - Training step 16000 loss 0.06058643385767937
[2025-03-24 20:01:03,612][model][INFO] - Training step 16160 loss 0.014477107673883438
[2025-03-24 20:02:20,483][model][INFO] - Training step 16320 loss 0.04892776161432266
[2025-03-24 20:03:37,574][model][INFO] - Training step 16480 loss 0.01699356734752655
[2025-03-24 20:04:57,322][model][INFO] - Training step 16640 loss 0.022220999002456665
[2025-03-24 20:06:16,161][model][INFO] - Training step 16800 loss 0.27484893798828125
[2025-03-24 20:07:36,047][model][INFO] - Training step 16960 loss 0.02770301140844822
[2025-03-24 20:08:53,431][model][INFO] - Training step 17120 loss 0.027622099965810776
[2025-03-24 20:10:15,109][model][INFO] - Training step 17280 loss 0.9141368865966797
[2025-03-24 20:11:33,124][model][INFO] - Training step 17440 loss 0.03689798712730408
[2025-03-24 20:12:53,756][model][INFO] - Training step 17600 loss 0.025114797055721283
[2025-03-24 20:14:12,620][model][INFO] - Training step 17760 loss 0.16876831650733948
[2025-03-24 20:15:31,231][model][INFO] - Training step 17920 loss 0.13675406575202942
[2025-03-24 20:16:49,567][model][INFO] - Training step 18080 loss 0.061574190855026245
[2025-03-24 20:18:08,329][model][INFO] - Training step 18240 loss 0.08554987609386444
[2025-03-24 20:19:30,763][model][INFO] - Training step 18400 loss 0.027945565059781075
[2025-03-24 20:20:49,798][model][INFO] - Training step 18560 loss 0.038138557225465775
[2025-03-24 20:22:12,311][model][INFO] - Training step 18720 loss 0.007179833482950926
[2025-03-24 20:23:31,464][model][INFO] - Training step 18880 loss 0.021192455664277077
[2025-03-24 20:24:50,551][model][INFO] - Training step 19040 loss 0.21618308126926422
[2025-03-24 20:26:08,960][model][INFO] - Training step 19200 loss 0.040042173117399216
[2025-03-24 20:27:26,193][model][INFO] - Training step 19360 loss 0.028472885489463806
[2025-03-24 20:28:45,349][model][INFO] - Training step 19520 loss 0.054885976016521454
[2025-03-24 20:30:06,581][model][INFO] - Training step 19680 loss 0.006243487820029259
[2025-03-24 20:31:29,169][model][INFO] - Training step 19840 loss 0.031946681439876556
[2025-03-24 20:32:49,130][model][INFO] - Training step 20000 loss 0.041189514100551605
[2025-03-24 20:34:09,113][model][INFO] - Training step 20160 loss 0.0278928242623806
[2025-03-24 20:35:26,591][model][INFO] - Training step 20320 loss 0.25762617588043213
[2025-03-24 20:36:45,388][model][INFO] - Training step 20480 loss 0.2553209066390991
[2025-03-24 20:38:06,664][model][INFO] - Training step 20640 loss 0.03565818443894386
[2025-03-24 20:39:26,828][model][INFO] - Training step 20800 loss 0.03619569540023804
[2025-03-24 20:40:48,788][model][INFO] - Training step 20960 loss 0.0192579198628664
[2025-03-24 20:42:11,083][model][INFO] - Training step 21120 loss 0.011927160434424877
[2025-03-24 20:43:29,236][model][INFO] - Training step 21280 loss 0.006710752844810486
[2025-03-24 20:44:49,684][model][INFO] - Training step 21440 loss 0.025803739205002785
[2025-03-24 20:46:11,142][model][INFO] - Training step 21600 loss 0.03909720480442047
[2025-03-24 20:47:34,229][model][INFO] - Training step 21760 loss 0.07684065401554108
[2025-03-24 20:48:53,138][model][INFO] - Training step 21920 loss 0.0033353962935507298
[2025-03-24 20:50:13,038][model][INFO] - Training step 22080 loss 0.009861589409410954
[2025-03-24 20:51:36,776][model][INFO] - Training step 22240 loss 0.015527431853115559
[2025-03-24 20:52:57,059][model][INFO] - Training step 22400 loss 0.03361984342336655
[2025-03-24 20:54:18,564][model][INFO] - Training step 22560 loss 0.09005573391914368
[2025-03-24 20:55:37,950][model][INFO] - Training step 22720 loss 0.013488737866282463
[2025-03-24 20:56:56,059][model][INFO] - Training step 22880 loss 0.022262457758188248
[2025-03-24 20:58:18,432][model][INFO] - Training step 23040 loss 0.04016409069299698
[2025-03-24 20:59:39,384][model][INFO] - Training step 23200 loss 0.24607372283935547
[2025-03-24 21:00:59,448][model][INFO] - Training step 23360 loss 0.03322579339146614
[2025-03-24 21:02:21,557][model][INFO] - Training step 23520 loss 0.005438347812741995
[2025-03-24 21:03:39,728][model][INFO] - Training step 23680 loss 0.0429096594452858
[2025-03-24 21:04:58,590][model][INFO] - Training step 23840 loss 0.0235313568264246
[2025-03-24 21:06:16,741][model][INFO] - Training step 24000 loss 0.2656378746032715
[2025-03-24 21:07:37,221][model][INFO] - Training step 24160 loss 0.04041635990142822
[2025-03-24 21:08:54,596][model][INFO] - Training step 24320 loss 0.07208104431629181
[2025-03-24 21:10:13,535][model][INFO] - Training step 24480 loss 0.008190369233489037
[2025-03-24 21:11:31,989][model][INFO] - Training step 24640 loss 0.02218230627477169
[2025-03-24 21:12:52,888][model][INFO] - Training step 24800 loss 0.2514674663543701
[2025-03-24 21:14:15,273][model][INFO] - Training step 24960 loss 0.11655695736408234
[2025-03-24 21:15:32,788][model][INFO] - Training step 25120 loss 0.05703117698431015
[2025-03-24 21:16:48,933][model][INFO] - Training step 25280 loss 0.025059230625629425
[2025-03-24 21:18:08,788][model][INFO] - Training step 25440 loss 0.07898405194282532
[2025-03-24 21:19:27,885][model][INFO] - Training step 25600 loss 0.25236737728118896
[2025-03-24 21:20:47,547][model][INFO] - Training step 25760 loss 0.022005733102560043
[2025-03-24 21:22:08,167][model][INFO] - Training step 25920 loss 0.0034586358815431595
[2025-03-24 21:23:25,862][model][INFO] - Training step 26080 loss 0.0975712388753891
[2025-03-24 21:24:45,676][model][INFO] - Training step 26240 loss 0.044495150446891785
[2025-03-24 21:26:09,126][model][INFO] - Training step 26400 loss 0.2545206546783447
[2025-03-24 21:27:28,228][model][INFO] - Training step 26560 loss 0.016138926148414612
[2025-03-24 21:28:46,818][model][INFO] - Training step 26720 loss 0.009063821285963058
[2025-03-24 21:30:06,065][model][INFO] - Training step 26880 loss 0.24961870908737183
[2025-03-24 21:31:24,803][model][INFO] - Training step 27040 loss 0.022783081978559494
[2025-03-24 21:32:45,458][model][INFO] - Training step 27200 loss 0.0190908033400774
[2025-03-24 21:34:04,216][model][INFO] - Training step 27360 loss 0.02973121590912342
[2025-03-24 21:35:22,250][model][INFO] - Training step 27520 loss 0.03276805579662323
[2025-03-24 21:36:39,877][model][INFO] - Training step 27680 loss 0.04201503098011017
[2025-03-24 21:37:59,794][model][INFO] - Training step 27840 loss 0.0065660635009408
[2025-03-24 21:39:17,988][model][INFO] - Training step 28000 loss 0.03294549882411957
[2025-03-24 21:40:36,706][model][INFO] - Training step 28160 loss 0.012213142588734627
[2025-03-24 21:41:54,547][model][INFO] - Training step 28320 loss 0.003135823644697666
[2025-03-24 21:43:15,231][model][INFO] - Training step 28480 loss 0.029140081256628036
[2025-03-24 21:44:36,331][model][INFO] - Training step 28640 loss 0.04205040633678436
[2025-03-24 21:45:56,929][model][INFO] - Training step 28800 loss 0.002387864515185356
[2025-03-24 21:47:17,104][model][INFO] - Training step 28960 loss 0.0032890085130929947
[2025-03-24 21:48:36,006][model][INFO] - Training step 29120 loss 0.2478879690170288
[2025-03-24 21:49:55,585][model][INFO] - Training step 29280 loss 0.02461101859807968
[2025-03-24 21:51:16,637][model][INFO] - Training step 29440 loss 0.024623390287160873
[2025-03-24 21:52:34,895][model][INFO] - Training step 29600 loss 0.288595050573349
[2025-03-24 21:53:54,787][model][INFO] - Training step 29760 loss 0.17259317636489868
[2025-03-24 21:55:12,235][model][INFO] - Training step 29920 loss 0.18000902235507965
[2025-03-24 21:56:31,446][model][INFO] - Training step 30080 loss 0.016864273697137833
[2025-03-24 21:57:52,263][model][INFO] - Training step 30240 loss 0.005726685747504234
[2025-03-24 21:59:11,795][model][INFO] - Training step 30400 loss 0.06428004056215286
[2025-03-24 22:00:29,333][model][INFO] - Training step 30560 loss 0.01876038871705532
[2025-03-24 22:01:44,102][model][INFO] - Training step 30720 loss 0.021176090463995934
[2025-03-24 22:03:00,306][model][INFO] - Training step 30880 loss 0.02244654670357704
[2025-03-24 22:04:20,678][model][INFO] - Training step 31040 loss 0.023425210267305374
[2025-03-24 22:05:38,289][model][INFO] - Training step 31200 loss 0.026778172701597214
[2025-03-24 22:06:57,988][model][INFO] - Training step 31360 loss 0.2524636685848236
[2025-03-24 22:08:18,743][model][INFO] - Training step 31520 loss 0.05966179072856903
[2025-03-24 22:09:39,339][model][INFO] - Training step 31680 loss 0.09872123599052429
[2025-03-24 22:10:58,084][model][INFO] - Training step 31840 loss 0.00696139270439744
[2025-03-24 22:12:19,213][model][INFO] - Training step 32000 loss 0.007112405262887478
[2025-03-24 22:13:37,462][model][INFO] - Training step 32160 loss 0.005509012378752232
[2025-03-24 22:14:57,345][model][INFO] - Training step 32320 loss 0.005409075412899256
[2025-03-24 22:16:16,218][model][INFO] - Training step 32480 loss 0.01859564147889614
[2025-03-24 22:17:38,112][model][INFO] - Training step 32640 loss 0.04074978083372116
[2025-03-24 22:18:59,014][model][INFO] - Training step 32800 loss 0.11058235168457031
[2025-03-24 22:20:24,492][model][INFO] - Training step 32960 loss 0.24995243549346924
[2025-03-24 22:21:44,355][model][INFO] - Training step 33120 loss 0.012919854372739792
[2025-03-24 22:23:03,793][model][INFO] - Training step 33280 loss 0.043411336839199066
[2025-03-24 22:24:22,476][model][INFO] - Training step 33440 loss 0.040502823889255524
[2025-03-24 22:25:43,458][model][INFO] - Training step 33600 loss 0.011041564866900444
[2025-03-24 22:27:02,029][model][INFO] - Training step 33760 loss 0.049029525369405746
[2025-03-24 22:28:22,162][model][INFO] - Training step 33920 loss 0.05293041467666626
[2025-03-24 22:29:43,701][model][INFO] - Training step 34080 loss 0.006862674839794636
[2025-03-24 22:31:06,292][model][INFO] - Training step 34240 loss 0.025950834155082703
[2025-03-24 22:32:27,054][model][INFO] - Training step 34400 loss 0.0057294112630188465
[2025-03-24 22:33:50,436][model][INFO] - Training step 34560 loss 0.2805842459201813
[2025-03-24 22:35:10,633][model][INFO] - Training step 34720 loss 0.01914234459400177
[2025-03-24 22:36:29,229][model][INFO] - Training step 34880 loss 0.019946759566664696
[2025-03-24 22:37:50,273][model][INFO] - Training step 35040 loss 0.04543335735797882
[2025-03-24 22:39:11,023][model][INFO] - Training step 35200 loss 0.004049329552799463
[2025-03-24 22:40:30,832][model][INFO] - Training step 35360 loss 0.029788926243782043
[2025-03-24 22:41:53,755][model][INFO] - Training step 35520 loss 0.028774037957191467
[2025-03-24 22:43:11,375][model][INFO] - Training step 35680 loss 0.019173450767993927
[2025-03-24 22:44:31,110][model][INFO] - Training step 35840 loss 0.014512954279780388
[2025-03-24 22:45:51,621][model][INFO] - Training step 36000 loss 0.20888108015060425
[2025-03-24 22:47:11,087][model][INFO] - Training step 36160 loss 0.06176593154668808
[2025-03-24 22:48:30,804][model][INFO] - Training step 36320 loss 0.004270797595381737
[2025-03-24 22:49:50,989][model][INFO] - Training step 36480 loss 0.018903370946645737
[2025-03-24 22:51:11,563][model][INFO] - Training step 36640 loss 0.02724432945251465
[2025-03-24 22:52:31,965][model][INFO] - Training step 36800 loss 0.005273763090372086
[2025-03-24 22:53:53,977][model][INFO] - Training step 36960 loss 0.013729030266404152
[2025-03-24 22:55:17,057][model][INFO] - Training step 37120 loss 0.018780790269374847
[2025-03-24 22:56:36,868][model][INFO] - Training step 37280 loss 0.20269790291786194
[2025-03-24 22:57:58,282][model][INFO] - Training step 37440 loss 0.051305413246154785
[2025-03-24 22:59:17,713][model][INFO] - Training step 37600 loss 0.22822199761867523
[2025-03-24 23:00:37,685][model][INFO] - Training step 37760 loss 0.025514377281069756
[2025-03-24 23:01:56,845][model][INFO] - Training step 37920 loss 0.011847540736198425
[2025-03-24 23:03:14,305][model][INFO] - Training step 38080 loss 0.06431225687265396
[2025-03-24 23:04:34,649][model][INFO] - Training step 38240 loss 0.02317000925540924
[2025-03-24 23:05:56,292][model][INFO] - Training step 38400 loss 0.0028642441611737013
[2025-03-24 23:07:13,624][model][INFO] - Training step 38560 loss 0.24893701076507568
[2025-03-24 23:08:35,063][model][INFO] - Training step 38720 loss 0.0312749519944191
[2025-03-24 23:09:55,325][model][INFO] - Training step 38880 loss 0.05206931382417679
[2025-03-24 23:11:16,486][model][INFO] - Training step 39040 loss 0.029017429798841476
[2025-03-24 23:12:34,671][model][INFO] - Training step 39200 loss 0.25099918246269226
[2025-03-24 23:13:55,208][model][INFO] - Training step 39360 loss 0.006769712548702955
[2025-03-24 23:15:16,309][model][INFO] - Training step 39520 loss 0.0236862450838089
[2025-03-24 23:16:36,005][model][INFO] - Training step 39680 loss 0.019618524238467216
[2025-03-24 23:17:55,027][model][INFO] - Training step 39840 loss 0.036449916660785675
[2025-03-24 23:19:13,301][model][INFO] - Training step 40000 loss 0.025354575365781784
[2025-03-24 23:20:35,822][model][INFO] - Training step 40160 loss 0.02748764492571354
[2025-03-24 23:21:55,458][model][INFO] - Training step 40320 loss 0.11910361051559448
[2025-03-24 23:23:19,202][model][INFO] - Training step 40480 loss 0.033580586314201355
[2025-03-24 23:24:39,813][model][INFO] - Training step 40640 loss 0.009625112637877464
[2025-03-24 23:25:58,789][model][INFO] - Training step 40800 loss 0.012799440883100033
[2025-03-24 23:27:16,997][model][INFO] - Training step 40960 loss 0.06507527083158493
[2025-03-24 23:28:36,615][model][INFO] - Training step 41120 loss 0.23658189177513123
[2025-03-24 23:29:58,118][model][INFO] - Training step 41280 loss 0.09514120221138
[2025-03-24 23:31:17,783][model][INFO] - Training step 41440 loss 0.24068006873130798
[2025-03-24 23:32:37,161][model][INFO] - Training step 41600 loss 0.03919675946235657
[2025-03-24 23:33:56,912][model][INFO] - Training step 41760 loss 0.015449506230652332
[2025-03-24 23:35:18,048][model][INFO] - Training step 41920 loss 0.09176203608512878
[2025-03-24 23:36:38,823][model][INFO] - Training step 42080 loss 0.010042723268270493
[2025-03-24 23:37:58,188][model][INFO] - Training step 42240 loss 0.0192670039832592
[2025-03-24 23:39:18,545][model][INFO] - Training step 42400 loss 0.031397681683301926
[2025-03-24 23:40:41,307][model][INFO] - Training step 42560 loss 0.008730702102184296
[2025-03-24 23:41:59,673][model][INFO] - Training step 42720 loss 0.029983848333358765
[2025-03-24 23:43:18,020][model][INFO] - Training step 42880 loss 0.03178945556282997
[2025-03-24 23:44:40,642][model][INFO] - Training step 43040 loss 0.25173360109329224
[2025-03-24 23:46:00,636][model][INFO] - Training step 43200 loss 0.3342180848121643
[2025-03-24 23:47:21,028][model][INFO] - Training step 43360 loss 0.16019505262374878
[2025-03-24 23:48:45,188][model][INFO] - Training step 43520 loss 0.0050553432665765285
[2025-03-24 23:50:03,203][model][INFO] - Training step 43680 loss 0.03249788284301758
[2025-03-24 23:51:22,429][model][INFO] - Training step 43840 loss 0.031641311943531036
[2025-03-24 23:52:40,524][model][INFO] - Training step 44000 loss 0.028481191024184227
[2025-03-24 23:53:59,843][model][INFO] - Training step 44160 loss 0.26475489139556885
[2025-03-24 23:55:21,491][model][INFO] - Training step 44320 loss 0.002019038889557123
[2025-03-24 23:56:41,330][model][INFO] - Training step 44480 loss 0.007600037381052971
[2025-03-24 23:57:58,481][model][INFO] - Training step 44640 loss 0.02822038158774376
[2025-03-24 23:59:19,828][model][INFO] - Training step 44800 loss 0.03618897497653961
[2025-03-25 00:00:35,722][model][INFO] - Training step 44960 loss 0.2485990822315216
[2025-03-25 00:01:55,463][model][INFO] - Training step 45120 loss 0.0063120173290371895
[2025-03-25 00:03:13,725][model][INFO] - Training step 45280 loss 0.019380468875169754
[2025-03-25 00:04:35,394][model][INFO] - Training step 45440 loss 0.05513238534331322
[2025-03-25 00:05:55,220][model][INFO] - Training step 45600 loss 0.0879787802696228
[2025-03-25 00:07:18,055][model][INFO] - Training step 45760 loss 0.0041387067176401615
[2025-03-25 00:08:36,767][model][INFO] - Training step 45920 loss 0.030156221240758896
[2025-03-25 00:09:55,559][model][INFO] - Training step 46080 loss 0.004859493114054203
[2025-03-25 00:11:14,432][model][INFO] - Training step 46240 loss 0.018625963479280472
[2025-03-25 00:12:36,224][model][INFO] - Training step 46400 loss 0.01282650139182806
[2025-03-25 00:13:55,273][model][INFO] - Training step 46560 loss 0.01520795188844204
[2025-03-25 00:15:17,518][model][INFO] - Training step 46720 loss 0.0021633747965097427
[2025-03-25 00:16:35,462][model][INFO] - Training step 46880 loss 0.03154750540852547
[2025-03-25 00:17:55,376][model][INFO] - Training step 47040 loss 0.03529989719390869
[2025-03-25 00:19:13,508][model][INFO] - Training step 47200 loss 0.06684929877519608
[2025-03-25 00:20:33,706][model][INFO] - Training step 47360 loss 0.029117831960320473
[2025-03-25 00:21:53,932][model][INFO] - Training step 47520 loss 0.01708131656050682
[2025-03-25 00:23:14,744][model][INFO] - Training step 47680 loss 0.030317507684230804
[2025-03-25 00:24:35,620][model][INFO] - Training step 47840 loss 0.0035876519978046417
[2025-03-25 00:25:52,177][model][INFO] - Training step 48000 loss 0.11740066111087799
[2025-03-25 00:27:12,256][model][INFO] - Training step 48160 loss 0.05993673950433731
[2025-03-25 00:28:31,750][model][INFO] - Training step 48320 loss 0.26518404483795166
[2025-03-25 00:29:50,367][model][INFO] - Training step 48480 loss 0.039717476814985275
[2025-03-25 00:31:12,901][model][INFO] - Training step 48640 loss 0.025429535657167435
[2025-03-25 00:32:30,010][model][INFO] - Training step 48800 loss 0.08291583508253098
[2025-03-25 00:33:50,282][model][INFO] - Training step 48960 loss 0.01879892498254776
[2025-03-25 00:35:10,086][model][INFO] - Training step 49120 loss 0.020850539207458496
[2025-03-25 00:36:31,617][model][INFO] - Training step 49280 loss 0.032940931618213654
[2025-03-25 00:37:52,103][model][INFO] - Training step 49440 loss 0.033304162323474884
[2025-03-25 00:39:12,470][model][INFO] - Training step 49600 loss 0.045364029705524445
[2025-03-25 00:40:30,273][model][INFO] - Training step 49760 loss 0.04963348060846329
[2025-03-25 00:41:48,872][model][INFO] - Training step 49920 loss 0.015075087547302246
[2025-03-25 00:43:09,034][model][INFO] - Training step 50080 loss 0.10041747242212296
[2025-03-25 00:44:30,484][model][INFO] - Training step 50240 loss 0.011064409278333187
[2025-03-25 00:45:53,384][model][INFO] - Training step 50400 loss 0.170329749584198
[2025-03-25 00:47:11,054][model][INFO] - Training step 50560 loss 0.2540321946144104
[2025-03-25 00:48:32,510][model][INFO] - Training step 50720 loss 0.0028857141733169556
[2025-03-25 00:58:11,037][model][INFO] - Training step 80 loss 0.04402864724397659
[2025-03-25 00:59:32,775][model][INFO] - Training step 240 loss 0.11451894789934158
[2025-03-25 01:00:54,232][model][INFO] - Training step 400 loss 0.026573356240987778
[2025-03-25 01:02:11,219][model][INFO] - Training step 560 loss 0.25020259618759155
[2025-03-25 01:03:29,824][model][INFO] - Training step 720 loss 0.24996471405029297
[2025-03-25 01:04:50,672][model][INFO] - Training step 880 loss 0.02367209643125534
[2025-03-25 01:06:09,932][model][INFO] - Training step 1040 loss 0.2468990981578827
[2025-03-25 01:07:29,369][model][INFO] - Training step 1200 loss 0.43624603748321533
[2025-03-25 01:08:48,800][model][INFO] - Training step 1360 loss 0.038142796605825424
[2025-03-25 01:10:09,135][model][INFO] - Training step 1520 loss 0.03038935363292694
[2025-03-25 01:11:28,920][model][INFO] - Training step 1680 loss 0.020239543169736862
[2025-03-25 01:12:49,421][model][INFO] - Training step 1840 loss 0.03372356668114662
[2025-03-25 01:14:07,179][model][INFO] - Training step 2000 loss 0.06743103265762329
[2025-03-25 01:15:29,356][model][INFO] - Training step 2160 loss 0.24864959716796875
[2025-03-25 01:16:46,337][model][INFO] - Training step 2320 loss 0.01822405308485031
[2025-03-25 01:18:03,217][model][INFO] - Training step 2480 loss 0.24950450658798218
[2025-03-25 01:19:21,320][model][INFO] - Training step 2640 loss 0.02552478015422821
[2025-03-25 01:20:41,277][model][INFO] - Training step 2800 loss 0.03629111498594284
[2025-03-25 01:21:59,385][model][INFO] - Training step 2960 loss 0.032366711646318436
[2025-03-25 01:23:16,495][model][INFO] - Training step 3120 loss 0.6684698462486267
[2025-03-25 01:24:36,807][model][INFO] - Training step 3280 loss 0.03202419355511665
[2025-03-25 01:25:56,550][model][INFO] - Training step 3440 loss 0.024019679054617882
[2025-03-25 01:27:16,170][model][INFO] - Training step 3600 loss 0.0035933793988078833
[2025-03-25 01:28:34,861][model][INFO] - Training step 3760 loss 0.020781785249710083
[2025-03-25 01:29:54,474][model][INFO] - Training step 3920 loss 0.036085665225982666
[2025-03-25 01:31:18,394][model][INFO] - Training step 4080 loss 0.06152503192424774
[2025-03-25 01:32:38,671][model][INFO] - Training step 4240 loss 0.04811016470193863
[2025-03-25 01:33:56,632][model][INFO] - Training step 4400 loss 0.02023998647928238
[2025-03-25 01:35:15,243][model][INFO] - Training step 4560 loss 0.049378059804439545
[2025-03-25 01:36:33,651][model][INFO] - Training step 4720 loss 0.0201135091483593
[2025-03-25 01:37:50,937][model][INFO] - Training step 4880 loss 0.012609662488102913
[2025-03-25 01:39:08,343][model][INFO] - Training step 5040 loss 0.0327376052737236
[2025-03-25 01:40:25,345][model][INFO] - Training step 5200 loss 0.018479056656360626
[2025-03-25 01:41:43,584][model][INFO] - Training step 5360 loss 0.04950046166777611
[2025-03-25 01:43:01,899][model][INFO] - Training step 5520 loss 0.033389002084732056
[2025-03-25 01:44:18,308][model][INFO] - Training step 5680 loss 0.019386883825063705
[2025-03-25 01:45:38,195][model][INFO] - Training step 5840 loss 0.0628383457660675
[2025-03-25 01:46:58,050][model][INFO] - Training step 6000 loss 0.06273290514945984
[2025-03-25 01:48:17,402][model][INFO] - Training step 6160 loss 0.01947903260588646
[2025-03-25 01:49:36,327][model][INFO] - Training step 6320 loss 0.26461026072502136
[2025-03-25 01:50:54,411][model][INFO] - Training step 6480 loss 0.06234876811504364
[2025-03-25 01:52:14,005][model][INFO] - Training step 6640 loss 0.008340521715581417
[2025-03-25 01:53:33,604][model][INFO] - Training step 6800 loss 0.015284037217497826
[2025-03-25 01:54:50,634][model][INFO] - Training step 6960 loss 0.023465853184461594
[2025-03-25 01:56:09,235][model][INFO] - Training step 7120 loss 0.0038924440741539
[2025-03-25 01:57:29,377][model][INFO] - Training step 7280 loss 0.2612593173980713
[2025-03-25 01:58:49,126][model][INFO] - Training step 7440 loss 0.016221456229686737
[2025-03-25 02:00:07,434][model][INFO] - Training step 7600 loss 0.030511924996972084
[2025-03-25 02:01:26,391][model][INFO] - Training step 7760 loss 0.004582503344863653
[2025-03-25 02:02:46,324][model][INFO] - Training step 7920 loss 0.04714684188365936
[2025-03-25 02:04:07,159][model][INFO] - Training step 8080 loss 0.027921881526708603
[2025-03-25 02:05:24,524][model][INFO] - Training step 8240 loss 0.02081703022122383
[2025-03-25 02:06:43,086][model][INFO] - Training step 8400 loss 0.040521085262298584
[2025-03-25 02:08:02,022][model][INFO] - Training step 8560 loss 0.2629547119140625
[2025-03-25 02:09:19,967][model][INFO] - Training step 8720 loss 0.01302416156977415
[2025-03-25 02:10:39,958][model][INFO] - Training step 8880 loss 0.016789188608527184
[2025-03-25 02:12:00,254][model][INFO] - Training step 9040 loss 0.022775093093514442
[2025-03-25 02:13:17,003][model][INFO] - Training step 9200 loss 0.08273481577634811
[2025-03-25 02:14:38,683][model][INFO] - Training step 9360 loss 0.05430226027965546
[2025-03-25 02:15:57,786][model][INFO] - Training step 9520 loss 0.012857526540756226
[2025-03-25 02:17:15,800][model][INFO] - Training step 9680 loss 0.14076513051986694
[2025-03-25 02:18:33,100][model][INFO] - Training step 9840 loss 0.053284578025341034
[2025-03-25 02:19:54,031][model][INFO] - Training step 10000 loss 0.012957450933754444
[2025-03-25 02:21:13,225][model][INFO] - Training step 10160 loss 0.24985270202159882
[2025-03-25 02:22:33,827][model][INFO] - Training step 10320 loss 0.23513227701187134
[2025-03-25 02:23:51,368][model][INFO] - Training step 10480 loss 0.032046250998973846
[2025-03-25 02:25:11,986][model][INFO] - Training step 10640 loss 0.028007779270410538
[2025-03-25 02:26:29,267][model][INFO] - Training step 10800 loss 0.033680710941553116
[2025-03-25 02:27:49,590][model][INFO] - Training step 10960 loss 0.3114471137523651
[2025-03-25 02:29:07,037][model][INFO] - Training step 11120 loss 0.027152080088853836
[2025-03-25 02:30:25,787][model][INFO] - Training step 11280 loss 0.17264190316200256
[2025-03-25 02:31:44,374][model][INFO] - Training step 11440 loss 0.04724041372537613
[2025-03-25 02:32:58,862][model][INFO] - Training step 11600 loss 0.052028119564056396
[2025-03-25 02:34:21,872][model][INFO] - Training step 11760 loss 0.24945837259292603
[2025-03-25 02:35:39,395][model][INFO] - Training step 11920 loss 0.2470177561044693
[2025-03-25 02:37:00,534][model][INFO] - Training step 12080 loss 0.2603466808795929
[2025-03-25 02:38:21,328][model][INFO] - Training step 12240 loss 0.13380758464336395
[2025-03-25 02:39:37,012][model][INFO] - Training step 12400 loss 0.041369713842868805
[2025-03-25 02:40:57,930][model][INFO] - Training step 12560 loss 0.02895265445113182
[2025-03-25 02:42:19,003][model][INFO] - Training step 12720 loss 0.22100162506103516
[2025-03-25 02:43:37,210][model][INFO] - Training step 12880 loss 0.02393225021660328
[2025-03-25 02:44:54,817][model][INFO] - Training step 13040 loss 0.026844922453165054
[2025-03-25 02:46:13,068][model][INFO] - Training step 13200 loss 0.23777827620506287
[2025-03-25 02:47:33,402][model][INFO] - Training step 13360 loss 0.05240190774202347
[2025-03-25 02:48:52,238][model][INFO] - Training step 13520 loss 0.03280913829803467
[2025-03-25 02:50:11,876][model][INFO] - Training step 13680 loss 0.07328565418720245
[2025-03-25 02:51:31,240][model][INFO] - Training step 13840 loss 0.01721460372209549
[2025-03-25 02:52:50,688][model][INFO] - Training step 14000 loss 0.018519354984164238
[2025-03-25 02:54:09,382][model][INFO] - Training step 14160 loss 0.24968916177749634
[2025-03-25 02:55:28,805][model][INFO] - Training step 14320 loss 0.017706038430333138
[2025-03-25 02:56:48,962][model][INFO] - Training step 14480 loss 0.012066609226167202
[2025-03-25 02:58:05,213][model][INFO] - Training step 14640 loss 0.016901839524507523
[2025-03-25 02:59:23,921][model][INFO] - Training step 14800 loss 0.00557097839191556
[2025-03-25 03:00:42,564][model][INFO] - Training step 14960 loss 0.016622815281152725
[2025-03-25 03:02:02,482][model][INFO] - Training step 15120 loss 0.02699771337211132
[2025-03-25 03:03:23,344][model][INFO] - Training step 15280 loss 0.2209683060646057
[2025-03-25 03:04:44,512][model][INFO] - Training step 15440 loss 0.014575627632439137
[2025-03-25 03:06:02,427][model][INFO] - Training step 15600 loss 0.056122761219739914
[2025-03-25 03:07:24,263][model][INFO] - Training step 15760 loss 0.13030502200126648
[2025-03-25 03:08:41,219][model][INFO] - Training step 15920 loss 0.03637707605957985
[2025-03-25 03:09:57,801][model][INFO] - Training step 16080 loss 0.10357742756605148
[2025-03-25 03:11:16,398][model][INFO] - Training step 16240 loss 0.06954747438430786
[2025-03-25 03:12:35,582][model][INFO] - Training step 16400 loss 0.2517317831516266
[2025-03-25 03:13:56,520][model][INFO] - Training step 16560 loss 0.0914262980222702
[2025-03-25 03:15:18,179][model][INFO] - Training step 16720 loss 0.0029253987595438957
[2025-03-25 03:16:34,799][model][INFO] - Training step 16880 loss 0.0970822125673294
[2025-03-25 03:17:52,276][model][INFO] - Training step 17040 loss 0.06104762852191925
[2025-03-25 03:19:12,903][model][INFO] - Training step 17200 loss 0.0032600313425064087
[2025-03-25 03:20:33,114][model][INFO] - Training step 17360 loss 0.025896884500980377
[2025-03-25 03:21:55,614][model][INFO] - Training step 17520 loss 0.02769852802157402
[2025-03-25 03:23:15,378][model][INFO] - Training step 17680 loss 0.026173152029514313
[2025-03-25 03:24:31,150][model][INFO] - Training step 17840 loss 0.035904981195926666
[2025-03-25 03:25:49,851][model][INFO] - Training step 18000 loss 0.029938552528619766
[2025-03-25 03:27:11,033][model][INFO] - Training step 18160 loss 0.002030778443440795
[2025-03-25 03:28:30,652][model][INFO] - Training step 18320 loss 0.023524917662143707
[2025-03-25 03:29:49,475][model][INFO] - Training step 18480 loss 0.09533485025167465
[2025-03-25 03:31:10,904][model][INFO] - Training step 18640 loss 0.006659692618995905
[2025-03-25 03:32:26,365][model][INFO] - Training step 18800 loss 0.06069544330239296
[2025-03-25 03:33:48,348][model][INFO] - Training step 18960 loss 0.1592596024274826
[2025-03-25 03:35:08,687][model][INFO] - Training step 19120 loss 0.006542016752064228
[2025-03-25 03:36:29,488][model][INFO] - Training step 19280 loss 0.13965854048728943
[2025-03-25 03:37:48,421][model][INFO] - Training step 19440 loss 0.2392297387123108
[2025-03-25 03:39:11,174][model][INFO] - Training step 19600 loss 0.003267924301326275
[2025-03-25 03:40:28,012][model][INFO] - Training step 19760 loss 0.2552456855773926
[2025-03-25 03:41:46,053][model][INFO] - Training step 19920 loss 0.04397863149642944
[2025-03-25 03:43:07,221][model][INFO] - Training step 20080 loss 0.0815182775259018
[2025-03-25 03:44:25,617][model][INFO] - Training step 20240 loss 0.09995456039905548
[2025-03-25 03:45:43,555][model][INFO] - Training step 20400 loss 0.06961959600448608
[2025-03-25 03:47:01,651][model][INFO] - Training step 20560 loss 0.032476965337991714
[2025-03-25 03:48:24,911][model][INFO] - Training step 20720 loss 0.05100620537996292
[2025-03-25 03:49:41,475][model][INFO] - Training step 20880 loss 0.19426314532756805
[2025-03-25 03:51:02,432][model][INFO] - Training step 21040 loss 0.19972039759159088
[2025-03-25 03:52:23,658][model][INFO] - Training step 21200 loss 0.09626460075378418
[2025-03-25 03:53:43,044][model][INFO] - Training step 21360 loss 0.1282767951488495
[2025-03-25 03:54:59,325][model][INFO] - Training step 21520 loss 0.012702107429504395
[2025-03-25 03:56:18,542][model][INFO] - Training step 21680 loss 0.005071650259196758
[2025-03-25 03:57:35,845][model][INFO] - Training step 21840 loss 0.0795014500617981
[2025-03-25 03:58:56,061][model][INFO] - Training step 22000 loss 0.26574212312698364
[2025-03-25 04:00:15,239][model][INFO] - Training step 22160 loss 0.2473839819431305
[2025-03-25 04:01:36,357][model][INFO] - Training step 22320 loss 0.026283390820026398
[2025-03-25 04:02:55,624][model][INFO] - Training step 22480 loss 0.01006593182682991
[2025-03-25 04:04:15,224][model][INFO] - Training step 22640 loss 0.01594548299908638
[2025-03-25 04:05:35,222][model][INFO] - Training step 22800 loss 0.06809698045253754
[2025-03-25 04:06:55,734][model][INFO] - Training step 22960 loss 0.017827671021223068
[2025-03-25 04:08:14,191][model][INFO] - Training step 23120 loss 0.05518445000052452
[2025-03-25 04:09:34,953][model][INFO] - Training step 23280 loss 0.047202497720718384
[2025-03-25 04:10:55,023][model][INFO] - Training step 23440 loss 0.020897764712572098
[2025-03-25 04:12:14,946][model][INFO] - Training step 23600 loss 0.04438186064362526
[2025-03-25 04:13:31,967][model][INFO] - Training step 23760 loss 0.03770233690738678
[2025-03-25 04:14:48,148][model][INFO] - Training step 23920 loss 0.029641272500157356
[2025-03-25 04:16:04,612][model][INFO] - Training step 24080 loss 0.04583133012056351
[2025-03-25 04:17:21,955][model][INFO] - Training step 24240 loss 0.020919859409332275
[2025-03-25 04:18:40,821][model][INFO] - Training step 24400 loss 0.09028416872024536
[2025-03-25 04:19:59,163][model][INFO] - Training step 24560 loss 0.06829706579446793
[2025-03-25 04:21:18,461][model][INFO] - Training step 24720 loss 0.054624274373054504
[2025-03-25 04:22:39,441][model][INFO] - Training step 24880 loss 0.07526152580976486
[2025-03-25 04:23:59,864][model][INFO] - Training step 25040 loss 0.046462468802928925
[2025-03-25 04:25:17,634][model][INFO] - Training step 25200 loss 0.01982812210917473
[2025-03-25 04:26:34,154][model][INFO] - Training step 25360 loss 0.0933782160282135
[2025-03-25 04:27:53,026][model][INFO] - Training step 25520 loss 0.043163321912288666
[2025-03-25 04:29:13,384][model][INFO] - Training step 25680 loss 0.020408716052770615
[2025-03-25 04:30:29,735][model][INFO] - Training step 25840 loss 0.04932987689971924
[2025-03-25 04:31:49,350][model][INFO] - Training step 26000 loss 0.12189668416976929
[2025-03-25 04:33:07,034][model][INFO] - Training step 26160 loss 0.017467696219682693
[2025-03-25 04:34:25,101][model][INFO] - Training step 26320 loss 0.12060831487178802
[2025-03-25 04:35:44,219][model][INFO] - Training step 26480 loss 0.024527987465262413
[2025-03-25 04:37:03,060][model][INFO] - Training step 26640 loss 0.04905150830745697
[2025-03-25 04:38:21,904][model][INFO] - Training step 26800 loss 0.009170407429337502
[2025-03-25 04:39:41,375][model][INFO] - Training step 26960 loss 0.034120112657547
[2025-03-25 04:41:01,499][model][INFO] - Training step 27120 loss 0.015061337500810623
[2025-03-25 04:42:20,495][model][INFO] - Training step 27280 loss 0.2637840509414673
[2025-03-25 04:43:38,976][model][INFO] - Training step 27440 loss 0.03500600904226303
[2025-03-25 04:44:59,360][model][INFO] - Training step 27600 loss 0.04509597271680832
[2025-03-25 04:46:19,198][model][INFO] - Training step 27760 loss 0.03552470728754997
[2025-03-25 04:47:34,564][model][INFO] - Training step 27920 loss 0.01325403992086649
[2025-03-25 04:48:53,892][model][INFO] - Training step 28080 loss 0.06286409497261047
[2025-03-25 04:50:12,980][model][INFO] - Training step 28240 loss 0.0443471223115921
[2025-03-25 04:51:32,534][model][INFO] - Training step 28400 loss 0.05796249210834503
[2025-03-25 04:52:55,044][model][INFO] - Training step 28560 loss 0.03084917925298214
[2025-03-25 04:54:11,562][model][INFO] - Training step 28720 loss 0.015965677797794342
[2025-03-25 04:55:30,731][model][INFO] - Training step 28880 loss 0.020075839012861252
[2025-03-25 04:56:50,196][model][INFO] - Training step 29040 loss 0.02871742844581604
[2025-03-25 04:58:11,214][model][INFO] - Training step 29200 loss 0.016423381865024567
[2025-03-25 04:59:30,078][model][INFO] - Training step 29360 loss 0.01057203859090805
[2025-03-25 05:00:48,031][model][INFO] - Training step 29520 loss 0.12152791768312454
[2025-03-25 05:02:04,363][model][INFO] - Training step 29680 loss 0.12072136998176575
[2025-03-25 05:03:22,922][model][INFO] - Training step 29840 loss 0.0025460871402174234
[2025-03-25 05:04:42,488][model][INFO] - Training step 30000 loss 0.011875515803694725
[2025-03-25 05:06:01,186][model][INFO] - Training step 30160 loss 0.24180376529693604
[2025-03-25 05:07:20,661][model][INFO] - Training step 30320 loss 0.02515782229602337
[2025-03-25 05:08:41,121][model][INFO] - Training step 30480 loss 0.004986478015780449
[2025-03-25 05:09:58,680][model][INFO] - Training step 30640 loss 0.015558379702270031
[2025-03-25 05:11:16,550][model][INFO] - Training step 30800 loss 0.04415922239422798
[2025-03-25 05:12:35,046][model][INFO] - Training step 30960 loss 0.14116428792476654
[2025-03-25 05:13:55,298][model][INFO] - Training step 31120 loss 0.03273581713438034
[2025-03-25 05:15:13,083][model][INFO] - Training step 31280 loss 0.038993190973997116
[2025-03-25 05:16:32,877][model][INFO] - Training step 31440 loss 0.10620580613613129
[2025-03-25 05:17:52,961][model][INFO] - Training step 31600 loss 0.25030750036239624
[2025-03-25 05:19:11,394][model][INFO] - Training step 31760 loss 0.005688976030796766
[2025-03-25 05:20:31,661][model][INFO] - Training step 31920 loss 0.03568882495164871
[2025-03-25 05:21:47,881][model][INFO] - Training step 32080 loss 0.24282170832157135
[2025-03-25 05:23:08,792][model][INFO] - Training step 32240 loss 0.029405225068330765
[2025-03-25 05:24:29,427][model][INFO] - Training step 32400 loss 0.0460757240653038
[2025-03-25 05:25:48,875][model][INFO] - Training step 32560 loss 0.025224728509783745
[2025-03-25 05:27:11,652][model][INFO] - Training step 32720 loss 0.05644308030605316
[2025-03-25 05:28:33,451][model][INFO] - Training step 32880 loss 0.22719614207744598
[2025-03-25 05:29:52,399][model][INFO] - Training step 33040 loss 0.04679083079099655
[2025-03-25 05:31:11,184][model][INFO] - Training step 33200 loss 0.025501877069473267
[2025-03-25 05:32:31,591][model][INFO] - Training step 33360 loss 0.25548282265663147
[2025-03-25 05:33:48,345][model][INFO] - Training step 33520 loss 0.029865384101867676
[2025-03-25 05:35:09,415][model][INFO] - Training step 33680 loss 0.009830714203417301
[2025-03-25 05:36:27,761][model][INFO] - Training step 33840 loss 0.01840369589626789
[2025-03-25 05:37:47,924][model][INFO] - Training step 34000 loss 0.07200299948453903
[2025-03-25 05:39:06,393][model][INFO] - Training step 34160 loss 0.2631475329399109
[2025-03-25 05:40:26,194][model][INFO] - Training step 34320 loss 0.041328512132167816
[2025-03-25 05:41:49,708][model][INFO] - Training step 34480 loss 0.037301212549209595
[2025-03-25 05:43:09,396][model][INFO] - Training step 34640 loss 0.04529397934675217
[2025-03-25 05:44:29,869][model][INFO] - Training step 34800 loss 0.02410033904016018
[2025-03-25 05:45:50,381][model][INFO] - Training step 34960 loss 0.00708954781293869
[2025-03-25 05:47:06,966][model][INFO] - Training step 35120 loss 0.013891387730836868
[2025-03-25 05:48:25,830][model][INFO] - Training step 35280 loss 0.25710976123809814
[2025-03-25 05:49:44,869][model][INFO] - Training step 35440 loss 0.021653588861227036
[2025-03-25 05:51:03,792][model][INFO] - Training step 35600 loss 0.04187972843647003
[2025-03-25 05:52:21,234][model][INFO] - Training step 35760 loss 0.023645754903554916
[2025-03-25 05:53:38,212][model][INFO] - Training step 35920 loss 0.006010306067764759
[2025-03-25 05:54:58,468][model][INFO] - Training step 36080 loss 0.038297392427921295
[2025-03-25 05:56:22,003][model][INFO] - Training step 36240 loss 0.018409457057714462
[2025-03-25 05:57:41,667][model][INFO] - Training step 36400 loss 0.057204991579055786
[2025-03-25 05:59:03,194][model][INFO] - Training step 36560 loss 0.04159345105290413
[2025-03-25 06:00:20,041][model][INFO] - Training step 36720 loss 0.002675221534445882
[2025-03-25 06:01:38,583][model][INFO] - Training step 36880 loss 0.38730984926223755
[2025-03-25 06:03:00,978][model][INFO] - Training step 37040 loss 0.03138196840882301
[2025-03-25 06:04:21,954][model][INFO] - Training step 37200 loss 0.025080466642975807
[2025-03-25 06:05:41,553][model][INFO] - Training step 37360 loss 0.024915697053074837
[2025-03-25 06:07:00,188][model][INFO] - Training step 37520 loss 0.016659945249557495
[2025-03-25 06:08:17,686][model][INFO] - Training step 37680 loss 0.02926391363143921
[2025-03-25 06:09:37,708][model][INFO] - Training step 37840 loss 0.26081547141075134
[2025-03-25 06:10:56,295][model][INFO] - Training step 38000 loss 0.008832639083266258
[2025-03-25 06:12:15,728][model][INFO] - Training step 38160 loss 0.018399395048618317
[2025-03-25 06:13:36,196][model][INFO] - Training step 38320 loss 0.11880354583263397
[2025-03-25 06:14:55,524][model][INFO] - Training step 38480 loss 0.026596028357744217
[2025-03-25 06:16:15,769][model][INFO] - Training step 38640 loss 0.024787133559584618
[2025-03-25 06:17:31,072][model][INFO] - Training step 38800 loss 0.017205622047185898
[2025-03-25 06:18:52,098][model][INFO] - Training step 38960 loss 0.0224053543061018
[2025-03-25 06:20:10,008][model][INFO] - Training step 39120 loss 0.027872521430253983
[2025-03-25 06:21:28,163][model][INFO] - Training step 39280 loss 0.18837738037109375
[2025-03-25 06:22:51,204][model][INFO] - Training step 39440 loss 0.01668151281774044
[2025-03-25 06:24:11,094][model][INFO] - Training step 39600 loss 0.0348384752869606
[2025-03-25 06:25:31,148][model][INFO] - Training step 39760 loss 0.020092330873012543
[2025-03-25 06:26:46,956][model][INFO] - Training step 39920 loss 0.24381999671459198
[2025-03-25 06:28:05,615][model][INFO] - Training step 40080 loss 0.01879461109638214
[2025-03-25 06:29:24,688][model][INFO] - Training step 40240 loss 0.043104931712150574
[2025-03-25 06:30:44,504][model][INFO] - Training step 40400 loss 0.0054605500772595406
[2025-03-25 06:32:05,470][model][INFO] - Training step 40560 loss 0.2581234574317932
[2025-03-25 06:33:24,158][model][INFO] - Training step 40720 loss 0.029470307752490044
[2025-03-25 06:34:43,742][model][INFO] - Training step 40880 loss 0.2730284631252289
[2025-03-25 06:36:01,747][model][INFO] - Training step 41040 loss 0.02699817717075348
[2025-03-25 06:37:25,224][model][INFO] - Training step 41200 loss 0.027302464470267296
[2025-03-25 06:38:47,080][model][INFO] - Training step 41360 loss 0.24462881684303284
[2025-03-25 06:40:07,018][model][INFO] - Training step 41520 loss 0.24980607628822327
[2025-03-25 06:41:25,966][model][INFO] - Training step 41680 loss 0.06302846968173981
[2025-03-25 06:42:44,198][model][INFO] - Training step 41840 loss 0.062156759202480316
[2025-03-25 06:44:02,628][model][INFO] - Training step 42000 loss 0.15005195140838623
[2025-03-25 06:45:22,661][model][INFO] - Training step 42160 loss 0.026335112750530243
[2025-03-25 06:46:43,984][model][INFO] - Training step 42320 loss 0.05168471485376358
[2025-03-25 06:48:03,854][model][INFO] - Training step 42480 loss 0.2616801857948303
[2025-03-25 06:49:22,301][model][INFO] - Training step 42640 loss 0.02003733441233635
[2025-03-25 06:50:43,690][model][INFO] - Training step 42800 loss 0.24687615036964417
[2025-03-25 06:52:01,787][model][INFO] - Training step 42960 loss 0.27356141805648804
[2025-03-25 06:53:19,799][model][INFO] - Training step 43120 loss 0.06505444645881653
[2025-03-25 06:54:39,319][model][INFO] - Training step 43280 loss 0.04886847361922264
[2025-03-25 06:55:59,891][model][INFO] - Training step 43440 loss 0.04443404823541641
[2025-03-25 06:57:17,937][model][INFO] - Training step 43600 loss 0.02697748690843582
[2025-03-25 06:58:37,816][model][INFO] - Training step 43760 loss 0.08296434581279755
[2025-03-25 06:59:58,199][model][INFO] - Training step 43920 loss 0.0063563198782503605
[2025-03-25 07:01:18,975][model][INFO] - Training step 44080 loss 0.24695554375648499
[2025-03-25 07:02:39,507][model][INFO] - Training step 44240 loss 0.040063418447971344
[2025-03-25 07:03:58,550][model][INFO] - Training step 44400 loss 0.038636818528175354
[2025-03-25 07:05:18,460][model][INFO] - Training step 44560 loss 0.2611653506755829
[2025-03-25 07:06:39,359][model][INFO] - Training step 44720 loss 0.021048013120889664
[2025-03-25 07:07:56,260][model][INFO] - Training step 44880 loss 0.25327444076538086
[2025-03-25 07:09:15,193][model][INFO] - Training step 45040 loss 0.04175439476966858
[2025-03-25 07:10:33,268][model][INFO] - Training step 45200 loss 0.008836819790303707
[2025-03-25 07:11:52,295][model][INFO] - Training step 45360 loss 0.0188205074518919
[2025-03-25 07:13:12,447][model][INFO] - Training step 45520 loss 0.035338226705789566
[2025-03-25 07:14:34,976][model][INFO] - Training step 45680 loss 0.014733202755451202
[2025-03-25 07:15:55,936][model][INFO] - Training step 45840 loss 0.06914104521274567
[2025-03-25 07:17:17,890][model][INFO] - Training step 46000 loss 0.03797265142202377
[2025-03-25 07:18:36,828][model][INFO] - Training step 46160 loss 0.03175949305295944
[2025-03-25 07:19:58,387][model][INFO] - Training step 46320 loss 0.02509154938161373
[2025-03-25 07:21:19,212][model][INFO] - Training step 46480 loss 0.02139831706881523
[2025-03-25 07:22:38,429][model][INFO] - Training step 46640 loss 0.03469862788915634
[2025-03-25 07:23:59,018][model][INFO] - Training step 46800 loss 0.0386248454451561
[2025-03-25 07:25:20,959][model][INFO] - Training step 46960 loss 0.03254937380552292
[2025-03-25 07:26:40,566][model][INFO] - Training step 47120 loss 0.03617815673351288
[2025-03-25 07:28:01,992][model][INFO] - Training step 47280 loss 0.004788251593708992
[2025-03-25 07:29:23,064][model][INFO] - Training step 47440 loss 0.2613241970539093
[2025-03-25 07:30:41,101][model][INFO] - Training step 47600 loss 0.0451059564948082
[2025-03-25 07:32:02,910][model][INFO] - Training step 47760 loss 0.043072156608104706
[2025-03-25 07:33:23,479][model][INFO] - Training step 47920 loss 0.04684992879629135
[2025-03-25 07:34:44,901][model][INFO] - Training step 48080 loss 0.0028890843968838453
[2025-03-25 07:36:03,750][model][INFO] - Training step 48240 loss 0.03507969155907631
[2025-03-25 07:37:22,103][model][INFO] - Training step 48400 loss 0.20139965415000916
[2025-03-25 07:38:39,673][model][INFO] - Training step 48560 loss 0.036752890795469284
[2025-03-25 07:40:01,461][model][INFO] - Training step 48720 loss 0.10371130704879761
[2025-03-25 07:41:18,239][model][INFO] - Training step 48880 loss 0.005656510125845671
[2025-03-25 07:42:38,742][model][INFO] - Training step 49040 loss 0.024254679679870605
[2025-03-25 07:44:00,199][model][INFO] - Training step 49200 loss 0.021331120282411575
[2025-03-25 07:45:16,451][model][INFO] - Training step 49360 loss 0.06093906611204147
[2025-03-25 07:46:37,241][model][INFO] - Training step 49520 loss 0.05326583981513977
[2025-03-25 07:47:58,114][model][INFO] - Training step 49680 loss 0.005252180155366659
[2025-03-25 07:49:15,600][model][INFO] - Training step 49840 loss 0.3486396074295044
[2025-03-25 07:50:34,945][model][INFO] - Training step 50000 loss 0.048891738057136536
[2025-03-25 07:51:54,567][model][INFO] - Training step 50160 loss 0.0322825163602829
[2025-03-25 07:53:14,097][model][INFO] - Training step 50320 loss 0.017836913466453552
[2025-03-25 07:54:30,581][model][INFO] - Training step 50480 loss 0.11107676476240158
[2025-03-25 07:55:48,148][model][INFO] - Training step 50640 loss 0.013052485883235931
[2025-03-25 08:05:23,162][model][INFO] - Training step 0 loss 0.24222618341445923
[2025-03-25 08:06:46,281][model][INFO] - Training step 160 loss 0.026654936373233795
[2025-03-25 08:08:04,902][model][INFO] - Training step 320 loss 0.24284455180168152
[2025-03-25 08:09:26,316][model][INFO] - Training step 480 loss 0.022032659500837326
[2025-03-25 08:10:42,531][model][INFO] - Training step 640 loss 0.2571561634540558
[2025-03-25 08:12:00,773][model][INFO] - Training step 800 loss 0.02387780323624611
[2025-03-25 08:13:24,025][model][INFO] - Training step 960 loss 0.01124896015971899
[2025-03-25 08:14:42,448][model][INFO] - Training step 1120 loss 0.006197748705744743
[2025-03-25 08:16:02,028][model][INFO] - Training step 1280 loss 0.019825708121061325
[2025-03-25 08:17:20,539][model][INFO] - Training step 1440 loss 0.026524938642978668
[2025-03-25 08:18:40,690][model][INFO] - Training step 1600 loss 0.07475616037845612
[2025-03-25 08:19:58,761][model][INFO] - Training step 1760 loss 0.033273130655288696
[2025-03-25 08:21:17,524][model][INFO] - Training step 1920 loss 0.25685662031173706
[2025-03-25 08:22:35,475][model][INFO] - Training step 2080 loss 0.2627197504043579
[2025-03-25 08:23:52,637][model][INFO] - Training step 2240 loss 0.26022642850875854
[2025-03-25 08:25:10,952][model][INFO] - Training step 2400 loss 0.004262491129338741
[2025-03-25 08:26:29,627][model][INFO] - Training step 2560 loss 0.0689079761505127
[2025-03-25 08:27:48,535][model][INFO] - Training step 2720 loss 0.07443098723888397
[2025-03-25 08:29:08,623][model][INFO] - Training step 2880 loss 0.018595263361930847
[2025-03-25 08:30:26,039][model][INFO] - Training step 3040 loss 0.04731358215212822
[2025-03-25 08:31:43,761][model][INFO] - Training step 3200 loss 0.013118203729391098
[2025-03-25 08:33:03,079][model][INFO] - Training step 3360 loss 0.008473965339362621
[2025-03-25 08:34:18,132][model][INFO] - Training step 3520 loss 0.11067064106464386
[2025-03-25 08:35:38,620][model][INFO] - Training step 3680 loss 0.2468869388103485
[2025-03-25 08:36:57,439][model][INFO] - Training step 3840 loss 0.03198108449578285
[2025-03-25 08:38:17,439][model][INFO] - Training step 4000 loss 0.034785784780979156
[2025-03-25 08:39:38,320][model][INFO] - Training step 4160 loss 0.015510430559515953
[2025-03-25 08:40:58,826][model][INFO] - Training step 4320 loss 0.2583557963371277
[2025-03-25 08:42:17,857][model][INFO] - Training step 4480 loss 0.026794973760843277
[2025-03-25 08:43:36,217][model][INFO] - Training step 4640 loss 0.004292652010917664
[2025-03-25 08:44:53,779][model][INFO] - Training step 4800 loss 0.028010554611682892
[2025-03-25 08:46:10,944][model][INFO] - Training step 4960 loss 0.0055112075060606
[2025-03-25 08:47:31,425][model][INFO] - Training step 5120 loss 0.0028405701741576195
[2025-03-25 08:48:49,820][model][INFO] - Training step 5280 loss 0.04628603905439377
[2025-03-25 08:50:10,969][model][INFO] - Training step 5440 loss 0.08107324689626694
[2025-03-25 08:51:31,265][model][INFO] - Training step 5600 loss 0.2592868208885193
[2025-03-25 08:52:49,195][model][INFO] - Training step 5760 loss 0.03635502979159355
[2025-03-25 08:54:09,621][model][INFO] - Training step 5920 loss 0.02265799418091774
[2025-03-25 08:55:26,082][model][INFO] - Training step 6080 loss 0.005175339989364147
[2025-03-25 08:56:47,588][model][INFO] - Training step 6240 loss 0.014720807783305645
[2025-03-25 08:58:09,908][model][INFO] - Training step 6400 loss 0.02345866523683071
[2025-03-25 08:59:28,913][model][INFO] - Training step 6560 loss 0.04182305559515953
[2025-03-25 09:00:48,956][model][INFO] - Training step 6720 loss 0.003074714681133628
[2025-03-25 09:02:10,170][model][INFO] - Training step 6880 loss 0.05063308775424957
[2025-03-25 09:03:31,313][model][INFO] - Training step 7040 loss 0.022670120000839233
[2025-03-25 09:04:55,223][model][INFO] - Training step 7200 loss 0.00492183119058609
[2025-03-25 09:06:12,222][model][INFO] - Training step 7360 loss 0.034684740006923676
[2025-03-25 09:07:30,516][model][INFO] - Training step 7520 loss 0.02823522314429283
[2025-03-25 09:08:48,287][model][INFO] - Training step 7680 loss 0.027881188318133354
[2025-03-25 09:10:08,598][model][INFO] - Training step 7840 loss 0.006386741064488888
[2025-03-25 09:11:27,777][model][INFO] - Training step 8000 loss 0.08301392197608948
[2025-03-25 09:12:46,836][model][INFO] - Training step 8160 loss 0.014870909042656422
[2025-03-25 09:14:06,928][model][INFO] - Training step 8320 loss 0.007273994851857424
[2025-03-25 09:15:25,669][model][INFO] - Training step 8480 loss 0.10879115760326385
[2025-03-25 09:16:47,464][model][INFO] - Training step 8640 loss 0.2798783779144287
[2025-03-25 09:18:05,253][model][INFO] - Training step 8800 loss 0.022570999339222908
[2025-03-25 09:19:26,090][model][INFO] - Training step 8960 loss 0.048265717923641205
[2025-03-25 09:20:44,287][model][INFO] - Training step 9120 loss 0.029334781691432
[2025-03-25 09:22:00,695][model][INFO] - Training step 9280 loss 0.026043199002742767
[2025-03-25 09:23:17,518][model][INFO] - Training step 9440 loss 0.0481756217777729
[2025-03-25 09:24:35,787][model][INFO] - Training step 9600 loss 0.15532495081424713
[2025-03-25 09:25:57,868][model][INFO] - Training step 9760 loss 0.2257494032382965
[2025-03-25 09:27:17,629][model][INFO] - Training step 9920 loss 0.024875901639461517
[2025-03-25 09:28:38,946][model][INFO] - Training step 10080 loss 0.02097868174314499
[2025-03-25 09:29:57,509][model][INFO] - Training step 10240 loss 0.016653822734951973
[2025-03-25 09:31:14,975][model][INFO] - Training step 10400 loss 0.017874039709568024
[2025-03-25 09:32:33,296][model][INFO] - Training step 10560 loss 0.13339173793792725
[2025-03-25 09:33:52,775][model][INFO] - Training step 10720 loss 0.2632717490196228
[2025-03-25 09:35:09,348][model][INFO] - Training step 10880 loss 0.032026275992393494
[2025-03-25 09:36:30,377][model][INFO] - Training step 11040 loss 0.10280530154705048
[2025-03-25 09:37:48,844][model][INFO] - Training step 11200 loss 0.01996569335460663
[2025-03-25 09:39:06,855][model][INFO] - Training step 11360 loss 0.24454763531684875
[2025-03-25 09:40:25,298][model][INFO] - Training step 11520 loss 0.018839552998542786
[2025-03-25 09:41:44,641][model][INFO] - Training step 11680 loss 0.033537350594997406
[2025-03-25 09:43:04,543][model][INFO] - Training step 11840 loss 0.06030174717307091
[2025-03-25 09:44:23,770][model][INFO] - Training step 12000 loss 0.02758944407105446
[2025-03-25 09:45:43,366][model][INFO] - Training step 12160 loss 0.027266893535852432
[2025-03-25 09:47:00,616][model][INFO] - Training step 12320 loss 0.03930778056383133
[2025-03-25 09:48:18,842][model][INFO] - Training step 12480 loss 0.02327650412917137
[2025-03-25 09:49:35,393][model][INFO] - Training step 12640 loss 0.029790710657835007
[2025-03-25 09:50:51,617][model][INFO] - Training step 12800 loss 0.2514371871948242
[2025-03-25 09:52:11,060][model][INFO] - Training step 12960 loss 0.014840247109532356
[2025-03-25 09:53:28,785][model][INFO] - Training step 13120 loss 0.016030404716730118
[2025-03-25 09:54:49,516][model][INFO] - Training step 13280 loss 0.006744295358657837
[2025-03-25 09:56:09,221][model][INFO] - Training step 13440 loss 0.007829088717699051
[2025-03-25 09:57:27,501][model][INFO] - Training step 13600 loss 0.24419227242469788
[2025-03-25 09:58:50,851][model][INFO] - Training step 13760 loss 0.027610689401626587
[2025-03-25 10:00:09,456][model][INFO] - Training step 13920 loss 0.06260497123003006
[2025-03-25 10:01:29,402][model][INFO] - Training step 14080 loss 0.019448284059762955
[2025-03-25 10:02:45,588][model][INFO] - Training step 14240 loss 0.09075485169887543
[2025-03-25 10:04:07,884][model][INFO] - Training step 14400 loss 0.007939651608467102
[2025-03-25 10:05:25,420][model][INFO] - Training step 14560 loss 0.02673978917300701
[2025-03-25 10:06:44,084][model][INFO] - Training step 14720 loss 0.016833188012242317
[2025-03-25 10:08:03,514][model][INFO] - Training step 14880 loss 0.216951385140419
[2025-03-25 10:09:23,940][model][INFO] - Training step 15040 loss 0.031971096992492676
[2025-03-25 10:10:44,282][model][INFO] - Training step 15200 loss 0.001751721603795886
[2025-03-25 10:12:02,429][model][INFO] - Training step 15360 loss 0.01261477917432785
[2025-03-25 10:13:22,717][model][INFO] - Training step 15520 loss 0.015001840889453888
[2025-03-25 10:14:42,001][model][INFO] - Training step 15680 loss 0.25601980090141296
[2025-03-25 10:16:02,496][model][INFO] - Training step 15840 loss 0.11486995965242386
[2025-03-25 10:17:23,971][model][INFO] - Training step 16000 loss 0.011874441057443619
[2025-03-25 10:18:42,139][model][INFO] - Training step 16160 loss 0.049968171864748
[2025-03-25 10:20:01,896][model][INFO] - Training step 16320 loss 0.003178538754582405
[2025-03-25 10:21:20,538][model][INFO] - Training step 16480 loss 0.02643679827451706
[2025-03-25 10:22:39,865][model][INFO] - Training step 16640 loss 0.019604265689849854
[2025-03-25 10:23:57,450][model][INFO] - Training step 16800 loss 0.02846706658601761
[2025-03-25 10:25:21,204][model][INFO] - Training step 16960 loss 0.2518044710159302
[2025-03-25 10:26:40,514][model][INFO] - Training step 17120 loss 0.03971881419420242
[2025-03-25 10:28:01,867][model][INFO] - Training step 17280 loss 0.028239766135811806
[2025-03-25 10:29:18,495][model][INFO] - Training step 17440 loss 0.0053261336870491505
[2025-03-25 10:30:37,902][model][INFO] - Training step 17600 loss 0.028675220906734467
[2025-03-25 10:31:56,397][model][INFO] - Training step 17760 loss 0.03160247951745987
[2025-03-25 10:33:16,508][model][INFO] - Training step 17920 loss 0.007126333191990852
[2025-03-25 10:34:35,628][model][INFO] - Training step 18080 loss 0.23436769843101501
[2025-03-25 10:35:51,922][model][INFO] - Training step 18240 loss 0.04718099534511566
[2025-03-25 10:37:11,579][model][INFO] - Training step 18400 loss 0.20807966589927673
[2025-03-25 10:38:30,452][model][INFO] - Training step 18560 loss 0.0332939475774765
[2025-03-25 10:39:51,413][model][INFO] - Training step 18720 loss 0.24830105900764465
[2025-03-25 10:41:09,396][model][INFO] - Training step 18880 loss 0.03548947721719742
[2025-03-25 10:42:28,516][model][INFO] - Training step 19040 loss 0.2216419130563736
[2025-03-25 10:43:46,865][model][INFO] - Training step 19200 loss 0.0763411670923233
[2025-03-25 10:45:03,087][model][INFO] - Training step 19360 loss 0.02428196743130684
[2025-03-25 10:46:22,428][model][INFO] - Training step 19520 loss 0.2300356775522232
[2025-03-25 10:47:40,729][model][INFO] - Training step 19680 loss 0.2569875419139862
[2025-03-25 10:48:56,474][model][INFO] - Training step 19840 loss 0.03502192348241806
[2025-03-25 10:50:16,392][model][INFO] - Training step 20000 loss 0.005806396249681711
[2025-03-25 10:51:37,488][model][INFO] - Training step 20160 loss 0.02169911563396454
[2025-03-25 10:52:56,748][model][INFO] - Training step 20320 loss 0.03488028049468994
[2025-03-25 10:54:14,920][model][INFO] - Training step 20480 loss 0.03689524531364441
[2025-03-25 10:55:32,425][model][INFO] - Training step 20640 loss 0.02479596622288227
[2025-03-25 10:56:51,023][model][INFO] - Training step 20800 loss 0.03255384415388107
[2025-03-25 10:58:08,632][model][INFO] - Training step 20960 loss 0.047067154198884964
[2025-03-25 10:59:27,266][model][INFO] - Training step 21120 loss 0.07922080159187317
[2025-03-25 11:00:47,912][model][INFO] - Training step 21280 loss 0.07044833898544312
[2025-03-25 11:02:07,947][model][INFO] - Training step 21440 loss 0.023383524268865585
[2025-03-25 11:03:24,513][model][INFO] - Training step 21600 loss 0.029150011017918587
[2025-03-25 11:04:47,061][model][INFO] - Training step 21760 loss 0.27112454175949097
[2025-03-25 11:06:06,330][model][INFO] - Training step 21920 loss 0.24641117453575134
[2025-03-25 11:07:26,883][model][INFO] - Training step 22080 loss 0.07202371954917908
[2025-03-25 11:08:47,805][model][INFO] - Training step 22240 loss 0.05194714665412903
[2025-03-25 11:10:10,133][model][INFO] - Training step 22400 loss 0.05127377063035965
----------------------------------------------------------------
Activating environment
Python version used:
Python 3.10.15
Starting training...
NVML Initialized
Driver Version: b'450.80.02'
[2025-04-07 14:47:02,208][__main__][INFO] - Start experiment: exp/default/2025-04-07_14-47-02_
[2025-04-07 14:47:02,387][__main__][INFO] - create datalogger
[2025-04-07 14:47:02,387][__main__][INFO] - Create new model
[2025-04-07 14:47:05,318][models.ncsnpp][DEBUG] - NCSNpp.__init__
[2025-04-07 14:47:05,318][models.ncsnpp][DEBUG] - all_resolutions: [256, 128, 64, 32, 16, 8, 4]
[2025-04-07 14:47:05,378][models.ncsnpp][DEBUG] - num_channels: 6
[2025-04-07 14:47:12,687][__main__][INFO] - start training
CHECKPOINT FOUND
[2025-04-07 14:47:47,559][model][INFO] - set optim with {'_target_': 'torch.optim.Adam', 'lr': 0.0001, 'weight_decay': 0.0}
┏━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓
┃   ┃ Name        ┃ Type             ┃ Params ┃ Mode  ┃
┡━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩
│ 0 │ model       │ ScoreModelNCSNpp │ 65.9 M │ train │
│ 1 │ loss        │ MSELoss          │      0 │ train │
│ 2 │ si_sdr_loss │ SISDRLoss        │      0 │ train │
└───┴─────────────┴──────────────────┴────────┴───────┘
Trainable params: 65.9 M                                                        
Non-trainable params: 128                                                       
Total params: 65.9 M                                                            
Total estimated model params size (MB): 263                                     
Modules in train mode: 444                                                      
Modules in eval mode: 0                                                         
[2025-04-07 14:48:32,867][model][INFO] - Training step 0 loss 0.028912000358104706
[2025-04-07 14:50:26,508][model][INFO] - Training step 160 loss 0.01390952430665493
[2025-04-07 14:52:18,394][model][INFO] - Training step 320 loss 0.06487910449504852
[2025-04-07 14:54:11,849][model][INFO] - Training step 480 loss 0.023211024701595306
[2025-04-07 14:56:01,955][model][INFO] - Training step 640 loss 0.257567822933197
[2025-04-07 14:57:56,472][model][INFO] - Training step 800 loss 0.00473668472841382
[2025-04-07 14:59:51,277][model][INFO] - Training step 960 loss 0.006561742164194584
[2025-04-07 15:01:38,773][model][INFO] - Training step 1120 loss 0.08399026095867157
[2025-04-07 15:03:35,830][model][INFO] - Training step 1280 loss 0.09013442695140839
[2025-04-07 15:05:28,535][model][INFO] - Training step 1440 loss 0.029060926288366318
[2025-04-07 15:07:22,115][model][INFO] - Training step 1600 loss 0.05005554482340813
[2025-04-07 15:09:15,538][model][INFO] - Training step 1760 loss 0.008322620764374733
[2025-04-07 15:11:07,874][model][INFO] - Training step 1920 loss 0.02719290554523468
[2025-04-07 15:13:03,719][model][INFO] - Training step 2080 loss 0.02412354201078415
[2025-04-07 15:14:57,961][model][INFO] - Training step 2240 loss 0.05819098278880119
[2025-04-07 15:16:52,154][model][INFO] - Training step 2400 loss 0.020207006484270096
[2025-04-07 15:18:43,402][model][INFO] - Training step 2560 loss 0.04680359363555908
[2025-04-07 15:20:37,141][model][INFO] - Training step 2720 loss 0.015804743394255638
[2025-04-07 15:22:32,074][model][INFO] - Training step 2880 loss 0.036767855286598206
[2025-04-07 15:24:28,016][model][INFO] - Training step 3040 loss 0.022333316504955292
[2025-04-07 15:26:23,001][model][INFO] - Training step 3200 loss 0.018566742539405823
[2025-04-07 15:28:19,105][model][INFO] - Training step 3360 loss 0.009404974989593029
[2025-04-07 15:30:09,277][model][INFO] - Training step 3520 loss 0.004457521252334118
[2025-04-07 15:32:04,921][model][INFO] - Training step 3680 loss 0.004250515252351761
[2025-04-07 15:33:55,919][model][INFO] - Training step 3840 loss 0.2240229696035385
[2025-04-07 15:35:55,036][model][INFO] - Training step 4000 loss 0.011836378835141659
[2025-04-07 15:37:50,097][model][INFO] - Training step 4160 loss 0.015947043895721436
[2025-04-07 15:39:41,623][model][INFO] - Training step 4320 loss 0.0661662146449089
[2025-04-07 15:41:36,800][model][INFO] - Training step 4480 loss 0.02851136028766632
Epoch 26/249 ━╸                   4562/50800 0:54:03 • 9:16:27 1.38it/s v_num: 1
[1;34mwandb[0m: 🚀 View run [33mFastGenSep++ (L)[0m at: [34mhttps://wandb.ai/anirudhbhalekar10-university-of-cambridge/shortcut-model-separation/runs/e1ifxn8j[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250407_144709-e1ifxn8j/logs[0m
...training finished
----------------------------------------------------------------
