
----------------------------------------------------------------
Activating environment
Python version used:
Python 3.10.15
Starting training...
NVML Initialized
Driver Version: b'450.80.02'
[2025-03-12 15:33:40,158][__main__][INFO] - Start experiment: exp/default/2025-03-12_15-33-40_
[2025-03-12 15:33:40,180][__main__][INFO] - create datalogger
[2025-03-12 15:33:40,180][__main__][INFO] - Create new model
[2025-03-12 15:33:41,579][models.ncsnpp][DEBUG] - NCSNpp.__init__
[2025-03-12 15:33:41,579][models.ncsnpp][DEBUG] - all_resolutions: [256, 128, 64, 32, 16, 8, 4]
[2025-03-12 15:33:41,580][models.ncsnpp][DEBUG] - num_channels: 6
[2025-03-12 15:33:43,246][__main__][INFO] - start training
CHECKPOINT FOUND
[2025-03-12 15:33:48,485][model][INFO] - set optim with {'_target_': 'torch.optim.Adam', 'lr': 0.0005, 'weight_decay': 0.0}
┏━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓
┃   ┃ Name        ┃ Type             ┃ Params ┃ Mode  ┃
┡━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩
│ 0 │ model       │ ScoreModelNCSNpp │ 16.5 M │ train │
│ 1 │ loss        │ MSELoss          │      0 │ train │
│ 2 │ si_sdr_loss │ SISDRLoss        │      0 │ train │
└───┴─────────────┴──────────────────┴────────┴───────┘
Trainable params: 16.5 M                                                        
Non-trainable params: 64                                                        
Total params: 16.5 M                                                            
Total estimated model params size (MB): 66                                      
Modules in train mode: 444                                                      
Modules in eval mode: 0                                                         
[2025-03-12 15:34:01,834][model][INFO] - Training step 0 loss 0.06954306364059448
[2025-03-12 15:34:45,155][model][INFO] - Training step 160 loss 0.24785226583480835
[2025-03-12 15:35:26,649][model][INFO] - Training step 320 loss 0.06734496355056763
[2025-03-12 15:36:10,240][model][INFO] - Training step 480 loss 0.24873623251914978
[2025-03-12 15:36:49,783][model][INFO] - Training step 640 loss 0.04812876135110855
[2025-03-12 15:37:30,002][model][INFO] - Training step 800 loss 0.025463834404945374
[2025-03-12 15:38:10,812][model][INFO] - Training step 960 loss 0.014732814393937588
[2025-03-12 15:38:50,979][model][INFO] - Training step 1120 loss 0.23849564790725708
[2025-03-12 15:39:31,334][model][INFO] - Training step 1280 loss 0.01687616854906082
[2025-03-12 15:40:10,538][model][INFO] - Training step 1440 loss 0.027641139924526215
[2025-03-12 15:40:53,071][model][INFO] - Training step 1600 loss 0.13129836320877075
[2025-03-12 15:41:32,248][model][INFO] - Training step 1760 loss 0.02665996178984642
[2025-03-12 15:42:12,021][model][INFO] - Training step 1920 loss 0.06154874712228775
[2025-03-12 15:42:52,821][model][INFO] - Training step 2080 loss 0.022153440862894058
[2025-03-12 15:43:35,141][model][INFO] - Training step 2240 loss 0.006765883415937424
[2025-03-12 15:44:33,831][model][INFO] - Training step 2400 loss 0.01320466585457325
[2025-03-12 15:45:48,221][model][INFO] - Training step 2560 loss 0.011319400742650032
[2025-03-12 15:46:58,743][model][INFO] - Training step 2720 loss 0.1944456696510315
[2025-03-12 15:48:07,601][model][INFO] - Training step 2880 loss 0.017264772206544876
[2025-03-12 15:49:18,852][model][INFO] - Training step 3040 loss 0.2577233910560608
[2025-03-12 15:50:32,408][model][INFO] - Training step 3200 loss 0.005704156123101711
[2025-03-12 15:51:47,469][model][INFO] - Training step 3360 loss 0.007629850879311562
[2025-03-12 15:52:58,667][model][INFO] - Training step 3520 loss 0.24897035956382751
[2025-03-12 15:54:11,205][model][INFO] - Training step 3680 loss 0.03420574218034744
[2025-03-12 15:55:21,289][model][INFO] - Training step 3840 loss 0.027114521712064743
[2025-03-12 15:56:33,421][model][INFO] - Training step 4000 loss 0.0850818082690239
[2025-03-12 15:57:46,184][model][INFO] - Training step 4160 loss 0.0047588408924639225
[2025-03-12 15:59:00,511][model][INFO] - Training step 4320 loss 0.02343018352985382
[2025-03-12 16:00:11,477][model][INFO] - Training step 4480 loss 0.02893983945250511
[2025-03-12 16:01:25,763][model][INFO] - Training step 4640 loss 0.10486426949501038
[2025-03-12 16:02:37,875][model][INFO] - Training step 4800 loss 0.0052851238287985325
[2025-03-12 16:03:49,444][model][INFO] - Training step 4960 loss 0.008948538452386856
[2025-03-12 16:05:01,595][model][INFO] - Training step 5120 loss 0.667748212814331
[2025-03-12 16:06:16,722][model][INFO] - Training step 5280 loss 0.23043864965438843
[2025-03-12 16:07:28,424][model][INFO] - Training step 5440 loss 0.06873886287212372
[2025-03-12 16:08:40,147][model][INFO] - Training step 5600 loss 0.03851954638957977
[2025-03-12 16:09:50,368][model][INFO] - Training step 5760 loss 0.022527314722537994
[2025-03-12 16:10:37,751][model][INFO] - Training step 5920 loss 0.020039238035678864
[2025-03-12 16:11:17,436][model][INFO] - Training step 6080 loss 0.019207961857318878
[2025-03-12 16:11:58,110][model][INFO] - Training step 6240 loss 0.022338826209306717
[2025-03-12 16:12:40,093][model][INFO] - Training step 6400 loss 0.12930557131767273
[2025-03-12 16:13:20,889][model][INFO] - Training step 6560 loss 0.02566007524728775
[2025-03-12 16:14:02,886][model][INFO] - Training step 6720 loss 0.005037632770836353
[2025-03-12 16:14:43,551][model][INFO] - Training step 6880 loss 0.12416334450244904
[2025-03-12 16:15:25,430][model][INFO] - Training step 7040 loss 0.2594830393791199
[2025-03-12 16:16:07,517][model][INFO] - Training step 7200 loss 0.008174759335815907
[2025-03-12 16:16:48,766][model][INFO] - Training step 7360 loss 0.05041950196027756
[2025-03-12 16:17:30,205][model][INFO] - Training step 7520 loss 0.02983183041214943
[2025-03-12 16:18:11,272][model][INFO] - Training step 7680 loss 0.04169580340385437
[2025-03-12 16:18:53,369][model][INFO] - Training step 7840 loss 0.04130706191062927
[2025-03-12 16:19:35,508][model][INFO] - Training step 8000 loss 0.006590964272618294
[2025-03-12 16:20:17,477][model][INFO] - Training step 8160 loss 0.15617097914218903
[2025-03-12 16:20:58,921][model][INFO] - Training step 8320 loss 0.018798597157001495
[2025-03-12 16:21:40,692][model][INFO] - Training step 8480 loss 0.00906083919107914
[2025-03-12 16:22:21,893][model][INFO] - Training step 8640 loss 0.017399299889802933
[2025-03-12 16:23:02,625][model][INFO] - Training step 8800 loss 0.061975933611392975
[2025-03-12 16:23:45,161][model][INFO] - Training step 8960 loss 0.02234818786382675
[2025-03-12 16:24:25,416][model][INFO] - Training step 9120 loss 0.03091621771454811
[2025-03-12 16:25:04,305][model][INFO] - Training step 9280 loss 0.25859707593917847
[2025-03-12 16:25:46,165][model][INFO] - Training step 9440 loss 0.03200266510248184
[2025-03-12 16:26:31,108][model][INFO] - Training step 9600 loss 0.004524845629930496
[2025-03-12 16:27:13,240][model][INFO] - Training step 9760 loss 0.034755680710077286
[2025-03-12 16:27:55,859][model][INFO] - Training step 9920 loss 0.018479015678167343
[2025-03-12 16:28:38,751][model][INFO] - Training step 10080 loss 0.2557148337364197
[2025-03-12 16:29:19,533][model][INFO] - Training step 10240 loss 0.013981381431221962
[2025-03-12 16:30:01,369][model][INFO] - Training step 10400 loss 0.07813742011785507
[2025-03-12 16:30:42,929][model][INFO] - Training step 10560 loss 0.03781883791089058
[2025-03-12 16:31:24,060][model][INFO] - Training step 10720 loss 0.018272481858730316
[2025-03-12 16:32:04,401][model][INFO] - Training step 10880 loss 0.033326856791973114
[2025-03-12 16:32:45,226][model][INFO] - Training step 11040 loss 0.1687251478433609
[2025-03-12 16:33:25,729][model][INFO] - Training step 11200 loss 0.06217263266444206
[2025-03-12 16:34:07,490][model][INFO] - Training step 11360 loss 0.0014902581460773945
[2025-03-12 16:34:47,101][model][INFO] - Training step 11520 loss 0.020647233352065086
[2025-03-12 16:35:26,079][model][INFO] - Training step 11680 loss 0.04344360530376434
[2025-03-12 16:36:08,850][model][INFO] - Training step 11840 loss 0.054352566599845886
[2025-03-12 16:36:49,855][model][INFO] - Training step 12000 loss 0.003675782587379217
[2025-03-12 16:37:31,995][model][INFO] - Training step 12160 loss 0.002605810994282365
[2025-03-12 16:38:13,687][model][INFO] - Training step 12320 loss 0.031583208590745926
[2025-03-12 16:38:55,273][model][INFO] - Training step 12480 loss 0.005068443715572357
[2025-03-12 16:39:36,971][model][INFO] - Training step 12640 loss 0.04732994735240936
[2025-03-12 16:40:18,759][model][INFO] - Training step 12800 loss 0.006540668662637472
[2025-03-12 16:40:59,985][model][INFO] - Training step 12960 loss 0.01724826544523239
[2025-03-12 16:41:40,324][model][INFO] - Training step 13120 loss 0.251419335603714
[2025-03-12 16:42:21,924][model][INFO] - Training step 13280 loss 0.018899492919445038
[2025-03-12 16:43:04,787][model][INFO] - Training step 13440 loss 0.23782485723495483
[2025-03-12 16:43:47,350][model][INFO] - Training step 13600 loss 0.03126462548971176
[2025-03-12 16:44:27,058][model][INFO] - Training step 13760 loss 0.060146331787109375
[2025-03-12 16:45:07,896][model][INFO] - Training step 13920 loss 0.2683899998664856
[2025-03-12 16:45:49,541][model][INFO] - Training step 14080 loss 0.028805933892726898
[2025-03-12 16:46:32,392][model][INFO] - Training step 14240 loss 0.0073975007981061935
[2025-03-12 16:47:14,190][model][INFO] - Training step 14400 loss 0.01587865874171257
[2025-03-12 16:47:54,625][model][INFO] - Training step 14560 loss 0.26364511251449585
[2025-03-12 16:48:35,818][model][INFO] - Training step 14720 loss 0.01534129586070776
[2025-03-12 16:49:17,496][model][INFO] - Training step 14880 loss 0.03400541841983795
[2025-03-12 16:49:59,685][model][INFO] - Training step 15040 loss 0.02882571518421173
[2025-03-12 16:50:42,574][model][INFO] - Training step 15200 loss 0.048004359006881714
[2025-03-12 16:51:24,401][model][INFO] - Training step 15360 loss 0.04590380936861038
[2025-03-12 16:52:06,777][model][INFO] - Training step 15520 loss 0.25334781408309937
[2025-03-12 16:52:48,800][model][INFO] - Training step 15680 loss 0.25474458932876587
[2025-03-12 16:53:31,849][model][INFO] - Training step 15840 loss 0.05000625178217888
[2025-03-12 16:54:13,458][model][INFO] - Training step 16000 loss 0.014720628969371319
[2025-03-12 16:54:57,497][model][INFO] - Training step 16160 loss 0.018529508262872696
[2025-03-12 16:55:37,723][model][INFO] - Training step 16320 loss 0.0023086811415851116
[2025-03-12 16:56:17,183][model][INFO] - Training step 16480 loss 0.23656535148620605
[2025-03-12 16:56:56,947][model][INFO] - Training step 16640 loss 0.38970690965652466
[2025-03-12 16:57:39,647][model][INFO] - Training step 16800 loss 0.27364033460617065
[2025-03-12 16:58:20,578][model][INFO] - Training step 16960 loss 0.034800946712493896
[2025-03-12 16:59:03,328][model][INFO] - Training step 17120 loss 0.05822524428367615
[2025-03-12 16:59:45,928][model][INFO] - Training step 17280 loss 0.09960292279720306
[2025-03-12 17:00:32,570][model][INFO] - Training step 17440 loss 0.24869565665721893
[2025-03-12 17:01:16,579][model][INFO] - Training step 17600 loss 0.026995625346899033
[2025-03-12 17:01:57,779][model][INFO] - Training step 17760 loss 0.0019938938785344362
[2025-03-12 17:02:39,065][model][INFO] - Training step 17920 loss 0.08303619176149368
[2025-03-12 17:03:19,277][model][INFO] - Training step 18080 loss 0.2414613664150238
[2025-03-12 17:04:00,574][model][INFO] - Training step 18240 loss 0.0065037840977311134
[2025-03-12 17:04:42,484][model][INFO] - Training step 18400 loss 0.3606569766998291
[2025-03-12 17:05:23,295][model][INFO] - Training step 18560 loss 0.007200613152235746
[2025-03-12 17:06:04,174][model][INFO] - Training step 18720 loss 0.03140878677368164
[2025-03-12 17:06:46,034][model][INFO] - Training step 18880 loss 0.2621133625507355
[2025-03-12 17:07:26,592][model][INFO] - Training step 19040 loss 0.033408790826797485
[2025-03-12 17:08:07,706][model][INFO] - Training step 19200 loss 0.02954178676009178
[2025-03-12 17:08:47,357][model][INFO] - Training step 19360 loss 0.10167942941188812
[2025-03-12 17:09:29,213][model][INFO] - Training step 19520 loss 0.22856542468070984
[2025-03-12 17:10:11,603][model][INFO] - Training step 19680 loss 0.2554466128349304
[2025-03-12 17:10:53,665][model][INFO] - Training step 19840 loss 0.007722344249486923
[2025-03-12 17:11:35,469][model][INFO] - Training step 20000 loss 0.04386696591973305
[2025-03-12 17:12:17,164][model][INFO] - Training step 20160 loss 0.05739831179380417
[2025-03-12 17:12:59,000][model][INFO] - Training step 20320 loss 0.004344626795500517
[2025-03-12 17:13:39,468][model][INFO] - Training step 20480 loss 0.1280594766139984
[2025-03-12 17:14:19,916][model][INFO] - Training step 20640 loss 0.03931190446019173
[2025-03-12 17:14:59,508][model][INFO] - Training step 20800 loss 0.10912619531154633
[2025-03-12 17:15:41,931][model][INFO] - Training step 20960 loss 0.003925902768969536
[2025-03-12 17:16:22,123][model][INFO] - Training step 21120 loss 0.010507256723940372
[2025-03-12 17:17:03,758][model][INFO] - Training step 21280 loss 0.003386987606063485
[2025-03-12 17:17:44,570][model][INFO] - Training step 21440 loss 0.014792175032198429
[2025-03-12 17:18:25,113][model][INFO] - Training step 21600 loss 0.25138580799102783
[2025-03-12 17:19:05,413][model][INFO] - Training step 21760 loss 0.02526848018169403
[2025-03-12 17:19:46,017][model][INFO] - Training step 21920 loss 0.01953006163239479
[2025-03-12 17:20:25,931][model][INFO] - Training step 22080 loss 0.25996649265289307
[2025-03-12 17:21:06,536][model][INFO] - Training step 22240 loss 0.12275417149066925
[2025-03-12 17:21:47,743][model][INFO] - Training step 22400 loss 0.029228761792182922
[2025-03-12 17:22:29,302][model][INFO] - Training step 22560 loss 0.027485720813274384
[2025-03-12 17:23:10,277][model][INFO] - Training step 22720 loss 0.01160002313554287
[2025-03-12 17:23:50,705][model][INFO] - Training step 22880 loss 0.017086993902921677
[2025-03-12 17:24:31,813][model][INFO] - Training step 23040 loss 0.04385839402675629
[2025-03-12 17:25:14,584][model][INFO] - Training step 23200 loss 0.005860151257365942
[2025-03-12 17:25:54,760][model][INFO] - Training step 23360 loss 0.032859668135643005
[2025-03-12 17:26:35,979][model][INFO] - Training step 23520 loss 0.023135297000408173
[2025-03-12 17:27:17,700][model][INFO] - Training step 23680 loss 0.07433387637138367
[2025-03-12 17:27:59,779][model][INFO] - Training step 23840 loss 0.2487693727016449
[2025-03-12 17:28:40,204][model][INFO] - Training step 24000 loss 0.14012876152992249
[2025-03-12 17:29:19,417][model][INFO] - Training step 24160 loss 0.02543771266937256
[2025-03-12 17:29:59,584][model][INFO] - Training step 24320 loss 0.0785658061504364
[2025-03-12 17:30:39,800][model][INFO] - Training step 24480 loss 0.011547599919140339
[2025-03-12 17:31:20,549][model][INFO] - Training step 24640 loss 0.25736004114151
[2025-03-12 17:32:00,221][model][INFO] - Training step 24800 loss 0.035097502171993256
[2025-03-12 17:32:40,327][model][INFO] - Training step 24960 loss 0.025057315826416016
[2025-03-12 17:33:21,699][model][INFO] - Training step 25120 loss 0.0772087350487709
[2025-03-12 17:34:00,777][model][INFO] - Training step 25280 loss 0.015532158315181732
[2025-03-12 17:34:41,486][model][INFO] - Training step 25440 loss 0.005053484812378883
[2025-03-12 17:35:20,097][model][INFO] - Training step 25600 loss 0.040238164365291595
[2025-03-12 17:35:59,332][model][INFO] - Training step 25760 loss 0.05258007347583771
[2025-03-12 17:36:40,422][model][INFO] - Training step 25920 loss 0.03782384842634201
[2025-03-12 17:37:21,066][model][INFO] - Training step 26080 loss 0.02184564620256424
[2025-03-12 17:38:01,901][model][INFO] - Training step 26240 loss 0.020849239081144333
[2025-03-12 17:38:43,599][model][INFO] - Training step 26400 loss 0.0283826794475317
[2025-03-12 17:39:24,745][model][INFO] - Training step 26560 loss 0.022387318313121796
[2025-03-12 17:40:06,509][model][INFO] - Training step 26720 loss 0.03471875935792923
[2025-03-12 17:40:47,106][model][INFO] - Training step 26880 loss 0.027809221297502518
[2025-03-12 17:41:27,512][model][INFO] - Training step 27040 loss 0.2596205770969391
[2025-03-12 17:42:08,841][model][INFO] - Training step 27200 loss 0.017655152827501297
[2025-03-12 17:42:49,106][model][INFO] - Training step 27360 loss 0.036423809826374054
[2025-03-12 17:43:29,366][model][INFO] - Training step 27520 loss 0.03099803254008293
[2025-03-12 17:44:11,027][model][INFO] - Training step 27680 loss 0.035590507090091705
[2025-03-12 17:44:52,086][model][INFO] - Training step 27840 loss 0.027987150475382805
[2025-03-12 17:45:32,212][model][INFO] - Training step 28000 loss 0.02305450849235058
[2025-03-12 17:46:13,732][model][INFO] - Training step 28160 loss 0.016184769570827484
[2025-03-12 17:46:56,552][model][INFO] - Training step 28320 loss 0.23866905272006989
[2025-03-12 17:47:37,870][model][INFO] - Training step 28480 loss 0.04050639271736145
[2025-03-12 17:48:19,446][model][INFO] - Training step 28640 loss 0.03822050243616104
[2025-03-12 17:48:58,723][model][INFO] - Training step 28800 loss 0.0025576658081263304
[2025-03-12 17:49:39,260][model][INFO] - Training step 28960 loss 0.07855649292469025
[2025-03-12 17:50:18,820][model][INFO] - Training step 29120 loss 0.23534250259399414
[2025-03-12 17:51:00,432][model][INFO] - Training step 29280 loss 0.022030416876077652
[2025-03-12 17:51:42,656][model][INFO] - Training step 29440 loss 0.018647126853466034
[2025-03-12 17:52:23,369][model][INFO] - Training step 29600 loss 0.0756639838218689
[2025-03-12 17:53:05,245][model][INFO] - Training step 29760 loss 0.03638347238302231
[2025-03-12 17:53:47,498][model][INFO] - Training step 29920 loss 0.2358439564704895
[2025-03-12 17:54:29,004][model][INFO] - Training step 30080 loss 0.002624990651383996
[2025-03-12 17:55:09,573][model][INFO] - Training step 30240 loss 0.03221505135297775
[2025-03-12 17:55:51,623][model][INFO] - Training step 30400 loss 0.2315763235092163
[2025-03-12 17:56:34,601][model][INFO] - Training step 30560 loss 0.2942768931388855
[2025-03-12 17:57:14,289][model][INFO] - Training step 30720 loss 0.06805112957954407
[2025-03-12 17:57:54,300][model][INFO] - Training step 30880 loss 0.06597462296485901
[2025-03-12 17:58:36,629][model][INFO] - Training step 31040 loss 0.02355126477777958
[2025-03-12 17:59:17,657][model][INFO] - Training step 31200 loss 0.019071433693170547
[2025-03-12 17:59:59,236][model][INFO] - Training step 31360 loss 0.03274271637201309
[2025-03-12 18:00:46,460][model][INFO] - Training step 31520 loss 0.08817660808563232
[2025-03-12 18:01:27,581][model][INFO] - Training step 31680 loss 0.25048044323921204
[2025-03-12 18:02:08,912][model][INFO] - Training step 31840 loss 0.0038702324964106083
[2025-03-12 18:02:49,842][model][INFO] - Training step 32000 loss 0.006213853135704994
[2025-03-12 18:03:30,315][model][INFO] - Training step 32160 loss 0.05113967880606651
[2025-03-12 18:04:10,927][model][INFO] - Training step 32320 loss 0.019969899207353592
[2025-03-12 18:04:50,583][model][INFO] - Training step 32480 loss 0.25342661142349243
[2025-03-12 18:05:31,910][model][INFO] - Training step 32640 loss 0.044800542294979095
[2025-03-12 18:06:13,460][model][INFO] - Training step 32800 loss 0.11688823997974396
[2025-03-12 18:06:55,157][model][INFO] - Training step 32960 loss 0.02679315209388733
[2025-03-12 18:07:35,677][model][INFO] - Training step 33120 loss 0.25069648027420044
[2025-03-12 18:08:16,039][model][INFO] - Training step 33280 loss 0.25224101543426514
[2025-03-12 18:08:57,938][model][INFO] - Training step 33440 loss 0.03306680917739868
[2025-03-12 18:09:38,900][model][INFO] - Training step 33600 loss 0.06255321949720383
[2025-03-12 18:10:20,064][model][INFO] - Training step 33760 loss 0.09108854830265045
[2025-03-12 18:11:01,345][model][INFO] - Training step 33920 loss 0.005482882261276245
[2025-03-12 18:11:42,417][model][INFO] - Training step 34080 loss 0.016614897176623344
[2025-03-12 18:12:23,836][model][INFO] - Training step 34240 loss 0.02707858756184578
[2025-03-12 18:13:04,811][model][INFO] - Training step 34400 loss 0.02675507962703705
[2025-03-12 18:13:45,235][model][INFO] - Training step 34560 loss 0.03115611895918846
[2025-03-12 18:14:26,522][model][INFO] - Training step 34720 loss 0.04027894139289856
[2025-03-12 18:15:08,535][model][INFO] - Training step 34880 loss 0.019304238259792328
[2025-03-12 18:15:49,832][model][INFO] - Training step 35040 loss 0.24525760114192963
[2025-03-12 18:16:30,241][model][INFO] - Training step 35200 loss 0.012490805238485336
[2025-03-12 18:17:12,349][model][INFO] - Training step 35360 loss 0.029017940163612366
[2025-03-12 18:17:52,812][model][INFO] - Training step 35520 loss 0.05331341177225113
[2025-03-12 18:18:33,843][model][INFO] - Training step 35680 loss 0.018290020525455475
[2025-03-12 18:19:15,237][model][INFO] - Training step 35840 loss 0.008564263582229614
[2025-03-12 18:19:54,797][model][INFO] - Training step 36000 loss 0.02790110558271408
[2025-03-12 18:20:35,521][model][INFO] - Training step 36160 loss 0.03043552301824093
[2025-03-12 18:21:16,001][model][INFO] - Training step 36320 loss 0.12102349102497101
[2025-03-12 18:21:55,894][model][INFO] - Training step 36480 loss 0.021335769444704056
[2025-03-12 18:22:36,957][model][INFO] - Training step 36640 loss 0.03734959661960602
[2025-03-12 18:23:17,955][model][INFO] - Training step 36800 loss 0.10443644225597382
[2025-03-12 18:23:59,617][model][INFO] - Training step 36960 loss 0.017684634774923325
[2025-03-12 18:24:39,528][model][INFO] - Training step 37120 loss 0.03460974246263504
[2025-03-12 18:25:19,936][model][INFO] - Training step 37280 loss 0.06491390615701675
[2025-03-12 18:26:02,776][model][INFO] - Training step 37440 loss 0.004218765068799257
[2025-03-12 18:26:43,356][model][INFO] - Training step 37600 loss 0.024501260370016098
[2025-03-12 18:27:23,886][model][INFO] - Training step 37760 loss 0.2211453914642334
[2025-03-12 18:28:04,384][model][INFO] - Training step 37920 loss 0.013636421412229538
[2025-03-12 18:28:45,143][model][INFO] - Training step 38080 loss 0.025159355252981186
[2025-03-12 18:29:25,347][model][INFO] - Training step 38240 loss 0.0213992390781641
[2025-03-12 18:30:07,927][model][INFO] - Training step 38400 loss 0.025882579386234283
[2025-03-12 18:30:51,210][model][INFO] - Training step 38560 loss 0.2598020136356354
[2025-03-12 18:31:33,597][model][INFO] - Training step 38720 loss 0.11005263030529022
[2025-03-12 18:32:15,651][model][INFO] - Training step 38880 loss 0.030629366636276245
[2025-03-12 18:32:57,348][model][INFO] - Training step 39040 loss 0.24956083297729492
[2025-03-12 18:33:58,683][model][INFO] - Training step 39200 loss 0.007686937227845192
[2025-03-12 18:34:54,285][model][INFO] - Training step 39360 loss 0.03986187279224396
[2025-03-12 18:35:37,722][model][INFO] - Training step 39520 loss 0.026712048798799515
[2025-03-12 18:36:20,422][model][INFO] - Training step 39680 loss 0.01911081187427044
[2025-03-12 18:37:01,428][model][INFO] - Training step 39840 loss 0.2451818883419037
[2025-03-12 18:37:42,913][model][INFO] - Training step 40000 loss 0.025192227214574814
[2025-03-12 18:38:26,565][model][INFO] - Training step 40160 loss 0.07048383355140686
[2025-03-12 18:39:09,123][model][INFO] - Training step 40320 loss 0.16756334900856018
[2025-03-12 18:39:51,066][model][INFO] - Training step 40480 loss 0.03691922500729561
[2025-03-12 18:40:33,355][model][INFO] - Training step 40640 loss 0.024690503254532814
[2025-03-12 18:41:14,075][model][INFO] - Training step 40800 loss 0.013620279729366302
[2025-03-12 18:41:56,171][model][INFO] - Training step 40960 loss 0.2806105613708496
[2025-03-12 18:42:36,945][model][INFO] - Training step 41120 loss 0.010386096313595772
[2025-03-12 18:43:19,783][model][INFO] - Training step 41280 loss 0.004230660852044821
[2025-03-12 18:44:01,201][model][INFO] - Training step 41440 loss 0.06433086097240448
[2025-03-12 18:44:41,893][model][INFO] - Training step 41600 loss 0.2486979216337204
[2025-03-12 18:45:23,842][model][INFO] - Training step 41760 loss 0.01801181584596634
[2025-03-12 18:46:05,916][model][INFO] - Training step 41920 loss 0.021400263532996178
[2025-03-12 18:46:47,272][model][INFO] - Training step 42080 loss 0.02116180583834648
[2025-03-12 18:47:29,467][model][INFO] - Training step 42240 loss 0.2559017539024353
[2025-03-12 18:48:12,561][model][INFO] - Training step 42400 loss 0.03404882177710533
[2025-03-12 18:48:53,480][model][INFO] - Training step 42560 loss 0.007885986007750034
[2025-03-12 18:49:35,205][model][INFO] - Training step 42720 loss 0.022302288562059402
[2025-03-12 18:50:17,575][model][INFO] - Training step 42880 loss 0.2611585557460785
[2025-03-12 18:50:58,704][model][INFO] - Training step 43040 loss 0.05870462954044342
[2025-03-12 18:51:42,619][model][INFO] - Training step 43200 loss 0.03023470565676689
[2025-03-12 18:52:26,016][model][INFO] - Training step 43360 loss 0.04212237894535065
[2025-03-12 18:53:07,460][model][INFO] - Training step 43520 loss 0.023370543494820595
[2025-03-12 18:53:47,719][model][INFO] - Training step 43680 loss 0.02587291970849037
[2025-03-12 18:54:29,024][model][INFO] - Training step 43840 loss 0.03196140006184578
[2025-03-12 18:55:11,699][model][INFO] - Training step 44000 loss 0.049823202192783356
[2025-03-12 18:55:52,710][model][INFO] - Training step 44160 loss 0.005932417698204517
[2025-03-12 18:56:36,587][model][INFO] - Training step 44320 loss 0.019037775695323944
[2025-03-12 18:57:19,417][model][INFO] - Training step 44480 loss 0.022367937490344048
[2025-03-12 18:58:00,402][model][INFO] - Training step 44640 loss 0.021291792392730713
[2025-03-12 18:58:42,196][model][INFO] - Training step 44800 loss 0.01916511356830597
[2025-03-12 18:59:24,467][model][INFO] - Training step 44960 loss 0.003531700698658824
[2025-03-12 19:00:05,971][model][INFO] - Training step 45120 loss 0.0470069944858551
[2025-03-12 19:00:47,496][model][INFO] - Training step 45280 loss 0.12406747043132782
[2025-03-12 19:01:34,009][model][INFO] - Training step 45440 loss 0.013902253471314907
[2025-03-12 19:02:13,921][model][INFO] - Training step 45600 loss 0.1901361346244812
[2025-03-12 19:02:55,171][model][INFO] - Training step 45760 loss 0.030599180608987808
[2025-03-12 19:03:36,957][model][INFO] - Training step 45920 loss 0.02443270944058895
[2025-03-12 19:04:18,730][model][INFO] - Training step 46080 loss 0.007422983180731535
[2025-03-12 19:04:59,579][model][INFO] - Training step 46240 loss 0.031405843794345856
[2025-03-12 19:05:41,870][model][INFO] - Training step 46400 loss 0.20935632288455963
[2025-03-12 19:06:23,863][model][INFO] - Training step 46560 loss 0.006668447982519865
[2025-03-12 19:07:06,123][model][INFO] - Training step 46720 loss 0.044806595891714096
[2025-03-12 19:07:46,831][model][INFO] - Training step 46880 loss 0.025031816214323044
[2025-03-12 19:08:28,814][model][INFO] - Training step 47040 loss 0.061262570321559906
[2025-03-12 19:09:09,998][model][INFO] - Training step 47200 loss 0.025793246924877167
[2025-03-12 19:09:52,585][model][INFO] - Training step 47360 loss 0.24529069662094116
[2025-03-12 19:10:34,224][model][INFO] - Training step 47520 loss 0.016012996435165405
[2025-03-12 19:11:17,211][model][INFO] - Training step 47680 loss 0.033934809267520905
[2025-03-12 19:11:55,969][model][INFO] - Training step 47840 loss 0.0338328555226326
[2025-03-12 19:12:37,457][model][INFO] - Training step 48000 loss 0.2552112936973572
[2025-03-12 19:13:20,319][model][INFO] - Training step 48160 loss 0.027123499661684036
[2025-03-12 19:14:01,347][model][INFO] - Training step 48320 loss 0.022058185189962387
[2025-03-12 19:14:42,920][model][INFO] - Training step 48480 loss 0.24975734949111938
[2025-03-12 19:15:23,327][model][INFO] - Training step 48640 loss 0.03489109128713608
[2025-03-12 19:16:05,063][model][INFO] - Training step 48800 loss 0.06805069744586945
[2025-03-12 19:16:45,651][model][INFO] - Training step 48960 loss 0.22240228950977325
[2025-03-12 19:17:27,075][model][INFO] - Training step 49120 loss 0.021203847602009773
[2025-03-12 19:18:09,266][model][INFO] - Training step 49280 loss 0.02913641929626465
[2025-03-12 19:18:51,954][model][INFO] - Training step 49440 loss 0.023534003645181656
[2025-03-12 19:19:33,348][model][INFO] - Training step 49600 loss 0.10828571021556854
[2025-03-12 19:20:13,816][model][INFO] - Training step 49760 loss 0.060872942209243774
[2025-03-12 19:20:55,253][model][INFO] - Training step 49920 loss 0.016607481986284256
[2025-03-12 19:21:36,899][model][INFO] - Training step 50080 loss 0.10345588624477386
[2025-03-12 19:22:20,050][model][INFO] - Training step 50240 loss 0.2740018367767334
[2025-03-12 19:23:01,232][model][INFO] - Training step 50400 loss 0.01972891390323639
[2025-03-12 19:23:40,869][model][INFO] - Training step 50560 loss 0.02983131632208824
[2025-03-12 19:24:21,414][model][INFO] - Training step 50720 loss 0.03704774007201195
[2025-03-12 19:30:09,039][model][INFO] - Training step 80 loss 0.0050031221471726894
[2025-03-12 19:30:49,472][model][INFO] - Training step 240 loss 0.03802935779094696
[2025-03-12 19:31:31,034][model][INFO] - Training step 400 loss 0.05424293503165245
[2025-03-12 19:32:09,988][model][INFO] - Training step 560 loss 0.02009771019220352
[2025-03-12 19:32:50,725][model][INFO] - Training step 720 loss 0.049302130937576294
[2025-03-12 19:33:30,385][model][INFO] - Training step 880 loss 0.04173453152179718
[2025-03-12 19:34:10,427][model][INFO] - Training step 1040 loss 0.014100472442805767
[2025-03-12 19:34:51,795][model][INFO] - Training step 1200 loss 0.08687444776296616
[2025-03-12 19:35:34,282][model][INFO] - Training step 1360 loss 0.0035815380979329348
[2025-03-12 19:36:15,742][model][INFO] - Training step 1520 loss 0.05728337913751602
[2025-03-12 19:36:55,948][model][INFO] - Training step 1680 loss 0.1063123345375061
[2025-03-12 19:37:36,482][model][INFO] - Training step 1840 loss 0.036876849830150604
[2025-03-12 19:38:15,698][model][INFO] - Training step 2000 loss 0.305602490901947
[2025-03-12 19:38:55,331][model][INFO] - Training step 2160 loss 0.02559342235326767
[2025-03-12 19:39:35,769][model][INFO] - Training step 2320 loss 0.1013307124376297
[2025-03-12 19:40:16,088][model][INFO] - Training step 2480 loss 0.004680628888309002
[2025-03-12 19:40:55,703][model][INFO] - Training step 2640 loss 0.2525627613067627
[2025-03-12 19:41:36,124][model][INFO] - Training step 2800 loss 0.03452451899647713
[2025-03-12 19:42:19,181][model][INFO] - Training step 2960 loss 0.006061234511435032
[2025-03-12 19:42:59,697][model][INFO] - Training step 3120 loss 0.13777822256088257
[2025-03-12 19:43:40,103][model][INFO] - Training step 3280 loss 0.030514374375343323
[2025-03-12 19:44:20,531][model][INFO] - Training step 3440 loss 0.0062091415748000145
[2025-03-12 19:44:59,727][model][INFO] - Training step 3600 loss 0.2465013712644577
[2025-03-12 19:45:40,924][model][INFO] - Training step 3760 loss 0.26637667417526245
[2025-03-12 19:46:19,835][model][INFO] - Training step 3920 loss 0.018023917451500893
[2025-03-12 19:47:01,373][model][INFO] - Training step 4080 loss 0.0310229305177927
[2025-03-12 19:47:41,324][model][INFO] - Training step 4240 loss 0.005578158888965845
[2025-03-12 19:48:21,476][model][INFO] - Training step 4400 loss 0.01502992119640112
[2025-03-12 19:49:02,013][model][INFO] - Training step 4560 loss 0.027805138379335403
[2025-03-12 19:49:44,144][model][INFO] - Training step 4720 loss 0.026229139417409897
[2025-03-12 19:50:24,157][model][INFO] - Training step 4880 loss 0.1055135652422905
[2025-03-12 19:51:05,143][model][INFO] - Training step 5040 loss 0.28725191950798035
[2025-03-12 19:51:45,552][model][INFO] - Training step 5200 loss 0.07206160575151443
[2025-03-12 19:52:26,015][model][INFO] - Training step 5360 loss 0.25515487790107727
[2025-03-12 19:53:06,428][model][INFO] - Training step 5520 loss 0.12308232486248016
[2025-03-12 19:53:47,192][model][INFO] - Training step 5680 loss 0.01589445397257805
[2025-03-12 19:54:28,692][model][INFO] - Training step 5840 loss 0.005386022850871086
[2025-03-12 19:55:09,594][model][INFO] - Training step 6000 loss 0.015353187918663025
[2025-03-12 19:55:50,674][model][INFO] - Training step 6160 loss 0.049300238490104675
[2025-03-12 19:56:32,872][model][INFO] - Training step 6320 loss 0.12658987939357758
[2025-03-12 19:57:15,888][model][INFO] - Training step 6480 loss 0.03538552671670914
[2025-03-12 19:57:57,063][model][INFO] - Training step 6640 loss 0.005874598864465952
[2025-03-12 19:58:37,520][model][INFO] - Training step 6800 loss 0.01678529381752014
[2025-03-12 19:59:17,538][model][INFO] - Training step 6960 loss 0.04481843486428261
[2025-03-12 19:59:58,352][model][INFO] - Training step 7120 loss 0.25088754296302795
[2025-03-12 20:00:39,357][model][INFO] - Training step 7280 loss 0.25908076763153076
[2025-03-12 20:01:20,002][model][INFO] - Training step 7440 loss 0.019468367099761963
[2025-03-12 20:02:01,514][model][INFO] - Training step 7600 loss 0.03661942481994629
[2025-03-12 20:02:43,266][model][INFO] - Training step 7760 loss 0.06516966223716736
[2025-03-12 20:03:23,641][model][INFO] - Training step 7920 loss 0.0028767057228833437
[2025-03-12 20:04:03,614][model][INFO] - Training step 8080 loss 0.02696804329752922
[2025-03-12 20:04:41,826][model][INFO] - Training step 8240 loss 0.2545478940010071
[2025-03-12 20:05:22,298][model][INFO] - Training step 8400 loss 0.03569037467241287
[2025-03-12 20:06:03,637][model][INFO] - Training step 8560 loss 0.01978098601102829
[2025-03-12 20:06:43,752][model][INFO] - Training step 8720 loss 0.04846278578042984
[2025-03-12 20:07:24,639][model][INFO] - Training step 8880 loss 0.023705266416072845
[2025-03-12 20:08:04,544][model][INFO] - Training step 9040 loss 0.01568455435335636
[2025-03-12 20:08:43,058][model][INFO] - Training step 9200 loss 0.10842693597078323
[2025-03-12 20:09:22,947][model][INFO] - Training step 9360 loss 0.0049385372549295425
[2025-03-12 20:10:04,376][model][INFO] - Training step 9520 loss 0.016441375017166138
[2025-03-12 20:10:45,979][model][INFO] - Training step 9680 loss 0.07594314217567444
[2025-03-12 20:11:27,435][model][INFO] - Training step 9840 loss 0.24938690662384033
[2025-03-12 20:12:09,327][model][INFO] - Training step 10000 loss 0.029533129185438156
[2025-03-12 20:12:50,739][model][INFO] - Training step 10160 loss 0.028439972549676895
[2025-03-12 20:13:33,170][model][INFO] - Training step 10320 loss 0.005285805091261864
[2025-03-12 20:14:12,340][model][INFO] - Training step 10480 loss 0.058088161051273346
[2025-03-12 20:14:52,251][model][INFO] - Training step 10640 loss 0.2511233687400818
[2025-03-12 20:15:32,297][model][INFO] - Training step 10800 loss 0.2515837550163269
[2025-03-12 20:16:12,480][model][INFO] - Training step 10960 loss 0.056588876992464066
[2025-03-12 20:16:53,013][model][INFO] - Training step 11120 loss 0.020608890801668167
[2025-03-12 20:17:31,548][model][INFO] - Training step 11280 loss 0.005812960676848888
[2025-03-12 20:18:11,520][model][INFO] - Training step 11440 loss 0.02415846846997738
[2025-03-12 20:18:51,597][model][INFO] - Training step 11600 loss 0.25227367877960205
[2025-03-12 20:19:31,964][model][INFO] - Training step 11760 loss 0.03099403902888298
[2025-03-12 20:20:13,124][model][INFO] - Training step 11920 loss 0.2937542200088501
[2025-03-12 20:20:55,147][model][INFO] - Training step 12080 loss 0.25040382146835327
[2025-03-12 20:21:36,442][model][INFO] - Training step 12240 loss 0.12774232029914856
[2025-03-12 20:22:17,354][model][INFO] - Training step 12400 loss 0.02137633040547371
[2025-03-12 20:22:58,674][model][INFO] - Training step 12560 loss 0.02914632484316826
[2025-03-12 20:23:39,319][model][INFO] - Training step 12720 loss 0.03419101610779762
[2025-03-12 20:24:20,050][model][INFO] - Training step 12880 loss 0.017845643684267998
[2025-03-12 20:25:02,209][model][INFO] - Training step 13040 loss 0.25506335496902466
[2025-03-12 20:25:43,606][model][INFO] - Training step 13200 loss 0.010660538449883461
[2025-03-12 20:26:24,750][model][INFO] - Training step 13360 loss 0.11174043267965317
[2025-03-12 20:27:06,054][model][INFO] - Training step 13520 loss 0.03199511766433716
[2025-03-12 20:27:46,617][model][INFO] - Training step 13680 loss 0.01347390003502369
[2025-03-12 20:28:26,564][model][INFO] - Training step 13840 loss 0.01806003600358963
[2025-03-12 20:29:07,306][model][INFO] - Training step 14000 loss 0.021249424666166306
[2025-03-12 20:29:48,012][model][INFO] - Training step 14160 loss 0.0025025615468621254
[2025-03-12 20:30:28,504][model][INFO] - Training step 14320 loss 0.2519596517086029
[2025-03-12 20:31:09,631][model][INFO] - Training step 14480 loss 0.02872656285762787
[2025-03-12 20:31:51,917][model][INFO] - Training step 14640 loss 0.0248597152531147
[2025-03-12 20:32:33,008][model][INFO] - Training step 14800 loss 0.062463223934173584
[2025-03-12 20:33:13,280][model][INFO] - Training step 14960 loss 0.017918281257152557
[2025-03-12 20:33:54,975][model][INFO] - Training step 15120 loss 0.23319946229457855
[2025-03-12 20:34:35,946][model][INFO] - Training step 15280 loss 0.24022802710533142
[2025-03-12 20:35:16,620][model][INFO] - Training step 15440 loss 0.014162770472466946
[2025-03-12 20:35:57,478][model][INFO] - Training step 15600 loss 0.2534233331680298
[2025-03-12 20:36:37,078][model][INFO] - Training step 15760 loss 0.05093389376997948
[2025-03-12 20:37:18,418][model][INFO] - Training step 15920 loss 0.24505145847797394
[2025-03-12 20:37:58,018][model][INFO] - Training step 16080 loss 0.034133367240428925
[2025-03-12 20:38:37,798][model][INFO] - Training step 16240 loss 0.24879662692546844
[2025-03-12 20:39:19,625][model][INFO] - Training step 16400 loss 0.005109557881951332
[2025-03-12 20:40:00,004][model][INFO] - Training step 16560 loss 0.04274698346853256
[2025-03-12 20:40:39,141][model][INFO] - Training step 16720 loss 0.2539258599281311
[2025-03-12 20:41:21,056][model][INFO] - Training step 16880 loss 0.0243949294090271
[2025-03-12 20:42:01,367][model][INFO] - Training step 17040 loss 0.739717423915863
[2025-03-12 20:42:42,827][model][INFO] - Training step 17200 loss 0.05362626165151596
[2025-03-12 20:43:23,121][model][INFO] - Training step 17360 loss 0.01380435936152935
[2025-03-12 20:44:03,838][model][INFO] - Training step 17520 loss 0.07515865564346313
[2025-03-12 20:44:45,252][model][INFO] - Training step 17680 loss 0.0022321545984596014
[2025-03-12 20:45:24,967][model][INFO] - Training step 17840 loss 0.25606387853622437
[2025-03-12 20:46:04,764][model][INFO] - Training step 18000 loss 0.028573036193847656
[2025-03-12 20:46:47,299][model][INFO] - Training step 18160 loss 0.023777909576892853
[2025-03-12 20:47:29,114][model][INFO] - Training step 18320 loss 0.022842086851596832
[2025-03-12 20:48:09,656][model][INFO] - Training step 18480 loss 0.021909140050411224
[2025-03-12 20:48:51,528][model][INFO] - Training step 18640 loss 0.004567693453282118
[2025-03-12 20:49:33,010][model][INFO] - Training step 18800 loss 0.01924918219447136
[2025-03-12 20:50:13,453][model][INFO] - Training step 18960 loss 0.006088978610932827
[2025-03-12 20:50:54,080][model][INFO] - Training step 19120 loss 0.018580015748739243
[2025-03-12 20:51:33,159][model][INFO] - Training step 19280 loss 0.006151318084448576
[2025-03-12 20:52:13,943][model][INFO] - Training step 19440 loss 0.027523962780833244
[2025-03-12 20:52:54,027][model][INFO] - Training step 19600 loss 0.0043934183195233345
[2025-03-12 20:53:35,586][model][INFO] - Training step 19760 loss 0.2598954439163208
[2025-03-12 20:54:16,889][model][INFO] - Training step 19920 loss 0.003165203845128417
[2025-03-12 20:54:57,972][model][INFO] - Training step 20080 loss 0.044200047850608826
[2025-03-12 20:55:36,693][model][INFO] - Training step 20240 loss 0.02190319076180458
[2025-03-12 20:56:17,164][model][INFO] - Training step 20400 loss 0.1164986789226532
[2025-03-12 20:56:57,116][model][INFO] - Training step 20560 loss 0.0173336211591959
[2025-03-12 20:57:37,542][model][INFO] - Training step 20720 loss 0.10860823094844818
[2025-03-12 20:58:19,267][model][INFO] - Training step 20880 loss 0.17092156410217285
[2025-03-12 20:59:00,116][model][INFO] - Training step 21040 loss 0.029069453477859497
[2025-03-12 20:59:43,497][model][INFO] - Training step 21200 loss 0.006900743115693331
[2025-03-12 21:00:25,040][model][INFO] - Training step 21360 loss 0.09435775876045227
[2025-03-12 21:01:05,881][model][INFO] - Training step 21520 loss 0.0346355140209198
[2025-03-12 21:01:47,056][model][INFO] - Training step 21680 loss 0.037596799433231354
[2025-03-12 21:02:26,742][model][INFO] - Training step 21840 loss 0.022459212690591812
[2025-03-12 21:03:07,217][model][INFO] - Training step 22000 loss 0.275256872177124
[2025-03-12 21:03:47,354][model][INFO] - Training step 22160 loss 0.23776403069496155
[2025-03-12 21:04:29,886][model][INFO] - Training step 22320 loss 0.14203709363937378
[2025-03-12 21:05:09,152][model][INFO] - Training step 22480 loss 0.009623030200600624
[2025-03-12 21:05:49,903][model][INFO] - Training step 22640 loss 0.1263638585805893
[2025-03-12 21:06:31,491][model][INFO] - Training step 22800 loss 0.029589904472231865
[2025-03-12 21:07:11,890][model][INFO] - Training step 22960 loss 0.026441052556037903
[2025-03-12 21:07:52,414][model][INFO] - Training step 23120 loss 0.27044492959976196
[2025-03-12 21:08:33,033][model][INFO] - Training step 23280 loss 0.1299816220998764
[2025-03-12 21:09:13,486][model][INFO] - Training step 23440 loss 0.25190091133117676
[2025-03-12 21:09:53,045][model][INFO] - Training step 23600 loss 0.03372916579246521
[2025-03-12 21:10:32,408][model][INFO] - Training step 23760 loss 0.05296291038393974
[2025-03-12 21:11:13,387][model][INFO] - Training step 23920 loss 0.028084203600883484
[2025-03-12 21:11:53,545][model][INFO] - Training step 24080 loss 0.037499260157346725
[2025-03-12 21:12:33,357][model][INFO] - Training step 24240 loss 0.026057569310069084
[2025-03-12 21:13:11,594][model][INFO] - Training step 24400 loss 0.03449711203575134
[2025-03-12 21:13:53,034][model][INFO] - Training step 24560 loss 0.04654410481452942
[2025-03-12 21:14:33,041][model][INFO] - Training step 24720 loss 0.0602521076798439
[2025-03-12 21:15:13,907][model][INFO] - Training step 24880 loss 0.24313056468963623
[2025-03-12 21:15:54,607][model][INFO] - Training step 25040 loss 0.008848907425999641
[2025-03-12 21:16:34,087][model][INFO] - Training step 25200 loss 0.0406663678586483
[2025-03-12 21:17:13,767][model][INFO] - Training step 25360 loss 0.25091710686683655
[2025-03-12 21:17:53,427][model][INFO] - Training step 25520 loss 0.006075604353100061
[2025-03-12 21:18:35,005][model][INFO] - Training step 25680 loss 0.0021425753366202116
[2025-03-12 21:19:14,687][model][INFO] - Training step 25840 loss 0.21257375180721283
[2025-03-12 21:19:56,078][model][INFO] - Training step 26000 loss 0.0792444497346878
[2025-03-12 21:20:36,876][model][INFO] - Training step 26160 loss 0.008065879344940186
[2025-03-12 21:21:16,991][model][INFO] - Training step 26320 loss 0.04033736139535904
[2025-03-12 21:21:57,855][model][INFO] - Training step 26480 loss 0.03599657863378525
[2025-03-12 21:22:37,971][model][INFO] - Training step 26640 loss 0.032088503241539
[2025-03-12 21:23:18,476][model][INFO] - Training step 26800 loss 0.008815423585474491
[2025-03-12 21:23:59,986][model][INFO] - Training step 26960 loss 0.023708902299404144
[2025-03-12 21:24:40,927][model][INFO] - Training step 27120 loss 0.22769014537334442
[2025-03-12 21:25:21,006][model][INFO] - Training step 27280 loss 0.011315644718706608
[2025-03-12 21:26:01,246][model][INFO] - Training step 27440 loss 0.004457981325685978
[2025-03-12 21:26:40,903][model][INFO] - Training step 27600 loss 0.059876296669244766
[2025-03-12 21:27:21,230][model][INFO] - Training step 27760 loss 0.028779488056898117
[2025-03-12 21:28:01,022][model][INFO] - Training step 27920 loss 0.012158272787928581
[2025-03-12 21:28:41,963][model][INFO] - Training step 28080 loss 0.2518542408943176
[2025-03-12 21:29:22,671][model][INFO] - Training step 28240 loss 0.03844951093196869
[2025-03-12 21:30:02,897][model][INFO] - Training step 28400 loss 0.2375325858592987
[2025-03-12 21:30:43,390][model][INFO] - Training step 28560 loss 0.1909959763288498
[2025-03-12 21:31:22,221][model][INFO] - Training step 28720 loss 0.01822604238986969
[2025-03-12 21:32:02,476][model][INFO] - Training step 28880 loss 0.24448728561401367
[2025-03-12 21:32:43,588][model][INFO] - Training step 29040 loss 0.024306099861860275
[2025-03-12 21:33:25,955][model][INFO] - Training step 29200 loss 0.005764137487858534
[2025-03-12 21:34:07,914][model][INFO] - Training step 29360 loss 0.007613700348883867
[2025-03-12 21:34:50,045][model][INFO] - Training step 29520 loss 0.2547457814216614
[2025-03-12 21:35:33,048][model][INFO] - Training step 29680 loss 0.05903112143278122
[2025-03-12 21:36:12,969][model][INFO] - Training step 29840 loss 0.03316270187497139
[2025-03-12 21:36:53,737][model][INFO] - Training step 30000 loss 0.05257967859506607
[2025-03-12 21:37:33,836][model][INFO] - Training step 30160 loss 0.007357141003012657
[2025-03-12 21:38:15,360][model][INFO] - Training step 30320 loss 0.025055520236492157
[2025-03-12 21:38:56,589][model][INFO] - Training step 30480 loss 0.2696959674358368
[2025-03-12 21:39:36,149][model][INFO] - Training step 30640 loss 0.023555699735879898
[2025-03-12 21:40:15,205][model][INFO] - Training step 30800 loss 0.007879398763179779
[2025-03-12 21:40:57,358][model][INFO] - Training step 30960 loss 0.10913646221160889
[2025-03-12 21:41:40,960][model][INFO] - Training step 31120 loss 0.03541159629821777
[2025-03-12 21:42:20,198][model][INFO] - Training step 31280 loss 0.052830204367637634
[2025-03-12 21:43:00,439][model][INFO] - Training step 31440 loss 0.03135666251182556
[2025-03-12 21:43:42,426][model][INFO] - Training step 31600 loss 0.02560860849916935
[2025-03-12 21:44:22,833][model][INFO] - Training step 31760 loss 0.0465090274810791
[2025-03-12 21:45:03,865][model][INFO] - Training step 31920 loss 0.025098949670791626
[2025-03-12 21:45:44,107][model][INFO] - Training step 32080 loss 0.021247047930955887
[2025-03-12 21:46:25,903][model][INFO] - Training step 32240 loss 0.03000141680240631
[2025-03-12 21:47:07,571][model][INFO] - Training step 32400 loss 0.0026971783954650164
[2025-03-12 21:47:48,214][model][INFO] - Training step 32560 loss 0.0262627974152565
[2025-03-12 21:48:30,048][model][INFO] - Training step 32720 loss 0.007437610998749733
[2025-03-12 21:49:12,327][model][INFO] - Training step 32880 loss 0.14977172017097473
[2025-03-12 21:49:52,892][model][INFO] - Training step 33040 loss 0.05362292751669884
[2025-03-12 21:50:33,699][model][INFO] - Training step 33200 loss 0.023933839052915573
[2025-03-12 21:51:12,948][model][INFO] - Training step 33360 loss 0.01940527930855751
[2025-03-12 21:51:52,735][model][INFO] - Training step 33520 loss 0.04550837725400925
[2025-03-12 21:52:33,084][model][INFO] - Training step 33680 loss 0.011074703186750412
[2025-03-12 21:53:14,189][model][INFO] - Training step 33840 loss 0.03471824526786804
[2025-03-12 21:53:53,203][model][INFO] - Training step 34000 loss 0.03048509731888771
[2025-03-12 21:54:33,327][model][INFO] - Training step 34160 loss 0.05670623481273651
[2025-03-12 21:55:14,621][model][INFO] - Training step 34320 loss 0.038326919078826904
[2025-03-12 21:55:54,911][model][INFO] - Training step 34480 loss 0.19962143898010254
[2025-03-12 21:56:35,837][model][INFO] - Training step 34640 loss 0.030328521504998207
[2025-03-12 21:57:16,543][model][INFO] - Training step 34800 loss 0.0072882408276200294
[2025-03-12 21:57:57,360][model][INFO] - Training step 34960 loss 0.00603299867361784
[2025-03-12 21:58:38,156][model][INFO] - Training step 35120 loss 0.01596967875957489
[2025-03-12 21:59:19,145][model][INFO] - Training step 35280 loss 0.03377055004239082
[2025-03-12 21:59:59,564][model][INFO] - Training step 35440 loss 0.23876343667507172
[2025-03-12 22:00:39,936][model][INFO] - Training step 35600 loss 0.25199735164642334
[2025-03-12 22:01:20,898][model][INFO] - Training step 35760 loss 0.020304076373577118
[2025-03-12 22:02:03,049][model][INFO] - Training step 35920 loss 0.0051293326541781425
[2025-03-12 22:02:43,616][model][INFO] - Training step 36080 loss 0.0357031375169754
[2025-03-12 22:03:23,580][model][INFO] - Training step 36240 loss 0.2600635290145874
[2025-03-12 22:04:05,401][model][INFO] - Training step 36400 loss 0.24888375401496887
[2025-03-12 22:04:47,182][model][INFO] - Training step 36560 loss 0.02283383719623089
[2025-03-12 22:05:28,434][model][INFO] - Training step 36720 loss 0.008055130951106548
[2025-03-12 22:06:08,982][model][INFO] - Training step 36880 loss 0.37989264726638794
[2025-03-12 22:06:49,241][model][INFO] - Training step 37040 loss 0.017494946718215942
[2025-03-12 22:07:29,563][model][INFO] - Training step 37200 loss 0.1990233063697815
[2025-03-12 22:08:09,657][model][INFO] - Training step 37360 loss 0.02384088933467865
[2025-03-12 22:08:50,530][model][INFO] - Training step 37520 loss 0.036511823534965515
[2025-03-12 22:09:30,157][model][INFO] - Training step 37680 loss 0.028358591720461845
[2025-03-12 22:10:09,257][model][INFO] - Training step 37840 loss 0.04619268327951431
[2025-03-12 22:10:49,342][model][INFO] - Training step 38000 loss 0.009702816605567932
[2025-03-12 22:11:29,903][model][INFO] - Training step 38160 loss 0.021513905376195908
[2025-03-12 22:12:12,137][model][INFO] - Training step 38320 loss 0.007187326438724995
[2025-03-12 22:12:53,065][model][INFO] - Training step 38480 loss 0.31141477823257446
[2025-03-12 22:13:34,171][model][INFO] - Training step 38640 loss 0.02721838280558586
[2025-03-12 22:14:16,726][model][INFO] - Training step 38800 loss 0.014720072969794273
[2025-03-12 22:14:58,262][model][INFO] - Training step 38960 loss 0.021890196949243546
[2025-03-12 22:15:38,757][model][INFO] - Training step 39120 loss 0.0383274108171463
[2025-03-12 22:16:18,238][model][INFO] - Training step 39280 loss 0.02757355570793152
[2025-03-12 22:16:59,518][model][INFO] - Training step 39440 loss 0.0018825551960617304
[2025-03-12 22:17:39,387][model][INFO] - Training step 39600 loss 0.044540658593177795
[2025-03-12 22:18:21,756][model][INFO] - Training step 39760 loss 0.03892287611961365
[2025-03-12 22:19:02,079][model][INFO] - Training step 39920 loss 0.002294589066877961
[2025-03-12 22:19:41,799][model][INFO] - Training step 40080 loss 0.014817634597420692
[2025-03-12 22:20:23,914][model][INFO] - Training step 40240 loss 0.0059140464290976524
[2025-03-12 22:21:05,492][model][INFO] - Training step 40400 loss 0.02420177310705185
[2025-03-12 22:21:45,856][model][INFO] - Training step 40560 loss 0.02858281135559082
[2025-03-12 22:22:26,247][model][INFO] - Training step 40720 loss 0.22860270738601685
[2025-03-12 22:23:05,755][model][INFO] - Training step 40880 loss 0.041270941495895386
[2025-03-12 22:23:46,118][model][INFO] - Training step 41040 loss 0.21699804067611694
[2025-03-12 22:24:25,116][model][INFO] - Training step 41200 loss 0.013588566333055496
[2025-03-12 22:25:05,391][model][INFO] - Training step 41360 loss 0.019350504502654076
[2025-03-12 22:25:46,139][model][INFO] - Training step 41520 loss 0.04986216872930527
[2025-03-12 22:26:27,476][model][INFO] - Training step 41680 loss 0.0025846806820482016
[2025-03-12 22:27:08,641][model][INFO] - Training step 41840 loss 0.030353449285030365
[2025-03-12 22:27:48,938][model][INFO] - Training step 42000 loss 0.03896819055080414
[2025-03-12 22:28:27,940][model][INFO] - Training step 42160 loss 0.25259995460510254
[2025-03-12 22:29:08,029][model][INFO] - Training step 42320 loss 0.0013117315247654915
[2025-03-12 22:29:51,156][model][INFO] - Training step 42480 loss 0.2591196298599243
[2025-03-12 22:30:32,542][model][INFO] - Training step 42640 loss 0.022982168942689896
[2025-03-12 22:31:12,356][model][INFO] - Training step 42800 loss 0.23202766478061676
[2025-03-12 22:31:53,450][model][INFO] - Training step 42960 loss 0.018385976552963257
[2025-03-12 22:32:35,211][model][INFO] - Training step 43120 loss 0.043683864176273346
[2025-03-12 22:33:15,839][model][INFO] - Training step 43280 loss 0.006838859990239143
[2025-03-12 22:33:56,659][model][INFO] - Training step 43440 loss 0.04195608198642731
[2025-03-12 22:34:36,077][model][INFO] - Training step 43600 loss 0.015565880574285984
[2025-03-12 22:35:16,299][model][INFO] - Training step 43760 loss 0.023171307519078255
[2025-03-12 22:35:56,993][model][INFO] - Training step 43920 loss 0.05921989679336548
[2025-03-12 22:36:37,858][model][INFO] - Training step 44080 loss 0.03797636181116104
[2025-03-12 22:37:19,708][model][INFO] - Training step 44240 loss 0.028347879648208618
[2025-03-12 22:37:59,417][model][INFO] - Training step 44400 loss 0.2513948082923889
[2025-03-12 22:38:39,415][model][INFO] - Training step 44560 loss 0.025898121297359467
[2025-03-12 22:39:20,373][model][INFO] - Training step 44720 loss 0.008520238101482391
[2025-03-12 22:39:58,922][model][INFO] - Training step 44880 loss 0.04562930762767792
[2025-03-12 22:40:40,459][model][INFO] - Training step 45040 loss 0.024059712886810303
[2025-03-12 22:41:20,629][model][INFO] - Training step 45200 loss 0.03556802123785019
[2025-03-12 22:42:01,060][model][INFO] - Training step 45360 loss 0.022922705858945847
[2025-03-12 22:42:42,063][model][INFO] - Training step 45520 loss 0.006248678546398878
[2025-03-12 22:43:23,032][model][INFO] - Training step 45680 loss 0.00854288786649704
[2025-03-12 22:44:03,199][model][INFO] - Training step 45840 loss 0.06478910148143768
[2025-03-12 22:44:43,822][model][INFO] - Training step 46000 loss 0.040837228298187256
[2025-03-12 22:45:26,519][model][INFO] - Training step 46160 loss 0.004565723240375519
[2025-03-12 22:46:08,593][model][INFO] - Training step 46320 loss 0.004794040694832802
[2025-03-12 22:46:49,062][model][INFO] - Training step 46480 loss 0.007127902936190367
[2025-03-12 22:47:29,011][model][INFO] - Training step 46640 loss 0.06318382918834686
[2025-03-12 22:48:10,976][model][INFO] - Training step 46800 loss 0.005234495270997286
[2025-03-12 22:48:51,446][model][INFO] - Training step 46960 loss 0.03924134373664856
[2025-03-12 22:49:30,888][model][INFO] - Training step 47120 loss 0.0940389484167099
[2025-03-12 22:50:11,914][model][INFO] - Training step 47280 loss 0.01725173369050026
[2025-03-12 22:50:50,928][model][INFO] - Training step 47440 loss 0.040334686636924744
[2025-03-12 22:51:32,184][model][INFO] - Training step 47600 loss 0.027661064639687538
[2025-03-12 22:52:13,613][model][INFO] - Training step 47760 loss 0.046686310321092606
[2025-03-12 22:52:53,688][model][INFO] - Training step 47920 loss 0.254067063331604
[2025-03-12 22:53:34,947][model][INFO] - Training step 48080 loss 0.24669155478477478
[2025-03-12 22:54:14,596][model][INFO] - Training step 48240 loss 0.02175082266330719
[2025-03-12 22:54:55,659][model][INFO] - Training step 48400 loss 0.03818172216415405
[2025-03-12 22:55:36,554][model][INFO] - Training step 48560 loss 0.05520392581820488
[2025-03-12 22:56:16,949][model][INFO] - Training step 48720 loss 0.002142768818885088
[2025-03-12 22:56:56,883][model][INFO] - Training step 48880 loss 0.015854397788643837
[2025-03-12 22:57:37,668][model][INFO] - Training step 49040 loss 0.026539213955402374
[2025-03-12 22:58:19,265][model][INFO] - Training step 49200 loss 0.02684619463980198
[2025-03-12 22:59:05,861][model][INFO] - Training step 49360 loss 0.023499764502048492
[2025-03-12 23:00:08,950][model][INFO] - Training step 49520 loss 0.03672115132212639
[2025-03-12 23:01:09,860][model][INFO] - Training step 49680 loss 0.013921157456934452
[2025-03-12 23:02:14,233][model][INFO] - Training step 49840 loss 0.0574248805642128
[2025-03-12 23:03:17,863][model][INFO] - Training step 50000 loss 0.04095963388681412
[2025-03-12 23:04:20,133][model][INFO] - Training step 50160 loss 0.24770045280456543
[2025-03-12 23:05:25,376][model][INFO] - Training step 50320 loss 0.023433268070220947
[2025-03-12 23:06:26,057][model][INFO] - Training step 50480 loss 0.05089903622865677
[2025-03-12 23:07:28,351][model][INFO] - Training step 50640 loss 0.01512833870947361
[2025-03-12 23:16:25,297][model][INFO] - Training step 0 loss 0.23728594183921814
[2025-03-12 23:17:27,261][model][INFO] - Training step 160 loss 0.021712925285100937
[2025-03-12 23:18:29,554][model][INFO] - Training step 320 loss 0.0038926852867007256
[2025-03-12 23:19:32,951][model][INFO] - Training step 480 loss 0.022896090522408485
[2025-03-12 23:20:34,769][model][INFO] - Training step 640 loss 0.02277257665991783
[2025-03-12 23:21:37,633][model][INFO] - Training step 800 loss 0.05126847326755524
[2025-03-12 23:22:41,054][model][INFO] - Training step 960 loss 0.018219202756881714
[2025-03-12 23:23:41,641][model][INFO] - Training step 1120 loss 0.006971694529056549
[2025-03-12 23:24:45,371][model][INFO] - Training step 1280 loss 0.005074258893728256
[2025-03-12 23:25:47,568][model][INFO] - Training step 1440 loss 0.026103630661964417
[2025-03-12 23:26:49,671][model][INFO] - Training step 1600 loss 0.04610642045736313
[2025-03-12 23:27:50,276][model][INFO] - Training step 1760 loss 0.045936375856399536
[2025-03-12 23:28:51,164][model][INFO] - Training step 1920 loss 0.02273964136838913
[2025-03-12 23:29:52,853][model][INFO] - Training step 2080 loss 0.2485698014497757
[2025-03-12 23:30:55,258][model][INFO] - Training step 2240 loss 0.02439161017537117
[2025-03-12 23:31:54,120][model][INFO] - Training step 2400 loss 0.025506295263767242
[2025-03-12 23:32:55,374][model][INFO] - Training step 2560 loss 0.04318702220916748
[2025-03-12 23:33:58,633][model][INFO] - Training step 2720 loss 0.017053745687007904
[2025-03-12 23:34:59,911][model][INFO] - Training step 2880 loss 0.25106698274612427
[2025-03-12 23:36:02,255][model][INFO] - Training step 3040 loss 0.02232498675584793
[2025-03-12 23:37:05,223][model][INFO] - Training step 3200 loss 0.10100357234477997
[2025-03-12 23:38:08,492][model][INFO] - Training step 3360 loss 0.0075288075022399426
[2025-03-12 23:39:12,345][model][INFO] - Training step 3520 loss 0.25006335973739624
[2025-03-12 23:40:15,179][model][INFO] - Training step 3680 loss 0.03342251852154732
[2025-03-12 23:41:16,029][model][INFO] - Training step 3840 loss 0.2431911677122116
[2025-03-12 23:42:23,282][model][INFO] - Training step 4000 loss 0.002163509838283062
[2025-03-12 23:43:26,493][model][INFO] - Training step 4160 loss 0.00284784659743309
[2025-03-12 23:44:30,597][model][INFO] - Training step 4320 loss 0.043203532695770264
[2025-03-12 23:45:34,420][model][INFO] - Training step 4480 loss 0.21886129677295685
[2025-03-12 23:46:35,784][model][INFO] - Training step 4640 loss 0.25155824422836304
[2025-03-12 23:47:36,617][model][INFO] - Training step 4800 loss 0.032554544508457184
[2025-03-12 23:48:36,776][model][INFO] - Training step 4960 loss 0.011688461527228355
[2025-03-12 23:49:39,388][model][INFO] - Training step 5120 loss 0.010128145106136799
[2025-03-12 23:50:41,955][model][INFO] - Training step 5280 loss 0.007334177382290363
[2025-03-12 23:51:45,651][model][INFO] - Training step 5440 loss 0.004115234594792128
[2025-03-12 23:52:48,340][model][INFO] - Training step 5600 loss 0.027188178151845932
[2025-03-12 23:53:50,590][model][INFO] - Training step 5760 loss 0.03440912812948227
[2025-03-12 23:54:54,070][model][INFO] - Training step 5920 loss 0.02369869127869606
[2025-03-12 23:55:55,066][model][INFO] - Training step 6080 loss 0.025128988549113274
[2025-03-12 23:56:58,285][model][INFO] - Training step 6240 loss 0.24472713470458984
[2025-03-12 23:58:01,351][model][INFO] - Training step 6400 loss 0.25356584787368774
[2025-03-12 23:59:04,145][model][INFO] - Training step 6560 loss 0.0024958618450909853
[2025-03-13 00:00:08,685][model][INFO] - Training step 6720 loss 0.010466883890330791
[2025-03-13 00:01:10,391][model][INFO] - Training step 6880 loss 0.25053784251213074
[2025-03-13 00:02:12,178][model][INFO] - Training step 7040 loss 0.28059932589530945
[2025-03-13 00:03:16,543][model][INFO] - Training step 7200 loss 0.2431187480688095
[2025-03-13 00:04:18,630][model][INFO] - Training step 7360 loss 0.041572317481040955
[2025-03-13 00:05:19,530][model][INFO] - Training step 7520 loss 0.030866343528032303
[2025-03-13 00:06:22,335][model][INFO] - Training step 7680 loss 0.05436201021075249
[2025-03-13 00:07:22,668][model][INFO] - Training step 7840 loss 0.027663297951221466
[2025-03-13 00:08:25,718][model][INFO] - Training step 8000 loss 0.006744111888110638
[2025-03-13 00:09:29,641][model][INFO] - Training step 8160 loss 0.002844169270247221
[2025-03-13 00:10:29,097][model][INFO] - Training step 8320 loss 0.01580323837697506
[2025-03-13 00:11:31,307][model][INFO] - Training step 8480 loss 0.15423956513404846
[2025-03-13 00:12:35,227][model][INFO] - Training step 8640 loss 0.03274506330490112
[2025-03-13 00:13:34,616][model][INFO] - Training step 8800 loss 0.18684475123882294
[2025-03-13 00:14:36,905][model][INFO] - Training step 8960 loss 0.038324542343616486
[2025-03-13 00:15:38,596][model][INFO] - Training step 9120 loss 0.026528887450695038
[2025-03-13 00:16:39,285][model][INFO] - Training step 9280 loss 0.18283525109291077
[2025-03-13 00:17:38,510][model][INFO] - Training step 9440 loss 0.04589862376451492
[2025-03-13 00:18:39,159][model][INFO] - Training step 9600 loss 0.016397204250097275
[2025-03-13 00:19:40,973][model][INFO] - Training step 9760 loss 0.017860332503914833
[2025-03-13 00:20:43,365][model][INFO] - Training step 9920 loss 0.027417629957199097
[2025-03-13 00:21:44,723][model][INFO] - Training step 10080 loss 0.2560683488845825
[2025-03-13 00:22:46,452][model][INFO] - Training step 10240 loss 0.015954626724123955
[2025-03-13 00:23:50,599][model][INFO] - Training step 10400 loss 0.030581597238779068
[2025-03-13 00:24:53,273][model][INFO] - Training step 10560 loss 0.03985346853733063
[2025-03-13 00:25:53,297][model][INFO] - Training step 10720 loss 0.01603347808122635
[2025-03-13 00:26:54,598][model][INFO] - Training step 10880 loss 0.03311764448881149
[2025-03-13 00:27:56,903][model][INFO] - Training step 11040 loss 0.023566028103232384
[2025-03-13 00:28:58,209][model][INFO] - Training step 11200 loss 0.08740732073783875
[2025-03-13 00:30:01,353][model][INFO] - Training step 11360 loss 0.030872423201799393
[2025-03-13 00:31:03,519][model][INFO] - Training step 11520 loss 0.03866450488567352
[2025-03-13 00:32:04,932][model][INFO] - Training step 11680 loss 0.03343112766742706
[2025-03-13 00:33:06,097][model][INFO] - Training step 11840 loss 0.0262337327003479
[2025-03-13 00:34:09,509][model][INFO] - Training step 12000 loss 0.1979493796825409
[2025-03-13 00:35:11,225][model][INFO] - Training step 12160 loss 0.18229621648788452
[2025-03-13 00:36:12,660][model][INFO] - Training step 12320 loss 0.03205982223153114
[2025-03-13 00:37:13,138][model][INFO] - Training step 12480 loss 0.02213665470480919
[2025-03-13 00:38:12,096][model][INFO] - Training step 12640 loss 0.026434052735567093
[2025-03-13 00:39:14,459][model][INFO] - Training step 12800 loss 0.023837659507989883
[2025-03-13 00:40:18,041][model][INFO] - Training step 12960 loss 0.024763718247413635
[2025-03-13 00:41:19,382][model][INFO] - Training step 13120 loss 0.25745970010757446
[2025-03-13 00:42:23,195][model][INFO] - Training step 13280 loss 0.018943343311548233
[2025-03-13 00:43:24,388][model][INFO] - Training step 13440 loss 0.07932637631893158
[2025-03-13 00:44:26,837][model][INFO] - Training step 13600 loss 0.022087465971708298
[2025-03-13 00:45:29,391][model][INFO] - Training step 13760 loss 0.0354190394282341
[2025-03-13 00:46:31,398][model][INFO] - Training step 13920 loss 0.2661899924278259
[2025-03-13 00:47:32,403][model][INFO] - Training step 14080 loss 0.018179528415203094
[2025-03-13 00:48:32,423][model][INFO] - Training step 14240 loss 0.08426065742969513
[2025-03-13 00:49:35,125][model][INFO] - Training step 14400 loss 0.011466724798083305
[2025-03-13 00:50:36,996][model][INFO] - Training step 14560 loss 0.24416273832321167
[2025-03-13 00:51:37,211][model][INFO] - Training step 14720 loss 0.2561849057674408
[2025-03-13 00:52:39,051][model][INFO] - Training step 14880 loss 0.22871029376983643
[2025-03-13 00:53:42,667][model][INFO] - Training step 15040 loss 0.04614803194999695
[2025-03-13 00:54:45,950][model][INFO] - Training step 15200 loss 0.019018352031707764
[2025-03-13 00:55:46,937][model][INFO] - Training step 15360 loss 0.008739097975194454
[2025-03-13 00:56:49,424][model][INFO] - Training step 15520 loss 0.015054675750434399
[2025-03-13 00:57:49,724][model][INFO] - Training step 15680 loss 0.262363076210022
[2025-03-13 00:58:50,580][model][INFO] - Training step 15840 loss 0.03776814043521881
[2025-03-13 00:59:52,607][model][INFO] - Training step 16000 loss 0.022082611918449402
[2025-03-13 01:00:53,917][model][INFO] - Training step 16160 loss 0.2507438361644745
[2025-03-13 01:01:54,721][model][INFO] - Training step 16320 loss 0.040711864829063416
[2025-03-13 01:02:56,150][model][INFO] - Training step 16480 loss 0.023869434371590614
[2025-03-13 01:03:58,942][model][INFO] - Training step 16640 loss 0.025466354563832283
[2025-03-13 01:04:58,859][model][INFO] - Training step 16800 loss 0.03248468041419983
[2025-03-13 01:06:02,404][model][INFO] - Training step 16960 loss 0.027625858783721924
[2025-03-13 01:07:05,360][model][INFO] - Training step 17120 loss 0.10139796137809753
[2025-03-13 01:08:09,238][model][INFO] - Training step 17280 loss 0.7474544644355774
[2025-03-13 01:09:08,104][model][INFO] - Training step 17440 loss 0.02603747323155403
[2025-03-13 01:10:11,078][model][INFO] - Training step 17600 loss 0.05827627331018448
[2025-03-13 01:11:12,408][model][INFO] - Training step 17760 loss 0.05389588326215744
[2025-03-13 01:12:13,857][model][INFO] - Training step 17920 loss 0.06174599006772041
[2025-03-13 01:13:16,065][model][INFO] - Training step 18080 loss 0.033823199570178986
[2025-03-13 01:14:19,910][model][INFO] - Training step 18240 loss 0.28112512826919556
[2025-03-13 01:15:22,508][model][INFO] - Training step 18400 loss 0.002650443697348237
[2025-03-13 01:16:24,778][model][INFO] - Training step 18560 loss 0.27389007806777954
[2025-03-13 01:17:25,347][model][INFO] - Training step 18720 loss 0.04132035747170448
[2025-03-13 01:18:29,228][model][INFO] - Training step 18880 loss 0.01699831709265709
[2025-03-13 01:19:31,640][model][INFO] - Training step 19040 loss 0.034442782402038574
[2025-03-13 01:20:32,450][model][INFO] - Training step 19200 loss 0.036396682262420654
[2025-03-13 01:21:33,527][model][INFO] - Training step 19360 loss 0.04923895373940468
[2025-03-13 01:22:35,257][model][INFO] - Training step 19520 loss 0.006408978253602982
[2025-03-13 01:23:37,199][model][INFO] - Training step 19680 loss 0.029695143923163414
[2025-03-13 01:24:38,710][model][INFO] - Training step 19840 loss 0.02500082179903984
[2025-03-13 01:25:38,980][model][INFO] - Training step 20000 loss 0.006602820008993149
[2025-03-13 01:26:40,741][model][INFO] - Training step 20160 loss 0.2506508529186249
[2025-03-13 01:27:41,576][model][INFO] - Training step 20320 loss 0.07628806680440903
[2025-03-13 01:28:43,649][model][INFO] - Training step 20480 loss 0.007599611766636372
[2025-03-13 01:29:46,559][model][INFO] - Training step 20640 loss 0.24770337343215942
[2025-03-13 01:30:48,732][model][INFO] - Training step 20800 loss 0.0334026962518692
[2025-03-13 01:31:52,490][model][INFO] - Training step 20960 loss 0.019344087690114975
[2025-03-13 01:32:54,638][model][INFO] - Training step 21120 loss 0.053083669394254684
[2025-03-13 01:33:55,396][model][INFO] - Training step 21280 loss 0.06941980868577957
[2025-03-13 01:34:57,762][model][INFO] - Training step 21440 loss 0.018668612465262413
[2025-03-13 01:35:57,824][model][INFO] - Training step 21600 loss 0.03510747849941254
[2025-03-13 01:36:59,166][model][INFO] - Training step 21760 loss 0.003184736240655184
[2025-03-13 01:38:00,669][model][INFO] - Training step 21920 loss 0.019462469965219498
[2025-03-13 01:39:03,894][model][INFO] - Training step 22080 loss 0.04558581858873367
[2025-03-13 01:40:08,388][model][INFO] - Training step 22240 loss 0.0263601616024971
[2025-03-13 01:41:10,730][model][INFO] - Training step 22400 loss 0.03420088812708855
[2025-03-13 01:42:13,439][model][INFO] - Training step 22560 loss 0.18674513697624207
[2025-03-13 01:43:15,626][model][INFO] - Training step 22720 loss 0.03544917702674866
[2025-03-13 01:44:17,801][model][INFO] - Training step 22880 loss 0.009238773956894875
[2025-03-13 01:45:23,358][model][INFO] - Training step 23040 loss 0.041503243148326874
[2025-03-13 01:46:28,057][model][INFO] - Training step 23200 loss 0.11972489953041077
[2025-03-13 01:47:32,009][model][INFO] - Training step 23360 loss 0.031881749629974365
[2025-03-13 01:48:33,764][model][INFO] - Training step 23520 loss 0.2459346055984497
[2025-03-13 01:49:35,277][model][INFO] - Training step 23680 loss 0.04424838721752167
[2025-03-13 01:50:39,385][model][INFO] - Training step 23840 loss 0.08393736183643341
[2025-03-13 01:51:40,860][model][INFO] - Training step 24000 loss 0.020413655787706375
[2025-03-13 01:52:42,412][model][INFO] - Training step 24160 loss 0.020723827183246613
[2025-03-13 01:53:43,495][model][INFO] - Training step 24320 loss 0.024611350148916245
[2025-03-13 01:54:44,474][model][INFO] - Training step 24480 loss 0.009065145626664162
[2025-03-13 01:55:43,938][model][INFO] - Training step 24640 loss 0.054399192333221436
[2025-03-13 01:56:48,493][model][INFO] - Training step 24800 loss 0.12273260951042175
[2025-03-13 01:57:52,160][model][INFO] - Training step 24960 loss 0.02593131735920906
[2025-03-13 01:58:54,624][model][INFO] - Training step 25120 loss 0.08999034762382507
[2025-03-13 01:59:56,016][model][INFO] - Training step 25280 loss 0.014401856809854507
[2025-03-13 02:00:57,513][model][INFO] - Training step 25440 loss 0.029474638402462006
[2025-03-13 02:01:57,037][model][INFO] - Training step 25600 loss 0.004425262100994587
[2025-03-13 02:02:56,538][model][INFO] - Training step 25760 loss 0.029142145067453384
[2025-03-13 02:03:58,974][model][INFO] - Training step 25920 loss 0.2506742775440216
[2025-03-13 02:04:58,252][model][INFO] - Training step 26080 loss 0.022559192031621933
[2025-03-13 02:05:59,797][model][INFO] - Training step 26240 loss 0.02285175397992134
[2025-03-13 02:07:03,578][model][INFO] - Training step 26400 loss 0.04515346884727478
[2025-03-13 02:08:04,612][model][INFO] - Training step 26560 loss 0.07372995465993881
[2025-03-13 02:09:08,733][model][INFO] - Training step 26720 loss 0.007571931462734938
[2025-03-13 02:10:09,160][model][INFO] - Training step 26880 loss 0.025072641670703888
[2025-03-13 02:11:09,836][model][INFO] - Training step 27040 loss 0.008685910142958164
[2025-03-13 02:12:09,750][model][INFO] - Training step 27200 loss 0.24700534343719482
[2025-03-13 02:13:09,999][model][INFO] - Training step 27360 loss 0.03580484911799431
[2025-03-13 02:14:11,747][model][INFO] - Training step 27520 loss 0.02703794836997986
[2025-03-13 02:15:15,242][model][INFO] - Training step 27680 loss 0.026481542736291885
[2025-03-13 02:16:16,762][model][INFO] - Training step 27840 loss 0.023743517696857452
[2025-03-13 02:17:18,763][model][INFO] - Training step 28000 loss 0.033587418496608734
[2025-03-13 02:18:22,777][model][INFO] - Training step 28160 loss 0.2508027255535126
[2025-03-13 02:19:22,375][model][INFO] - Training step 28320 loss 0.017434190958738327
[2025-03-13 02:20:23,416][model][INFO] - Training step 28480 loss 0.04699670523405075
[2025-03-13 02:21:23,695][model][INFO] - Training step 28640 loss 0.06680005043745041
[2025-03-13 02:22:24,049][model][INFO] - Training step 28800 loss 0.053054146468639374
[2025-03-13 02:23:27,329][model][INFO] - Training step 28960 loss 0.03497031331062317
[2025-03-13 02:24:28,080][model][INFO] - Training step 29120 loss 0.2494606077671051
[2025-03-13 02:25:28,762][model][INFO] - Training step 29280 loss 0.030010156333446503
[2025-03-13 02:26:31,889][model][INFO] - Training step 29440 loss 0.03540138155221939
[2025-03-13 02:27:32,068][model][INFO] - Training step 29600 loss 0.045467205345630646
[2025-03-13 02:28:35,350][model][INFO] - Training step 29760 loss 0.1320001184940338
[2025-03-13 02:29:38,083][model][INFO] - Training step 29920 loss 0.24898651242256165
[2025-03-13 02:30:40,994][model][INFO] - Training step 30080 loss 0.24584487080574036
[2025-03-13 02:31:41,298][model][INFO] - Training step 30240 loss 0.005079390946775675
[2025-03-13 02:32:42,495][model][INFO] - Training step 30400 loss 0.029229700565338135
[2025-03-13 02:33:43,175][model][INFO] - Training step 30560 loss 0.03459624946117401
[2025-03-13 02:34:42,322][model][INFO] - Training step 30720 loss 0.01393074356019497
[2025-03-13 02:35:42,438][model][INFO] - Training step 30880 loss 0.0043914602138102055
[2025-03-13 02:36:45,372][model][INFO] - Training step 31040 loss 0.0502345934510231
[2025-03-13 02:37:45,028][model][INFO] - Training step 31200 loss 0.019153479486703873
[2025-03-13 02:38:47,446][model][INFO] - Training step 31360 loss 0.029019925743341446
[2025-03-13 02:39:47,301][model][INFO] - Training step 31520 loss 0.05568651854991913
[2025-03-13 02:40:48,481][model][INFO] - Training step 31680 loss 0.07187621295452118
[2025-03-13 02:41:51,724][model][INFO] - Training step 31840 loss 0.2637163996696472
[2025-03-13 02:42:57,645][model][INFO] - Training step 32000 loss 0.005691827740520239
[2025-03-13 02:43:58,491][model][INFO] - Training step 32160 loss 0.2534361481666565
[2025-03-13 02:45:00,915][model][INFO] - Training step 32320 loss 0.029531214386224747
[2025-03-13 02:46:02,773][model][INFO] - Training step 32480 loss 0.016400940716266632
[2025-03-13 02:47:05,626][model][INFO] - Training step 32640 loss 0.029574323445558548
[2025-03-13 02:48:07,135][model][INFO] - Training step 32800 loss 0.057169027626514435
[2025-03-13 02:49:11,001][model][INFO] - Training step 32960 loss 0.04190743342041969
[2025-03-13 02:50:12,536][model][INFO] - Training step 33120 loss 0.24852484464645386
[2025-03-13 02:51:15,404][model][INFO] - Training step 33280 loss 0.04239996150135994
[2025-03-13 02:52:17,098][model][INFO] - Training step 33440 loss 0.010542366653680801
[2025-03-13 02:53:19,412][model][INFO] - Training step 33600 loss 0.02257426269352436
[2025-03-13 02:54:21,942][model][INFO] - Training step 33760 loss 0.24957174062728882
[2025-03-13 02:55:25,107][model][INFO] - Training step 33920 loss 0.03744463622570038
[2025-03-13 02:56:28,307][model][INFO] - Training step 34080 loss 0.029352590441703796
[2025-03-13 02:57:29,865][model][INFO] - Training step 34240 loss 0.038550492376089096
[2025-03-13 02:58:31,890][model][INFO] - Training step 34400 loss 0.18740803003311157
[2025-03-13 02:59:37,536][model][INFO] - Training step 34560 loss 0.03037114441394806
[2025-03-13 03:00:41,252][model][INFO] - Training step 34720 loss 0.018944229930639267
[2025-03-13 03:01:45,707][model][INFO] - Training step 34880 loss 0.0186435729265213
[2025-03-13 03:02:48,473][model][INFO] - Training step 35040 loss 0.07765419781208038
[2025-03-13 03:03:50,628][model][INFO] - Training step 35200 loss 0.02907947450876236
[2025-03-13 03:04:54,805][model][INFO] - Training step 35360 loss 0.016903236508369446
[2025-03-13 03:05:58,195][model][INFO] - Training step 35520 loss 0.029516808688640594
[2025-03-13 03:07:01,784][model][INFO] - Training step 35680 loss 0.03210733085870743
[2025-03-13 03:08:02,929][model][INFO] - Training step 35840 loss 0.015691081061959267
[2025-03-13 03:09:02,988][model][INFO] - Training step 36000 loss 0.02556009590625763
[2025-03-13 03:10:04,893][model][INFO] - Training step 36160 loss 0.15323586761951447
[2025-03-13 03:11:10,138][model][INFO] - Training step 36320 loss 0.013746997341513634
[2025-03-13 03:12:13,045][model][INFO] - Training step 36480 loss 0.23226435482501984
[2025-03-13 03:13:17,057][model][INFO] - Training step 36640 loss 0.02237536758184433
[2025-03-13 03:14:20,418][model][INFO] - Training step 36800 loss 0.005499030463397503
[2025-03-13 03:15:24,108][model][INFO] - Training step 36960 loss 0.01057421788573265
[2025-03-13 03:16:27,191][model][INFO] - Training step 37120 loss 0.003550931578502059
[2025-03-13 03:17:32,551][model][INFO] - Training step 37280 loss 0.027943655848503113
[2025-03-13 03:18:32,415][model][INFO] - Training step 37440 loss 0.031699422746896744
[2025-03-13 03:19:34,347][model][INFO] - Training step 37600 loss 0.02304573357105255
[2025-03-13 03:20:35,622][model][INFO] - Training step 37760 loss 0.005112564191222191
[2025-03-13 03:21:36,876][model][INFO] - Training step 37920 loss 0.013605463318526745
[2025-03-13 03:22:38,945][model][INFO] - Training step 38080 loss 0.05310384929180145
[2025-03-13 03:23:43,398][model][INFO] - Training step 38240 loss 0.006022498942911625
[2025-03-13 03:24:46,693][model][INFO] - Training step 38400 loss 0.03225111961364746
[2025-03-13 03:25:47,762][model][INFO] - Training step 38560 loss 0.24972838163375854
[2025-03-13 03:26:51,133][model][INFO] - Training step 38720 loss 0.05005195736885071
[2025-03-13 03:27:52,367][model][INFO] - Training step 38880 loss 0.030452612787485123
[2025-03-13 03:28:56,230][model][INFO] - Training step 39040 loss 0.021158577874302864
[2025-03-13 03:29:58,605][model][INFO] - Training step 39200 loss 0.017622973769903183
[2025-03-13 03:31:01,200][model][INFO] - Training step 39360 loss 0.019993409514427185
[2025-03-13 03:32:03,439][model][INFO] - Training step 39520 loss 0.26593858003616333
[2025-03-13 03:33:06,391][model][INFO] - Training step 39680 loss 0.01807091385126114
[2025-03-13 03:34:09,545][model][INFO] - Training step 39840 loss 0.044081397354602814
[2025-03-13 03:35:13,311][model][INFO] - Training step 40000 loss 0.021360382437705994
[2025-03-13 03:36:15,878][model][INFO] - Training step 40160 loss 0.025791097432374954
[2025-03-13 03:37:18,427][model][INFO] - Training step 40320 loss 0.0061142356134951115
[2025-03-13 03:38:19,814][model][INFO] - Training step 40480 loss 0.23557253181934357
[2025-03-13 03:39:22,518][model][INFO] - Training step 40640 loss 0.2444171905517578
[2025-03-13 03:40:23,470][model][INFO] - Training step 40800 loss 0.24095943570137024
[2025-03-13 03:41:27,635][model][INFO] - Training step 40960 loss 0.022789478302001953
[2025-03-13 03:42:30,371][model][INFO] - Training step 41120 loss 0.0031506463419646025
[2025-03-13 03:43:35,027][model][INFO] - Training step 41280 loss 0.007251199800521135
[2025-03-13 03:44:37,841][model][INFO] - Training step 41440 loss 0.04080580174922943
[2025-03-13 03:45:40,181][model][INFO] - Training step 41600 loss 0.004306115675717592
[2025-03-13 03:46:42,566][model][INFO] - Training step 41760 loss 0.2624911665916443
[2025-03-13 03:47:45,307][model][INFO] - Training step 41920 loss 0.0034561564680188894
[2025-03-13 03:48:48,388][model][INFO] - Training step 42080 loss 0.23734945058822632
[2025-03-13 03:49:48,879][model][INFO] - Training step 42240 loss 0.02714690752327442
[2025-03-13 03:50:52,006][model][INFO] - Training step 42400 loss 0.07218833267688751
[2025-03-13 03:51:53,509][model][INFO] - Training step 42560 loss 0.2665669918060303
[2025-03-13 03:52:57,234][model][INFO] - Training step 42720 loss 0.020913682878017426
[2025-03-13 03:53:58,748][model][INFO] - Training step 42880 loss 0.24796360731124878
[2025-03-13 03:55:00,583][model][INFO] - Training step 43040 loss 0.24436746537685394
[2025-03-13 03:56:03,563][model][INFO] - Training step 43200 loss 0.03469223156571388
[2025-03-13 03:57:06,476][model][INFO] - Training step 43360 loss 0.24039620161056519
[2025-03-13 03:58:08,826][model][INFO] - Training step 43520 loss 0.02700178325176239
[2025-03-13 03:59:10,040][model][INFO] - Training step 43680 loss 0.04410073533654213
[2025-03-13 04:00:12,011][model][INFO] - Training step 43840 loss 0.03021163120865822
[2025-03-13 04:01:11,976][model][INFO] - Training step 44000 loss 0.025009701028466225
[2025-03-13 04:02:14,618][model][INFO] - Training step 44160 loss 0.011544529348611832
[2025-03-13 04:03:16,764][model][INFO] - Training step 44320 loss 0.015773732215166092
[2025-03-13 04:04:18,654][model][INFO] - Training step 44480 loss 0.009203191846609116
[2025-03-13 04:05:17,046][model][INFO] - Training step 44640 loss 0.02198798581957817
[2025-03-13 04:06:18,587][model][INFO] - Training step 44800 loss 0.049677614122629166
[2025-03-13 04:07:22,174][model][INFO] - Training step 44960 loss 0.05609045922756195
[2025-03-13 04:08:24,619][model][INFO] - Training step 45120 loss 0.10012838244438171
[2025-03-13 04:09:26,205][model][INFO] - Training step 45280 loss 0.019910018891096115
[2025-03-13 04:10:28,823][model][INFO] - Training step 45440 loss 0.007982056587934494
[2025-03-13 04:11:31,599][model][INFO] - Training step 45600 loss 0.022206809371709824
[2025-03-13 04:12:36,480][model][INFO] - Training step 45760 loss 0.03150245174765587
[2025-03-13 04:13:39,343][model][INFO] - Training step 45920 loss 0.26418375968933105
[2025-03-13 04:14:42,344][model][INFO] - Training step 46080 loss 0.022882480174303055
[2025-03-13 04:15:45,931][model][INFO] - Training step 46240 loss 0.07058151066303253
[2025-03-13 04:16:50,218][model][INFO] - Training step 46400 loss 0.0678376704454422
[2025-03-13 04:17:49,527][model][INFO] - Training step 46560 loss 0.018604561686515808
[2025-03-13 04:18:53,250][model][INFO] - Training step 46720 loss 0.24626706540584564
[2025-03-13 04:19:57,134][model][INFO] - Training step 46880 loss 0.06248044967651367
[2025-03-13 04:20:59,342][model][INFO] - Training step 47040 loss 0.263194739818573
[2025-03-13 04:22:03,215][model][INFO] - Training step 47200 loss 0.02832939475774765
[2025-03-13 04:23:05,271][model][INFO] - Training step 47360 loss 0.02182871475815773
[2025-03-13 04:24:10,744][model][INFO] - Training step 47520 loss 0.014700895175337791
[2025-03-13 04:25:15,581][model][INFO] - Training step 47680 loss 0.004066867288202047
[2025-03-13 04:26:15,965][model][INFO] - Training step 47840 loss 0.021810565143823624
[2025-03-13 04:27:17,370][model][INFO] - Training step 48000 loss 0.0026802809443324804
[2025-03-13 04:28:20,742][model][INFO] - Training step 48160 loss 0.0020193224772810936
[2025-03-13 04:29:18,687][model][INFO] - Training step 48320 loss 0.05317912995815277
[2025-03-13 04:30:19,916][model][INFO] - Training step 48480 loss 0.056426696479320526
[2025-03-13 04:31:21,219][model][INFO] - Training step 48640 loss 0.02149537391960621
[2025-03-13 04:32:23,565][model][INFO] - Training step 48800 loss 0.25108227133750916
[2025-03-13 04:33:25,877][model][INFO] - Training step 48960 loss 0.012010226026177406
[2025-03-13 04:34:29,169][model][INFO] - Training step 49120 loss 0.0270705409348011
[2025-03-13 04:35:30,414][model][INFO] - Training step 49280 loss 0.05814151465892792
[2025-03-13 04:36:32,692][model][INFO] - Training step 49440 loss 0.25411343574523926
[2025-03-13 04:37:34,896][model][INFO] - Training step 49600 loss 0.0036739991046488285
[2025-03-13 04:38:39,055][model][INFO] - Training step 49760 loss 0.010932709090411663
[2025-03-13 04:39:43,607][model][INFO] - Training step 49920 loss 0.017609942704439163
[2025-03-13 04:40:47,030][model][INFO] - Training step 50080 loss 0.019481513649225235
[2025-03-13 04:41:50,288][model][INFO] - Training step 50240 loss 0.03568663448095322
[2025-03-13 04:42:53,336][model][INFO] - Training step 50400 loss 0.007210109382867813
[2025-03-13 04:43:53,288][model][INFO] - Training step 50560 loss 0.018696755170822144
[2025-03-13 04:44:57,029][model][INFO] - Training step 50720 loss 0.03625127300620079
[2025-03-13 04:53:54,138][model][INFO] - Training step 80 loss 0.044015027582645416
[2025-03-13 04:54:55,901][model][INFO] - Training step 240 loss 0.23207658529281616
[2025-03-13 04:55:57,055][model][INFO] - Training step 400 loss 0.02772388607263565
[2025-03-13 04:56:57,530][model][INFO] - Training step 560 loss 0.019100479781627655
[2025-03-13 04:57:57,472][model][INFO] - Training step 720 loss 0.024428099393844604
[2025-03-13 04:58:58,347][model][INFO] - Training step 880 loss 0.0675349235534668
[2025-03-13 04:59:59,078][model][INFO] - Training step 1040 loss 0.025732815265655518
[2025-03-13 05:01:03,049][model][INFO] - Training step 1200 loss 0.07814981043338776
[2025-03-13 05:02:08,566][model][INFO] - Training step 1360 loss 0.031089629977941513
[2025-03-13 05:03:09,619][model][INFO] - Training step 1520 loss 0.04113708436489105
[2025-03-13 05:04:13,580][model][INFO] - Training step 1680 loss 0.0026563056744635105
[2025-03-13 05:05:15,122][model][INFO] - Training step 1840 loss 0.03387906774878502
[2025-03-13 05:06:15,274][model][INFO] - Training step 2000 loss 0.0372634083032608
[2025-03-13 05:07:16,738][model][INFO] - Training step 2160 loss 0.23961515724658966
[2025-03-13 05:08:19,126][model][INFO] - Training step 2320 loss 0.02041352167725563
[2025-03-13 05:09:23,012][model][INFO] - Training step 2480 loss 0.27343547344207764
[2025-03-13 05:10:22,881][model][INFO] - Training step 2640 loss 0.020172275602817535
[2025-03-13 05:11:25,688][model][INFO] - Training step 2800 loss 0.0892438217997551
[2025-03-13 05:12:28,770][model][INFO] - Training step 2960 loss 0.0042684501968324184
[2025-03-13 05:13:30,746][model][INFO] - Training step 3120 loss 0.05507999286055565
[2025-03-13 05:14:31,982][model][INFO] - Training step 3280 loss 0.04686405509710312
[2025-03-13 05:15:34,293][model][INFO] - Training step 3440 loss 0.027652569115161896
[2025-03-13 05:16:35,398][model][INFO] - Training step 3600 loss 0.24767756462097168
[2025-03-13 05:17:36,385][model][INFO] - Training step 3760 loss 0.019713744521141052
[2025-03-13 05:18:37,216][model][INFO] - Training step 3920 loss 0.016213437542319298
[2025-03-13 05:19:41,025][model][INFO] - Training step 4080 loss 0.1975204348564148
[2025-03-13 05:20:43,003][model][INFO] - Training step 4240 loss 0.03360620141029358
[2025-03-13 05:21:45,559][model][INFO] - Training step 4400 loss 0.01310616172850132
[2025-03-13 05:22:50,524][model][INFO] - Training step 4560 loss 0.0897553563117981
[2025-03-13 05:23:51,941][model][INFO] - Training step 4720 loss 0.0639214962720871
[2025-03-13 05:24:52,040][model][INFO] - Training step 4880 loss 0.01142219640314579
[2025-03-13 05:25:54,324][model][INFO] - Training step 5040 loss 0.010160179808735847
[2025-03-13 05:26:56,977][model][INFO] - Training step 5200 loss 0.04443603381514549
[2025-03-13 05:27:58,970][model][INFO] - Training step 5360 loss 0.22282302379608154
[2025-03-13 05:29:00,056][model][INFO] - Training step 5520 loss 0.03960055112838745
[2025-03-13 05:30:02,246][model][INFO] - Training step 5680 loss 0.07920834422111511
[2025-03-13 05:31:05,386][model][INFO] - Training step 5840 loss 0.021026158705353737
[2025-03-13 05:32:09,617][model][INFO] - Training step 6000 loss 0.021529514342546463
[2025-03-13 05:33:09,138][model][INFO] - Training step 6160 loss 0.007025853730738163
[2025-03-13 05:34:12,003][model][INFO] - Training step 6320 loss 0.03843923285603523
[2025-03-13 05:35:14,351][model][INFO] - Training step 6480 loss 0.024530548602342606
[2025-03-13 05:36:17,967][model][INFO] - Training step 6640 loss 0.006338005885481834
[2025-03-13 05:37:19,259][model][INFO] - Training step 6800 loss 0.002713058842346072
[2025-03-13 05:38:21,254][model][INFO] - Training step 6960 loss 0.02415219135582447
[2025-03-13 05:39:24,150][model][INFO] - Training step 7120 loss 0.0028474871069192886
[2025-03-13 05:40:26,105][model][INFO] - Training step 7280 loss 0.013217062689363956
[2025-03-13 05:41:27,910][model][INFO] - Training step 7440 loss 0.020789770409464836
[2025-03-13 05:42:30,008][model][INFO] - Training step 7600 loss 0.030322808772325516
[2025-03-13 05:43:30,698][model][INFO] - Training step 7760 loss 0.002456058282405138
[2025-03-13 05:44:34,553][model][INFO] - Training step 7920 loss 0.028636088594794273
[2025-03-13 05:45:36,804][model][INFO] - Training step 8080 loss 0.1910208761692047
[2025-03-13 05:46:39,419][model][INFO] - Training step 8240 loss 0.016497408971190453
[2025-03-13 05:47:42,109][model][INFO] - Training step 8400 loss 0.04512743651866913
[2025-03-13 05:48:44,070][model][INFO] - Training step 8560 loss 0.0074203889816999435
[2025-03-13 05:49:45,681][model][INFO] - Training step 8720 loss 0.09335356950759888
[2025-03-13 05:50:47,191][model][INFO] - Training step 8880 loss 0.030211158096790314
[2025-03-13 05:51:49,913][model][INFO] - Training step 9040 loss 0.05519648641347885
[2025-03-13 05:52:49,720][model][INFO] - Training step 9200 loss 0.022739090025424957
[2025-03-13 05:53:53,333][model][INFO] - Training step 9360 loss 0.25697505474090576
[2025-03-13 05:54:54,802][model][INFO] - Training step 9520 loss 0.011331665329635143
[2025-03-13 05:55:55,037][model][INFO] - Training step 9680 loss 0.005283747334033251
[2025-03-13 05:56:56,848][model][INFO] - Training step 9840 loss 0.10573722422122955
[2025-03-13 05:57:59,164][model][INFO] - Training step 10000 loss 0.07663176953792572
[2025-03-13 05:58:59,853][model][INFO] - Training step 10160 loss 0.062235210090875626
[2025-03-13 05:59:59,466][model][INFO] - Training step 10320 loss 0.018815502524375916
[2025-03-13 06:01:03,384][model][INFO] - Training step 10480 loss 0.021065201610326767
[2025-03-13 06:02:08,084][model][INFO] - Training step 10640 loss 0.026038523763418198
[2025-03-13 06:03:08,694][model][INFO] - Training step 10800 loss 0.005425779614597559
[2025-03-13 06:04:09,865][model][INFO] - Training step 10960 loss 0.003986366558820009
[2025-03-13 06:05:11,806][model][INFO] - Training step 11120 loss 0.02265997789800167
[2025-03-13 06:06:11,437][model][INFO] - Training step 11280 loss 0.2509087026119232
[2025-03-13 06:07:11,907][model][INFO] - Training step 11440 loss 0.021978599950671196
[2025-03-13 06:08:13,968][model][INFO] - Training step 11600 loss 0.014280952513217926
[2025-03-13 06:09:17,337][model][INFO] - Training step 11760 loss 0.06162363290786743
[2025-03-13 06:10:19,866][model][INFO] - Training step 11920 loss 0.08869309723377228
[2025-03-13 06:11:25,007][model][INFO] - Training step 12080 loss 0.2519586980342865
[2025-03-13 06:12:25,619][model][INFO] - Training step 12240 loss 0.03410937637090683
[2025-03-13 06:13:26,629][model][INFO] - Training step 12400 loss 0.24918752908706665
[2025-03-13 06:14:27,828][model][INFO] - Training step 12560 loss 0.02640470489859581
[2025-03-13 06:15:29,463][model][INFO] - Training step 12720 loss 0.029529809951782227
[2025-03-13 06:16:33,231][model][INFO] - Training step 12880 loss 0.0026410184800624847
[2025-03-13 06:17:35,344][model][INFO] - Training step 13040 loss 0.24368727207183838
[2025-03-13 06:18:38,436][model][INFO] - Training step 13200 loss 0.02929610013961792
[2025-03-13 06:19:41,736][model][INFO] - Training step 13360 loss 0.06204831972718239
[2025-03-13 06:20:45,136][model][INFO] - Training step 13520 loss 0.022335398942232132
[2025-03-13 06:21:50,615][model][INFO] - Training step 13680 loss 0.016882561147212982
[2025-03-13 06:22:56,019][model][INFO] - Training step 13840 loss 0.03648661822080612
[2025-03-13 06:23:57,585][model][INFO] - Training step 14000 loss 0.026279132813215256
[2025-03-13 06:24:58,569][model][INFO] - Training step 14160 loss 0.02795981429517269
[2025-03-13 06:26:00,696][model][INFO] - Training step 14320 loss 0.03369149565696716
[2025-03-13 06:27:03,223][model][INFO] - Training step 14480 loss 0.020070917904376984
[2025-03-13 06:28:05,316][model][INFO] - Training step 14640 loss 0.23197907209396362
[2025-03-13 06:29:05,577][model][INFO] - Training step 14800 loss 0.03322289511561394
[2025-03-13 06:30:05,740][model][INFO] - Training step 14960 loss 0.09658832848072052
[2025-03-13 06:31:07,474][model][INFO] - Training step 15120 loss 0.215755432844162
[2025-03-13 06:32:09,432][model][INFO] - Training step 15280 loss 0.001988315023481846
[2025-03-13 06:33:13,241][model][INFO] - Training step 15440 loss 0.00912674143910408
[2025-03-13 06:34:16,699][model][INFO] - Training step 15600 loss 0.059814512729644775
[2025-03-13 06:35:17,465][model][INFO] - Training step 15760 loss 0.3069370985031128
[2025-03-13 06:36:19,035][model][INFO] - Training step 15920 loss 0.2505764961242676
[2025-03-13 06:37:21,285][model][INFO] - Training step 16080 loss 0.25036197900772095
[2025-03-13 06:38:26,958][model][INFO] - Training step 16240 loss 0.027118416503071785
[2025-03-13 06:39:30,554][model][INFO] - Training step 16400 loss 0.028651056811213493
[2025-03-13 06:40:31,163][model][INFO] - Training step 16560 loss 0.03554435074329376
[2025-03-13 06:41:31,044][model][INFO] - Training step 16720 loss 0.02268374152481556
[2025-03-13 06:42:33,159][model][INFO] - Training step 16880 loss 0.019092649221420288
[2025-03-13 06:43:34,873][model][INFO] - Training step 17040 loss 0.0567602664232254
[2025-03-13 06:44:35,813][model][INFO] - Training step 17200 loss 0.039815500378608704
[2025-03-13 06:45:39,938][model][INFO] - Training step 17360 loss 0.017600510269403458
[2025-03-13 06:46:42,303][model][INFO] - Training step 17520 loss 0.04678967967629433
[2025-03-13 06:47:46,573][model][INFO] - Training step 17680 loss 0.04045306146144867
[2025-03-13 06:48:48,918][model][INFO] - Training step 17840 loss 0.25715410709381104
[2025-03-13 06:49:52,133][model][INFO] - Training step 18000 loss 0.027345454320311546
[2025-03-13 06:50:53,858][model][INFO] - Training step 18160 loss 0.023400548845529556
[2025-03-13 06:51:55,658][model][INFO] - Training step 18320 loss 0.025300201028585434
[2025-03-13 06:52:58,465][model][INFO] - Training step 18480 loss 0.003937072120606899
[2025-03-13 06:54:01,161][model][INFO] - Training step 18640 loss 0.051342569291591644
[2025-03-13 06:55:00,732][model][INFO] - Training step 18800 loss 0.01668507233262062
[2025-03-13 06:56:02,473][model][INFO] - Training step 18960 loss 0.26653212308883667
[2025-03-13 06:57:00,976][model][INFO] - Training step 19120 loss 0.21403956413269043
[2025-03-13 06:58:04,016][model][INFO] - Training step 19280 loss 0.007212365977466106
[2025-03-13 06:59:05,879][model][INFO] - Training step 19440 loss 0.005487086251378059
[2025-03-13 07:00:09,571][model][INFO] - Training step 19600 loss 0.03207895904779434
[2025-03-13 07:01:12,261][model][INFO] - Training step 19760 loss 0.0052078235894441605
[2025-03-13 07:02:16,550][model][INFO] - Training step 19920 loss 0.05682281032204628
[2025-03-13 07:03:16,693][model][INFO] - Training step 20080 loss 0.04297179356217384
[2025-03-13 07:04:19,939][model][INFO] - Training step 20240 loss 0.1743486523628235
[2025-03-13 07:05:19,269][model][INFO] - Training step 20400 loss 0.10728790611028671
[2025-03-13 07:06:21,192][model][INFO] - Training step 20560 loss 0.021869823336601257
[2025-03-13 07:07:25,209][model][INFO] - Training step 20720 loss 0.05412794649600983
[2025-03-13 07:08:27,157][model][INFO] - Training step 20880 loss 0.03801947832107544
[2025-03-13 07:09:29,877][model][INFO] - Training step 21040 loss 0.14433304965496063
[2025-03-13 07:10:32,308][model][INFO] - Training step 21200 loss 0.0028072583954781294
[2025-03-13 07:11:34,488][model][INFO] - Training step 21360 loss 0.007819782011210918
[2025-03-13 07:12:35,460][model][INFO] - Training step 21520 loss 0.26919692754745483
[2025-03-13 07:13:39,710][model][INFO] - Training step 21680 loss 0.02347959578037262
[2025-03-13 07:14:44,377][model][INFO] - Training step 21840 loss 0.00242894166149199
[2025-03-13 07:15:44,918][model][INFO] - Training step 22000 loss 0.004005198832601309
[2025-03-13 07:16:44,871][model][INFO] - Training step 22160 loss 0.24350669980049133
[2025-03-13 07:17:45,677][model][INFO] - Training step 22320 loss 0.005120429210364819
[2025-03-13 07:18:47,483][model][INFO] - Training step 22480 loss 0.24600911140441895
[2025-03-13 07:19:52,851][model][INFO] - Training step 22640 loss 0.012134023942053318
[2025-03-13 07:20:53,316][model][INFO] - Training step 22800 loss 0.2504766583442688
[2025-03-13 07:21:57,226][model][INFO] - Training step 22960 loss 0.018237974494695663
[2025-03-13 07:23:00,191][model][INFO] - Training step 23120 loss 0.15450060367584229
[2025-03-13 07:24:02,661][model][INFO] - Training step 23280 loss 0.0025453337002545595
[2025-03-13 07:25:04,355][model][INFO] - Training step 23440 loss 0.1920895129442215
[2025-03-13 07:26:06,730][model][INFO] - Training step 23600 loss 0.003404188435524702
[2025-03-13 07:27:08,344][model][INFO] - Training step 23760 loss 0.2551910877227783
[2025-03-13 07:28:10,686][model][INFO] - Training step 23920 loss 0.07707883417606354
[2025-03-13 07:29:12,656][model][INFO] - Training step 24080 loss 0.08273489773273468
[2025-03-13 07:30:11,433][model][INFO] - Training step 24240 loss 0.010414996184408665
[2025-03-13 07:31:12,438][model][INFO] - Training step 24400 loss 0.2509521245956421
[2025-03-13 07:32:13,073][model][INFO] - Training step 24560 loss 0.25593292713165283
[2025-03-13 07:33:15,306][model][INFO] - Training step 24720 loss 0.025263678282499313
[2025-03-13 07:34:16,325][model][INFO] - Training step 24880 loss 0.005367223173379898
[2025-03-13 07:35:18,135][model][INFO] - Training step 25040 loss 0.006081755273044109
[2025-03-13 07:36:21,359][model][INFO] - Training step 25200 loss 0.019388649612665176
[2025-03-13 07:37:23,336][model][INFO] - Training step 25360 loss 0.26548993587493896
[2025-03-13 07:38:23,862][model][INFO] - Training step 25520 loss 0.030620090663433075
[2025-03-13 07:39:26,817][model][INFO] - Training step 25680 loss 0.012025369331240654
[2025-03-13 07:40:26,620][model][INFO] - Training step 25840 loss 0.10470730066299438
[2025-03-13 07:41:29,689][model][INFO] - Training step 26000 loss 0.28879913687705994
[2025-03-13 07:42:29,908][model][INFO] - Training step 26160 loss 0.2571762502193451
[2025-03-13 07:43:35,699][model][INFO] - Training step 26320 loss 0.004228212870657444
[2025-03-13 07:44:38,539][model][INFO] - Training step 26480 loss 0.1539238691329956
[2025-03-13 07:45:41,396][model][INFO] - Training step 26640 loss 0.04247187077999115
[2025-03-13 07:46:41,210][model][INFO] - Training step 26800 loss 0.01045592688024044
[2025-03-13 07:47:41,325][model][INFO] - Training step 26960 loss 0.03583911433815956
[2025-03-13 07:48:44,998][model][INFO] - Training step 27120 loss 0.07381238043308258
[2025-03-13 07:49:45,527][model][INFO] - Training step 27280 loss 0.17425334453582764
[2025-03-13 07:50:50,506][model][INFO] - Training step 27440 loss 0.03793400153517723
[2025-03-13 07:51:51,094][model][INFO] - Training step 27600 loss 0.119392991065979
[2025-03-13 07:52:53,762][model][INFO] - Training step 27760 loss 0.006019410211592913
[2025-03-13 07:53:57,333][model][INFO] - Training step 27920 loss 0.022177666425704956
[2025-03-13 07:55:00,652][model][INFO] - Training step 28080 loss 0.2508992552757263
[2025-03-13 07:56:03,401][model][INFO] - Training step 28240 loss 0.2430921047925949
[2025-03-13 07:57:04,363][model][INFO] - Training step 28400 loss 0.049541398882865906
[2025-03-13 07:58:05,624][model][INFO] - Training step 28560 loss 0.02891334518790245
[2025-03-13 07:59:09,283][model][INFO] - Training step 28720 loss 0.011923983693122864
[2025-03-13 08:00:13,111][model][INFO] - Training step 28880 loss 0.003918392118066549
[2025-03-13 08:01:14,606][model][INFO] - Training step 29040 loss 0.021967871114611626
[2025-03-13 08:02:15,795][model][INFO] - Training step 29200 loss 0.042661599814891815
[2025-03-13 08:03:17,311][model][INFO] - Training step 29360 loss 0.007610069587826729
[2025-03-13 08:04:18,920][model][INFO] - Training step 29520 loss 0.003216556506231427
[2025-03-13 08:05:22,092][model][INFO] - Training step 29680 loss 0.24363169074058533
[2025-03-13 08:06:24,014][model][INFO] - Training step 29840 loss 0.27267494797706604
[2025-03-13 08:07:26,948][model][INFO] - Training step 30000 loss 0.012691567651927471
[2025-03-13 08:08:29,961][model][INFO] - Training step 30160 loss 0.047289300709962845
[2025-03-13 08:09:34,485][model][INFO] - Training step 30320 loss 0.02229861170053482
[2025-03-13 08:10:36,911][model][INFO] - Training step 30480 loss 0.02613656595349312
[2025-03-13 08:11:35,881][model][INFO] - Training step 30640 loss 0.02396596595644951
[2025-03-13 08:12:36,523][model][INFO] - Training step 30800 loss 0.03410367667675018
[2025-03-13 08:13:38,476][model][INFO] - Training step 30960 loss 0.02700394205749035
[2025-03-13 08:14:40,528][model][INFO] - Training step 31120 loss 0.24890315532684326
[2025-03-13 08:15:41,358][model][INFO] - Training step 31280 loss 0.004839691333472729
[2025-03-13 08:16:44,753][model][INFO] - Training step 31440 loss 0.02890823781490326
[2025-03-13 08:17:46,438][model][INFO] - Training step 31600 loss 0.03870120272040367
[2025-03-13 08:18:48,472][model][INFO] - Training step 31760 loss 0.27184605598449707
[2025-03-13 08:19:48,703][model][INFO] - Training step 31920 loss 0.024886053055524826
[2025-03-13 08:20:51,982][model][INFO] - Training step 32080 loss 0.0295436792075634
[2025-03-13 08:21:55,194][model][INFO] - Training step 32240 loss 0.013163764029741287
[2025-03-13 08:22:56,710][model][INFO] - Training step 32400 loss 0.03282729536294937
[2025-03-13 08:23:59,628][model][INFO] - Training step 32560 loss 0.04092969745397568
[2025-03-13 08:25:04,954][model][INFO] - Training step 32720 loss 0.027528751641511917
[2025-03-13 08:26:09,183][model][INFO] - Training step 32880 loss 0.04092686250805855
[2025-03-13 08:27:13,087][model][INFO] - Training step 33040 loss 0.026301801204681396
[2025-03-13 08:28:16,419][model][INFO] - Training step 33200 loss 0.18062186241149902
[2025-03-13 08:29:19,245][model][INFO] - Training step 33360 loss 0.02887418493628502
[2025-03-13 08:30:19,491][model][INFO] - Training step 33520 loss 0.005706769414246082
[2025-03-13 08:31:25,086][model][INFO] - Training step 33680 loss 0.25473475456237793
[2025-03-13 08:32:26,310][model][INFO] - Training step 33840 loss 0.030845224857330322
[2025-03-13 08:33:27,711][model][INFO] - Training step 34000 loss 0.2530902028083801
[2025-03-13 08:34:32,306][model][INFO] - Training step 34160 loss 0.041408833116292953
[2025-03-13 08:35:33,293][model][INFO] - Training step 34320 loss 0.018667027354240417
[2025-03-13 08:36:35,665][model][INFO] - Training step 34480 loss 0.15046969056129456
[2025-03-13 08:37:38,550][model][INFO] - Training step 34640 loss 0.23612794280052185
[2025-03-13 08:38:38,607][model][INFO] - Training step 34800 loss 0.04393414780497551
[2025-03-13 08:39:42,934][model][INFO] - Training step 34960 loss 0.026801524683833122
[2025-03-13 08:40:42,717][model][INFO] - Training step 35120 loss 0.009640207514166832
[2025-03-13 08:41:44,602][model][INFO] - Training step 35280 loss 0.2368191033601761
[2025-03-13 08:42:46,204][model][INFO] - Training step 35440 loss 0.026085101068019867
[2025-03-13 08:43:49,042][model][INFO] - Training step 35600 loss 0.26544180512428284
[2025-03-13 08:44:50,450][model][INFO] - Training step 35760 loss 0.2493874877691269
[2025-03-13 08:45:52,891][model][INFO] - Training step 35920 loss 0.028465958312153816
[2025-03-13 08:46:55,988][model][INFO] - Training step 36080 loss 0.03978395089507103
[2025-03-13 08:47:56,173][model][INFO] - Training step 36240 loss 0.2508670389652252
[2025-03-13 08:48:57,364][model][INFO] - Training step 36400 loss 0.040239252150058746
[2025-03-13 08:49:59,354][model][INFO] - Training step 36560 loss 0.003288683481514454
[2025-03-13 08:51:01,637][model][INFO] - Training step 36720 loss 0.019627179950475693
[2025-03-13 08:52:04,227][model][INFO] - Training step 36880 loss 0.0029277659486979246
[2025-03-13 08:53:08,804][model][INFO] - Training step 37040 loss 0.014626341871917248
[2025-03-13 08:54:11,476][model][INFO] - Training step 37200 loss 0.02751331403851509
[2025-03-13 08:55:13,700][model][INFO] - Training step 37360 loss 0.03490261361002922
[2025-03-13 08:56:16,936][model][INFO] - Training step 37520 loss 0.011177795007824898
[2025-03-13 08:57:17,309][model][INFO] - Training step 37680 loss 0.024650007486343384
[2025-03-13 08:58:20,800][model][INFO] - Training step 37840 loss 0.0557703822851181
[2025-03-13 08:59:20,305][model][INFO] - Training step 38000 loss 0.03758861869573593
[2025-03-13 09:00:20,521][model][INFO] - Training step 38160 loss 0.0204533189535141
[2025-03-13 09:01:21,874][model][INFO] - Training step 38320 loss 0.03043748065829277
[2025-03-13 09:02:23,357][model][INFO] - Training step 38480 loss 0.030492231249809265
[2025-03-13 09:03:23,630][model][INFO] - Training step 38640 loss 0.025414632633328438
[2025-03-13 09:04:24,519][model][INFO] - Training step 38800 loss 0.01392689161002636
[2025-03-13 09:05:26,968][model][INFO] - Training step 38960 loss 0.022897988557815552
[2025-03-13 09:06:26,247][model][INFO] - Training step 39120 loss 0.04550031200051308
[2025-03-13 09:07:26,515][model][INFO] - Training step 39280 loss 0.1621420681476593
[2025-03-13 09:08:29,749][model][INFO] - Training step 39440 loss 0.13939562439918518
[2025-03-13 09:09:30,776][model][INFO] - Training step 39600 loss 0.022202804684638977
[2025-03-13 09:10:34,417][model][INFO] - Training step 39760 loss 0.021073296666145325
[2025-03-13 09:11:35,721][model][INFO] - Training step 39920 loss 0.18087923526763916
[2025-03-13 09:12:38,053][model][INFO] - Training step 40080 loss 0.021500198170542717
[2025-03-13 09:13:40,317][model][INFO] - Training step 40240 loss 0.21775370836257935
[2025-03-13 09:14:40,495][model][INFO] - Training step 40400 loss 0.04434322565793991
[2025-03-13 09:15:40,810][model][INFO] - Training step 40560 loss 0.04800863564014435
[2025-03-13 09:16:43,128][model][INFO] - Training step 40720 loss 0.03216028958559036
[2025-03-13 09:17:44,610][model][INFO] - Training step 40880 loss 0.259187787771225
[2025-03-13 09:18:45,808][model][INFO] - Training step 41040 loss 0.04721090942621231
[2025-03-13 09:19:49,963][model][INFO] - Training step 41200 loss 0.014194682240486145
[2025-03-13 09:20:52,980][model][INFO] - Training step 41360 loss 0.03012288361787796
[2025-03-13 09:21:53,348][model][INFO] - Training step 41520 loss 0.08439558744430542
[2025-03-13 09:22:55,552][model][INFO] - Training step 41680 loss 0.09397478401660919
[2025-03-13 09:23:59,209][model][INFO] - Training step 41840 loss 0.016563192009925842
[2025-03-13 09:25:00,020][model][INFO] - Training step 42000 loss 0.2496757209300995
[2025-03-13 09:26:01,845][model][INFO] - Training step 42160 loss 0.03154246509075165
[2025-03-13 09:27:05,262][model][INFO] - Training step 42320 loss 0.016729792580008507
[2025-03-13 09:28:09,875][model][INFO] - Training step 42480 loss 0.022148145362734795
[2025-03-13 09:29:11,132][model][INFO] - Training step 42640 loss 0.2474118173122406
[2025-03-13 09:30:11,245][model][INFO] - Training step 42800 loss 0.042385928332805634
[2025-03-13 09:31:12,307][model][INFO] - Training step 42960 loss 0.020511996001005173
[2025-03-13 09:32:15,854][model][INFO] - Training step 43120 loss 0.04501688852906227
[2025-03-13 09:33:15,836][model][INFO] - Training step 43280 loss 0.03895898908376694
[2025-03-13 09:34:20,273][model][INFO] - Training step 43440 loss 0.05063428729772568
[2025-03-13 09:35:24,354][model][INFO] - Training step 43600 loss 0.014926725998520851
[2025-03-13 09:36:26,279][model][INFO] - Training step 43760 loss 0.09042072296142578
[2025-03-13 09:37:31,319][model][INFO] - Training step 43920 loss 0.04926922172307968
[2025-03-13 09:38:38,962][model][INFO] - Training step 44080 loss 0.0535687580704689
[2025-03-13 09:39:40,397][model][INFO] - Training step 44240 loss 0.029276985675096512
[2025-03-13 09:40:42,725][model][INFO] - Training step 44400 loss 0.03738950192928314
[2025-03-13 09:41:42,983][model][INFO] - Training step 44560 loss 0.025453822687268257
[2025-03-13 09:42:42,865][model][INFO] - Training step 44720 loss 0.02066987380385399
[2025-03-13 09:43:45,474][model][INFO] - Training step 44880 loss 0.058519959449768066
[2025-03-13 09:44:48,339][model][INFO] - Training step 45040 loss 0.019297346472740173
[2025-03-13 09:45:46,948][model][INFO] - Training step 45200 loss 0.01485490147024393
[2025-03-13 09:46:50,838][model][INFO] - Training step 45360 loss 0.028052639216184616
[2025-03-13 09:47:52,459][model][INFO] - Training step 45520 loss 0.00880773738026619
[2025-03-13 09:48:53,922][model][INFO] - Training step 45680 loss 0.24487422406673431
[2025-03-13 09:49:56,411][model][INFO] - Training step 45840 loss 0.004365220200270414
[2025-03-13 09:50:56,670][model][INFO] - Training step 46000 loss 0.11941540986299515
[2025-03-13 09:52:00,428][model][INFO] - Training step 46160 loss 0.25809168815612793
[2025-03-13 09:53:04,099][model][INFO] - Training step 46320 loss 0.05605187267065048
[2025-03-13 09:54:06,415][model][INFO] - Training step 46480 loss 0.02423439547419548
[2025-03-13 09:55:09,218][model][INFO] - Training step 46640 loss 0.21140894293785095
[2025-03-13 09:56:11,355][model][INFO] - Training step 46800 loss 0.0305776447057724
[2025-03-13 09:57:12,360][model][INFO] - Training step 46960 loss 0.03652651607990265
[2025-03-13 09:58:14,443][model][INFO] - Training step 47120 loss 0.03927525505423546
[2025-03-13 09:59:16,959][model][INFO] - Training step 47280 loss 0.0026973122730851173
[2025-03-13 10:00:21,624][model][INFO] - Training step 47440 loss 0.2568912208080292
[2025-03-13 10:01:23,868][model][INFO] - Training step 47600 loss 0.03876539319753647
[2025-03-13 10:02:25,961][model][INFO] - Training step 47760 loss 0.035283781588077545
[2025-03-13 10:03:30,921][model][INFO] - Training step 47920 loss 0.2562202215194702
[2025-03-13 10:04:33,722][model][INFO] - Training step 48080 loss 0.2589278221130371
[2025-03-13 10:05:33,278][model][INFO] - Training step 48240 loss 0.004148969426751137
[2025-03-13 10:06:33,648][model][INFO] - Training step 48400 loss 0.005785546265542507
[2025-03-13 10:07:36,419][model][INFO] - Training step 48560 loss 0.25766003131866455
[2025-03-13 10:08:40,393][model][INFO] - Training step 48720 loss 0.024799006059765816
[2025-03-13 10:09:41,999][model][INFO] - Training step 48880 loss 0.01606234908103943
[2025-03-13 10:10:43,630][model][INFO] - Training step 49040 loss 0.028663039207458496
[2025-03-13 10:11:46,427][model][INFO] - Training step 49200 loss 0.029873009771108627
[2025-03-13 10:12:48,888][model][INFO] - Training step 49360 loss 0.250296413898468
[2025-03-13 10:13:52,767][model][INFO] - Training step 49520 loss 0.03564782440662384
[2025-03-13 10:14:53,748][model][INFO] - Training step 49680 loss 0.013342887163162231
[2025-03-13 10:15:55,854][model][INFO] - Training step 49840 loss 0.1026882603764534
[2025-03-13 10:16:59,294][model][INFO] - Training step 50000 loss 0.026409445330500603
[2025-03-13 10:18:03,383][model][INFO] - Training step 50160 loss 0.03799031674861908
[2025-03-13 10:19:06,273][model][INFO] - Training step 50320 loss 0.024020399898290634
[2025-03-13 10:20:07,983][model][INFO] - Training step 50480 loss 0.07560693472623825
[2025-03-13 10:21:07,084][model][INFO] - Training step 50640 loss 0.24671152234077454
[2025-03-13 10:30:02,354][model][INFO] - Training step 0 loss 0.2411210536956787
[2025-03-13 10:31:05,034][model][INFO] - Training step 160 loss 0.014018550515174866
[2025-03-13 10:32:08,155][model][INFO] - Training step 320 loss 0.11290495097637177
[2025-03-13 10:33:10,922][model][INFO] - Training step 480 loss 0.019380390644073486
[2025-03-13 10:34:12,877][model][INFO] - Training step 640 loss 0.25532862544059753
[2025-03-13 10:35:15,138][model][INFO] - Training step 800 loss 0.0038172942586243153
[2025-03-13 10:36:17,022][model][INFO] - Training step 960 loss 0.017644282430410385
[2025-03-13 10:37:17,530][model][INFO] - Training step 1120 loss 0.05841643735766411
[2025-03-13 10:38:16,661][model][INFO] - Training step 1280 loss 0.013573351316154003
[2025-03-13 10:39:16,109][model][INFO] - Training step 1440 loss 0.030349384993314743
[2025-03-13 10:40:16,582][model][INFO] - Training step 1600 loss 0.1076938658952713
[2025-03-13 10:41:18,410][model][INFO] - Training step 1760 loss 0.033229246735572815
[2025-03-13 10:42:19,383][model][INFO] - Training step 1920 loss 0.008705340325832367
[2025-03-13 10:43:21,446][model][INFO] - Training step 2080 loss 0.22141773998737335
[2025-03-13 10:44:22,525][model][INFO] - Training step 2240 loss 0.019395459443330765
[2025-03-13 10:45:22,561][model][INFO] - Training step 2400 loss 0.05679648369550705
[2025-03-13 10:46:23,582][model][INFO] - Training step 2560 loss 0.2682216167449951
[2025-03-13 10:47:27,615][model][INFO] - Training step 2720 loss 0.02218865603208542
[2025-03-13 10:48:30,256][model][INFO] - Training step 2880 loss 0.018616629764437675
[2025-03-13 10:49:33,447][model][INFO] - Training step 3040 loss 0.022341370582580566
[2025-03-13 10:50:37,770][model][INFO] - Training step 3200 loss 0.003968764096498489
[2025-03-13 10:51:39,267][model][INFO] - Training step 3360 loss 0.28863269090652466
[2025-03-13 10:52:42,962][model][INFO] - Training step 3520 loss 0.006559701636433601
[2025-03-13 10:53:45,711][model][INFO] - Training step 3680 loss 0.002543830778449774
[2025-03-13 10:54:47,204][model][INFO] - Training step 3840 loss 0.03635939210653305
[2025-03-13 10:55:50,622][model][INFO] - Training step 4000 loss 0.03649430721998215
[2025-03-13 10:56:51,958][model][INFO] - Training step 4160 loss 0.01284458115696907
[2025-03-13 10:57:54,721][model][INFO] - Training step 4320 loss 0.06522971391677856
[2025-03-13 10:59:01,611][model][INFO] - Training step 4480 loss 0.002244282281026244
[2025-03-13 11:00:03,725][model][INFO] - Training step 4640 loss 0.0075088259764015675
[2025-03-13 11:01:03,043][model][INFO] - Training step 4800 loss 0.003992689307779074
[2025-03-13 11:02:06,720][model][INFO] - Training step 4960 loss 0.011086709797382355
[2025-03-13 11:03:10,877][model][INFO] - Training step 5120 loss 0.6842746138572693
[2025-03-13 11:04:12,584][model][INFO] - Training step 5280 loss 0.009833531454205513
[2025-03-13 11:05:13,180][model][INFO] - Training step 5440 loss 0.03990742936730385
[2025-03-13 11:06:12,104][model][INFO] - Training step 5600 loss 0.015585159882903099
[2025-03-13 11:07:14,606][model][INFO] - Training step 5760 loss 0.02235914021730423
[2025-03-13 11:08:18,551][model][INFO] - Training step 5920 loss 0.022792179137468338
[2025-03-13 11:09:20,062][model][INFO] - Training step 6080 loss 0.005321874748915434
[2025-03-13 11:10:25,196][model][INFO] - Training step 6240 loss 0.24183103442192078
[2025-03-13 11:11:29,397][model][INFO] - Training step 6400 loss 0.02230062149465084
[2025-03-13 11:12:30,905][model][INFO] - Training step 6560 loss 0.004485462326556444
[2025-03-13 11:13:32,950][model][INFO] - Training step 6720 loss 0.008312210440635681
[2025-03-13 11:14:34,838][model][INFO] - Training step 6880 loss 0.06655645370483398
[2025-03-13 11:15:37,593][model][INFO] - Training step 7040 loss 0.2608788311481476
[2025-03-13 11:16:42,445][model][INFO] - Training step 7200 loss 0.016411274671554565
[2025-03-13 11:17:41,632][model][INFO] - Training step 7360 loss 0.029272425919771194
[2025-03-13 11:18:45,344][model][INFO] - Training step 7520 loss 0.030738523229956627
[2025-03-13 11:19:47,289][model][INFO] - Training step 7680 loss 0.10744324326515198
[2025-03-13 11:20:50,417][model][INFO] - Training step 7840 loss 0.029190849512815475
[2025-03-13 11:21:54,540][model][INFO] - Training step 8000 loss 0.0034860065206885338
[2025-03-13 11:22:56,066][model][INFO] - Training step 8160 loss 0.002872889395803213
[2025-03-13 11:23:56,109][model][INFO] - Training step 8320 loss 0.004227381199598312
[2025-03-13 11:24:57,479][model][INFO] - Training step 8480 loss 0.14022549986839294
[2025-03-13 11:25:59,795][model][INFO] - Training step 8640 loss 0.01722337305545807
[2025-03-13 11:27:00,480][model][INFO] - Training step 8800 loss 0.02041636034846306
[2025-03-13 11:28:01,424][model][INFO] - Training step 8960 loss 0.530583918094635
[2025-03-13 11:29:02,976][model][INFO] - Training step 9120 loss 0.04985973984003067
[2025-03-13 11:30:04,855][model][INFO] - Training step 9280 loss 0.030662929639220238
[2025-03-13 11:31:07,978][model][INFO] - Training step 9440 loss 0.013544783927500248
[2025-03-13 11:32:07,765][model][INFO] - Training step 9600 loss 0.05012807995080948
[2025-03-13 11:33:12,061][model][INFO] - Training step 9760 loss 0.23922984302043915
[2025-03-13 11:34:15,304][model][INFO] - Training step 9920 loss 0.026174651458859444
[2025-03-13 11:35:17,932][model][INFO] - Training step 10080 loss 0.1688958704471588
[2025-03-13 11:36:20,149][model][INFO] - Training step 10240 loss 0.003165331669151783
[2025-03-13 11:37:21,743][model][INFO] - Training step 10400 loss 0.053463295102119446
[2025-03-13 11:38:24,707][model][INFO] - Training step 10560 loss 0.14904318749904633
[2025-03-13 11:39:26,464][model][INFO] - Training step 10720 loss 0.16968342661857605
[2025-03-13 11:40:30,443][model][INFO] - Training step 10880 loss 0.008078421466052532
[2025-03-13 11:41:30,836][model][INFO] - Training step 11040 loss 0.027462005615234375
[2025-03-13 11:42:32,505][model][INFO] - Training step 11200 loss 0.06213190034031868
[2025-03-13 11:43:34,833][model][INFO] - Training step 11360 loss 0.031714245676994324
[2025-03-13 11:44:36,527][model][INFO] - Training step 11520 loss 0.02586575411260128
[2025-03-13 11:45:39,969][model][INFO] - Training step 11680 loss 0.040321528911590576
[2025-03-13 11:46:43,117][model][INFO] - Training step 11840 loss 0.024133168160915375
[2025-03-13 11:47:44,949][model][INFO] - Training step 12000 loss 0.03558018431067467
[2025-03-13 11:48:47,950][model][INFO] - Training step 12160 loss 0.07350286841392517
[2025-03-13 11:49:50,901][model][INFO] - Training step 12320 loss 0.24476107954978943
[2025-03-13 11:50:53,891][model][INFO] - Training step 12480 loss 0.022646315395832062
[2025-03-13 11:51:56,197][model][INFO] - Training step 12640 loss 0.102597177028656
[2025-03-13 11:52:58,422][model][INFO] - Training step 12800 loss 0.028688104823231697
[2025-03-13 11:54:01,855][model][INFO] - Training step 12960 loss 0.05732092633843422
[2025-03-13 11:55:03,000][model][INFO] - Training step 13120 loss 0.01724681258201599
[2025-03-13 11:56:05,941][model][INFO] - Training step 13280 loss 0.005666749551892281
[2025-03-13 11:57:04,896][model][INFO] - Training step 13440 loss 0.06929834187030792
[2025-03-13 11:58:06,402][model][INFO] - Training step 13600 loss 0.02409512922167778
[2025-03-13 11:59:09,917][model][INFO] - Training step 13760 loss 0.12625916302204132
[2025-03-13 12:00:11,597][model][INFO] - Training step 13920 loss 0.0804080218076706
[2025-03-13 12:01:14,259][model][INFO] - Training step 14080 loss 0.016494056209921837
[2025-03-13 12:02:14,933][model][INFO] - Training step 14240 loss 0.12655094265937805
[2025-03-13 12:03:18,859][model][INFO] - Training step 14400 loss 0.013347981497645378
[2025-03-13 12:04:21,289][model][INFO] - Training step 14560 loss 0.00989469699561596
[2025-03-13 12:05:23,431][model][INFO] - Training step 14720 loss 0.023539133369922638
[2025-03-13 12:06:25,460][model][INFO] - Training step 14880 loss 0.038836538791656494
[2025-03-13 12:07:30,422][model][INFO] - Training step 15040 loss 0.08145799487829208
[2025-03-13 12:08:34,902][model][INFO] - Training step 15200 loss 0.02210986614227295
[2025-03-13 12:09:36,428][model][INFO] - Training step 15360 loss 0.0154296038672328
[2025-03-13 12:10:41,692][model][INFO] - Training step 15520 loss 0.014805186539888382
[2025-03-13 12:11:45,511][model][INFO] - Training step 15680 loss 0.005463903769850731
[2025-03-13 12:12:47,997][model][INFO] - Training step 15840 loss 0.04110800847411156
[2025-03-13 12:13:51,953][model][INFO] - Training step 16000 loss 0.01277555339038372
[2025-03-13 12:14:54,170][model][INFO] - Training step 16160 loss 0.021539773792028427
[2025-03-13 12:15:53,793][model][INFO] - Training step 16320 loss 0.09622983634471893
[2025-03-13 12:16:54,945][model][INFO] - Training step 16480 loss 0.016906464472413063
[2025-03-13 12:17:59,105][model][INFO] - Training step 16640 loss 0.3822364807128906
[2025-03-13 12:19:00,750][model][INFO] - Training step 16800 loss 0.07619982957839966
[2025-03-13 12:20:04,508][model][INFO] - Training step 16960 loss 0.10451941192150116
[2025-03-13 12:21:07,851][model][INFO] - Training step 17120 loss 0.07206405699253082
[2025-03-13 12:22:11,302][model][INFO] - Training step 17280 loss 0.7233363389968872
[2025-03-13 12:23:12,713][model][INFO] - Training step 17440 loss 0.02822822704911232
[2025-03-13 12:24:14,327][model][INFO] - Training step 17600 loss 0.03736954182386398
[2025-03-13 12:25:16,046][model][INFO] - Training step 17760 loss 0.032115764915943146
[2025-03-13 12:26:17,664][model][INFO] - Training step 17920 loss 0.2629830539226532
[2025-03-13 12:27:18,089][model][INFO] - Training step 18080 loss 0.04369032382965088
[2025-03-13 12:28:18,798][model][INFO] - Training step 18240 loss 0.03474537283182144
[2025-03-13 12:29:22,550][model][INFO] - Training step 18400 loss 0.2537634074687958
[2025-03-13 12:30:22,775][model][INFO] - Training step 18560 loss 0.09429094940423965
[2025-03-13 12:31:25,434][model][INFO] - Training step 18720 loss 0.050235114991664886
[2025-03-13 12:32:27,402][model][INFO] - Training step 18880 loss 0.017916344106197357
[2025-03-13 12:33:28,685][model][INFO] - Training step 19040 loss 0.03058413416147232
[2025-03-13 12:34:31,179][model][INFO] - Training step 19200 loss 0.025183167308568954
[2025-03-13 12:35:31,263][model][INFO] - Training step 19360 loss 0.025104572996497154
[2025-03-13 12:36:34,136][model][INFO] - Training step 19520 loss 0.004110401961952448
[2025-03-13 12:37:37,173][model][INFO] - Training step 19680 loss 0.02942405641078949
[2025-03-13 12:38:36,945][model][INFO] - Training step 19840 loss 0.04120531305670738
[2025-03-13 12:39:39,462][model][INFO] - Training step 20000 loss 0.005663003772497177
[2025-03-13 12:40:42,150][model][INFO] - Training step 20160 loss 0.07220039516687393
[2025-03-13 12:41:44,158][model][INFO] - Training step 20320 loss 0.03108629211783409
[2025-03-13 12:42:44,009][model][INFO] - Training step 20480 loss 0.020807312801480293
[2025-03-13 12:43:45,204][model][INFO] - Training step 20640 loss 0.02262425422668457
[2025-03-13 12:44:47,238][model][INFO] - Training step 20800 loss 0.2206200659275055
[2025-03-13 12:45:49,335][model][INFO] - Training step 20960 loss 0.01780691184103489
[2025-03-13 12:46:52,737][model][INFO] - Training step 21120 loss 0.05551072955131531
[2025-03-13 12:47:53,691][model][INFO] - Training step 21280 loss 0.017884735018014908
[2025-03-13 12:48:56,040][model][INFO] - Training step 21440 loss 0.008778221905231476
[2025-03-13 12:49:57,721][model][INFO] - Training step 21600 loss 0.2508354187011719
[2025-03-13 12:51:01,097][model][INFO] - Training step 21760 loss 0.26821306347846985
[2025-03-13 12:52:01,370][model][INFO] - Training step 21920 loss 0.04416290298104286
[2025-03-13 12:53:03,424][model][INFO] - Training step 22080 loss 0.05227284878492355
[2025-03-13 12:54:02,662][model][INFO] - Training step 22240 loss 0.0364791676402092
[2025-03-13 12:55:06,344][model][INFO] - Training step 22400 loss 0.2268044352531433
[2025-03-13 12:56:07,430][model][INFO] - Training step 22560 loss 0.034459132701158524
[2025-03-13 12:57:09,139][model][INFO] - Training step 22720 loss 0.11128517985343933
[2025-03-13 12:58:11,343][model][INFO] - Training step 22880 loss 0.02076755464076996
[2025-03-13 12:59:13,519][model][INFO] - Training step 23040 loss 0.040177106857299805
[2025-03-13 13:00:13,813][model][INFO] - Training step 23200 loss 0.07117161154747009
[2025-03-13 13:01:16,010][model][INFO] - Training step 23360 loss 0.0058274781331419945
[2025-03-13 13:02:20,010][model][INFO] - Training step 23520 loss 0.03411000967025757
[2025-03-13 13:03:21,709][model][INFO] - Training step 23680 loss 0.027463873848319054
[2025-03-13 13:04:24,915][model][INFO] - Training step 23840 loss 0.018592823296785355
[2025-03-13 13:05:27,806][model][INFO] - Training step 24000 loss 0.00584021070972085
[2025-03-13 13:06:27,722][model][INFO] - Training step 24160 loss 0.024050403386354446
[2025-03-13 13:07:28,302][model][INFO] - Training step 24320 loss 0.025355814024806023
[2025-03-13 13:08:31,321][model][INFO] - Training step 24480 loss 0.00875966064631939
[2025-03-13 13:09:31,040][model][INFO] - Training step 24640 loss 0.0024584648199379444
[2025-03-13 13:10:35,639][model][INFO] - Training step 24800 loss 0.09194576740264893
[2025-03-13 13:11:41,485][model][INFO] - Training step 24960 loss 0.02108462154865265
[2025-03-13 13:12:44,930][model][INFO] - Training step 25120 loss 0.0047808317467570305
[2025-03-13 13:13:47,101][model][INFO] - Training step 25280 loss 0.27118387818336487
[2025-03-13 13:14:49,374][model][INFO] - Training step 25440 loss 0.0290736835449934
[2025-03-13 13:15:51,784][model][INFO] - Training step 25600 loss 0.193587064743042
[2025-03-13 13:16:51,945][model][INFO] - Training step 25760 loss 0.025106344372034073
[2025-03-13 13:17:54,041][model][INFO] - Training step 25920 loss 0.0286562442779541
[2025-03-13 13:18:55,038][model][INFO] - Training step 26080 loss 0.02759043127298355
[2025-03-13 13:19:56,978][model][INFO] - Training step 26240 loss 0.003748408518731594
[2025-03-13 13:20:59,896][model][INFO] - Training step 26400 loss 0.026574494317173958
[2025-03-13 13:22:01,045][model][INFO] - Training step 26560 loss 0.015673452988266945
[2025-03-13 13:23:01,600][model][INFO] - Training step 26720 loss 0.231733500957489
[2025-03-13 13:24:06,153][model][INFO] - Training step 26880 loss 0.028649285435676575
[2025-03-13 13:25:07,526][model][INFO] - Training step 27040 loss 0.007962715812027454
[2025-03-13 13:26:10,212][model][INFO] - Training step 27200 loss 0.24446067214012146
[2025-03-13 13:27:15,357][model][INFO] - Training step 27360 loss 0.06466628611087799
[2025-03-13 13:28:18,191][model][INFO] - Training step 27520 loss 0.004810974933207035
[2025-03-13 13:29:22,394][model][INFO] - Training step 27680 loss 0.247479647397995
[2025-03-13 13:30:24,006][model][INFO] - Training step 27840 loss 0.23937541246414185
[2025-03-13 13:31:26,083][model][INFO] - Training step 28000 loss 0.022657394409179688
[2025-03-13 13:32:29,693][model][INFO] - Training step 28160 loss 0.23718231916427612
[2025-03-13 13:33:31,942][model][INFO] - Training step 28320 loss 0.25880885124206543
[2025-03-13 13:34:33,552][model][INFO] - Training step 28480 loss 0.17547914385795593
[2025-03-13 13:35:36,437][model][INFO] - Training step 28640 loss 0.005273198708891869
[2025-03-13 13:36:37,143][model][INFO] - Training step 28800 loss 0.14978563785552979
[2025-03-13 13:37:39,974][model][INFO] - Training step 28960 loss 0.04039309173822403
[2025-03-13 13:38:41,393][model][INFO] - Training step 29120 loss 0.00804871041327715
[2025-03-13 13:39:44,792][model][INFO] - Training step 29280 loss 0.04964958876371384
[2025-03-13 13:40:46,621][model][INFO] - Training step 29440 loss 0.016844842582941055
[2025-03-13 13:41:48,431][model][INFO] - Training step 29600 loss 0.0780922919511795
[2025-03-13 13:42:48,254][model][INFO] - Training step 29760 loss 0.10392452776432037
[2025-03-13 13:43:50,648][model][INFO] - Training step 29920 loss 0.262939989566803
[2025-03-13 13:44:51,923][model][INFO] - Training step 30080 loss 0.024055171757936478
[2025-03-13 13:45:53,286][model][INFO] - Training step 30240 loss 0.03121182508766651
[2025-03-13 13:46:58,769][model][INFO] - Training step 30400 loss 0.0293579138815403
[2025-03-13 13:48:00,859][model][INFO] - Training step 30560 loss 0.27759265899658203
[2025-03-13 13:48:58,556][model][INFO] - Training step 30720 loss 0.010163122788071632
[2025-03-13 13:50:00,274][model][INFO] - Training step 30880 loss 0.25605344772338867
[2025-03-13 13:51:01,753][model][INFO] - Training step 31040 loss 0.24969783425331116
[2025-03-13 13:52:02,970][model][INFO] - Training step 31200 loss 0.02611563354730606
[2025-03-13 13:53:04,140][model][INFO] - Training step 31360 loss 0.06803710758686066
[2025-03-13 13:54:07,550][model][INFO] - Training step 31520 loss 0.00947162602096796
[2025-03-13 13:55:11,606][model][INFO] - Training step 31680 loss 0.024310670793056488
[2025-03-13 13:56:11,496][model][INFO] - Training step 31840 loss 0.008610868826508522
[2025-03-13 13:57:12,738][model][INFO] - Training step 32000 loss 0.079652801156044
[2025-03-13 13:58:16,482][model][INFO] - Training step 32160 loss 0.005288305226713419
[2025-03-13 13:59:17,027][model][INFO] - Training step 32320 loss 0.02778495103120804
[2025-03-13 14:00:17,635][model][INFO] - Training step 32480 loss 0.021463315933942795
[2025-03-13 14:01:23,557][model][INFO] - Training step 32640 loss 0.1754833310842514
[2025-03-13 14:02:26,226][model][INFO] - Training step 32800 loss 0.07051139324903488
[2025-03-13 14:03:28,064][model][INFO] - Training step 32960 loss 0.003968751523643732
[2025-03-13 14:04:29,859][model][INFO] - Training step 33120 loss 0.006343252025544643
[2025-03-13 14:05:31,977][model][INFO] - Training step 33280 loss 0.041903991252183914
[2025-03-13 14:06:33,266][model][INFO] - Training step 33440 loss 0.10398802161216736
[2025-03-13 14:07:35,992][model][INFO] - Training step 33600 loss 0.02303187921643257
[2025-03-13 14:08:37,835][model][INFO] - Training step 33760 loss 0.02587183192372322
[2025-03-13 14:09:42,854][model][INFO] - Training step 33920 loss 0.07249715179204941
[2025-03-13 14:10:45,384][model][INFO] - Training step 34080 loss 0.0037853452377021313
[2025-03-13 14:11:46,360][model][INFO] - Training step 34240 loss 0.028530552983283997
[2025-03-13 14:12:47,616][model][INFO] - Training step 34400 loss 0.04429025948047638
[2025-03-13 14:13:47,733][model][INFO] - Training step 34560 loss 0.03420909121632576
[2025-03-13 14:14:53,151][model][INFO] - Training step 34720 loss 0.020687595009803772
[2025-03-13 14:15:55,870][model][INFO] - Training step 34880 loss 0.23766005039215088
[2025-03-13 14:16:59,685][model][INFO] - Training step 35040 loss 0.023630503565073013
[2025-03-13 14:17:59,967][model][INFO] - Training step 35200 loss 0.04013906046748161
[2025-03-13 14:19:02,837][model][INFO] - Training step 35360 loss 0.043060462921857834
[2025-03-13 14:20:07,193][model][INFO] - Training step 35520 loss 0.052207931876182556
[2025-03-13 14:21:07,931][model][INFO] - Training step 35680 loss 0.09328483045101166
[2025-03-13 14:22:10,230][model][INFO] - Training step 35840 loss 0.01695748046040535
[2025-03-13 14:23:13,559][model][INFO] - Training step 36000 loss 0.029386984184384346
[2025-03-13 14:24:13,950][model][INFO] - Training step 36160 loss 0.006114204414188862
[2025-03-13 14:25:20,804][model][INFO] - Training step 36320 loss 0.025149662047624588
[2025-03-13 14:26:22,399][model][INFO] - Training step 36480 loss 0.020365621894598007
[2025-03-13 14:27:25,184][model][INFO] - Training step 36640 loss 0.22870154678821564
[2025-03-13 14:28:29,099][model][INFO] - Training step 36800 loss 0.027470842003822327
[2025-03-13 14:29:33,639][model][INFO] - Training step 36960 loss 0.01069234125316143
[2025-03-13 14:30:34,200][model][INFO] - Training step 37120 loss 0.01943853497505188
[2025-03-13 14:31:39,142][model][INFO] - Training step 37280 loss 0.046877823770046234
[2025-03-13 14:32:41,140][model][INFO] - Training step 37440 loss 0.005471707321703434
[2025-03-13 14:33:40,336][model][INFO] - Training step 37600 loss 0.23988746106624603
[2025-03-13 14:34:41,805][model][INFO] - Training step 37760 loss 0.02356913313269615
[2025-03-13 14:35:44,763][model][INFO] - Training step 37920 loss 0.014571240171790123
[2025-03-13 14:36:45,991][model][INFO] - Training step 38080 loss 0.004750413820147514
[2025-03-13 14:37:49,106][model][INFO] - Training step 38240 loss 0.05431375280022621
[2025-03-13 14:38:51,532][model][INFO] - Training step 38400 loss 0.024124450981616974
[2025-03-13 14:39:51,947][model][INFO] - Training step 38560 loss 0.006372850388288498
[2025-03-13 14:40:55,304][model][INFO] - Training step 38720 loss 0.0503457710146904
[2025-03-13 14:41:58,247][model][INFO] - Training step 38880 loss 0.04009091854095459
[2025-03-13 14:43:00,542][model][INFO] - Training step 39040 loss 0.015789862722158432
[2025-03-13 14:44:01,329][model][INFO] - Training step 39200 loss 0.18809302151203156
[2025-03-13 14:45:01,135][model][INFO] - Training step 39360 loss 0.027269981801509857
[2025-03-13 14:46:02,514][model][INFO] - Training step 39520 loss 0.25780075788497925
[2025-03-13 14:47:03,101][model][INFO] - Training step 39680 loss 0.05707067251205444
[2025-03-13 14:48:07,231][model][INFO] - Training step 39840 loss 0.03600938990712166
[2025-03-13 14:49:09,133][model][INFO] - Training step 40000 loss 0.032067641615867615
[2025-03-13 14:50:12,885][model][INFO] - Training step 40160 loss 0.13163602352142334
[2025-03-13 14:51:16,267][model][INFO] - Training step 40320 loss 0.026577945798635483
[2025-03-13 14:52:19,916][model][INFO] - Training step 40480 loss 0.24693506956100464
[2025-03-13 14:53:22,197][model][INFO] - Training step 40640 loss 0.061149366199970245
[2025-03-13 14:54:22,794][model][INFO] - Training step 40800 loss 0.01104893907904625
[2025-03-13 14:55:21,539][model][INFO] - Training step 40960 loss 0.24749299883842468
[2025-03-13 14:56:24,152][model][INFO] - Training step 41120 loss 0.011717701330780983
[2025-03-13 14:57:26,716][model][INFO] - Training step 41280 loss 0.035900093615055084
[2025-03-13 14:58:27,705][model][INFO] - Training step 41440 loss 0.24712404608726501
[2025-03-13 14:59:30,544][model][INFO] - Training step 41600 loss 0.024734867736697197
[2025-03-13 15:00:35,217][model][INFO] - Training step 41760 loss 0.039102040231227875
[2025-03-13 15:01:38,151][model][INFO] - Training step 41920 loss 0.0059443190693855286
[2025-03-13 15:02:41,593][model][INFO] - Training step 42080 loss 0.2685515880584717
[2025-03-13 15:03:42,374][model][INFO] - Training step 42240 loss 0.258974552154541
[2025-03-13 15:04:43,954][model][INFO] - Training step 42400 loss 0.04652661830186844
[2025-03-13 15:05:44,261][model][INFO] - Training step 42560 loss 0.02019987627863884
[2025-03-13 15:06:46,123][model][INFO] - Training step 42720 loss 0.2634241580963135
[2025-03-13 15:07:48,541][model][INFO] - Training step 42880 loss 0.06875178217887878
[2025-03-13 15:08:51,791][model][INFO] - Training step 43040 loss 0.030618488788604736
[2025-03-13 15:09:52,398][model][INFO] - Training step 43200 loss 0.03676288574934006
[2025-03-13 15:10:55,220][model][INFO] - Training step 43360 loss 0.2506946921348572
[2025-03-13 15:11:56,988][model][INFO] - Training step 43520 loss 0.17830204963684082
[2025-03-13 15:12:57,567][model][INFO] - Training step 43680 loss 0.01918431743979454
[2025-03-13 15:14:00,901][model][INFO] - Training step 43840 loss 0.02797962911427021
[2025-03-13 15:15:04,278][model][INFO] - Training step 44000 loss 0.026946891099214554
[2025-03-13 15:16:08,070][model][INFO] - Training step 44160 loss 0.0419204942882061
[2025-03-13 15:17:10,351][model][INFO] - Training step 44320 loss 0.017874430865049362
[2025-03-13 15:18:12,266][model][INFO] - Training step 44480 loss 0.014942302368581295
[2025-03-13 15:19:12,870][model][INFO] - Training step 44640 loss 0.06090332567691803
[2025-03-13 15:20:14,807][model][INFO] - Training step 44800 loss 0.256732702255249
[2025-03-13 15:21:16,831][model][INFO] - Training step 44960 loss 0.034714434295892715
[2025-03-13 15:22:19,255][model][INFO] - Training step 45120 loss 0.006377729121595621
[2025-03-13 15:23:23,272][model][INFO] - Training step 45280 loss 0.029457762837409973
[2025-03-13 15:24:28,066][model][INFO] - Training step 45440 loss 0.010677341371774673
[2025-03-13 15:25:29,769][model][INFO] - Training step 45600 loss 0.024168141186237335
[2025-03-13 15:26:34,146][model][INFO] - Training step 45760 loss 0.044784508645534515
[2025-03-13 15:27:38,576][model][INFO] - Training step 45920 loss 0.03275076299905777
[2025-03-13 15:28:43,420][model][INFO] - Training step 46080 loss 0.055112965404987335
[2025-03-13 15:29:44,808][model][INFO] - Training step 46240 loss 0.021989939734339714
[2025-03-13 15:30:45,994][model][INFO] - Training step 46400 loss 0.010105108842253685
[2025-03-13 15:31:46,623][model][INFO] - Training step 46560 loss 0.02551916241645813
[2025-03-13 15:32:47,476][model][INFO] - Training step 46720 loss 0.0245674941688776
[2025-03-13 15:33:49,055][model][INFO] - Training step 46880 loss 0.023125778883695602
[2025-03-13 15:34:52,064][model][INFO] - Training step 47040 loss 0.20732253789901733
[2025-03-13 15:35:55,930][model][INFO] - Training step 47200 loss 0.25991562008857727
[2025-03-13 15:36:58,507][model][INFO] - Training step 47360 loss 0.05299133434891701
[2025-03-13 15:38:00,772][model][INFO] - Training step 47520 loss 0.10062462836503983
[2025-03-13 15:39:03,778][model][INFO] - Training step 47680 loss 0.027297429740428925
[2025-03-13 15:40:07,033][model][INFO] - Training step 47840 loss 0.043878860771656036
[2025-03-13 15:41:08,859][model][INFO] - Training step 48000 loss 0.04289744794368744
[2025-03-13 15:42:11,241][model][INFO] - Training step 48160 loss 0.08256657421588898
[2025-03-13 15:43:13,315][model][INFO] - Training step 48320 loss 0.019512884318828583
[2025-03-13 15:44:12,884][model][INFO] - Training step 48480 loss 0.24768899381160736
[2025-03-13 15:45:12,763][model][INFO] - Training step 48640 loss 0.022735532373189926
[2025-03-13 15:46:17,607][model][INFO] - Training step 48800 loss 0.028054267168045044
[2025-03-13 15:47:19,115][model][INFO] - Training step 48960 loss 0.013132378458976746
[2025-03-13 15:48:21,856][model][INFO] - Training step 49120 loss 0.02302182838320732
[2025-03-13 15:49:25,042][model][INFO] - Training step 49280 loss 0.0802626833319664
[2025-03-13 15:50:26,717][model][INFO] - Training step 49440 loss 0.025284357368946075
[2025-03-13 15:51:28,381][model][INFO] - Training step 49600 loss 0.027992313727736473
[2025-03-13 15:52:34,151][model][INFO] - Training step 49760 loss 0.011358090676367283
[2025-03-13 15:53:35,630][model][INFO] - Training step 49920 loss 0.01290840096771717
[2025-03-13 15:54:39,495][model][INFO] - Training step 50080 loss 0.006668830756098032
[2025-03-13 15:55:40,397][model][INFO] - Training step 50240 loss 0.011327048763632774
[2025-03-13 15:56:41,004][model][INFO] - Training step 50400 loss 0.04543272405862808
[2025-03-13 15:57:42,978][model][INFO] - Training step 50560 loss 0.014288600534200668
[2025-03-13 15:58:45,199][model][INFO] - Training step 50720 loss 0.02063293755054474
[2025-03-13 16:07:40,806][model][INFO] - Training step 80 loss 0.07325372099876404
[2025-03-13 16:08:45,336][model][INFO] - Training step 240 loss 0.03201567754149437
[2025-03-13 16:09:46,709][model][INFO] - Training step 400 loss 0.20433573424816132
[2025-03-13 16:10:47,570][model][INFO] - Training step 560 loss 0.25703752040863037
[2025-03-13 16:11:49,756][model][INFO] - Training step 720 loss 0.003005308797582984
[2025-03-13 16:12:51,266][model][INFO] - Training step 880 loss 0.03063354454934597
[2025-03-13 16:13:51,477][model][INFO] - Training step 1040 loss 0.015627067536115646
[2025-03-13 16:14:57,306][model][INFO] - Training step 1200 loss 0.44532227516174316
[2025-03-13 16:16:02,713][model][INFO] - Training step 1360 loss 0.006073298864066601
[2025-03-13 16:17:04,546][model][INFO] - Training step 1520 loss 0.04389385133981705
[2025-03-13 16:18:04,636][model][INFO] - Training step 1680 loss 0.02246803045272827
[2025-03-13 16:19:04,815][model][INFO] - Training step 1840 loss 0.006606008391827345
[2025-03-13 16:20:07,722][model][INFO] - Training step 2000 loss 0.0029783849604427814
[2025-03-13 16:21:09,705][model][INFO] - Training step 2160 loss 0.08552464842796326
[2025-03-13 16:22:14,219][model][INFO] - Training step 2320 loss 0.10617154091596603
[2025-03-13 16:23:15,829][model][INFO] - Training step 2480 loss 0.035856686532497406
[2025-03-13 16:24:19,291][model][INFO] - Training step 2640 loss 0.025423884391784668
[2025-03-13 16:25:21,837][model][INFO] - Training step 2800 loss 0.03767884522676468
[2025-03-13 16:26:25,107][model][INFO] - Training step 2960 loss 0.005162789486348629
[2025-03-13 16:27:27,105][model][INFO] - Training step 3120 loss 0.003035535104572773
[2025-03-13 16:28:28,525][model][INFO] - Training step 3280 loss 0.026452843099832535
[2025-03-13 16:29:31,421][model][INFO] - Training step 3440 loss 0.23739010095596313
[2025-03-13 16:30:33,905][model][INFO] - Training step 3600 loss 0.05108500272035599
[2025-03-13 16:31:36,748][model][INFO] - Training step 3760 loss 0.029494918882846832
[2025-03-13 16:32:39,077][model][INFO] - Training step 3920 loss 0.011995116248726845
[2025-03-13 16:33:41,593][model][INFO] - Training step 4080 loss 0.07127580046653748
[2025-03-13 16:34:44,984][model][INFO] - Training step 4240 loss 0.005725494585931301
[2025-03-13 16:35:47,151][model][INFO] - Training step 4400 loss 0.013687677681446075
[2025-03-13 16:36:49,107][model][INFO] - Training step 4560 loss 0.02675558812916279
[2025-03-13 16:37:52,218][model][INFO] - Training step 4720 loss 0.026135632768273354
[2025-03-13 16:38:53,409][model][INFO] - Training step 4880 loss 0.02799462154507637
[2025-03-13 16:39:55,253][model][INFO] - Training step 5040 loss 0.0018933818209916353
[2025-03-13 16:40:56,521][model][INFO] - Training step 5200 loss 0.00557197630405426
[2025-03-13 16:41:58,382][model][INFO] - Training step 5360 loss 0.2540353834629059
[2025-03-13 16:42:59,523][model][INFO] - Training step 5520 loss 0.10221704840660095
[2025-03-13 16:44:00,698][model][INFO] - Training step 5680 loss 0.07016052305698395
[2025-03-13 16:45:02,486][model][INFO] - Training step 5840 loss 0.03371400386095047
[2025-03-13 16:46:05,938][model][INFO] - Training step 6000 loss 0.010039561428129673
[2025-03-13 16:47:06,510][model][INFO] - Training step 6160 loss 0.14675894379615784
[2025-03-13 16:48:08,302][model][INFO] - Training step 6320 loss 0.046325162053108215
[2025-03-13 16:49:12,118][model][INFO] - Training step 6480 loss 0.24921491742134094
[2025-03-13 16:50:13,837][model][INFO] - Training step 6640 loss 0.2686837315559387
[2025-03-13 16:51:15,211][model][INFO] - Training step 6800 loss 0.015509597957134247
[2025-03-13 16:52:17,414][model][INFO] - Training step 6960 loss 0.021301448345184326
[2025-03-13 16:53:19,464][model][INFO] - Training step 7120 loss 0.003679267130792141
[2025-03-13 16:54:20,588][model][INFO] - Training step 7280 loss 0.25417083501815796
[2025-03-13 16:55:22,335][model][INFO] - Training step 7440 loss 0.015524860471487045
[2025-03-13 16:56:24,516][model][INFO] - Training step 7600 loss 0.024281101301312447
[2025-03-13 16:57:26,788][model][INFO] - Training step 7760 loss 0.06548137962818146
[2025-03-13 16:58:28,993][model][INFO] - Training step 7920 loss 0.004224525298923254
[2025-03-13 16:59:30,286][model][INFO] - Training step 8080 loss 0.0365947000682354
[2025-03-13 17:00:31,629][model][INFO] - Training step 8240 loss 0.03430694341659546
[2025-03-13 17:01:33,683][model][INFO] - Training step 8400 loss 0.032222501933574677
[2025-03-13 17:02:35,297][model][INFO] - Training step 8560 loss 0.06004004925489426
[2025-03-13 17:03:37,376][model][INFO] - Training step 8720 loss 0.03365228697657585
[2025-03-13 17:04:42,289][model][INFO] - Training step 8880 loss 0.018639247864484787
[2025-03-13 17:05:43,082][model][INFO] - Training step 9040 loss 0.02354174107313156
[2025-03-13 17:06:44,192][model][INFO] - Training step 9200 loss 0.2591145634651184
[2025-03-13 17:07:45,231][model][INFO] - Training step 9360 loss 0.05597393214702606
[2025-03-13 17:08:48,675][model][INFO] - Training step 9520 loss 0.025214597582817078
[2025-03-13 17:09:51,942][model][INFO] - Training step 9680 loss 0.2241043746471405
[2025-03-13 17:10:57,425][model][INFO] - Training step 9840 loss 0.04261495918035507
[2025-03-13 17:11:58,548][model][INFO] - Training step 10000 loss 0.24951614439487457
[2025-03-13 17:12:59,768][model][INFO] - Training step 10160 loss 0.03286600857973099
[2025-03-13 17:13:59,245][model][INFO] - Training step 10320 loss 0.024307657033205032
[2025-03-13 17:15:01,034][model][INFO] - Training step 10480 loss 0.2507098913192749
[2025-03-13 17:16:04,737][model][INFO] - Training step 10640 loss 0.03929419443011284
[2025-03-13 17:17:06,219][model][INFO] - Training step 10800 loss 0.030620157718658447
[2025-03-13 17:18:09,238][model][INFO] - Training step 10960 loss 0.07554081827402115
[2025-03-13 17:19:10,357][model][INFO] - Training step 11120 loss 0.03145618364214897
[2025-03-13 17:20:12,470][model][INFO] - Training step 11280 loss 0.0299527645111084
[2025-03-13 17:21:13,250][model][INFO] - Training step 11440 loss 0.029827989637851715
[2025-03-13 17:22:16,249][model][INFO] - Training step 11600 loss 0.012406179681420326
[2025-03-13 17:23:18,103][model][INFO] - Training step 11760 loss 0.031767286360263824
[2025-03-13 17:24:16,482][model][INFO] - Training step 11920 loss 0.05595100671052933
[2025-03-13 17:25:19,334][model][INFO] - Training step 12080 loss 0.03475077077746391
[2025-03-13 17:26:20,582][model][INFO] - Training step 12240 loss 0.039664965122938156
[2025-03-13 17:27:20,756][model][INFO] - Training step 12400 loss 0.020949712023139
[2025-03-13 17:28:21,634][model][INFO] - Training step 12560 loss 0.023889753967523575
[2025-03-13 17:29:24,215][model][INFO] - Training step 12720 loss 0.13772347569465637
[2025-03-13 17:30:29,417][model][INFO] - Training step 12880 loss 0.006310813128948212
[2025-03-13 17:31:31,761][model][INFO] - Training step 13040 loss 0.0246170274913311
[2025-03-13 17:32:34,430][model][INFO] - Training step 13200 loss 0.27518653869628906
[2025-03-13 17:33:37,411][model][INFO] - Training step 13360 loss 0.07534927129745483
[2025-03-13 17:34:38,337][model][INFO] - Training step 13520 loss 0.05405173450708389
[2025-03-13 17:35:40,330][model][INFO] - Training step 13680 loss 0.27132999897003174
[2025-03-13 17:36:44,416][model][INFO] - Training step 13840 loss 0.030649865046143532
[2025-03-13 17:37:47,627][model][INFO] - Training step 14000 loss 0.10322833061218262
[2025-03-13 17:38:47,427][model][INFO] - Training step 14160 loss 0.0286614578217268
[2025-03-13 17:39:48,436][model][INFO] - Training step 14320 loss 0.027280133217573166
[2025-03-13 17:40:50,527][model][INFO] - Training step 14480 loss 0.015941090881824493
[2025-03-13 17:41:53,128][model][INFO] - Training step 14640 loss 0.02635199949145317
[2025-03-13 17:42:54,635][model][INFO] - Training step 14800 loss 0.03292451798915863
[2025-03-13 17:43:56,920][model][INFO] - Training step 14960 loss 0.288646399974823
[2025-03-13 17:44:58,199][model][INFO] - Training step 15120 loss 0.034305259585380554
[2025-03-13 17:45:59,167][model][INFO] - Training step 15280 loss 0.003177233040332794
[2025-03-13 17:47:02,414][model][INFO] - Training step 15440 loss 0.021769050508737564
[2025-03-13 17:48:06,018][model][INFO] - Training step 15600 loss 0.12726834416389465
[2025-03-13 17:49:11,216][model][INFO] - Training step 15760 loss 0.027033450081944466
[2025-03-13 17:50:12,202][model][INFO] - Training step 15920 loss 0.03390352800488472
[2025-03-13 17:51:15,539][model][INFO] - Training step 16080 loss 0.0026656165719032288
[2025-03-13 17:52:19,671][model][INFO] - Training step 16240 loss 0.027130067348480225
[2025-03-13 17:53:20,583][model][INFO] - Training step 16400 loss 0.028239980340003967
[2025-03-13 17:54:23,533][model][INFO] - Training step 16560 loss 0.038095660507678986
[2025-03-13 17:55:24,433][model][INFO] - Training step 16720 loss 0.023731572553515434
[2025-03-13 17:56:25,954][model][INFO] - Training step 16880 loss 0.019933100789785385
[2025-03-13 17:57:28,294][model][INFO] - Training step 17040 loss 0.060641221702098846
[2025-03-13 17:58:30,569][model][INFO] - Training step 17200 loss 0.0832831859588623
[2025-03-13 17:59:31,662][model][INFO] - Training step 17360 loss 0.026322729885578156
[2025-03-13 18:00:33,345][model][INFO] - Training step 17520 loss 0.05440675467252731
[2025-03-13 18:01:36,897][model][INFO] - Training step 17680 loss 0.025413934141397476
[2025-03-13 18:02:36,100][model][INFO] - Training step 17840 loss 0.0807666927576065
[2025-03-13 18:03:39,420][model][INFO] - Training step 18000 loss 0.22127649188041687
[2025-03-13 18:04:43,060][model][INFO] - Training step 18160 loss 0.045373350381851196
[2025-03-13 18:05:44,552][model][INFO] - Training step 18320 loss 0.24490880966186523
[2025-03-13 18:06:45,638][model][INFO] - Training step 18480 loss 0.02871832065284252
[2025-03-13 18:07:50,433][model][INFO] - Training step 18640 loss 0.04947780817747116
[2025-03-13 18:08:52,808][model][INFO] - Training step 18800 loss 0.01143610943108797
[2025-03-13 18:09:52,792][model][INFO] - Training step 18960 loss 0.0070672426372766495
[2025-03-13 18:10:54,530][model][INFO] - Training step 19120 loss 0.018582236021757126
[2025-03-13 18:11:56,083][model][INFO] - Training step 19280 loss 0.023242149502038956
[2025-03-13 18:12:56,333][model][INFO] - Training step 19440 loss 0.22918975353240967
[2025-03-13 18:14:00,021][model][INFO] - Training step 19600 loss 0.029119249433279037
[2025-03-13 18:15:03,394][model][INFO] - Training step 19760 loss 0.028091436251997948
[2025-03-13 18:16:05,406][model][INFO] - Training step 19920 loss 0.25900396704673767
[2025-03-13 18:17:08,351][model][INFO] - Training step 20080 loss 0.2576713562011719
[2025-03-13 18:18:11,255][model][INFO] - Training step 20240 loss 0.03247062861919403
[2025-03-13 18:19:16,238][model][INFO] - Training step 20400 loss 0.17101727426052094
[2025-03-13 18:20:17,476][model][INFO] - Training step 20560 loss 0.019764887169003487
[2025-03-13 18:21:20,489][model][INFO] - Training step 20720 loss 0.0030891275964677334
[2025-03-13 18:22:22,837][model][INFO] - Training step 20880 loss 0.02111639268696308
[2025-03-13 18:23:26,081][model][INFO] - Training step 21040 loss 0.029439497739076614
[2025-03-13 18:24:28,434][model][INFO] - Training step 21200 loss 0.03060346096754074
[2025-03-13 18:25:31,289][model][INFO] - Training step 21360 loss 0.04023006558418274
[2025-03-13 18:26:32,992][model][INFO] - Training step 21520 loss 0.00921013206243515
[2025-03-13 18:27:36,086][model][INFO] - Training step 21680 loss 0.07072287052869797
[2025-03-13 18:28:36,550][model][INFO] - Training step 21840 loss 0.019620856270194054
[2025-03-13 18:29:37,535][model][INFO] - Training step 22000 loss 0.04433610290288925
[2025-03-13 18:30:38,941][model][INFO] - Training step 22160 loss 0.07499410212039948
[2025-03-13 18:31:40,570][model][INFO] - Training step 22320 loss 0.005526730790734291
[2025-03-13 18:32:44,382][model][INFO] - Training step 22480 loss 0.011026600375771523
[2025-03-13 18:33:49,409][model][INFO] - Training step 22640 loss 0.011570213362574577
[2025-03-13 18:34:50,777][model][INFO] - Training step 22800 loss 0.24318179488182068
[2025-03-13 18:35:54,620][model][INFO] - Training step 22960 loss 0.0215308777987957
[2025-03-13 18:36:56,182][model][INFO] - Training step 23120 loss 0.034272320568561554
[2025-03-13 18:37:59,263][model][INFO] - Training step 23280 loss 0.2501477599143982
[2025-03-13 18:39:01,273][model][INFO] - Training step 23440 loss 0.030128227546811104
[2025-03-13 18:40:03,476][model][INFO] - Training step 23600 loss 0.3435302674770355
[2025-03-13 18:41:04,580][model][INFO] - Training step 23760 loss 0.03226364403963089
[2025-03-13 18:42:07,362][model][INFO] - Training step 23920 loss 0.028861891478300095
[2025-03-13 18:43:10,719][model][INFO] - Training step 24080 loss 0.006407672539353371
[2025-03-13 18:44:10,797][model][INFO] - Training step 24240 loss 0.028387941420078278
[2025-03-13 18:45:12,550][model][INFO] - Training step 24400 loss 0.02110150456428528
[2025-03-13 18:46:13,792][model][INFO] - Training step 24560 loss 0.24598532915115356
[2025-03-13 18:47:15,582][model][INFO] - Training step 24720 loss 0.25533735752105713
[2025-03-13 18:48:18,005][model][INFO] - Training step 24880 loss 0.25344574451446533
[2025-03-13 18:49:19,859][model][INFO] - Training step 25040 loss 0.03978501260280609
[2025-03-13 18:50:22,301][model][INFO] - Training step 25200 loss 0.09107859432697296
[2025-03-13 18:51:24,099][model][INFO] - Training step 25360 loss 0.25360220670700073
[2025-03-13 18:52:24,497][model][INFO] - Training step 25520 loss 0.03370220959186554
[2025-03-13 18:53:27,909][model][INFO] - Training step 25680 loss 0.014411339536309242
[2025-03-13 18:54:29,404][model][INFO] - Training step 25840 loss 0.04354508966207504
[2025-03-13 18:55:31,309][model][INFO] - Training step 26000 loss 0.061548974364995956
[2025-03-13 18:56:33,518][model][INFO] - Training step 26160 loss 0.024298014119267464
[2025-03-13 18:57:35,585][model][INFO] - Training step 26320 loss 0.07098216563463211
[2025-03-13 18:58:37,397][model][INFO] - Training step 26480 loss 0.04073334485292435
[2025-03-13 18:59:39,439][model][INFO] - Training step 26640 loss 0.034780390560626984
[2025-03-13 19:00:40,739][model][INFO] - Training step 26800 loss 0.012059399858117104
[2025-03-13 19:01:44,875][model][INFO] - Training step 26960 loss 0.004015075974166393
[2025-03-13 19:02:52,763][model][INFO] - Training step 27120 loss 0.03407717123627663
[2025-03-13 19:03:54,306][model][INFO] - Training step 27280 loss 0.2654437720775604
[2025-03-13 19:04:54,444][model][INFO] - Training step 27440 loss 0.03989604488015175
[2025-03-13 19:05:55,472][model][INFO] - Training step 27600 loss 0.10448537021875381
[2025-03-13 19:06:55,865][model][INFO] - Training step 27760 loss 0.028082137927412987
[2025-03-13 19:07:56,066][model][INFO] - Training step 27920 loss 0.013687355443835258
[2025-03-13 19:08:57,033][model][INFO] - Training step 28080 loss 0.00528174452483654
[2025-03-13 19:09:59,675][model][INFO] - Training step 28240 loss 0.1773325502872467
[2025-03-13 19:10:59,918][model][INFO] - Training step 28400 loss 0.14379769563674927
[2025-03-13 19:12:02,197][model][INFO] - Training step 28560 loss 0.023760279640555382
[2025-03-13 19:13:02,221][model][INFO] - Training step 28720 loss 0.08200667053461075
[2025-03-13 19:14:05,222][model][INFO] - Training step 28880 loss 0.0342545285820961
[2025-03-13 19:15:07,742][model][INFO] - Training step 29040 loss 0.00503068370744586
[2025-03-13 19:16:09,648][model][INFO] - Training step 29200 loss 0.08899439871311188
[2025-03-13 19:17:13,412][model][INFO] - Training step 29360 loss 0.028403006494045258
[2025-03-13 19:18:14,527][model][INFO] - Training step 29520 loss 0.0501396544277668
[2025-03-13 19:19:16,449][model][INFO] - Training step 29680 loss 0.03087686002254486
[2025-03-13 19:20:19,226][model][INFO] - Training step 29840 loss 0.0038295758422464132
[2025-03-13 19:21:22,525][model][INFO] - Training step 30000 loss 0.0180092491209507
[2025-03-13 19:22:26,393][model][INFO] - Training step 30160 loss 0.24322357773780823
[2025-03-13 19:23:25,870][model][INFO] - Training step 30320 loss 0.02723611705005169
[2025-03-13 19:24:28,629][model][INFO] - Training step 30480 loss 0.017751000821590424
[2025-03-13 19:25:31,885][model][INFO] - Training step 30640 loss 0.05405344069004059
[2025-03-13 19:26:31,912][model][INFO] - Training step 30800 loss 0.035108860582113266
[2025-03-13 19:27:31,968][model][INFO] - Training step 30960 loss 0.23639672994613647
[2025-03-13 19:28:36,259][model][INFO] - Training step 31120 loss 0.031785644590854645
[2025-03-13 19:29:38,540][model][INFO] - Training step 31280 loss 0.03585682064294815
[2025-03-13 19:30:41,075][model][INFO] - Training step 31440 loss 0.040994446724653244
[2025-03-13 19:31:42,294][model][INFO] - Training step 31600 loss 0.025928007438778877
[2025-03-13 19:32:45,770][model][INFO] - Training step 31760 loss 0.10131388902664185
[2025-03-13 19:33:47,590][model][INFO] - Training step 31920 loss 0.03022497147321701
[2025-03-13 19:34:49,744][model][INFO] - Training step 32080 loss 0.010077224113047123
[2025-03-13 19:35:53,244][model][INFO] - Training step 32240 loss 0.0020036345813423395
[2025-03-13 19:36:57,754][model][INFO] - Training step 32400 loss 0.05853836238384247
[2025-03-13 19:37:59,382][model][INFO] - Training step 32560 loss 0.17174270749092102
[2025-03-13 19:39:01,297][model][INFO] - Training step 32720 loss 0.16784533858299255
[2025-03-13 19:40:02,460][model][INFO] - Training step 32880 loss 0.10952942818403244
[2025-03-13 19:41:03,473][model][INFO] - Training step 33040 loss 0.026148991659283638
[2025-03-13 19:42:08,142][model][INFO] - Training step 33200 loss 0.02298986166715622
[2025-03-13 19:43:09,244][model][INFO] - Training step 33360 loss 0.25681382417678833
[2025-03-13 19:44:11,897][model][INFO] - Training step 33520 loss 0.04071417078375816
[2025-03-13 19:45:11,091][model][INFO] - Training step 33680 loss 0.00932544656097889
[2025-03-13 19:46:12,872][model][INFO] - Training step 33840 loss 0.02161838673055172
[2025-03-13 19:47:13,792][model][INFO] - Training step 34000 loss 0.012155607342720032
[2025-03-13 19:48:17,301][model][INFO] - Training step 34160 loss 0.26849764585494995
[2025-03-13 19:49:20,056][model][INFO] - Training step 34320 loss 0.0062075406312942505
[2025-03-13 19:50:23,978][model][INFO] - Training step 34480 loss 0.036288194358348846
[2025-03-13 19:51:25,366][model][INFO] - Training step 34640 loss 0.2051035761833191
[2025-03-13 19:52:27,438][model][INFO] - Training step 34800 loss 0.018521999940276146
[2025-03-13 19:53:31,195][model][INFO] - Training step 34960 loss 0.2540245056152344
[2025-03-13 19:54:33,121][model][INFO] - Training step 35120 loss 0.009257983416318893
[2025-03-13 19:55:34,629][model][INFO] - Training step 35280 loss 0.03552216291427612
[2025-03-13 19:56:36,617][model][INFO] - Training step 35440 loss 0.014682058244943619
[2025-03-13 19:57:39,510][model][INFO] - Training step 35600 loss 0.03761209547519684
[2025-03-13 19:58:40,416][model][INFO] - Training step 35760 loss 0.019685007631778717
[2025-03-13 19:59:40,108][model][INFO] - Training step 35920 loss 0.06998399645090103
[2025-03-13 20:00:43,486][model][INFO] - Training step 36080 loss 0.0353589691221714
[2025-03-13 20:01:45,434][model][INFO] - Training step 36240 loss 0.01726851612329483
[2025-03-13 20:02:46,829][model][INFO] - Training step 36400 loss 0.021368738263845444
[2025-03-13 20:03:50,407][model][INFO] - Training step 36560 loss 0.01741517335176468
[2025-03-13 20:04:52,213][model][INFO] - Training step 36720 loss 0.010460931807756424
[2025-03-13 20:05:56,322][model][INFO] - Training step 36880 loss 0.03182080388069153
[2025-03-13 20:06:58,986][model][INFO] - Training step 37040 loss 0.02172699198126793
[2025-03-13 20:08:00,343][model][INFO] - Training step 37200 loss 0.042187243700027466
[2025-03-13 20:09:03,686][model][INFO] - Training step 37360 loss 0.03161633014678955
[2025-03-13 20:10:06,938][model][INFO] - Training step 37520 loss 0.011039430275559425
[2025-03-13 20:11:09,244][model][INFO] - Training step 37680 loss 0.24186164140701294
[2025-03-13 20:12:10,925][model][INFO] - Training step 37840 loss 0.2672274112701416
[2025-03-13 20:13:11,050][model][INFO] - Training step 38000 loss 0.24982410669326782
[2025-03-13 20:14:14,211][model][INFO] - Training step 38160 loss 0.022917360067367554
[2025-03-13 20:15:14,966][model][INFO] - Training step 38320 loss 0.052483074367046356
[2025-03-13 20:16:19,452][model][INFO] - Training step 38480 loss 0.05991692468523979
[2025-03-13 20:17:19,377][model][INFO] - Training step 38640 loss 0.03589196875691414
[2025-03-13 20:18:21,717][model][INFO] - Training step 38800 loss 0.01173277199268341
[2025-03-13 20:19:23,179][model][INFO] - Training step 38960 loss 0.03371858969330788
[2025-03-13 20:20:23,912][model][INFO] - Training step 39120 loss 0.019495248794555664
[2025-03-13 20:21:25,775][model][INFO] - Training step 39280 loss 0.029384298250079155
[2025-03-13 20:22:29,354][model][INFO] - Training step 39440 loss 0.24794968962669373
[2025-03-13 20:23:31,095][model][INFO] - Training step 39600 loss 0.030240818858146667
[2025-03-13 20:24:33,799][model][INFO] - Training step 39760 loss 0.24633952975273132
[2025-03-13 20:25:36,836][model][INFO] - Training step 39920 loss 0.018760131672024727
[2025-03-13 20:26:39,223][model][INFO] - Training step 40080 loss 0.023678258061408997
[2025-03-13 20:27:42,869][model][INFO] - Training step 40240 loss 0.0257603470236063
[2025-03-13 20:28:46,145][model][INFO] - Training step 40400 loss 0.08133935928344727
[2025-03-13 20:29:49,787][model][INFO] - Training step 40560 loss 0.024929579347372055
[2025-03-13 20:30:52,273][model][INFO] - Training step 40720 loss 0.028700031340122223
[2025-03-13 20:31:55,438][model][INFO] - Training step 40880 loss 0.016282882541418076
[2025-03-13 20:32:54,704][model][INFO] - Training step 41040 loss 0.13525447249412537
[2025-03-13 20:33:56,832][model][INFO] - Training step 41200 loss 0.001946427975781262
[2025-03-13 20:35:00,656][model][INFO] - Training step 41360 loss 0.09304365515708923
[2025-03-13 20:36:01,915][model][INFO] - Training step 41520 loss 0.04038732498884201
[2025-03-13 20:37:03,269][model][INFO] - Training step 41680 loss 0.05554140359163284
[2025-03-13 20:38:07,911][model][INFO] - Training step 41840 loss 0.024540003389120102
[2025-03-13 20:39:11,078][model][INFO] - Training step 42000 loss 0.0434718057513237
[2025-03-13 20:40:14,744][model][INFO] - Training step 42160 loss 0.02599422261118889
[2025-03-13 20:41:16,133][model][INFO] - Training step 42320 loss 0.013882556930184364
[2025-03-13 20:42:17,748][model][INFO] - Training step 42480 loss 0.019617119804024696
[2025-03-13 20:43:19,217][model][INFO] - Training step 42640 loss 0.07239514589309692
[2025-03-13 20:44:22,636][model][INFO] - Training step 42800 loss 0.01744837313890457
[2025-03-13 20:45:24,017][model][INFO] - Training step 42960 loss 0.023089151829481125
[2025-03-13 20:46:24,699][model][INFO] - Training step 43120 loss 0.04073312506079674
[2025-03-13 20:47:25,601][model][INFO] - Training step 43280 loss 0.25095900893211365
[2025-03-13 20:48:31,473][model][INFO] - Training step 43440 loss 0.002916330238804221
[2025-03-13 20:49:31,499][model][INFO] - Training step 43600 loss 0.012122013606131077
[2025-03-13 20:50:34,177][model][INFO] - Training step 43760 loss 0.04522467032074928
[2025-03-13 20:51:34,972][model][INFO] - Training step 43920 loss 0.04708753898739815
[2025-03-13 20:52:37,021][model][INFO] - Training step 44080 loss 0.005850205197930336
[2025-03-13 20:53:38,715][model][INFO] - Training step 44240 loss 0.02330547571182251
[2025-03-13 20:54:41,652][model][INFO] - Training step 44400 loss 0.10769512504339218
[2025-03-13 20:55:41,865][model][INFO] - Training step 44560 loss 0.02557550184428692
[2025-03-13 20:56:42,402][model][INFO] - Training step 44720 loss 0.020387426018714905
[2025-03-13 20:57:44,307][model][INFO] - Training step 44880 loss 0.005504743196070194
[2025-03-13 20:58:46,436][model][INFO] - Training step 45040 loss 0.04132438823580742
[2025-03-13 20:59:48,783][model][INFO] - Training step 45200 loss 0.05228153243660927
[2025-03-13 21:00:52,117][model][INFO] - Training step 45360 loss 0.15918371081352234
[2025-03-13 21:01:51,702][model][INFO] - Training step 45520 loss 0.062185708433389664
[2025-03-13 21:02:56,176][model][INFO] - Training step 45680 loss 0.01030700746923685
[2025-03-13 21:04:00,423][model][INFO] - Training step 45840 loss 0.06407028436660767
[2025-03-13 21:05:01,535][model][INFO] - Training step 46000 loss 0.03710721433162689
[2025-03-13 21:06:02,037][model][INFO] - Training step 46160 loss 0.06943363696336746
[2025-03-13 21:07:05,846][model][INFO] - Training step 46320 loss 0.025058649480342865
[2025-03-13 21:08:08,057][model][INFO] - Training step 46480 loss 0.01361132599413395
[2025-03-13 21:09:08,151][model][INFO] - Training step 46640 loss 0.040017321705818176
[2025-03-13 21:10:08,731][model][INFO] - Training step 46800 loss 0.24202486872673035
[2025-03-13 21:11:10,771][model][INFO] - Training step 46960 loss 0.03182592988014221
[2025-03-13 21:12:11,397][model][INFO] - Training step 47120 loss 0.14224737882614136
[2025-03-13 21:13:11,495][model][INFO] - Training step 47280 loss 0.016716361045837402
[2025-03-13 21:14:13,550][model][INFO] - Training step 47440 loss 0.006668619811534882
[2025-03-13 21:15:17,523][model][INFO] - Training step 47600 loss 0.008082764223217964
[2025-03-13 21:16:21,379][model][INFO] - Training step 47760 loss 0.14283297955989838
[2025-03-13 21:17:21,003][model][INFO] - Training step 47920 loss 0.15224961936473846
[2025-03-13 21:18:22,987][model][INFO] - Training step 48080 loss 0.26079556345939636
[2025-03-13 21:19:23,434][model][INFO] - Training step 48240 loss 0.05199267342686653
[2025-03-13 21:20:24,411][model][INFO] - Training step 48400 loss 0.05152812600135803
[2025-03-13 21:21:26,131][model][INFO] - Training step 48560 loss 0.2511003017425537
[2025-03-13 21:22:29,191][model][INFO] - Training step 48720 loss 0.016699954867362976
[2025-03-13 21:23:30,330][model][INFO] - Training step 48880 loss 0.015755444765090942
[2025-03-13 21:24:31,804][model][INFO] - Training step 49040 loss 0.008264049887657166
[2025-03-13 21:25:36,976][model][INFO] - Training step 49200 loss 0.021464308723807335
[2025-03-13 21:26:40,448][model][INFO] - Training step 49360 loss 0.24065585434436798
[2025-03-13 21:27:41,187][model][INFO] - Training step 49520 loss 0.16141441464424133
[2025-03-13 21:28:41,850][model][INFO] - Training step 49680 loss 0.01162189245223999
[2025-03-13 21:29:43,652][model][INFO] - Training step 49840 loss 0.0035936906933784485
[2025-03-13 21:30:45,352][model][INFO] - Training step 50000 loss 0.0037427181378006935
[2025-03-13 21:31:47,605][model][INFO] - Training step 50160 loss 0.01568441651761532
[2025-03-13 21:32:48,462][model][INFO] - Training step 50320 loss 0.019537480548024178
[2025-03-13 21:33:50,458][model][INFO] - Training step 50480 loss 0.007493294775485992
[2025-03-13 21:34:51,271][model][INFO] - Training step 50640 loss 0.015584303997457027
[2025-03-13 21:43:52,851][model][INFO] - Training step 0 loss 0.005155658349394798
[2025-03-13 21:44:56,096][model][INFO] - Training step 160 loss 0.026759805157780647
[2025-03-13 21:45:58,454][model][INFO] - Training step 320 loss 0.047560423612594604
[2025-03-13 21:47:01,488][model][INFO] - Training step 480 loss 0.02228625677525997
[2025-03-13 21:48:03,276][model][INFO] - Training step 640 loss 0.261752724647522
[2025-03-13 21:49:06,665][model][INFO] - Training step 800 loss 0.0050691901706159115
[2025-03-13 21:50:08,770][model][INFO] - Training step 960 loss 0.016506237909197807
[2025-03-13 21:51:09,475][model][INFO] - Training step 1120 loss 0.046392772346735
[2025-03-13 21:52:11,740][model][INFO] - Training step 1280 loss 0.03351719304919243
[2025-03-13 21:53:12,906][model][INFO] - Training step 1440 loss 0.02803851291537285
[2025-03-13 21:54:15,837][model][INFO] - Training step 1600 loss 0.07593832910060883
[2025-03-13 21:55:17,550][model][INFO] - Training step 1760 loss 0.03822316229343414
[2025-03-13 21:56:17,663][model][INFO] - Training step 1920 loss 0.018978625535964966
[2025-03-13 21:57:23,027][model][INFO] - Training step 2080 loss 0.027070075273513794
[2025-03-13 21:58:23,133][model][INFO] - Training step 2240 loss 0.01689687743782997
[2025-03-13 21:59:25,216][model][INFO] - Training step 2400 loss 0.015331003814935684
[2025-03-13 22:00:25,411][model][INFO] - Training step 2560 loss 0.04016992449760437
[2025-03-13 22:01:26,756][model][INFO] - Training step 2720 loss 0.016992758959531784
[2025-03-13 22:02:29,428][model][INFO] - Training step 2880 loss 0.00585101218894124
[2025-03-13 22:03:32,072][model][INFO] - Training step 3040 loss 0.02223890833556652
[2025-03-13 22:04:34,776][model][INFO] - Training step 3200 loss 0.013910091482102871
[2025-03-13 22:05:37,329][model][INFO] - Training step 3360 loss 0.07780572772026062
[2025-03-13 22:06:40,162][model][INFO] - Training step 3520 loss 0.06012188643217087
[2025-03-13 22:07:44,617][model][INFO] - Training step 3680 loss 0.02471613697707653
[2025-03-13 22:08:45,944][model][INFO] - Training step 3840 loss 0.026332657784223557
[2025-03-13 22:09:48,388][model][INFO] - Training step 4000 loss 0.03884819149971008
[2025-03-13 22:10:50,556][model][INFO] - Training step 4160 loss 0.021029885858297348
[2025-03-13 22:11:51,060][model][INFO] - Training step 4320 loss 0.24974077939987183
[2025-03-13 22:12:52,264][model][INFO] - Training step 4480 loss 0.026253793388605118
[2025-03-13 22:13:55,072][model][INFO] - Training step 4640 loss 0.00175489392131567
[2025-03-13 22:14:55,808][model][INFO] - Training step 4800 loss 0.39272841811180115
[2025-03-13 22:15:56,328][model][INFO] - Training step 4960 loss 0.01592734456062317
[2025-03-13 22:16:59,204][model][INFO] - Training step 5120 loss 0.15636815130710602
[2025-03-13 22:18:01,851][model][INFO] - Training step 5280 loss 0.007328486070036888
[2025-03-13 22:19:04,368][model][INFO] - Training step 5440 loss 0.25100216269493103
[2025-03-13 22:20:05,402][model][INFO] - Training step 5600 loss 0.02052396535873413
[2025-03-13 22:21:08,475][model][INFO] - Training step 5760 loss 0.28072863817214966
[2025-03-13 22:22:12,122][model][INFO] - Training step 5920 loss 0.027561470866203308
[2025-03-13 22:23:12,666][model][INFO] - Training step 6080 loss 0.02127695642411709
[2025-03-13 22:24:14,996][model][INFO] - Training step 6240 loss 0.03963571786880493
[2025-03-13 22:25:21,613][model][INFO] - Training step 6400 loss 0.023740913718938828
[2025-03-13 22:26:25,868][model][INFO] - Training step 6560 loss 0.009162787348031998
[2025-03-13 22:27:27,188][model][INFO] - Training step 6720 loss 0.26318174600601196
[2025-03-13 22:28:28,727][model][INFO] - Training step 6880 loss 0.08699192106723785
[2025-03-13 22:29:32,047][model][INFO] - Training step 7040 loss 0.018905064091086388
[2025-03-13 22:30:36,136][model][INFO] - Training step 7200 loss 0.016568657010793686
[2025-03-13 22:31:41,129][model][INFO] - Training step 7360 loss 0.024761175736784935
[2025-03-13 22:32:42,473][model][INFO] - Training step 7520 loss 0.03970400243997574
[2025-03-13 22:33:43,976][model][INFO] - Training step 7680 loss 0.2472802698612213
[2025-03-13 22:34:47,186][model][INFO] - Training step 7840 loss 0.031623996794223785
[2025-03-13 22:35:49,536][model][INFO] - Training step 8000 loss 0.23815980553627014
[2025-03-13 22:36:52,555][model][INFO] - Training step 8160 loss 0.034012533724308014
[2025-03-13 22:37:55,949][model][INFO] - Training step 8320 loss 0.0299653559923172
[2025-03-13 22:38:58,915][model][INFO] - Training step 8480 loss 0.06197533756494522
[2025-03-13 22:40:00,162][model][INFO] - Training step 8640 loss 0.11717808246612549
[2025-03-13 22:41:01,880][model][INFO] - Training step 8800 loss 0.021238932386040688
[2025-03-13 22:42:01,623][model][INFO] - Training step 8960 loss 0.3232857286930084
[2025-03-13 22:43:02,855][model][INFO] - Training step 9120 loss 0.03242858499288559
[2025-03-13 22:44:05,570][model][INFO] - Training step 9280 loss 0.028234362602233887
[2025-03-13 22:45:06,330][model][INFO] - Training step 9440 loss 0.039145536720752716
[2025-03-13 22:46:08,084][model][INFO] - Training step 9600 loss 0.015954436734318733
[2025-03-13 22:47:10,426][model][INFO] - Training step 9760 loss 0.22974024713039398
[2025-03-13 22:48:09,989][model][INFO] - Training step 9920 loss 0.024278786033391953
[2025-03-13 22:49:11,245][model][INFO] - Training step 10080 loss 0.0026760483160614967
[2025-03-13 22:50:13,627][model][INFO] - Training step 10240 loss 0.013998834416270256
[2025-03-13 22:51:16,090][model][INFO] - Training step 10400 loss 0.003161373548209667
[2025-03-13 22:52:19,538][model][INFO] - Training step 10560 loss 0.17618370056152344
[2025-03-13 22:53:20,441][model][INFO] - Training step 10720 loss 0.013174260035157204
[2025-03-13 22:54:22,654][model][INFO] - Training step 10880 loss 0.037932414561510086
[2025-03-13 22:55:23,884][model][INFO] - Training step 11040 loss 0.02463650330901146
[2025-03-13 22:56:24,305][model][INFO] - Training step 11200 loss 0.006807236932218075
[2025-03-13 22:57:24,588][model][INFO] - Training step 11360 loss 0.027243521064519882
[2025-03-13 22:58:27,777][model][INFO] - Training step 11520 loss 0.25794360041618347
[2025-03-13 22:59:30,019][model][INFO] - Training step 11680 loss 0.05466741696000099
[2025-03-13 23:00:33,727][model][INFO] - Training step 11840 loss 0.025636104866862297
[2025-03-13 23:01:34,043][model][INFO] - Training step 12000 loss 0.031203921884298325
[2025-03-13 23:02:37,792][model][INFO] - Training step 12160 loss 0.005236984230577946
[2025-03-13 23:03:38,634][model][INFO] - Training step 12320 loss 0.05561412125825882
[2025-03-13 23:04:39,873][model][INFO] - Training step 12480 loss 0.04502974450588226
[2025-03-13 23:05:42,226][model][INFO] - Training step 12640 loss 0.029217559844255447
[2025-03-13 23:06:43,458][model][INFO] - Training step 12800 loss 0.04826081916689873
[2025-03-13 23:07:46,556][model][INFO] - Training step 12960 loss 0.026889968663454056
[2025-03-13 23:08:51,228][model][INFO] - Training step 13120 loss 0.007932043634355068
[2025-03-13 23:09:52,441][model][INFO] - Training step 13280 loss 0.019899185746908188
[2025-03-13 23:10:52,464][model][INFO] - Training step 13440 loss 0.5204733610153198
[2025-03-13 23:11:55,557][model][INFO] - Training step 13600 loss 0.014464620500802994
[2025-03-13 23:12:58,446][model][INFO] - Training step 13760 loss 0.029713362455368042
[2025-03-13 23:14:00,554][model][INFO] - Training step 13920 loss 0.05027158558368683
[2025-03-13 23:15:01,024][model][INFO] - Training step 14080 loss 0.016213396564126015
[2025-03-13 23:16:02,500][model][INFO] - Training step 14240 loss 0.0077125923708081245
[2025-03-13 23:17:04,380][model][INFO] - Training step 14400 loss 0.008464283309876919
[2025-03-13 23:18:05,820][model][INFO] - Training step 14560 loss 0.25334641337394714
[2025-03-13 23:19:06,681][model][INFO] - Training step 14720 loss 0.016964007169008255
[2025-03-13 23:20:09,051][model][INFO] - Training step 14880 loss 0.09669259190559387
[2025-03-13 23:21:10,434][model][INFO] - Training step 15040 loss 0.037503428757190704
[2025-03-13 23:22:14,111][model][INFO] - Training step 15200 loss 0.026103831827640533
[2025-03-13 23:23:17,566][model][INFO] - Training step 15360 loss 0.04641351476311684
[2025-03-13 23:24:19,785][model][INFO] - Training step 15520 loss 0.027169905602931976
[2025-03-13 23:25:22,244][model][INFO] - Training step 15680 loss 0.02697371318936348
[2025-03-13 23:26:24,780][model][INFO] - Training step 15840 loss 0.24724918603897095
[2025-03-13 23:27:26,332][model][INFO] - Training step 16000 loss 0.005668218247592449
[2025-03-13 23:28:29,038][model][INFO] - Training step 16160 loss 0.025698969140648842
[2025-03-13 23:29:32,951][model][INFO] - Training step 16320 loss 0.034443825483322144
[2025-03-13 23:30:34,643][model][INFO] - Training step 16480 loss 0.01875380054116249
[2025-03-13 23:31:36,804][model][INFO] - Training step 16640 loss 0.3792515993118286
[2025-03-13 23:32:38,761][model][INFO] - Training step 16800 loss 0.051981255412101746
[2025-03-13 23:33:42,851][model][INFO] - Training step 16960 loss 0.026961350813508034
[2025-03-13 23:34:44,209][model][INFO] - Training step 17120 loss 0.2574203610420227
[2025-03-13 23:35:48,224][model][INFO] - Training step 17280 loss 0.622385561466217
[2025-03-13 23:36:51,291][model][INFO] - Training step 17440 loss 0.004984310362488031
[2025-03-13 23:37:54,524][model][INFO] - Training step 17600 loss 0.27101296186447144
[2025-03-13 23:38:57,839][model][INFO] - Training step 17760 loss 0.0803900808095932
[2025-03-13 23:39:58,362][model][INFO] - Training step 17920 loss 0.1545315384864807
[2025-03-13 23:41:01,464][model][INFO] - Training step 18080 loss 0.04278137534856796
[2025-03-13 23:42:03,058][model][INFO] - Training step 18240 loss 0.03281755745410919
[2025-03-13 23:43:05,769][model][INFO] - Training step 18400 loss 0.028834030032157898
[2025-03-13 23:44:07,279][model][INFO] - Training step 18560 loss 0.07184843719005585
[2025-03-13 23:45:07,131][model][INFO] - Training step 18720 loss 0.04545088857412338
[2025-03-13 23:46:08,475][model][INFO] - Training step 18880 loss 0.06851164996623993
[2025-03-13 23:47:10,489][model][INFO] - Training step 19040 loss 0.002094229916110635
[2025-03-13 23:48:12,773][model][INFO] - Training step 19200 loss 0.13874061405658722
[2025-03-13 23:49:12,333][model][INFO] - Training step 19360 loss 0.005092109087854624
[2025-03-13 23:50:14,439][model][INFO] - Training step 19520 loss 0.08941292762756348
[2025-03-13 23:51:17,805][model][INFO] - Training step 19680 loss 0.10338494181632996
[2025-03-13 23:52:19,754][model][INFO] - Training step 19840 loss 0.051768869161605835
[2025-03-13 23:53:20,815][model][INFO] - Training step 20000 loss 0.036538586020469666
[2025-03-13 23:54:23,030][model][INFO] - Training step 20160 loss 0.022916274145245552
[2025-03-13 23:55:24,470][model][INFO] - Training step 20320 loss 0.045564331114292145
[2025-03-13 23:56:23,869][model][INFO] - Training step 20480 loss 0.25516071915626526
[2025-03-13 23:57:24,173][model][INFO] - Training step 20640 loss 0.021894365549087524
[2025-03-13 23:58:28,030][model][INFO] - Training step 20800 loss 0.24742043018341064
[2025-03-13 23:59:31,646][model][INFO] - Training step 20960 loss 0.01892259158194065
[2025-03-14 00:00:35,675][model][INFO] - Training step 21120 loss 0.10328887403011322
[2025-03-14 00:01:40,278][model][INFO] - Training step 21280 loss 0.09609876573085785
[2025-03-14 00:02:42,945][model][INFO] - Training step 21440 loss 0.017047788947820663
[2025-03-14 00:03:45,165][model][INFO] - Training step 21600 loss 0.03168340399861336
[2025-03-14 00:04:45,650][model][INFO] - Training step 21760 loss 0.252971351146698
[2025-03-14 00:05:45,598][model][INFO] - Training step 21920 loss 0.25092828273773193
[2025-03-14 00:06:47,468][model][INFO] - Training step 22080 loss 0.05596889555454254
[2025-03-14 00:07:49,768][model][INFO] - Training step 22240 loss 0.007490423507988453
[2025-03-14 00:08:53,398][model][INFO] - Training step 22400 loss 0.24547244608402252
[2025-03-14 00:09:54,912][model][INFO] - Training step 22560 loss 0.025227388367056847
[2025-03-14 00:10:56,068][model][INFO] - Training step 22720 loss 0.04263535887002945
[2025-03-14 00:11:57,413][model][INFO] - Training step 22880 loss 0.03430218994617462
[2025-03-14 00:13:00,978][model][INFO] - Training step 23040 loss 0.005735489539802074
[2025-03-14 00:14:04,559][model][INFO] - Training step 23200 loss 0.0364733561873436
[2025-03-14 00:15:07,141][model][INFO] - Training step 23360 loss 0.032006412744522095
[2025-03-14 00:16:10,300][model][INFO] - Training step 23520 loss 0.06866012513637543
[2025-03-14 00:17:12,082][model][INFO] - Training step 23680 loss 0.07280854880809784
[2025-03-14 00:18:15,180][model][INFO] - Training step 23840 loss 0.019307397305965424
[2025-03-14 00:19:15,934][model][INFO] - Training step 24000 loss 0.025698304176330566
[2025-03-14 00:20:17,241][model][INFO] - Training step 24160 loss 0.02202455699443817
[2025-03-14 00:21:22,284][model][INFO] - Training step 24320 loss 0.03579846769571304
[2025-03-14 00:22:27,409][model][INFO] - Training step 24480 loss 0.008335094898939133
[2025-03-14 00:23:26,158][model][INFO] - Training step 24640 loss 0.18372908234596252
[2025-03-14 00:24:26,673][model][INFO] - Training step 24800 loss 0.1749556064605713
[2025-03-14 00:25:30,071][model][INFO] - Training step 24960 loss 0.012509547173976898
[2025-03-14 00:26:31,731][model][INFO] - Training step 25120 loss 0.25241684913635254
[2025-03-14 00:27:32,520][model][INFO] - Training step 25280 loss 0.25484907627105713
[2025-03-14 00:28:33,482][model][INFO] - Training step 25440 loss 0.23586395382881165
[2025-03-14 00:29:34,795][model][INFO] - Training step 25600 loss 0.24687239527702332
[2025-03-14 00:30:34,307][model][INFO] - Training step 25760 loss 0.01962260901927948
[2025-03-14 00:31:37,931][model][INFO] - Training step 25920 loss 0.17569971084594727
[2025-03-14 00:32:39,704][model][INFO] - Training step 26080 loss 0.007361047901213169
[2025-03-14 00:33:43,793][model][INFO] - Training step 26240 loss 0.06994397938251495
[2025-03-14 00:34:47,406][model][INFO] - Training step 26400 loss 0.023975927382707596
[2025-03-14 00:35:52,030][model][INFO] - Training step 26560 loss 0.02070847526192665
[2025-03-14 00:36:54,796][model][INFO] - Training step 26720 loss 0.018621105700731277
[2025-03-14 00:37:56,437][model][INFO] - Training step 26880 loss 0.02680295705795288
[2025-03-14 00:38:57,808][model][INFO] - Training step 27040 loss 0.25442197918891907
[2025-03-14 00:39:59,372][model][INFO] - Training step 27200 loss 0.016317171975970268
[2025-03-14 00:41:00,452][model][INFO] - Training step 27360 loss 0.03504923731088638
[2025-03-14 00:42:04,835][model][INFO] - Training step 27520 loss 0.11850506067276001
[2025-03-14 00:43:05,672][model][INFO] - Training step 27680 loss 0.020694442093372345
[2025-03-14 00:44:08,170][model][INFO] - Training step 27840 loss 0.022244509309530258
[2025-03-14 00:45:11,584][model][INFO] - Training step 28000 loss 0.005083472467958927
[2025-03-14 00:46:15,252][model][INFO] - Training step 28160 loss 0.0030320228543132544
[2025-03-14 00:47:16,407][model][INFO] - Training step 28320 loss 0.018025342375040054
[2025-03-14 00:48:18,929][model][INFO] - Training step 28480 loss 0.14836826920509338
[2025-03-14 00:49:19,852][model][INFO] - Training step 28640 loss 0.03191031515598297
[2025-03-14 00:50:21,706][model][INFO] - Training step 28800 loss 0.03526299446821213
[2025-03-14 00:51:25,281][model][INFO] - Training step 28960 loss 0.12664543092250824
[2025-03-14 00:52:27,896][model][INFO] - Training step 29120 loss 0.24811780452728271
[2025-03-14 00:53:30,337][model][INFO] - Training step 29280 loss 0.003941862843930721
[2025-03-14 00:54:30,218][model][INFO] - Training step 29440 loss 0.018489962443709373
[2025-03-14 00:55:31,735][model][INFO] - Training step 29600 loss 0.006890806369483471
[2025-03-14 00:56:36,219][model][INFO] - Training step 29760 loss 0.16921362280845642
[2025-03-14 00:57:35,846][model][INFO] - Training step 29920 loss 0.23929910361766815
[2025-03-14 00:58:41,155][model][INFO] - Training step 30080 loss 0.02329418435692787
[2025-03-14 00:59:43,956][model][INFO] - Training step 30240 loss 0.24314814805984497
[2025-03-14 01:00:45,849][model][INFO] - Training step 30400 loss 0.03419075906276703
[2025-03-14 01:01:46,985][model][INFO] - Training step 30560 loss 0.018672838807106018
[2025-03-14 01:02:45,631][model][INFO] - Training step 30720 loss 0.06523486971855164
[2025-03-14 01:03:45,259][model][INFO] - Training step 30880 loss 0.005661844741553068
[2025-03-14 01:04:45,931][model][INFO] - Training step 31040 loss 0.05710281804203987
[2025-03-14 01:05:48,733][model][INFO] - Training step 31200 loss 0.08835554122924805
[2025-03-14 01:06:48,647][model][INFO] - Training step 31360 loss 0.02422293648123741
[2025-03-14 01:07:49,699][model][INFO] - Training step 31520 loss 0.05543971061706543
[2025-03-14 01:08:51,655][model][INFO] - Training step 31680 loss 0.02367427758872509
[2025-03-14 01:09:53,175][model][INFO] - Training step 31840 loss 0.003442671848461032
[2025-03-14 01:10:56,202][model][INFO] - Training step 32000 loss 0.02666407637298107
[2025-03-14 01:11:57,258][model][INFO] - Training step 32160 loss 0.0300455205142498
[2025-03-14 01:12:59,569][model][INFO] - Training step 32320 loss 0.05380476266145706
[2025-03-14 01:14:01,174][model][INFO] - Training step 32480 loss 0.023358529433608055
[2025-03-14 01:15:03,126][model][INFO] - Training step 32640 loss 0.030419833958148956
[2025-03-14 01:16:07,677][model][INFO] - Training step 32800 loss 0.2491651177406311
[2025-03-14 01:17:13,744][model][INFO] - Training step 32960 loss 0.002013768767938018
[2025-03-14 01:18:15,248][model][INFO] - Training step 33120 loss 0.02415541373193264
[2025-03-14 01:19:17,275][model][INFO] - Training step 33280 loss 0.003338688053190708
[2025-03-14 01:20:19,510][model][INFO] - Training step 33440 loss 0.0019101772923022509
[2025-03-14 01:21:22,512][model][INFO] - Training step 33600 loss 0.04255149886012077
[2025-03-14 01:22:25,519][model][INFO] - Training step 33760 loss 0.04052434116601944
[2025-03-14 01:23:28,581][model][INFO] - Training step 33920 loss 0.022166546434164047
[2025-03-14 01:24:29,387][model][INFO] - Training step 34080 loss 0.016759619116783142
[2025-03-14 01:25:31,083][model][INFO] - Training step 34240 loss 0.09561200439929962
[2025-03-14 01:26:35,800][model][INFO] - Training step 34400 loss 0.026469185948371887
[2025-03-14 01:27:39,030][model][INFO] - Training step 34560 loss 0.030451592057943344
[2025-03-14 01:28:41,326][model][INFO] - Training step 34720 loss 0.033611495047807693
[2025-03-14 01:29:43,561][model][INFO] - Training step 34880 loss 0.006952829658985138
[2025-03-14 01:30:48,774][model][INFO] - Training step 35040 loss 0.0056259166449308395
[2025-03-14 01:31:52,131][model][INFO] - Training step 35200 loss 0.006204936653375626
[2025-03-14 01:32:52,842][model][INFO] - Training step 35360 loss 0.2513267695903778
[2025-03-14 01:33:55,315][model][INFO] - Training step 35520 loss 0.0052885329350829124
[2025-03-14 01:34:55,809][model][INFO] - Training step 35680 loss 0.04438632354140282
[2025-03-14 01:35:58,296][model][INFO] - Training step 35840 loss 0.02851846069097519
[2025-03-14 01:36:59,936][model][INFO] - Training step 36000 loss 0.24891066551208496
[2025-03-14 01:38:01,715][model][INFO] - Training step 36160 loss 0.07067049294710159
[2025-03-14 01:39:04,650][model][INFO] - Training step 36320 loss 0.017357461154460907
[2025-03-14 01:40:05,688][model][INFO] - Training step 36480 loss 0.0046378327533602715
[2025-03-14 01:41:08,041][model][INFO] - Training step 36640 loss 0.23854613304138184
[2025-03-14 01:42:08,821][model][INFO] - Training step 36800 loss 0.06254018843173981
[2025-03-14 01:43:12,717][model][INFO] - Training step 36960 loss 0.017866969108581543
[2025-03-14 01:44:16,431][model][INFO] - Training step 37120 loss 0.02058410458266735
[2025-03-14 01:45:19,437][model][INFO] - Training step 37280 loss 0.02340528927743435
[2025-03-14 01:46:20,463][model][INFO] - Training step 37440 loss 0.07063028216362
[2025-03-14 01:47:22,740][model][INFO] - Training step 37600 loss 0.005102291237562895
[2025-03-14 01:48:22,888][model][INFO] - Training step 37760 loss 0.04696960747241974
[2025-03-14 01:49:25,004][model][INFO] - Training step 37920 loss 0.015451408922672272
[2025-03-14 01:50:26,663][model][INFO] - Training step 38080 loss 0.2546312212944031
[2025-03-14 01:51:30,977][model][INFO] - Training step 38240 loss 0.020705174654722214
[2025-03-14 01:52:31,450][model][INFO] - Training step 38400 loss 0.1553465574979782
[2025-03-14 01:53:31,164][model][INFO] - Training step 38560 loss 0.255939781665802
[2025-03-14 01:54:33,486][model][INFO] - Training step 38720 loss 0.03146857023239136
[2025-03-14 01:55:32,736][model][INFO] - Training step 38880 loss 0.001956910826265812
[2025-03-14 01:56:36,024][model][INFO] - Training step 39040 loss 0.01899000257253647
[2025-03-14 01:57:37,635][model][INFO] - Training step 39200 loss 0.006760797463357449
[2025-03-14 01:58:41,619][model][INFO] - Training step 39360 loss 0.2564642131328583
[2025-03-14 01:59:44,023][model][INFO] - Training step 39520 loss 0.024262133985757828
[2025-03-14 02:00:46,215][model][INFO] - Training step 39680 loss 0.027476344257593155
[2025-03-14 02:01:48,428][model][INFO] - Training step 39840 loss 0.2480311095714569
[2025-03-14 02:02:50,119][model][INFO] - Training step 40000 loss 0.022455640137195587
[2025-03-14 02:03:52,893][model][INFO] - Training step 40160 loss 0.2572811543941498
[2025-03-14 02:04:56,086][model][INFO] - Training step 40320 loss 0.031932055950164795
[2025-03-14 02:05:59,301][model][INFO] - Training step 40480 loss 0.03342311829328537
[2025-03-14 02:07:02,147][model][INFO] - Training step 40640 loss 0.0876486748456955
[2025-03-14 02:08:02,381][model][INFO] - Training step 40800 loss 0.01355380192399025
[2025-03-14 02:09:02,874][model][INFO] - Training step 40960 loss 0.2564214766025543
[2025-03-14 02:10:04,558][model][INFO] - Training step 41120 loss 0.010921789333224297
[2025-03-14 02:11:09,151][model][INFO] - Training step 41280 loss 0.2507116496562958
[2025-03-14 02:12:09,964][model][INFO] - Training step 41440 loss 0.04267776012420654
[2025-03-14 02:13:11,583][model][INFO] - Training step 41600 loss 0.24833068251609802
[2025-03-14 02:14:12,898][model][INFO] - Training step 41760 loss 0.25479814410209656
[2025-03-14 02:15:16,636][model][INFO] - Training step 41920 loss 0.02316560596227646
[2025-03-14 02:16:18,701][model][INFO] - Training step 42080 loss 0.007848291657865047
[2025-03-14 02:17:19,371][model][INFO] - Training step 42240 loss 0.005052206572145224
[2025-03-14 02:18:19,824][model][INFO] - Training step 42400 loss 0.25678586959838867
[2025-03-14 02:19:23,246][model][INFO] - Training step 42560 loss 0.26801612973213196
[2025-03-14 02:20:25,326][model][INFO] - Training step 42720 loss 0.01567065343260765
[2025-03-14 02:21:25,898][model][INFO] - Training step 42880 loss 0.031871896237134933
[2025-03-14 02:22:26,501][model][INFO] - Training step 43040 loss 0.2307569682598114
[2025-03-14 02:23:28,212][model][INFO] - Training step 43200 loss 0.02717679738998413
[2025-03-14 02:24:29,700][model][INFO] - Training step 43360 loss 0.03756967931985855
[2025-03-14 02:25:31,590][model][INFO] - Training step 43520 loss 0.0578584298491478
[2025-03-14 02:26:34,465][model][INFO] - Training step 43680 loss 0.24552711844444275
[2025-03-14 02:27:36,544][model][INFO] - Training step 43840 loss 0.2624226212501526
[2025-03-14 02:28:38,843][model][INFO] - Training step 44000 loss 0.2525634169578552
[2025-03-14 02:29:44,081][model][INFO] - Training step 44160 loss 0.01058228313922882
[2025-03-14 02:30:46,462][model][INFO] - Training step 44320 loss 0.004917521961033344
[2025-03-14 02:31:49,792][model][INFO] - Training step 44480 loss 0.2544507384300232
[2025-03-14 02:32:52,144][model][INFO] - Training step 44640 loss 0.030923373997211456
[2025-03-14 02:33:55,894][model][INFO] - Training step 44800 loss 0.022314369678497314
[2025-03-14 02:34:55,112][model][INFO] - Training step 44960 loss 0.034811560064554214
[2025-03-14 02:35:55,777][model][INFO] - Training step 45120 loss 0.03435327112674713
[2025-03-14 02:36:56,539][model][INFO] - Training step 45280 loss 0.03941204398870468
[2025-03-14 02:37:59,279][model][INFO] - Training step 45440 loss 0.004403363913297653
[2025-03-14 02:39:02,865][model][INFO] - Training step 45600 loss 0.03125372529029846
[2025-03-14 02:40:07,190][model][INFO] - Training step 45760 loss 0.25918829441070557
[2025-03-14 02:41:06,748][model][INFO] - Training step 45920 loss 0.052804142236709595
[2025-03-14 02:42:08,709][model][INFO] - Training step 46080 loss 0.25102823972702026
[2025-03-14 02:43:08,872][model][INFO] - Training step 46240 loss 0.022132229059934616
[2025-03-14 02:44:17,622][model][INFO] - Training step 46400 loss 0.007650177460163832
[2025-03-14 02:45:19,227][model][INFO] - Training step 46560 loss 0.02852833829820156
[2025-03-14 02:46:22,487][model][INFO] - Training step 46720 loss 0.10892981290817261
[2025-03-14 02:47:23,337][model][INFO] - Training step 46880 loss 0.025511961430311203
[2025-03-14 02:48:23,773][model][INFO] - Training step 47040 loss 0.034076184034347534
[2025-03-14 02:49:26,837][model][INFO] - Training step 47200 loss 0.2647393047809601
[2025-03-14 02:50:26,514][model][INFO] - Training step 47360 loss 0.08393773436546326
[2025-03-14 02:51:27,973][model][INFO] - Training step 47520 loss 0.05372553691267967
[2025-03-14 02:52:30,516][model][INFO] - Training step 47680 loss 0.30748480558395386
[2025-03-14 02:53:32,718][model][INFO] - Training step 47840 loss 0.01867426559329033
[2025-03-14 02:54:34,443][model][INFO] - Training step 48000 loss 0.04343348741531372
[2025-03-14 02:55:35,996][model][INFO] - Training step 48160 loss 0.2556105852127075
[2025-03-14 02:56:36,976][model][INFO] - Training step 48320 loss 0.26449084281921387
[2025-03-14 02:57:40,296][model][INFO] - Training step 48480 loss 0.01694975234568119
[2025-03-14 02:58:40,524][model][INFO] - Training step 48640 loss 0.023863371461629868
[2025-03-14 02:59:42,075][model][INFO] - Training step 48800 loss 0.002403413411229849
[2025-03-14 03:00:42,786][model][INFO] - Training step 48960 loss 0.012970279902219772
[2025-03-14 03:01:46,837][model][INFO] - Training step 49120 loss 0.019865579903125763
[2025-03-14 03:02:48,801][model][INFO] - Training step 49280 loss 0.06539572775363922
[2025-03-14 03:04:01,282][model][INFO] - Training step 49440 loss 0.044257134199142456
[2025-03-14 03:05:05,524][model][INFO] - Training step 49600 loss 0.02591826021671295
[2025-03-14 03:06:08,677][model][INFO] - Training step 49760 loss 0.05353296548128128
[2025-03-14 03:07:10,946][model][INFO] - Training step 49920 loss 0.012617794796824455
[2025-03-14 03:08:13,279][model][INFO] - Training step 50080 loss 0.017708828672766685
[2025-03-14 03:09:15,248][model][INFO] - Training step 50240 loss 0.014401253312826157
[2025-03-14 03:10:16,579][model][INFO] - Training step 50400 loss 0.026507161557674408
[2025-03-14 03:11:18,376][model][INFO] - Training step 50560 loss 0.01824059709906578
[2025-03-14 03:12:19,666][model][INFO] - Training step 50720 loss 0.255695641040802
[2025-03-14 03:21:13,366][model][INFO] - Training step 80 loss 0.007720152847468853
[2025-03-14 03:22:13,762][model][INFO] - Training step 240 loss 0.06365734338760376
[2025-03-14 03:23:16,105][model][INFO] - Training step 400 loss 0.026065398007631302
[2025-03-14 03:24:14,425][model][INFO] - Training step 560 loss 0.023176640272140503
[2025-03-14 03:25:16,377][model][INFO] - Training step 720 loss 0.024191444739699364
[2025-03-14 03:26:19,674][model][INFO] - Training step 880 loss 0.02534920908510685
[2025-03-14 03:27:20,618][model][INFO] - Training step 1040 loss 0.006539246067404747
[2025-03-14 03:28:21,820][model][INFO] - Training step 1200 loss 0.44160977005958557
[2025-03-14 03:29:25,274][model][INFO] - Training step 1360 loss 0.03502766788005829
[2025-03-14 03:30:26,368][model][INFO] - Training step 1520 loss 0.25137022137641907
[2025-03-14 03:31:29,779][model][INFO] - Training step 1680 loss 0.021284060552716255
[2025-03-14 03:32:32,516][model][INFO] - Training step 1840 loss 0.2571241557598114
[2025-03-14 03:33:32,837][model][INFO] - Training step 2000 loss 0.044764310121536255
[2025-03-14 03:34:33,056][model][INFO] - Training step 2160 loss 0.018464388325810432
[2025-03-14 03:35:33,972][model][INFO] - Training step 2320 loss 0.029243864119052887
[2025-03-14 03:36:38,161][model][INFO] - Training step 2480 loss 0.018955491483211517
[2025-03-14 03:37:38,024][model][INFO] - Training step 2640 loss 0.022092150524258614
[2025-03-14 03:38:38,896][model][INFO] - Training step 2800 loss 0.08896862715482712
[2025-03-14 03:39:42,396][model][INFO] - Training step 2960 loss 0.03594845533370972
[2025-03-14 03:40:41,877][model][INFO] - Training step 3120 loss 0.6542672514915466
[2025-03-14 03:41:42,006][model][INFO] - Training step 3280 loss 0.028691746294498444
[2025-03-14 03:42:44,064][model][INFO] - Training step 3440 loss 0.022795837372541428
[2025-03-14 03:43:45,405][model][INFO] - Training step 3600 loss 0.005055613350123167
[2025-03-14 03:44:47,903][model][INFO] - Training step 3760 loss 0.018237385898828506
[2025-03-14 03:45:50,243][model][INFO] - Training step 3920 loss 0.015813661739230156
[2025-03-14 03:46:53,059][model][INFO] - Training step 4080 loss 0.007191496901214123
[2025-03-14 03:47:56,113][model][INFO] - Training step 4240 loss 0.03372076153755188
[2025-03-14 03:48:56,266][model][INFO] - Training step 4400 loss 0.010731607675552368
[2025-03-14 03:49:57,972][model][INFO] - Training step 4560 loss 0.005492816679179668
[2025-03-14 03:51:00,035][model][INFO] - Training step 4720 loss 0.257815420627594
[2025-03-14 03:51:57,965][model][INFO] - Training step 4880 loss 0.014157619327306747
[2025-03-14 03:52:58,817][model][INFO] - Training step 5040 loss 0.2784358561038971
[2025-03-14 03:54:01,300][model][INFO] - Training step 5200 loss 0.03772653266787529
[2025-03-14 03:55:05,347][model][INFO] - Training step 5360 loss 0.24599513411521912
[2025-03-14 03:56:06,360][model][INFO] - Training step 5520 loss 0.2723855674266815
[2025-03-14 03:57:06,274][model][INFO] - Training step 5680 loss 0.0185244120657444
[2025-03-14 03:58:10,431][model][INFO] - Training step 5840 loss 0.006993037648499012
[2025-03-14 03:59:13,004][model][INFO] - Training step 6000 loss 0.005351416766643524
[2025-03-14 04:00:15,260][model][INFO] - Training step 6160 loss 0.021258139982819557
[2025-03-14 04:01:19,451][model][INFO] - Training step 6320 loss 0.2770949602127075
[2025-03-14 04:02:22,084][model][INFO] - Training step 6480 loss 0.0384712815284729
[2025-03-14 04:03:26,424][model][INFO] - Training step 6640 loss 0.006039422005414963
[2025-03-14 04:04:28,494][model][INFO] - Training step 6800 loss 0.018129151314496994
[2025-03-14 04:05:30,954][model][INFO] - Training step 6960 loss 0.023125460371375084
[2025-03-14 04:06:33,656][model][INFO] - Training step 7120 loss 0.005450077820569277
[2025-03-14 04:07:38,748][model][INFO] - Training step 7280 loss 0.025854401290416718
[2025-03-14 04:08:43,713][model][INFO] - Training step 7440 loss 0.022508123889565468
[2025-03-14 04:09:47,766][model][INFO] - Training step 7600 loss 0.053816843777894974
[2025-03-14 04:10:49,047][model][INFO] - Training step 7760 loss 0.005193348973989487
[2025-03-14 04:11:50,854][model][INFO] - Training step 7920 loss 0.2524419128894806
[2025-03-14 04:12:51,395][model][INFO] - Training step 8080 loss 0.0331403985619545
[2025-03-14 04:13:54,585][model][INFO] - Training step 8240 loss 0.03388203680515289
[2025-03-14 04:14:55,707][model][INFO] - Training step 8400 loss 0.06548450887203217
[2025-03-14 04:15:56,202][model][INFO] - Training step 8560 loss 0.029366854578256607
[2025-03-14 04:16:56,954][model][INFO] - Training step 8720 loss 0.021763015538454056
[2025-03-14 04:17:58,412][model][INFO] - Training step 8880 loss 0.26802775263786316
[2025-03-14 04:18:58,237][model][INFO] - Training step 9040 loss 0.023505723103880882
[2025-03-14 04:19:57,406][model][INFO] - Training step 9200 loss 0.019184455275535583
[2025-03-14 04:21:00,172][model][INFO] - Training step 9360 loss 0.09776397049427032
[2025-03-14 04:22:01,215][model][INFO] - Training step 9520 loss 0.014047995209693909
[2025-03-14 04:23:03,831][model][INFO] - Training step 9680 loss 0.09502260386943817
[2025-03-14 04:24:07,915][model][INFO] - Training step 9840 loss 0.057543475180864334
[2025-03-14 04:25:07,194][model][INFO] - Training step 10000 loss 0.24318769574165344
[2025-03-14 04:26:10,717][model][INFO] - Training step 10160 loss 0.0163302980363369
[2025-03-14 04:27:13,197][model][INFO] - Training step 10320 loss 0.015388413332402706
[2025-03-14 04:28:16,842][model][INFO] - Training step 10480 loss 0.00281329033896327
[2025-03-14 04:29:17,070][model][INFO] - Training step 10640 loss 0.005400448106229305
[2025-03-14 04:30:18,943][model][INFO] - Training step 10800 loss 0.10447219014167786
[2025-03-14 04:31:21,379][model][INFO] - Training step 10960 loss 0.0520695298910141
[2025-03-14 04:32:22,627][model][INFO] - Training step 11120 loss 0.030639342963695526
[2025-03-14 04:33:23,078][model][INFO] - Training step 11280 loss 0.02371363714337349
[2025-03-14 04:34:26,727][model][INFO] - Training step 11440 loss 0.26572710275650024
[2025-03-14 04:35:28,018][model][INFO] - Training step 11600 loss 0.012782151810824871
[2025-03-14 04:36:30,068][model][INFO] - Training step 11760 loss 0.04462745413184166
[2025-03-14 04:37:31,253][model][INFO] - Training step 11920 loss 0.0029273140244185925
[2025-03-14 04:38:31,136][model][INFO] - Training step 12080 loss 0.031309422105550766
[2025-03-14 04:39:32,673][model][INFO] - Training step 12240 loss 0.0432458333671093
[2025-03-14 04:40:33,675][model][INFO] - Training step 12400 loss 0.046390268951654434
[2025-03-14 04:41:36,576][model][INFO] - Training step 12560 loss 0.005319785326719284
[2025-03-14 04:42:39,872][model][INFO] - Training step 12720 loss 0.24274340271949768
[2025-03-14 04:43:43,338][model][INFO] - Training step 12880 loss 0.020641691982746124
[2025-03-14 04:44:45,732][model][INFO] - Training step 13040 loss 0.1219392642378807
[2025-03-14 04:45:48,493][model][INFO] - Training step 13200 loss 0.03311567008495331
[2025-03-14 04:46:53,346][model][INFO] - Training step 13360 loss 0.046958811581134796
[2025-03-14 04:47:54,757][model][INFO] - Training step 13520 loss 0.0278363935649395
[2025-03-14 04:48:56,802][model][INFO] - Training step 13680 loss 0.0036834008060395718
[2025-03-14 04:49:58,961][model][INFO] - Training step 13840 loss 0.01930464617908001
[2025-03-14 04:51:00,238][model][INFO] - Training step 14000 loss 0.02719947323203087
[2025-03-14 04:52:00,929][model][INFO] - Training step 14160 loss 0.01987464353442192
[2025-03-14 04:53:03,759][model][INFO] - Training step 14320 loss 0.25368404388427734
[2025-03-14 04:54:05,341][model][INFO] - Training step 14480 loss 0.23970560729503632
[2025-03-14 04:55:08,079][model][INFO] - Training step 14640 loss 0.01625433936715126
[2025-03-14 04:56:09,356][model][INFO] - Training step 14800 loss 0.24234876036643982
[2025-03-14 04:57:12,831][model][INFO] - Training step 14960 loss 0.017319558188319206
[2025-03-14 04:58:15,091][model][INFO] - Training step 15120 loss 0.01513667032122612
[2025-03-14 04:59:15,675][model][INFO] - Training step 15280 loss 0.025827977806329727
[2025-03-14 05:00:17,783][model][INFO] - Training step 15440 loss 0.01290937140583992
[2025-03-14 05:01:18,918][model][INFO] - Training step 15600 loss 0.05160868912935257
[2025-03-14 05:02:22,046][model][INFO] - Training step 15760 loss 0.003189608920365572
[2025-03-14 05:03:22,610][model][INFO] - Training step 15920 loss 0.2560722827911377
[2025-03-14 05:04:23,983][model][INFO] - Training step 16080 loss 0.002300407039001584
[2025-03-14 05:05:24,330][model][INFO] - Training step 16240 loss 0.20923706889152527
[2025-03-14 05:06:24,835][model][INFO] - Training step 16400 loss 0.05481420457363129
[2025-03-14 05:07:28,443][model][INFO] - Training step 16560 loss 0.009828424081206322
[2025-03-14 05:08:30,249][model][INFO] - Training step 16720 loss 0.023438531905412674
[2025-03-14 05:09:30,968][model][INFO] - Training step 16880 loss 0.24567237496376038
[2025-03-14 05:10:32,279][model][INFO] - Training step 17040 loss 0.889549195766449
[2025-03-14 05:11:36,002][model][INFO] - Training step 17200 loss 0.0947333574295044
[2025-03-14 05:12:38,491][model][INFO] - Training step 17360 loss 0.030046457424759865
[2025-03-14 05:13:40,667][model][INFO] - Training step 17520 loss 0.02589375525712967
[2025-03-14 05:14:44,144][model][INFO] - Training step 17680 loss 0.024041716009378433
[2025-03-14 05:15:43,887][model][INFO] - Training step 17840 loss 0.010625758208334446
[2025-03-14 05:16:47,276][model][INFO] - Training step 18000 loss 0.0862148255109787
[2025-03-14 05:17:51,755][model][INFO] - Training step 18160 loss 0.036139532923698425
[2025-03-14 05:18:53,598][model][INFO] - Training step 18320 loss 0.03256547451019287
[2025-03-14 05:19:55,456][model][INFO] - Training step 18480 loss 0.005278396420180798
[2025-03-14 05:20:57,991][model][INFO] - Training step 18640 loss 0.03371221572160721
[2025-03-14 05:21:57,813][model][INFO] - Training step 18800 loss 0.013251090422272682
[2025-03-14 05:22:58,260][model][INFO] - Training step 18960 loss 0.03311474993824959
[2025-03-14 05:24:01,156][model][INFO] - Training step 19120 loss 0.084311842918396
[2025-03-14 05:25:02,658][model][INFO] - Training step 19280 loss 0.13342216610908508
[2025-03-14 05:26:05,048][model][INFO] - Training step 19440 loss 0.034967631101608276
[2025-03-14 05:27:08,151][model][INFO] - Training step 19600 loss 0.042799562215805054
[2025-03-14 05:28:11,640][model][INFO] - Training step 19760 loss 0.26124507188796997
[2025-03-14 05:29:16,748][model][INFO] - Training step 19920 loss 0.049385689198970795
[2025-03-14 05:30:18,069][model][INFO] - Training step 20080 loss 0.042549941688776016
[2025-03-14 05:31:20,459][model][INFO] - Training step 20240 loss 0.020868539810180664
[2025-03-14 05:32:22,953][model][INFO] - Training step 20400 loss 0.05409713089466095
[2025-03-14 05:33:25,371][model][INFO] - Training step 20560 loss 0.017695745453238487
[2025-03-14 05:34:28,162][model][INFO] - Training step 20720 loss 0.041613005101680756
[2025-03-14 05:35:29,118][model][INFO] - Training step 20880 loss 0.1531984508037567
[2025-03-14 05:36:29,965][model][INFO] - Training step 21040 loss 0.006212162785232067
[2025-03-14 05:37:31,188][model][INFO] - Training step 21200 loss 0.022179774940013885
[2025-03-14 05:38:32,686][model][INFO] - Training step 21360 loss 0.040694840252399445
[2025-03-14 05:39:33,567][model][INFO] - Training step 21520 loss 0.08906321227550507
[2025-03-14 05:40:35,764][model][INFO] - Training step 21680 loss 0.020901329815387726
[2025-03-14 05:41:38,202][model][INFO] - Training step 21840 loss 0.0018840826814994216
[2025-03-14 05:42:40,922][model][INFO] - Training step 22000 loss 0.03382293879985809
[2025-03-14 05:43:41,959][model][INFO] - Training step 22160 loss 0.029358793050050735
[2025-03-14 05:44:44,691][model][INFO] - Training step 22320 loss 0.02349168062210083
[2025-03-14 05:45:49,420][model][INFO] - Training step 22480 loss 0.0069908639416098595
[2025-03-14 05:46:51,205][model][INFO] - Training step 22640 loss 0.017330335453152657
[2025-03-14 05:47:54,212][model][INFO] - Training step 22800 loss 0.022495916113257408
[2025-03-14 05:48:56,518][model][INFO] - Training step 22960 loss 0.02218293771147728
[2025-03-14 05:49:57,793][model][INFO] - Training step 23120 loss 0.02223827689886093
[2025-03-14 05:50:58,595][model][INFO] - Training step 23280 loss 0.02004624903202057
[2025-03-14 05:52:04,017][model][INFO] - Training step 23440 loss 0.2521760165691376
[2025-03-14 05:53:05,384][model][INFO] - Training step 23600 loss 0.348825603723526
[2025-03-14 05:54:07,268][model][INFO] - Training step 23760 loss 0.02069774642586708
[2025-03-14 05:55:10,236][model][INFO] - Training step 23920 loss 0.008719377219676971
[2025-03-14 05:56:11,274][model][INFO] - Training step 24080 loss 0.04199498891830444
[2025-03-14 05:57:11,152][model][INFO] - Training step 24240 loss 0.021842923015356064
[2025-03-14 05:58:12,500][model][INFO] - Training step 24400 loss 0.022859303280711174
[2025-03-14 05:59:14,810][model][INFO] - Training step 24560 loss 0.2017531394958496
[2025-03-14 06:00:16,250][model][INFO] - Training step 24720 loss 0.033166609704494476
[2025-03-14 06:01:18,585][model][INFO] - Training step 24880 loss 0.0058459024876356125
[2025-03-14 06:02:18,268][model][INFO] - Training step 25040 loss 0.3084613084793091
[2025-03-14 06:03:20,835][model][INFO] - Training step 25200 loss 0.07927317917346954
[2025-03-14 06:04:24,633][model][INFO] - Training step 25360 loss 0.25490397214889526
[2025-03-14 06:05:26,504][model][INFO] - Training step 25520 loss 0.08106528222560883
[2025-03-14 06:06:26,707][model][INFO] - Training step 25680 loss 0.014936406165361404
[2025-03-14 06:07:29,491][model][INFO] - Training step 25840 loss 0.07145614922046661
[2025-03-14 06:08:31,656][model][INFO] - Training step 26000 loss 0.09237761050462723
[2025-03-14 06:09:32,968][model][INFO] - Training step 26160 loss 0.00549282506108284
[2025-03-14 06:10:35,222][model][INFO] - Training step 26320 loss 0.003487368579953909
[2025-03-14 06:11:38,163][model][INFO] - Training step 26480 loss 0.2420976758003235
[2025-03-14 06:12:40,396][model][INFO] - Training step 26640 loss 0.03628510236740112
[2025-03-14 06:13:42,639][model][INFO] - Training step 26800 loss 0.045459866523742676
[2025-03-14 06:14:45,291][model][INFO] - Training step 26960 loss 0.021847102791070938
[2025-03-14 06:15:46,906][model][INFO] - Training step 27120 loss 0.07242710888385773
[2025-03-14 06:16:48,772][model][INFO] - Training step 27280 loss 0.09507478773593903
[2025-03-14 06:17:50,138][model][INFO] - Training step 27440 loss 0.27303922176361084
[2025-03-14 06:18:50,981][model][INFO] - Training step 27600 loss 0.060018301010131836
[2025-03-14 06:19:55,133][model][INFO] - Training step 27760 loss 0.13556396961212158
[2025-03-14 06:20:56,343][model][INFO] - Training step 27920 loss 0.04133719205856323
[2025-03-14 06:21:59,990][model][INFO] - Training step 28080 loss 0.02919168211519718
[2025-03-14 06:23:00,536][model][INFO] - Training step 28240 loss 0.24459829926490784
[2025-03-14 06:24:03,713][model][INFO] - Training step 28400 loss 0.26324933767318726
[2025-03-14 06:25:05,582][model][INFO] - Training step 28560 loss 0.26162058115005493
[2025-03-14 06:26:07,376][model][INFO] - Training step 28720 loss 0.006731216795742512
[2025-03-14 06:27:08,788][model][INFO] - Training step 28880 loss 0.017829474061727524
[2025-03-14 06:28:08,542][model][INFO] - Training step 29040 loss 0.2512999176979065
[2025-03-14 06:29:10,767][model][INFO] - Training step 29200 loss 0.01566110923886299
[2025-03-14 06:30:13,719][model][INFO] - Training step 29360 loss 0.007065308280289173
[2025-03-14 06:31:13,880][model][INFO] - Training step 29520 loss 0.12320548295974731
[2025-03-14 06:32:15,191][model][INFO] - Training step 29680 loss 0.03958340361714363
[2025-03-14 06:33:18,358][model][INFO] - Training step 29840 loss 0.26590093970298767
[2025-03-14 06:34:21,176][model][INFO] - Training step 30000 loss 0.012023985385894775
[2025-03-14 06:35:24,250][model][INFO] - Training step 30160 loss 0.009501053020358086
[2025-03-14 06:36:29,052][model][INFO] - Training step 30320 loss 0.021193411201238632
[2025-03-14 06:37:31,440][model][INFO] - Training step 30480 loss 0.25861310958862305
[2025-03-14 06:38:30,206][model][INFO] - Training step 30640 loss 0.03131327033042908
[2025-03-14 06:39:29,749][model][INFO] - Training step 30800 loss 0.04407153278589249
[2025-03-14 06:40:32,834][model][INFO] - Training step 30960 loss 0.020438820123672485
[2025-03-14 06:41:35,464][model][INFO] - Training step 31120 loss 0.058688484132289886
[2025-03-14 06:42:39,422][model][INFO] - Training step 31280 loss 0.03695456683635712
[2025-03-14 06:43:39,599][model][INFO] - Training step 31440 loss 0.030109316110610962
[2025-03-14 06:44:41,306][model][INFO] - Training step 31600 loss 0.2588050961494446
[2025-03-14 06:45:44,435][model][INFO] - Training step 31760 loss 0.04179481416940689
[2025-03-14 06:46:44,473][model][INFO] - Training step 31920 loss 0.028377987444400787
[2025-03-14 06:47:47,015][model][INFO] - Training step 32080 loss 0.025670040398836136
[2025-03-14 06:48:49,309][model][INFO] - Training step 32240 loss 0.04219106584787369
[2025-03-14 06:49:50,482][model][INFO] - Training step 32400 loss 0.24636216461658478
[2025-03-14 06:50:53,607][model][INFO] - Training step 32560 loss 0.03055669367313385
[2025-03-14 06:51:56,250][model][INFO] - Training step 32720 loss 0.2525964379310608
[2025-03-14 06:52:58,138][model][INFO] - Training step 32880 loss 0.05092807114124298
[2025-03-14 06:53:58,794][model][INFO] - Training step 33040 loss 0.026412371546030045
[2025-03-14 06:55:00,112][model][INFO] - Training step 33200 loss 0.044463224709033966
[2025-03-14 06:56:01,227][model][INFO] - Training step 33360 loss 0.2560165524482727
[2025-03-14 06:57:06,666][model][INFO] - Training step 33520 loss 0.050893619656562805
[2025-03-14 06:58:11,200][model][INFO] - Training step 33680 loss 0.2581127882003784
[2025-03-14 06:59:14,719][model][INFO] - Training step 33840 loss 0.020387455821037292
[2025-03-14 07:00:15,478][model][INFO] - Training step 34000 loss 0.015011584386229515
[2025-03-14 07:01:18,309][model][INFO] - Training step 34160 loss 0.04402484744787216
[2025-03-14 07:02:19,768][model][INFO] - Training step 34320 loss 0.01775258779525757
[2025-03-14 07:03:21,276][model][INFO] - Training step 34480 loss 0.08859243988990784
[2025-03-14 07:04:21,751][model][INFO] - Training step 34640 loss 0.0043593221344053745
[2025-03-14 07:05:21,881][model][INFO] - Training step 34800 loss 0.023313526064157486
[2025-03-14 07:06:24,878][model][INFO] - Training step 34960 loss 0.21019259095191956
[2025-03-14 07:07:26,474][model][INFO] - Training step 35120 loss 0.006046498194336891
[2025-03-14 07:08:25,926][model][INFO] - Training step 35280 loss 0.024492189288139343
[2025-03-14 07:09:26,524][model][INFO] - Training step 35440 loss 0.012869579717516899
[2025-03-14 07:10:29,780][model][INFO] - Training step 35600 loss 0.005587143357843161
[2025-03-14 07:11:31,520][model][INFO] - Training step 35760 loss 0.022226672619581223
[2025-03-14 07:12:31,509][model][INFO] - Training step 35920 loss 0.2507510781288147
[2025-03-14 07:13:33,246][model][INFO] - Training step 36080 loss 0.037588246166706085
[2025-03-14 07:14:36,328][model][INFO] - Training step 36240 loss 0.256200909614563
[2025-03-14 07:15:40,006][model][INFO] - Training step 36400 loss 0.2572290599346161
[2025-03-14 07:16:43,369][model][INFO] - Training step 36560 loss 0.004815779626369476
[2025-03-14 07:17:45,368][model][INFO] - Training step 36720 loss 0.007284169085323811
[2025-03-14 07:18:49,096][model][INFO] - Training step 36880 loss 0.13241474330425262
[2025-03-14 07:19:49,775][model][INFO] - Training step 37040 loss 0.07598714530467987
[2025-03-14 07:20:51,376][model][INFO] - Training step 37200 loss 0.029633037745952606
[2025-03-14 07:21:53,863][model][INFO] - Training step 37360 loss 0.02141055464744568
[2025-03-14 07:22:55,373][model][INFO] - Training step 37520 loss 0.0229136124253273
[2025-03-14 07:23:55,839][model][INFO] - Training step 37680 loss 0.046081483364105225
[2025-03-14 07:24:58,118][model][INFO] - Training step 37840 loss 0.039859797805547714
[2025-03-14 07:25:59,080][model][INFO] - Training step 38000 loss 0.23382581770420074
[2025-03-14 07:26:59,866][model][INFO] - Training step 38160 loss 0.030916593968868256
[2025-03-14 07:28:00,890][model][INFO] - Training step 38320 loss 0.030507594347000122
[2025-03-14 07:29:03,210][model][INFO] - Training step 38480 loss 0.028729818761348724
[2025-03-14 07:30:03,925][model][INFO] - Training step 38640 loss 0.26351431012153625
[2025-03-14 07:31:02,762][model][INFO] - Training step 38800 loss 0.06480928510427475
[2025-03-14 07:32:04,711][model][INFO] - Training step 38960 loss 0.020071011036634445
[2025-03-14 07:33:05,848][model][INFO] - Training step 39120 loss 0.05479706823825836
[2025-03-14 07:34:08,040][model][INFO] - Training step 39280 loss 0.005925424862653017
[2025-03-14 07:35:10,293][model][INFO] - Training step 39440 loss 0.2492312639951706
[2025-03-14 07:36:15,033][model][INFO] - Training step 39600 loss 0.09327715635299683
[2025-03-14 07:37:15,552][model][INFO] - Training step 39760 loss 0.02641972154378891
[2025-03-14 07:38:18,021][model][INFO] - Training step 39920 loss 0.020165184512734413
[2025-03-14 07:39:19,374][model][INFO] - Training step 40080 loss 0.013370506465435028
[2025-03-14 07:40:21,012][model][INFO] - Training step 40240 loss 0.04785317927598953
[2025-03-14 07:41:24,613][model][INFO] - Training step 40400 loss 0.006830672733485699
[2025-03-14 07:42:29,355][model][INFO] - Training step 40560 loss 0.0335884615778923
[2025-03-14 07:43:31,098][model][INFO] - Training step 40720 loss 0.033740606158971786
[2025-03-14 07:44:35,936][model][INFO] - Training step 40880 loss 0.018487796187400818
[2025-03-14 07:45:38,051][model][INFO] - Training step 41040 loss 0.03259754180908203
[2025-03-14 07:46:41,098][model][INFO] - Training step 41200 loss 0.08343254029750824
[2025-03-14 07:47:43,756][model][INFO] - Training step 41360 loss 0.2539341449737549
[2025-03-14 07:48:42,772][model][INFO] - Training step 41520 loss 0.033270444720983505
[2025-03-14 07:49:45,015][model][INFO] - Training step 41680 loss 0.07906137406826019
[2025-03-14 07:50:47,051][model][INFO] - Training step 41840 loss 0.011602628976106644
[2025-03-14 07:51:48,141][model][INFO] - Training step 42000 loss 0.05515674501657486
[2025-03-14 07:52:49,907][model][INFO] - Training step 42160 loss 0.005664442665874958
[2025-03-14 07:53:52,677][model][INFO] - Training step 42320 loss 0.012965377420186996
[2025-03-14 07:54:53,534][model][INFO] - Training step 42480 loss 0.2385234832763672
[2025-03-14 07:55:53,367][model][INFO] - Training step 42640 loss 0.022904083132743835
[2025-03-14 07:56:55,921][model][INFO] - Training step 42800 loss 0.02577963098883629
[2025-03-14 07:57:57,093][model][INFO] - Training step 42960 loss 0.04442167282104492
[2025-03-14 07:59:03,809][model][INFO] - Training step 43120 loss 0.039210423827171326
[2025-03-14 08:00:03,841][model][INFO] - Training step 43280 loss 0.04848058894276619
[2025-03-14 08:01:07,180][model][INFO] - Training step 43440 loss 0.004567614756524563
[2025-03-14 08:02:07,434][model][INFO] - Training step 43600 loss 0.0067483214661479
[2025-03-14 08:03:11,420][model][INFO] - Training step 43760 loss 0.20996329188346863
[2025-03-14 08:04:11,780][model][INFO] - Training step 43920 loss 0.034763820469379425
[2025-03-14 08:05:13,671][model][INFO] - Training step 44080 loss 0.029142793267965317
[2025-03-14 08:06:15,535][model][INFO] - Training step 44240 loss 0.03258766233921051
[2025-03-14 08:07:15,854][model][INFO] - Training step 44400 loss 0.029737431555986404
[2025-03-14 08:08:17,465][model][INFO] - Training step 44560 loss 0.006680692546069622
[2025-03-14 08:09:19,041][model][INFO] - Training step 44720 loss 0.018877115100622177
[2025-03-14 08:10:19,473][model][INFO] - Training step 44880 loss 0.04159922152757645
[2025-03-14 08:11:19,315][model][INFO] - Training step 45040 loss 0.2585441768169403
[2025-03-14 08:12:20,218][model][INFO] - Training step 45200 loss 0.014906255528330803
[2025-03-14 08:13:23,246][model][INFO] - Training step 45360 loss 0.019562143832445145
[2025-03-14 08:14:24,773][model][INFO] - Training step 45520 loss 0.03631049767136574
[2025-03-14 08:15:30,211][model][INFO] - Training step 45680 loss 0.011521466076374054
[2025-03-14 08:16:29,031][model][INFO] - Training step 45840 loss 0.080385722219944
[2025-03-14 08:17:31,718][model][INFO] - Training step 46000 loss 0.075975701212883
[2025-03-14 08:18:32,662][model][INFO] - Training step 46160 loss 0.031301937997341156
[2025-03-14 08:19:34,583][model][INFO] - Training step 46320 loss 0.02862974815070629
[2025-03-14 08:20:36,094][model][INFO] - Training step 46480 loss 0.05420403927564621
[2025-03-14 08:21:36,023][model][INFO] - Training step 46640 loss 0.16345132887363434
[2025-03-14 08:22:39,043][model][INFO] - Training step 46800 loss 0.03793715685606003
[2025-03-14 08:23:43,494][model][INFO] - Training step 46960 loss 0.030032364651560783
[2025-03-14 08:24:46,533][model][INFO] - Training step 47120 loss 0.06615197658538818
[2025-03-14 08:25:48,220][model][INFO] - Training step 47280 loss 0.037204403430223465
[2025-03-14 08:26:49,804][model][INFO] - Training step 47440 loss 0.01357605867087841
[2025-03-14 08:27:50,264][model][INFO] - Training step 47600 loss 0.07531362026929855
[2025-03-14 08:28:52,624][model][INFO] - Training step 47760 loss 0.2473597526550293
[2025-03-14 08:29:53,754][model][INFO] - Training step 47920 loss 0.03214264661073685
[2025-03-14 08:30:58,713][model][INFO] - Training step 48080 loss 0.2573425769805908
[2025-03-14 08:31:59,499][model][INFO] - Training step 48240 loss 0.01810251921415329
[2025-03-14 08:32:59,847][model][INFO] - Training step 48400 loss 0.24994871020317078
[2025-03-14 08:34:01,304][model][INFO] - Training step 48560 loss 0.032251328229904175
[2025-03-14 08:35:02,943][model][INFO] - Training step 48720 loss 0.020082328468561172
[2025-03-14 08:36:02,556][model][INFO] - Training step 48880 loss 0.04095706343650818
[2025-03-14 08:37:04,067][model][INFO] - Training step 49040 loss 0.008598938584327698
[2025-03-14 08:38:04,689][model][INFO] - Training step 49200 loss 0.018298033624887466
[2025-03-14 08:39:05,217][model][INFO] - Training step 49360 loss 0.022977221757173538
[2025-03-14 08:40:07,241][model][INFO] - Training step 49520 loss 0.0031558885239064693
[2025-03-14 08:41:07,052][model][INFO] - Training step 49680 loss 0.013595812022686005
[2025-03-14 08:42:08,700][model][INFO] - Training step 49840 loss 0.1616211235523224
[2025-03-14 08:43:11,074][model][INFO] - Training step 50000 loss 0.04360123351216316
[2025-03-14 08:44:11,970][model][INFO] - Training step 50160 loss 0.013942440040409565
[2025-03-14 08:45:15,696][model][INFO] - Training step 50320 loss 0.0023281206376850605
[2025-03-14 08:46:17,208][model][INFO] - Training step 50480 loss 0.0075761545449495316
[2025-03-14 08:47:17,787][model][INFO] - Training step 50640 loss 0.0017872803146019578
[2025-03-14 08:56:12,517][model][INFO] - Training step 0 loss 0.19511908292770386
[2025-03-14 08:57:14,285][model][INFO] - Training step 160 loss 0.24869607388973236
[2025-03-14 08:58:14,716][model][INFO] - Training step 320 loss 0.027597203850746155
[2025-03-14 08:59:17,287][model][INFO] - Training step 480 loss 0.05862624570727348
[2025-03-14 09:00:17,269][model][INFO] - Training step 640 loss 0.25292420387268066
[2025-03-14 09:01:17,640][model][INFO] - Training step 800 loss 0.03442809730768204
[2025-03-14 09:02:20,081][model][INFO] - Training step 960 loss 0.015431612730026245
[2025-03-14 09:03:19,388][model][INFO] - Training step 1120 loss 0.03924760967493057
[2025-03-14 09:04:21,142][model][INFO] - Training step 1280 loss 0.2490479052066803
[2025-03-14 09:05:21,034][model][INFO] - Training step 1440 loss 0.02457142248749733
[2025-03-14 09:06:22,794][model][INFO] - Training step 1600 loss 0.26761144399642944
[2025-03-14 09:07:22,760][model][INFO] - Training step 1760 loss 0.02962060272693634
[2025-03-14 09:08:22,222][model][INFO] - Training step 1920 loss 0.013469698838889599
[2025-03-14 09:09:23,177][model][INFO] - Training step 2080 loss 0.012133743613958359
[2025-03-14 09:10:24,149][model][INFO] - Training step 2240 loss 0.025665488094091415
[2025-03-14 09:11:25,194][model][INFO] - Training step 2400 loss 0.04056230187416077
[2025-03-14 09:12:27,337][model][INFO] - Training step 2560 loss 0.09669788181781769
[2025-03-14 09:13:31,382][model][INFO] - Training step 2720 loss 0.015209807083010674
[2025-03-14 09:14:33,413][model][INFO] - Training step 2880 loss 0.25445660948753357
[2025-03-14 09:15:34,046][model][INFO] - Training step 3040 loss 0.04971706122159958
[2025-03-14 09:16:33,406][model][INFO] - Training step 3200 loss 0.0048969038762152195
Epoch 44/249 ━                    3298/50800 0:21:01 • 5:24:26 2.44it/s v_num: 1
[1;34mwandb[0m: 🚀 View run [33mFastGenSep++[0m at: [34mhttps://wandb.ai/anirudhbhalekar10-university-of-cambridge/shortcut-model-separation/runs/t0fe4klb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250312_153342-t0fe4klb/logs[0m
...training finished
----------------------------------------------------------------
----------------------------------------------------------------
Activating environment
Python version used:
Python 3.10.15
Starting training...
NVML Initialized
Driver Version: b'450.80.02'
[2025-03-14 13:17:14,865][__main__][INFO] - Start experiment: exp/default/2025-03-14_13-17-14_
[2025-03-14 13:17:14,888][__main__][INFO] - create datalogger
[2025-03-14 13:17:14,888][__main__][INFO] - Create new model
[2025-03-14 13:18:07,166][models.ncsnpp][DEBUG] - NCSNpp.__init__
[2025-03-14 13:18:07,167][models.ncsnpp][DEBUG] - all_resolutions: [256, 128, 64, 32, 16, 8, 4]
[2025-03-14 13:18:07,168][models.ncsnpp][DEBUG] - num_channels: 6
[2025-03-14 13:18:08,823][__main__][INFO] - start training
CHECKPOINT FOUND
[2025-03-14 13:18:22,782][model][INFO] - set optim with {'_target_': 'torch.optim.Adam', 'lr': 0.0005, 'weight_decay': 0.0}
┏━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓
┃   ┃ Name        ┃ Type             ┃ Params ┃ Mode  ┃
┡━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩
│ 0 │ model       │ ScoreModelNCSNpp │ 16.5 M │ train │
│ 1 │ loss        │ MSELoss          │      0 │ train │
│ 2 │ si_sdr_loss │ SISDRLoss        │      0 │ train │
└───┴─────────────┴──────────────────┴────────┴───────┘
Trainable params: 16.5 M                                                        
Non-trainable params: 64                                                        
Total params: 16.5 M                                                            
Total estimated model params size (MB): 66                                      
Modules in train mode: 444                                                      
Modules in eval mode: 0                                                         
[2025-03-14 13:18:37,995][model][INFO] - Training step 0 loss 0.06537283957004547
[2025-03-14 13:19:22,653][model][INFO] - Training step 160 loss 0.24395927786827087
[2025-03-14 13:20:03,235][model][INFO] - Training step 320 loss 0.06567403674125671
[2025-03-14 13:20:46,827][model][INFO] - Training step 480 loss 0.24402496218681335
[2025-03-14 13:21:26,753][model][INFO] - Training step 640 loss 0.04598376154899597
[2025-03-14 13:22:07,755][model][INFO] - Training step 800 loss 0.02527659758925438
[2025-03-14 13:22:50,196][model][INFO] - Training step 960 loss 0.014405008405447006
[2025-03-14 13:23:31,195][model][INFO] - Training step 1120 loss 0.241037055850029
[2025-03-14 13:24:11,819][model][INFO] - Training step 1280 loss 0.017386194318532944
[2025-03-14 13:24:51,504][model][INFO] - Training step 1440 loss 0.02593342214822769
[2025-03-14 13:25:32,642][model][INFO] - Training step 1600 loss 0.1265823245048523
[2025-03-14 13:26:12,733][model][INFO] - Training step 1760 loss 0.025153934955596924
[2025-03-14 13:26:54,257][model][INFO] - Training step 1920 loss 0.05954503268003464
[2025-03-14 13:27:35,404][model][INFO] - Training step 2080 loss 0.02135876566171646
[2025-03-14 13:28:17,145][model][INFO] - Training step 2240 loss 0.00637729000300169
[2025-03-14 13:28:58,910][model][INFO] - Training step 2400 loss 0.00948810763657093
[2025-03-14 13:29:41,597][model][INFO] - Training step 2560 loss 0.009836728684604168
[2025-03-14 13:30:22,371][model][INFO] - Training step 2720 loss 0.199163019657135
[2025-03-14 13:31:02,994][model][INFO] - Training step 2880 loss 0.016888808459043503
[2025-03-14 13:31:44,585][model][INFO] - Training step 3040 loss 0.2538566589355469
[2025-03-14 13:32:27,303][model][INFO] - Training step 3200 loss 0.004077904857695103
[2025-03-14 13:33:10,855][model][INFO] - Training step 3360 loss 0.007105578668415546
[2025-03-14 13:33:52,468][model][INFO] - Training step 3520 loss 0.24857833981513977
[2025-03-14 13:34:34,414][model][INFO] - Training step 3680 loss 0.032731249928474426
[2025-03-14 13:35:15,132][model][INFO] - Training step 3840 loss 0.02533675730228424
[2025-03-14 13:35:57,302][model][INFO] - Training step 4000 loss 0.08373738825321198
[2025-03-14 13:36:39,683][model][INFO] - Training step 4160 loss 0.004115360789000988
[2025-03-14 13:37:23,233][model][INFO] - Training step 4320 loss 0.022762849926948547
[2025-03-14 13:38:05,113][model][INFO] - Training step 4480 loss 0.027978764846920967
[2025-03-14 13:38:48,284][model][INFO] - Training step 4640 loss 0.10293442010879517
[2025-03-14 13:39:30,398][model][INFO] - Training step 4800 loss 0.00550883961841464
[2025-03-14 13:40:12,324][model][INFO] - Training step 4960 loss 0.010759567841887474
[2025-03-14 13:40:54,524][model][INFO] - Training step 5120 loss 0.6597376465797424
[2025-03-14 13:41:37,617][model][INFO] - Training step 5280 loss 0.2396666705608368
[2025-03-14 13:42:19,175][model][INFO] - Training step 5440 loss 0.07198582589626312
[2025-03-14 13:43:00,559][model][INFO] - Training step 5600 loss 0.034937407821416855
[2025-03-14 13:43:41,763][model][INFO] - Training step 5760 loss 0.02387978881597519
[2025-03-14 13:44:23,290][model][INFO] - Training step 5920 loss 0.022839881479740143
[2025-03-14 13:45:04,088][model][INFO] - Training step 6080 loss 0.01961139217019081
[2025-03-14 13:45:45,305][model][INFO] - Training step 6240 loss 0.022230438888072968
[2025-03-14 13:46:27,827][model][INFO] - Training step 6400 loss 0.13695496320724487
[2025-03-14 13:47:08,290][model][INFO] - Training step 6560 loss 0.024835139513015747
[2025-03-14 13:47:49,568][model][INFO] - Training step 6720 loss 0.004422018304467201
[2025-03-14 13:48:31,818][model][INFO] - Training step 6880 loss 0.12520059943199158
[2025-03-14 13:49:14,102][model][INFO] - Training step 7040 loss 0.26439112424850464
[2025-03-14 13:49:56,850][model][INFO] - Training step 7200 loss 0.0034597357735037804
[2025-03-14 13:50:38,668][model][INFO] - Training step 7360 loss 0.04858120530843735
[2025-03-14 13:51:21,182][model][INFO] - Training step 7520 loss 0.029120508581399918
[2025-03-14 13:52:02,272][model][INFO] - Training step 7680 loss 0.041329022496938705
[2025-03-14 13:52:44,846][model][INFO] - Training step 7840 loss 0.04060855507850647
[2025-03-14 13:53:27,624][model][INFO] - Training step 8000 loss 0.00640046875923872
[2025-03-14 13:54:09,969][model][INFO] - Training step 8160 loss 0.15452256798744202
[2025-03-14 13:54:52,342][model][INFO] - Training step 8320 loss 0.017876023426651955
[2025-03-14 13:55:34,544][model][INFO] - Training step 8480 loss 0.011425310745835304
[2025-03-14 13:56:15,783][model][INFO] - Training step 8640 loss 0.017125092446804047
[2025-03-14 13:56:57,819][model][INFO] - Training step 8800 loss 0.062329210340976715
[2025-03-14 13:57:40,849][model][INFO] - Training step 8960 loss 0.2115059643983841
[2025-03-14 13:58:22,317][model][INFO] - Training step 9120 loss 0.02920687012374401
[2025-03-14 13:59:02,281][model][INFO] - Training step 9280 loss 0.2591209411621094
[2025-03-14 13:59:44,400][model][INFO] - Training step 9440 loss 0.03304891288280487
[2025-03-14 14:00:30,044][model][INFO] - Training step 9600 loss 0.0029491675086319447
[2025-03-14 14:01:12,078][model][INFO] - Training step 9760 loss 0.03735585883259773
[2025-03-14 14:01:54,443][model][INFO] - Training step 9920 loss 0.019096463918685913
[2025-03-14 14:02:37,615][model][INFO] - Training step 10080 loss 0.2550658583641052
[2025-03-14 14:03:19,811][model][INFO] - Training step 10240 loss 0.013837778940796852
[2025-03-14 14:04:01,627][model][INFO] - Training step 10400 loss 0.07563085854053497
[2025-03-14 14:04:44,013][model][INFO] - Training step 10560 loss 0.052594948559999466
[2025-03-14 14:05:25,754][model][INFO] - Training step 10720 loss 0.017698373645544052
[2025-03-14 14:06:07,162][model][INFO] - Training step 10880 loss 0.03610687702894211
[2025-03-14 14:06:49,185][model][INFO] - Training step 11040 loss 0.16924908757209778
[2025-03-14 14:07:30,439][model][INFO] - Training step 11200 loss 0.06372837722301483
[2025-03-14 14:08:13,001][model][INFO] - Training step 11360 loss 0.0019317734986543655
[2025-03-14 14:08:53,972][model][INFO] - Training step 11520 loss 0.020548256114125252
[2025-03-14 14:09:33,610][model][INFO] - Training step 11680 loss 0.04396527260541916
[2025-03-14 14:10:16,320][model][INFO] - Training step 11840 loss 0.07151086628437042
[2025-03-14 14:10:57,405][model][INFO] - Training step 12000 loss 0.003767368383705616
[2025-03-14 14:11:39,847][model][INFO] - Training step 12160 loss 0.0023126890882849693
[2025-03-14 14:12:21,845][model][INFO] - Training step 12320 loss 0.03330320864915848
[2025-03-14 14:13:03,951][model][INFO] - Training step 12480 loss 0.0043196287006139755
[2025-03-14 14:13:46,759][model][INFO] - Training step 12640 loss 0.04782690107822418
[2025-03-14 14:14:29,373][model][INFO] - Training step 12800 loss 0.004254297818988562
[2025-03-14 14:15:10,733][model][INFO] - Training step 12960 loss 0.017272984609007835
[2025-03-14 14:15:52,425][model][INFO] - Training step 13120 loss 0.244890958070755
[2025-03-14 14:16:34,302][model][INFO] - Training step 13280 loss 0.018268872052431107
[2025-03-14 14:17:15,621][model][INFO] - Training step 13440 loss 0.2367539405822754
[2025-03-14 14:17:58,557][model][INFO] - Training step 13600 loss 0.022844096645712852
[2025-03-14 14:18:39,418][model][INFO] - Training step 13760 loss 0.059948451817035675
[2025-03-14 14:19:21,036][model][INFO] - Training step 13920 loss 0.26821792125701904
[2025-03-14 14:20:03,497][model][INFO] - Training step 14080 loss 0.028628475964069366
[2025-03-14 14:20:46,707][model][INFO] - Training step 14240 loss 0.006061008665710688
[2025-03-14 14:21:29,147][model][INFO] - Training step 14400 loss 0.017760202288627625
[2025-03-14 14:22:10,337][model][INFO] - Training step 14560 loss 0.26462244987487793
[2025-03-14 14:22:52,578][model][INFO] - Training step 14720 loss 0.01558566465973854
[2025-03-14 14:23:34,619][model][INFO] - Training step 14880 loss 0.034162212163209915
[2025-03-14 14:24:17,067][model][INFO] - Training step 15040 loss 0.06789503246545792
[2025-03-14 14:25:00,063][model][INFO] - Training step 15200 loss 0.05010642856359482
[2025-03-14 14:25:42,052][model][INFO] - Training step 15360 loss 0.0501418299973011
[2025-03-14 14:26:24,526][model][INFO] - Training step 15520 loss 0.2514598071575165
[2025-03-14 14:27:06,937][model][INFO] - Training step 15680 loss 0.2555008828639984
[2025-03-14 14:27:50,465][model][INFO] - Training step 15840 loss 0.04545557498931885
[2025-03-14 14:28:32,037][model][INFO] - Training step 16000 loss 0.013351170346140862
[2025-03-14 14:29:16,623][model][INFO] - Training step 16160 loss 0.018289022147655487
[2025-03-14 14:29:58,025][model][INFO] - Training step 16320 loss 0.0030692091677337885
[2025-03-14 14:30:38,812][model][INFO] - Training step 16480 loss 0.23828163743019104
[2025-03-14 14:31:19,724][model][INFO] - Training step 16640 loss 0.3915320038795471
[2025-03-14 14:32:02,085][model][INFO] - Training step 16800 loss 0.27194657921791077
[2025-03-14 14:32:43,055][model][INFO] - Training step 16960 loss 0.03434135764837265
[2025-03-14 14:33:24,804][model][INFO] - Training step 17120 loss 0.056988514959812164
[2025-03-14 14:34:07,830][model][INFO] - Training step 17280 loss 0.034303970634937286
[2025-03-14 14:34:48,472][model][INFO] - Training step 17440 loss 0.25400495529174805
[2025-03-14 14:35:28,480][model][INFO] - Training step 17600 loss 0.02413235977292061
[2025-03-14 14:36:08,719][model][INFO] - Training step 17760 loss 0.005600417964160442
[2025-03-14 14:36:48,838][model][INFO] - Training step 17920 loss 0.0779859647154808
[2025-03-14 14:37:28,079][model][INFO] - Training step 18080 loss 0.23479686677455902
[2025-03-14 14:38:09,383][model][INFO] - Training step 18240 loss 0.007541057653725147
[2025-03-14 14:38:50,480][model][INFO] - Training step 18400 loss 0.0944075658917427
[2025-03-14 14:39:30,122][model][INFO] - Training step 18560 loss 0.0063761454075574875
[2025-03-14 14:40:10,718][model][INFO] - Training step 18720 loss 0.02624686434864998
[2025-03-14 14:40:51,068][model][INFO] - Training step 18880 loss 0.267386257648468
[2025-03-14 14:41:30,260][model][INFO] - Training step 19040 loss 0.03232431039214134
[2025-03-14 14:42:10,955][model][INFO] - Training step 19200 loss 0.02789825201034546
[2025-03-14 14:42:50,225][model][INFO] - Training step 19360 loss 0.102313332259655
[2025-03-14 14:43:30,933][model][INFO] - Training step 19520 loss 0.2443659007549286
[2025-03-14 14:44:11,257][model][INFO] - Training step 19680 loss 0.2528756558895111
[2025-03-14 14:44:52,752][model][INFO] - Training step 19840 loss 0.006429686211049557
[2025-03-14 14:45:33,609][model][INFO] - Training step 20000 loss 0.04434727132320404
[2025-03-14 14:46:14,886][model][INFO] - Training step 20160 loss 0.057541586458683014
[2025-03-14 14:46:56,859][model][INFO] - Training step 20320 loss 0.003450632095336914
[2025-03-14 14:47:36,072][model][INFO] - Training step 20480 loss 0.12572164833545685
[2025-03-14 14:48:16,036][model][INFO] - Training step 20640 loss 0.038734763860702515
[2025-03-14 14:48:55,667][model][INFO] - Training step 20800 loss 0.11089038103818893
[2025-03-14 14:49:37,849][model][INFO] - Training step 20960 loss 0.004267154261469841
[2025-03-14 14:50:17,870][model][INFO] - Training step 21120 loss 0.010060062631964684
[2025-03-14 14:50:59,195][model][INFO] - Training step 21280 loss 0.004900055006146431
[2025-03-14 14:51:39,459][model][INFO] - Training step 21440 loss 0.017924334853887558
[2025-03-14 14:52:19,808][model][INFO] - Training step 21600 loss 0.252765953540802
[2025-03-14 14:52:59,744][model][INFO] - Training step 21760 loss 0.026858437806367874
[2025-03-14 14:53:39,955][model][INFO] - Training step 21920 loss 0.019643861800432205
[2025-03-14 14:54:19,612][model][INFO] - Training step 22080 loss 0.2564254701137543
[2025-03-14 14:54:59,890][model][INFO] - Training step 22240 loss 0.11513566970825195
[2025-03-14 14:55:40,761][model][INFO] - Training step 22400 loss 0.026732951402664185
[2025-03-14 14:56:21,603][model][INFO] - Training step 22560 loss 0.026392746716737747
[2025-03-14 14:57:02,282][model][INFO] - Training step 22720 loss 0.01195805985480547
[2025-03-14 14:57:42,203][model][INFO] - Training step 22880 loss 0.016752328723669052
[2025-03-14 14:58:22,797][model][INFO] - Training step 23040 loss 0.04100355505943298
[2025-03-14 14:59:03,873][model][INFO] - Training step 23200 loss 0.00789374765008688
[2025-03-14 14:59:43,679][model][INFO] - Training step 23360 loss 0.03151974454522133
[2025-03-14 15:00:24,394][model][INFO] - Training step 23520 loss 0.02238655649125576
[2025-03-14 15:01:05,837][model][INFO] - Training step 23680 loss 0.07068420946598053
[2025-03-14 15:01:47,589][model][INFO] - Training step 23840 loss 0.2493503838777542
[2025-03-14 15:02:27,569][model][INFO] - Training step 24000 loss 0.1344933807849884
[2025-03-14 15:03:06,474][model][INFO] - Training step 24160 loss 0.023006659001111984
[2025-03-14 15:03:46,880][model][INFO] - Training step 24320 loss 0.07337065041065216
[2025-03-14 15:04:26,857][model][INFO] - Training step 24480 loss 0.010434979572892189
[2025-03-14 15:05:06,686][model][INFO] - Training step 24640 loss 0.25607413053512573
[2025-03-14 15:05:46,057][model][INFO] - Training step 24800 loss 0.03607656806707382
[2025-03-14 15:06:26,203][model][INFO] - Training step 24960 loss 0.027294036000967026
[2025-03-14 15:07:07,533][model][INFO] - Training step 25120 loss 0.07389839738607407
[2025-03-14 15:07:46,425][model][INFO] - Training step 25280 loss 0.015130222775042057
[2025-03-14 15:08:26,460][model][INFO] - Training step 25440 loss 0.0060727400705218315
[2025-03-14 15:09:04,606][model][INFO] - Training step 25600 loss 0.03812097758054733
[2025-03-14 15:09:43,287][model][INFO] - Training step 25760 loss 0.0529104508459568
[2025-03-14 15:10:24,048][model][INFO] - Training step 25920 loss 0.039734311401844025
[2025-03-14 15:11:04,094][model][INFO] - Training step 26080 loss 0.02115698717534542
[2025-03-14 15:11:44,599][model][INFO] - Training step 26240 loss 0.020665764808654785
[2025-03-14 15:12:26,289][model][INFO] - Training step 26400 loss 0.02619026228785515
[2025-03-14 15:13:07,118][model][INFO] - Training step 26560 loss 0.02219710499048233
[2025-03-14 15:13:48,875][model][INFO] - Training step 26720 loss 0.033380236476659775
[2025-03-14 15:14:28,685][model][INFO] - Training step 26880 loss 0.02663007192313671
[2025-03-14 15:15:09,284][model][INFO] - Training step 27040 loss 0.2617698311805725
[2025-03-14 15:15:50,564][model][INFO] - Training step 27200 loss 0.017580803483724594
[2025-03-14 15:16:30,808][model][INFO] - Training step 27360 loss 0.03553912043571472
[2025-03-14 15:17:10,873][model][INFO] - Training step 27520 loss 0.028701718896627426
[2025-03-14 15:17:52,530][model][INFO] - Training step 27680 loss 0.029420964419841766
[2025-03-14 15:18:33,356][model][INFO] - Training step 27840 loss 0.025711311027407646
[2025-03-14 15:19:13,629][model][INFO] - Training step 28000 loss 0.02215755358338356
[2025-03-14 15:19:54,704][model][INFO] - Training step 28160 loss 0.017116602510213852
[2025-03-14 15:20:37,188][model][INFO] - Training step 28320 loss 0.23167850077152252
[2025-03-14 15:21:18,295][model][INFO] - Training step 28480 loss 0.03278367593884468
[2025-03-14 15:21:59,586][model][INFO] - Training step 28640 loss 0.035535089671611786
[2025-03-14 15:22:38,765][model][INFO] - Training step 28800 loss 0.0024885141756385565
[2025-03-14 15:23:19,356][model][INFO] - Training step 28960 loss 0.07795348763465881
[2025-03-14 15:23:59,015][model][INFO] - Training step 29120 loss 0.23233947157859802
[2025-03-14 15:24:39,708][model][INFO] - Training step 29280 loss 0.020061396062374115
[2025-03-14 15:25:22,250][model][INFO] - Training step 29440 loss 0.01986561343073845
[2025-03-14 15:26:02,613][model][INFO] - Training step 29600 loss 0.06925800442695618
[2025-03-14 15:26:43,444][model][INFO] - Training step 29760 loss 0.03551226854324341
[2025-03-14 15:27:24,916][model][INFO] - Training step 29920 loss 0.23472818732261658
[2025-03-14 15:28:05,920][model][INFO] - Training step 30080 loss 0.002485552104189992
[2025-03-14 15:28:45,976][model][INFO] - Training step 30240 loss 0.030590619891881943
[2025-03-14 15:29:27,185][model][INFO] - Training step 30400 loss 0.231583371758461
[2025-03-14 15:30:09,758][model][INFO] - Training step 30560 loss 0.2994893193244934
[2025-03-14 15:30:48,701][model][INFO] - Training step 30720 loss 0.068998321890831
[2025-03-14 15:31:28,179][model][INFO] - Training step 30880 loss 0.06558587402105331
[2025-03-14 15:32:09,883][model][INFO] - Training step 31040 loss 0.02363588474690914
[2025-03-14 15:32:50,149][model][INFO] - Training step 31200 loss 0.018840104341506958
[2025-03-14 15:33:31,493][model][INFO] - Training step 31360 loss 0.03245805203914642
[2025-03-14 15:34:11,837][model][INFO] - Training step 31520 loss 0.08687509596347809
[2025-03-14 15:34:52,881][model][INFO] - Training step 31680 loss 0.24600887298583984
[2025-03-14 15:35:33,466][model][INFO] - Training step 31840 loss 0.004119472578167915
[2025-03-14 15:36:14,501][model][INFO] - Training step 32000 loss 0.005582970567047596
[2025-03-14 15:36:54,409][model][INFO] - Training step 32160 loss 0.05078927427530289
[2025-03-14 15:37:34,923][model][INFO] - Training step 32320 loss 0.01955494098365307
[2025-03-14 15:38:15,106][model][INFO] - Training step 32480 loss 0.253470242023468
[2025-03-14 15:38:56,370][model][INFO] - Training step 32640 loss 0.04020805284380913
[2025-03-14 15:39:37,931][model][INFO] - Training step 32800 loss 0.11405761539936066
[2025-03-14 15:40:19,594][model][INFO] - Training step 32960 loss 0.025219406932592392
[2025-03-14 15:41:00,247][model][INFO] - Training step 33120 loss 0.2513600289821625
[2025-03-14 15:41:40,674][model][INFO] - Training step 33280 loss 0.25073012709617615
[2025-03-14 15:42:21,974][model][INFO] - Training step 33440 loss 0.026785368099808693
[2025-03-14 15:43:01,786][model][INFO] - Training step 33600 loss 0.05991178750991821
[2025-03-14 15:43:43,140][model][INFO] - Training step 33760 loss 0.08940328657627106
[2025-03-14 15:44:24,703][model][INFO] - Training step 33920 loss 0.007951067760586739
[2025-03-14 15:45:05,440][model][INFO] - Training step 34080 loss 0.017581216990947723
[2025-03-14 15:45:46,563][model][INFO] - Training step 34240 loss 0.02565820701420307
[2025-03-14 15:46:27,561][model][INFO] - Training step 34400 loss 0.025926880538463593
[2025-03-14 15:47:07,849][model][INFO] - Training step 34560 loss 0.03037978708744049
[2025-03-14 15:47:49,021][model][INFO] - Training step 34720 loss 0.04013796150684357
[2025-03-14 15:48:30,935][model][INFO] - Training step 34880 loss 0.01818598434329033
[2025-03-14 15:49:12,254][model][INFO] - Training step 35040 loss 0.24677643179893494
[2025-03-14 15:49:52,278][model][INFO] - Training step 35200 loss 0.011617591604590416
[2025-03-14 15:50:33,044][model][INFO] - Training step 35360 loss 0.02744145318865776
[2025-03-14 15:51:13,789][model][INFO] - Training step 35520 loss 0.05151048302650452
[2025-03-14 15:51:54,821][model][INFO] - Training step 35680 loss 0.016746150329709053
[2025-03-14 15:52:35,925][model][INFO] - Training step 35840 loss 0.006858297623693943
[2025-03-14 15:53:15,431][model][INFO] - Training step 36000 loss 0.026980649679899216
[2025-03-14 15:53:56,050][model][INFO] - Training step 36160 loss 0.027316436171531677
[2025-03-14 15:54:36,665][model][INFO] - Training step 36320 loss 0.11923961341381073
[2025-03-14 15:55:16,952][model][INFO] - Training step 36480 loss 0.020555952563881874
[2025-03-14 15:55:58,075][model][INFO] - Training step 36640 loss 0.03635215759277344
[2025-03-14 15:56:38,959][model][INFO] - Training step 36800 loss 0.10251393169164658
[2025-03-14 15:57:20,071][model][INFO] - Training step 36960 loss 0.017105570062994957
[2025-03-14 15:58:00,031][model][INFO] - Training step 37120 loss 0.03632393851876259
[2025-03-14 15:58:40,418][model][INFO] - Training step 37280 loss 0.05993924289941788
[2025-03-14 15:59:23,305][model][INFO] - Training step 37440 loss 0.003767707385122776
[2025-03-14 16:00:03,771][model][INFO] - Training step 37600 loss 0.022351060062646866
[2025-03-14 16:00:44,423][model][INFO] - Training step 37760 loss 0.20915907621383667
[2025-03-14 16:01:24,931][model][INFO] - Training step 37920 loss 0.012419383972883224
[2025-03-14 16:02:05,285][model][INFO] - Training step 38080 loss 0.023319870233535767
[2025-03-14 16:02:44,840][model][INFO] - Training step 38240 loss 0.020467577502131462
[2025-03-14 16:03:26,797][model][INFO] - Training step 38400 loss 0.02409481629729271
[2025-03-14 16:04:09,243][model][INFO] - Training step 38560 loss 0.2590923607349396
[2025-03-14 16:04:51,011][model][INFO] - Training step 38720 loss 0.10592588782310486
[2025-03-14 16:05:32,193][model][INFO] - Training step 38880 loss 0.029969990253448486
[2025-03-14 16:06:12,575][model][INFO] - Training step 39040 loss 0.25081926584243774
[2025-03-14 16:06:52,779][model][INFO] - Training step 39200 loss 0.007148861885070801
[2025-03-14 16:07:32,815][model][INFO] - Training step 39360 loss 0.0396316722035408
[2025-03-14 16:08:14,424][model][INFO] - Training step 39520 loss 0.025008704513311386
[2025-03-14 16:08:55,595][model][INFO] - Training step 39680 loss 0.017893286421895027
[2025-03-14 16:09:35,732][model][INFO] - Training step 39840 loss 0.2439311146736145
[2025-03-14 16:10:16,081][model][INFO] - Training step 40000 loss 0.022242624312639236
[2025-03-14 16:10:58,179][model][INFO] - Training step 40160 loss 0.06865827739238739
[2025-03-14 16:11:39,690][model][INFO] - Training step 40320 loss 0.14726859331130981
[2025-03-14 16:12:20,767][model][INFO] - Training step 40480 loss 0.03585725277662277
[2025-03-14 16:13:02,026][model][INFO] - Training step 40640 loss 0.023196939378976822
[2025-03-14 16:13:41,930][model][INFO] - Training step 40800 loss 0.01478850468993187
[2025-03-14 16:14:22,587][model][INFO] - Training step 40960 loss 0.27797529101371765
[2025-03-14 16:15:02,505][model][INFO] - Training step 41120 loss 0.009641441516578197
[2025-03-14 16:15:43,899][model][INFO] - Training step 41280 loss 0.004158952739089727
[2025-03-14 16:16:24,193][model][INFO] - Training step 41440 loss 0.06309133768081665
[2025-03-14 16:17:03,640][model][INFO] - Training step 41600 loss 0.24752306938171387
[2025-03-14 16:17:44,266][model][INFO] - Training step 41760 loss 0.016545113176107407
[2025-03-14 16:18:24,803][model][INFO] - Training step 41920 loss 0.021019740030169487
[2025-03-14 16:19:04,673][model][INFO] - Training step 42080 loss 0.02019723877310753
[2025-03-14 16:19:45,689][model][INFO] - Training step 42240 loss 0.24765153229236603
[2025-03-14 16:20:27,946][model][INFO] - Training step 42400 loss 0.030770940706133842
[2025-03-14 16:21:08,978][model][INFO] - Training step 42560 loss 0.007166242226958275
[2025-03-14 16:21:50,189][model][INFO] - Training step 42720 loss 0.0199423935264349
[2025-03-14 16:22:31,448][model][INFO] - Training step 42880 loss 0.25314366817474365
[2025-03-14 16:23:12,239][model][INFO] - Training step 43040 loss 0.05645398795604706
[2025-03-14 16:23:55,396][model][INFO] - Training step 43200 loss 0.029450245201587677
[2025-03-14 16:24:38,157][model][INFO] - Training step 43360 loss 0.04101201146841049
[2025-03-14 16:25:18,836][model][INFO] - Training step 43520 loss 0.021817464381456375
[2025-03-14 16:25:58,358][model][INFO] - Training step 43680 loss 0.02358332835137844
[2025-03-14 16:26:38,876][model][INFO] - Training step 43840 loss 0.02853453904390335
[2025-03-14 16:27:20,483][model][INFO] - Training step 44000 loss 0.04826323688030243
[2025-03-14 16:28:00,783][model][INFO] - Training step 44160 loss 0.0052151307463645935
[2025-03-14 16:28:43,371][model][INFO] - Training step 44320 loss 0.018335839733481407
[2025-03-14 16:29:25,560][model][INFO] - Training step 44480 loss 0.021274855360388756
[2025-03-14 16:30:05,625][model][INFO] - Training step 44640 loss 0.0214836522936821
[2025-03-14 16:30:46,347][model][INFO] - Training step 44800 loss 0.01877882331609726
[2025-03-14 16:31:27,828][model][INFO] - Training step 44960 loss 0.00412047328427434
[2025-03-14 16:32:08,698][model][INFO] - Training step 45120 loss 0.0467945896089077
[2025-03-14 16:32:49,265][model][INFO] - Training step 45280 loss 0.10412813723087311
[2025-03-14 16:33:32,387][model][INFO] - Training step 45440 loss 0.012839416041970253
[2025-03-14 16:34:11,701][model][INFO] - Training step 45600 loss 0.18586790561676025
[2025-03-14 16:34:52,459][model][INFO] - Training step 45760 loss 0.02920261211693287
[2025-03-14 16:35:33,610][model][INFO] - Training step 45920 loss 0.023459242656826973
[2025-03-14 16:36:14,606][model][INFO] - Training step 46080 loss 0.006789558567106724
[2025-03-14 16:36:54,794][model][INFO] - Training step 46240 loss 0.026828933507204056
[2025-03-14 16:37:36,329][model][INFO] - Training step 46400 loss 0.21213668584823608
[2025-03-14 16:38:17,182][model][INFO] - Training step 46560 loss 0.005117055028676987
[2025-03-14 16:38:58,292][model][INFO] - Training step 46720 loss 0.03993390128016472
[2025-03-14 16:39:38,141][model][INFO] - Training step 46880 loss 0.023817259818315506
[2025-03-14 16:40:19,085][model][INFO] - Training step 47040 loss 0.0592467337846756
[2025-03-14 16:40:59,628][model][INFO] - Training step 47200 loss 0.02439257502555847
[2025-03-14 16:41:41,542][model][INFO] - Training step 47360 loss 0.2507905960083008
[2025-03-14 16:42:22,298][model][INFO] - Training step 47520 loss 0.016317617148160934
[2025-03-14 16:43:04,812][model][INFO] - Training step 47680 loss 0.03343575447797775
[2025-03-14 16:43:43,491][model][INFO] - Training step 47840 loss 0.03224751353263855
[2025-03-14 16:44:24,117][model][INFO] - Training step 48000 loss 0.25375211238861084
[2025-03-14 16:45:06,175][model][INFO] - Training step 48160 loss 0.023454507812857628
[2025-03-14 16:45:46,513][model][INFO] - Training step 48320 loss 0.020918767899274826
[2025-03-14 16:46:27,378][model][INFO] - Training step 48480 loss 0.24842596054077148
[2025-03-14 16:47:07,225][model][INFO] - Training step 48640 loss 0.030794378370046616
[2025-03-14 16:47:48,161][model][INFO] - Training step 48800 loss 0.0629306212067604
[2025-03-14 16:48:28,082][model][INFO] - Training step 48960 loss 0.22613507509231567
[2025-03-14 16:49:08,522][model][INFO] - Training step 49120 loss 0.01775727979838848
[2025-03-14 16:49:49,405][model][INFO] - Training step 49280 loss 0.026922795921564102
[2025-03-14 16:50:30,956][model][INFO] - Training step 49440 loss 0.022272180765867233
[2025-03-14 16:51:11,681][model][INFO] - Training step 49600 loss 0.10214824229478836
[2025-03-14 16:51:51,456][model][INFO] - Training step 49760 loss 0.059629857540130615
[2025-03-14 16:52:32,239][model][INFO] - Training step 49920 loss 0.016142524778842926
[2025-03-14 16:53:13,033][model][INFO] - Training step 50080 loss 0.05633129924535751
[2025-03-14 16:53:55,481][model][INFO] - Training step 50240 loss 0.26668041944503784
[2025-03-14 16:54:36,456][model][INFO] - Training step 50400 loss 0.018848802894353867
[2025-03-14 16:55:16,082][model][INFO] - Training step 50560 loss 0.029694467782974243
[2025-03-14 16:55:56,714][model][INFO] - Training step 50720 loss 0.03604426607489586
[2025-03-14 17:01:53,120][model][INFO] - Training step 80 loss 0.004215565510094166
[2025-03-14 17:02:33,635][model][INFO] - Training step 240 loss 0.033804893493652344
[2025-03-14 17:03:15,354][model][INFO] - Training step 400 loss 0.052572280168533325
[2025-03-14 17:03:54,331][model][INFO] - Training step 560 loss 0.01973724365234375
[2025-03-14 17:04:34,886][model][INFO] - Training step 720 loss 0.04845406115055084
[2025-03-14 17:05:14,078][model][INFO] - Training step 880 loss 0.041055552661418915
[2025-03-14 17:05:54,365][model][INFO] - Training step 1040 loss 0.013858569785952568
[2025-03-14 17:06:35,983][model][INFO] - Training step 1200 loss 0.06050499528646469
[2025-03-14 17:07:18,724][model][INFO] - Training step 1360 loss 0.003451596014201641
[2025-03-14 17:08:00,122][model][INFO] - Training step 1520 loss 0.05818076431751251
[2025-03-14 17:08:40,494][model][INFO] - Training step 1680 loss 0.10598846524953842
[2025-03-14 17:09:21,300][model][INFO] - Training step 1840 loss 0.0356404110789299
[2025-03-14 17:10:00,856][model][INFO] - Training step 2000 loss 0.2969176173210144
[2025-03-14 17:10:40,540][model][INFO] - Training step 2160 loss 0.024972427636384964
[2025-03-14 17:11:20,865][model][INFO] - Training step 2320 loss 0.09977521747350693
[2025-03-14 17:12:01,589][model][INFO] - Training step 2480 loss 0.004097338765859604
[2025-03-14 17:12:41,338][model][INFO] - Training step 2640 loss 0.2529295086860657
[2025-03-14 17:13:22,019][model][INFO] - Training step 2800 loss 0.034088365733623505
[2025-03-14 17:14:03,619][model][INFO] - Training step 2960 loss 0.005396113730967045
[2025-03-14 17:14:43,929][model][INFO] - Training step 3120 loss 0.1534828394651413
[2025-03-14 17:15:24,205][model][INFO] - Training step 3280 loss 0.03178585320711136
[2025-03-14 17:16:04,635][model][INFO] - Training step 3440 loss 0.0068529220297932625
[2025-03-14 17:16:43,942][model][INFO] - Training step 3600 loss 0.24572670459747314
[2025-03-14 17:17:24,875][model][INFO] - Training step 3760 loss 0.2646994888782501
[2025-03-14 17:18:04,202][model][INFO] - Training step 3920 loss 0.019181614741683006
[2025-03-14 17:18:45,483][model][INFO] - Training step 4080 loss 0.030811432749032974
[2025-03-14 17:19:25,519][model][INFO] - Training step 4240 loss 0.005511901341378689
[2025-03-14 17:20:05,672][model][INFO] - Training step 4400 loss 0.014947153627872467
[2025-03-14 17:20:46,293][model][INFO] - Training step 4560 loss 0.027569759637117386
[2025-03-14 17:21:28,369][model][INFO] - Training step 4720 loss 0.026104867458343506
[2025-03-14 17:22:08,366][model][INFO] - Training step 4880 loss 0.10467497259378433
[2025-03-14 17:22:49,011][model][INFO] - Training step 5040 loss 0.2825319766998291
[2025-03-14 17:23:29,263][model][INFO] - Training step 5200 loss 0.0638933777809143
[2025-03-14 17:24:09,502][model][INFO] - Training step 5360 loss 0.2516973316669464
[2025-03-14 17:24:50,064][model][INFO] - Training step 5520 loss 0.12359889596700668
[2025-03-14 17:25:30,588][model][INFO] - Training step 5680 loss 0.01582275703549385
[2025-03-14 17:26:12,141][model][INFO] - Training step 5840 loss 0.004918121267110109
[2025-03-14 17:26:53,050][model][INFO] - Training step 6000 loss 0.01429801806807518
[2025-03-14 17:27:33,816][model][INFO] - Training step 6160 loss 0.047151483595371246
[2025-03-14 17:28:15,827][model][INFO] - Training step 6320 loss 0.12158522754907608
[2025-03-14 17:28:58,701][model][INFO] - Training step 6480 loss 0.03266798332333565
[2025-03-14 17:29:39,570][model][INFO] - Training step 6640 loss 0.006879817228764296
[2025-03-14 17:30:19,539][model][INFO] - Training step 6800 loss 0.016328714787960052
[2025-03-14 17:30:59,310][model][INFO] - Training step 6960 loss 0.04392222315073013
[2025-03-14 17:31:40,573][model][INFO] - Training step 7120 loss 0.2514582872390747
[2025-03-14 17:32:21,223][model][INFO] - Training step 7280 loss 0.2611996829509735
[2025-03-14 17:33:01,635][model][INFO] - Training step 7440 loss 0.01739167794585228
[2025-03-14 17:33:43,300][model][INFO] - Training step 7600 loss 0.03581758588552475
[2025-03-14 17:34:25,155][model][INFO] - Training step 7760 loss 0.06373657286167145
[2025-03-14 17:35:05,329][model][INFO] - Training step 7920 loss 0.002470018807798624
[2025-03-14 17:35:44,825][model][INFO] - Training step 8080 loss 0.024584520608186722
[2025-03-14 17:36:22,745][model][INFO] - Training step 8240 loss 0.2520350217819214
[2025-03-14 17:37:02,834][model][INFO] - Training step 8400 loss 0.034436751157045364
[2025-03-14 17:37:44,490][model][INFO] - Training step 8560 loss 0.01956917904317379
[2025-03-14 17:38:24,557][model][INFO] - Training step 8720 loss 0.04831228405237198
[2025-03-14 17:39:05,418][model][INFO] - Training step 8880 loss 0.027672473341226578
[2025-03-14 17:39:45,265][model][INFO] - Training step 9040 loss 0.01370109710842371
[2025-03-14 17:40:23,710][model][INFO] - Training step 9200 loss 0.10782971978187561
[2025-03-14 17:41:03,424][model][INFO] - Training step 9360 loss 0.005423264112323523
[2025-03-14 17:41:44,934][model][INFO] - Training step 9520 loss 0.015178767032921314
[2025-03-14 17:42:26,760][model][INFO] - Training step 9680 loss 0.07277581095695496
[2025-03-14 17:43:08,229][model][INFO] - Training step 9840 loss 0.24846228957176208
[2025-03-14 17:43:50,254][model][INFO] - Training step 10000 loss 0.02053871750831604
[2025-03-14 17:44:31,652][model][INFO] - Training step 10160 loss 0.027306482195854187
[2025-03-14 17:45:13,851][model][INFO] - Training step 10320 loss 0.006165426690131426
[2025-03-14 17:45:52,921][model][INFO] - Training step 10480 loss 0.057345252484083176
[2025-03-14 17:46:32,786][model][INFO] - Training step 10640 loss 0.25192099809646606
[2025-03-14 17:47:12,883][model][INFO] - Training step 10800 loss 0.25092941522598267
[2025-03-14 17:47:53,048][model][INFO] - Training step 10960 loss 0.05558105930685997
[2025-03-14 17:48:33,493][model][INFO] - Training step 11120 loss 0.01971897855401039
[2025-03-14 17:49:11,892][model][INFO] - Training step 11280 loss 0.005506017245352268
[2025-03-14 17:49:51,753][model][INFO] - Training step 11440 loss 0.022986654192209244
[2025-03-14 17:50:31,856][model][INFO] - Training step 11600 loss 0.2522459626197815
[2025-03-14 17:51:11,949][model][INFO] - Training step 11760 loss 0.0274520106613636
[2025-03-14 17:51:53,039][model][INFO] - Training step 11920 loss 0.2859196066856384
[2025-03-14 17:52:34,931][model][INFO] - Training step 12080 loss 0.2525932788848877
[2025-03-14 17:53:16,473][model][INFO] - Training step 12240 loss 0.12065856158733368
[2025-03-14 17:53:57,190][model][INFO] - Training step 12400 loss 0.01868521422147751
[2025-03-14 17:54:38,277][model][INFO] - Training step 12560 loss 0.028007902204990387
[2025-03-14 17:55:18,602][model][INFO] - Training step 12720 loss 0.031085588037967682
[2025-03-14 17:55:58,850][model][INFO] - Training step 12880 loss 0.017471708357334137
[2025-03-14 17:56:40,967][model][INFO] - Training step 13040 loss 0.2568833827972412
[2025-03-14 17:57:22,103][model][INFO] - Training step 13200 loss 0.010107608512043953
[2025-03-14 17:58:02,973][model][INFO] - Training step 13360 loss 0.1106446236371994
[2025-03-14 17:58:44,097][model][INFO] - Training step 13520 loss 0.031109444797039032
[2025-03-14 17:59:24,577][model][INFO] - Training step 13680 loss 0.01353733241558075
[2025-03-14 18:00:04,368][model][INFO] - Training step 13840 loss 0.019841846078634262
[2025-03-14 18:00:44,781][model][INFO] - Training step 14000 loss 0.02077862247824669
[2025-03-14 18:01:25,272][model][INFO] - Training step 14160 loss 0.0025463104248046875
[2025-03-14 18:02:05,379][model][INFO] - Training step 14320 loss 0.25212281942367554
[2025-03-14 18:02:46,532][model][INFO] - Training step 14480 loss 0.029283076524734497
[2025-03-14 18:03:28,987][model][INFO] - Training step 14640 loss 0.02519623562693596
[2025-03-14 18:04:10,447][model][INFO] - Training step 14800 loss 0.062045738101005554
[2025-03-14 18:04:50,593][model][INFO] - Training step 14960 loss 0.017700372263789177
[2025-03-14 18:05:32,318][model][INFO] - Training step 15120 loss 0.23619452118873596
[2025-03-14 18:06:13,602][model][INFO] - Training step 15280 loss 0.24014633893966675
[2025-03-14 18:06:54,258][model][INFO] - Training step 15440 loss 0.014069823548197746
[2025-03-14 18:07:34,987][model][INFO] - Training step 15600 loss 0.2524607181549072
[2025-03-14 18:08:14,541][model][INFO] - Training step 15760 loss 0.04960966855287552
[2025-03-14 18:08:55,750][model][INFO] - Training step 15920 loss 0.2459632158279419
[2025-03-14 18:09:35,148][model][INFO] - Training step 16080 loss 0.03294149786233902
[2025-03-14 18:10:15,215][model][INFO] - Training step 16240 loss 0.2506171464920044
[2025-03-14 18:10:57,136][model][INFO] - Training step 16400 loss 0.010753256268799305
[2025-03-14 18:11:37,572][model][INFO] - Training step 16560 loss 0.04041285440325737
[2025-03-14 18:12:16,818][model][INFO] - Training step 16720 loss 0.253823459148407
[2025-03-14 18:12:58,819][model][INFO] - Training step 16880 loss 0.023855281993746758
[2025-03-14 18:13:39,601][model][INFO] - Training step 17040 loss 0.2464391440153122
[2025-03-14 18:14:21,176][model][INFO] - Training step 17200 loss 0.05245792120695114
[2025-03-14 18:15:01,461][model][INFO] - Training step 17360 loss 0.016778837889432907
[2025-03-14 18:15:41,697][model][INFO] - Training step 17520 loss 0.0740327537059784
[2025-03-14 18:16:23,536][model][INFO] - Training step 17680 loss 0.0025385511107742786
[2025-03-14 18:17:03,292][model][INFO] - Training step 17840 loss 0.25569427013397217
[2025-03-14 18:17:42,884][model][INFO] - Training step 18000 loss 0.028089603409171104
[2025-03-14 18:18:25,547][model][INFO] - Training step 18160 loss 0.023034270852804184
[2025-03-14 18:19:07,291][model][INFO] - Training step 18320 loss 0.022350503131747246
[2025-03-14 18:19:47,763][model][INFO] - Training step 18480 loss 0.021069474518299103
[2025-03-14 18:20:29,562][model][INFO] - Training step 18640 loss 0.004872244782745838
[2025-03-14 18:21:11,101][model][INFO] - Training step 18800 loss 0.018540196120738983
[2025-03-14 18:21:51,046][model][INFO] - Training step 18960 loss 0.005936522036790848
[2025-03-14 18:22:31,761][model][INFO] - Training step 19120 loss 0.017497913911938667
[2025-03-14 18:23:10,960][model][INFO] - Training step 19280 loss 0.006283747032284737
[2025-03-14 18:23:51,866][model][INFO] - Training step 19440 loss 0.026222623884677887
[2025-03-14 18:24:31,811][model][INFO] - Training step 19600 loss 0.006398078054189682
[2025-03-14 18:25:13,166][model][INFO] - Training step 19760 loss 0.25999677181243896
[2025-03-14 18:25:54,378][model][INFO] - Training step 19920 loss 0.0025571295991539955
[2025-03-14 18:26:35,358][model][INFO] - Training step 20080 loss 0.04644894227385521
[2025-03-14 18:27:13,998][model][INFO] - Training step 20240 loss 0.02445194497704506
[2025-03-14 18:27:54,189][model][INFO] - Training step 20400 loss 0.10944456607103348
[2025-03-14 18:28:34,324][model][INFO] - Training step 20560 loss 0.019646119326353073
[2025-03-14 18:29:14,776][model][INFO] - Training step 20720 loss 0.10146456956863403
[2025-03-14 18:29:56,660][model][INFO] - Training step 20880 loss 0.20094837248325348
[2025-03-14 18:30:37,621][model][INFO] - Training step 21040 loss 0.029153142124414444
[2025-03-14 18:31:21,162][model][INFO] - Training step 21200 loss 0.00771955493837595
[2025-03-14 18:32:02,545][model][INFO] - Training step 21360 loss 0.09084531664848328
[2025-03-14 18:32:43,101][model][INFO] - Training step 21520 loss 0.03306455537676811
[2025-03-14 18:33:24,401][model][INFO] - Training step 21680 loss 0.03609699755907059
[2025-03-14 18:34:03,704][model][INFO] - Training step 21840 loss 0.0194629468023777
[2025-03-14 18:34:43,519][model][INFO] - Training step 22000 loss 0.2782009541988373
[2025-03-14 18:35:23,204][model][INFO] - Training step 22160 loss 0.2500598728656769
[2025-03-14 18:36:06,036][model][INFO] - Training step 22320 loss 0.1426437497138977
[2025-03-14 18:36:45,385][model][INFO] - Training step 22480 loss 0.009510560892522335
[2025-03-14 18:37:26,218][model][INFO] - Training step 22640 loss 0.12769153714179993
[2025-03-14 18:38:07,962][model][INFO] - Training step 22800 loss 0.02565879002213478
[2025-03-14 18:38:48,436][model][INFO] - Training step 22960 loss 0.018088366836309433
[2025-03-14 18:39:28,950][model][INFO] - Training step 23120 loss 0.27190667390823364
[2025-03-14 18:40:09,482][model][INFO] - Training step 23280 loss 0.12805795669555664
[2025-03-14 18:40:49,705][model][INFO] - Training step 23440 loss 0.25081712007522583
[2025-03-14 18:41:29,059][model][INFO] - Training step 23600 loss 0.03789279982447624
[2025-03-14 18:42:08,596][model][INFO] - Training step 23760 loss 0.04886516183614731
[2025-03-14 18:42:49,753][model][INFO] - Training step 23920 loss 0.02778368815779686
[2025-03-14 18:43:30,148][model][INFO] - Training step 24080 loss 0.03746458888053894
[2025-03-14 18:44:09,875][model][INFO] - Training step 24240 loss 0.02559008076786995
[2025-03-14 18:44:47,901][model][INFO] - Training step 24400 loss 0.033706218004226685
[2025-03-14 18:45:29,192][model][INFO] - Training step 24560 loss 0.06477657705545425
[2025-03-14 18:46:09,130][model][INFO] - Training step 24720 loss 0.08002642542123795
[2025-03-14 18:46:50,034][model][INFO] - Training step 24880 loss 0.26804855465888977
[2025-03-14 18:47:30,541][model][INFO] - Training step 25040 loss 0.007864302024245262
[2025-03-14 18:48:10,277][model][INFO] - Training step 25200 loss 0.039078935980796814
[2025-03-14 18:48:50,030][model][INFO] - Training step 25360 loss 0.25244519114494324
[2025-03-14 18:49:29,811][model][INFO] - Training step 25520 loss 0.003968497738242149
[2025-03-14 18:50:11,334][model][INFO] - Training step 25680 loss 0.0025132903829216957
[2025-03-14 18:50:50,989][model][INFO] - Training step 25840 loss 0.20254182815551758
[2025-03-14 18:51:32,442][model][INFO] - Training step 26000 loss 0.054765380918979645
[2025-03-14 18:52:13,221][model][INFO] - Training step 26160 loss 0.006230782251805067
[2025-03-14 18:52:53,276][model][INFO] - Training step 26320 loss 0.03743797540664673
[2025-03-14 18:53:34,274][model][INFO] - Training step 26480 loss 0.030452009290456772
[2025-03-14 18:54:13,962][model][INFO] - Training step 26640 loss 0.027860285714268684
[2025-03-14 18:54:54,693][model][INFO] - Training step 26800 loss 0.014393879100680351
[2025-03-14 18:55:36,000][model][INFO] - Training step 26960 loss 0.02780994400382042
[2025-03-14 18:56:16,844][model][INFO] - Training step 27120 loss 0.22423167526721954
[2025-03-14 18:56:56,851][model][INFO] - Training step 27280 loss 0.0059988051652908325
[2025-03-14 18:57:37,166][model][INFO] - Training step 27440 loss 0.0030108466744422913
[2025-03-14 18:58:16,882][model][INFO] - Training step 27600 loss 0.06210053712129593
[2025-03-14 18:58:57,409][model][INFO] - Training step 27760 loss 0.030350040644407272
[2025-03-14 18:59:37,134][model][INFO] - Training step 27920 loss 0.012329576537013054
[2025-03-14 19:00:18,274][model][INFO] - Training step 28080 loss 0.2513887882232666
[2025-03-14 19:00:59,014][model][INFO] - Training step 28240 loss 0.038556233048439026
[2025-03-14 19:01:39,288][model][INFO] - Training step 28400 loss 0.23676452040672302
[2025-03-14 19:02:19,871][model][INFO] - Training step 28560 loss 0.19240137934684753
[2025-03-14 19:02:58,773][model][INFO] - Training step 28720 loss 0.018083037808537483
[2025-03-14 19:03:39,052][model][INFO] - Training step 28880 loss 0.24288269877433777
[2025-03-14 19:04:19,933][model][INFO] - Training step 29040 loss 0.024266384541988373
[2025-03-14 19:05:01,852][model][INFO] - Training step 29200 loss 0.004455420188605785
[2025-03-14 19:05:44,074][model][INFO] - Training step 29360 loss 0.012845991179347038
[2025-03-14 19:06:26,188][model][INFO] - Training step 29520 loss 0.2545158863067627
[2025-03-14 19:07:09,260][model][INFO] - Training step 29680 loss 0.05544237047433853
[2025-03-14 19:07:49,288][model][INFO] - Training step 29840 loss 0.0316745862364769
[2025-03-14 19:08:30,105][model][INFO] - Training step 30000 loss 0.050590887665748596
[2025-03-14 19:09:10,219][model][INFO] - Training step 30160 loss 0.00619086716324091
[2025-03-14 19:09:51,755][model][INFO] - Training step 30320 loss 0.025057964026927948
[2025-03-14 19:10:33,187][model][INFO] - Training step 30480 loss 0.2657628655433655
[2025-03-14 19:11:12,581][model][INFO] - Training step 30640 loss 0.023200087249279022
[2025-03-14 19:11:51,374][model][INFO] - Training step 30800 loss 0.004132960457354784
[2025-03-14 19:12:33,758][model][INFO] - Training step 30960 loss 0.10768964886665344
[2025-03-14 19:13:17,216][model][INFO] - Training step 31120 loss 0.03540938347578049
[2025-03-14 19:13:56,556][model][INFO] - Training step 31280 loss 0.05229814350605011
[2025-03-14 19:14:36,762][model][INFO] - Training step 31440 loss 0.031286224722862244
[2025-03-14 19:15:18,939][model][INFO] - Training step 31600 loss 0.025182077661156654
[2025-03-14 19:15:59,311][model][INFO] - Training step 31760 loss 0.04772220551967621
[2025-03-14 19:16:40,244][model][INFO] - Training step 31920 loss 0.02463197335600853
[2025-03-14 19:17:20,511][model][INFO] - Training step 32080 loss 0.03695371001958847
[2025-03-14 19:18:02,394][model][INFO] - Training step 32240 loss 0.030262146145105362
[2025-03-14 19:18:44,031][model][INFO] - Training step 32400 loss 0.0024725899565964937
[2025-03-14 19:19:24,518][model][INFO] - Training step 32560 loss 0.026931656524538994
[2025-03-14 19:20:06,525][model][INFO] - Training step 32720 loss 0.007368714548647404
[2025-03-14 19:20:48,716][model][INFO] - Training step 32880 loss 0.1502618044614792
[2025-03-14 19:21:29,222][model][INFO] - Training step 33040 loss 0.052715547382831573
[2025-03-14 19:22:10,218][model][INFO] - Training step 33200 loss 0.023535754531621933
[2025-03-14 19:22:49,446][model][INFO] - Training step 33360 loss 0.019301192834973335
[2025-03-14 19:23:29,308][model][INFO] - Training step 33520 loss 0.04851154237985611
[2025-03-14 19:24:09,577][model][INFO] - Training step 33680 loss 0.011162295937538147
[2025-03-14 19:24:50,549][model][INFO] - Training step 33840 loss 0.034918300807476044
[2025-03-14 19:25:29,150][model][INFO] - Training step 34000 loss 0.030185099691152573
[2025-03-14 19:26:09,246][model][INFO] - Training step 34160 loss 0.05706807225942612
[2025-03-14 19:26:50,231][model][INFO] - Training step 34320 loss 0.03640366345643997
[2025-03-14 19:27:30,479][model][INFO] - Training step 34480 loss 0.19901958107948303
[2025-03-14 19:28:11,290][model][INFO] - Training step 34640 loss 0.035084620118141174
[2025-03-14 19:28:51,936][model][INFO] - Training step 34800 loss 0.006567295640707016
[2025-03-14 19:29:32,635][model][INFO] - Training step 34960 loss 0.004799538757652044
[2025-03-14 19:30:13,424][model][INFO] - Training step 35120 loss 0.015823425725102425
[2025-03-14 19:30:54,187][model][INFO] - Training step 35280 loss 0.03293416276574135
[2025-03-14 19:31:34,791][model][INFO] - Training step 35440 loss 0.24714592099189758
[2025-03-14 19:32:15,434][model][INFO] - Training step 35600 loss 0.2492283284664154
[2025-03-14 19:32:56,347][model][INFO] - Training step 35760 loss 0.020121483132243156
[2025-03-14 19:33:38,938][model][INFO] - Training step 35920 loss 0.004754824563860893
[2025-03-14 19:34:19,545][model][INFO] - Training step 36080 loss 0.03659750521183014
[2025-03-14 19:34:59,363][model][INFO] - Training step 36240 loss 0.26005738973617554
[2025-03-14 19:35:40,996][model][INFO] - Training step 36400 loss 0.2451101839542389
[2025-03-14 19:36:22,639][model][INFO] - Training step 36560 loss 0.02296433225274086
[2025-03-14 19:37:03,772][model][INFO] - Training step 36720 loss 0.007893718779087067
[2025-03-14 19:37:44,451][model][INFO] - Training step 36880 loss 0.36163827776908875
[2025-03-14 19:38:24,317][model][INFO] - Training step 37040 loss 0.016552891582250595
[2025-03-14 19:39:04,376][model][INFO] - Training step 37200 loss 0.17703339457511902
[2025-03-14 19:39:44,168][model][INFO] - Training step 37360 loss 0.02347523346543312
[2025-03-14 19:40:24,809][model][INFO] - Training step 37520 loss 0.04117540270090103
[2025-03-14 19:41:04,292][model][INFO] - Training step 37680 loss 0.02568851038813591
[2025-03-14 19:41:43,461][model][INFO] - Training step 37840 loss 0.03908576816320419
[2025-03-14 19:42:23,646][model][INFO] - Training step 38000 loss 0.005980365909636021
[2025-03-14 19:43:04,225][model][INFO] - Training step 38160 loss 0.019274631515145302
[2025-03-14 19:43:46,640][model][INFO] - Training step 38320 loss 0.00646325945854187
[2025-03-14 19:44:27,251][model][INFO] - Training step 38480 loss 0.30351728200912476
[2025-03-14 19:45:07,122][model][INFO] - Training step 38640 loss 0.023183489218354225
[2025-03-14 19:45:48,998][model][INFO] - Training step 38800 loss 0.01362541876733303
[2025-03-14 19:46:30,310][model][INFO] - Training step 38960 loss 0.021607715636491776
[2025-03-14 19:47:10,653][model][INFO] - Training step 39120 loss 0.038063809275627136
[2025-03-14 19:47:50,090][model][INFO] - Training step 39280 loss 0.02572464756667614
[2025-03-14 19:48:31,487][model][INFO] - Training step 39440 loss 0.0016644124407321215
[2025-03-14 19:49:11,388][model][INFO] - Training step 39600 loss 0.04136929661035538
[2025-03-14 19:49:54,085][model][INFO] - Training step 39760 loss 0.0327087827026844
[2025-03-14 19:50:34,543][model][INFO] - Training step 39920 loss 0.0018675694009289145
[2025-03-14 19:51:14,244][model][INFO] - Training step 40080 loss 0.014503290876746178
[2025-03-14 19:51:56,162][model][INFO] - Training step 40240 loss 0.0057356939651072025
[2025-03-14 19:52:37,732][model][INFO] - Training step 40400 loss 0.024883368983864784
[2025-03-14 19:53:18,383][model][INFO] - Training step 40560 loss 0.028134115040302277
[2025-03-14 19:53:58,919][model][INFO] - Training step 40720 loss 0.24036915600299835
[2025-03-14 19:54:38,403][model][INFO] - Training step 40880 loss 0.03921908885240555
[2025-03-14 19:55:18,461][model][INFO] - Training step 41040 loss 0.2209278792142868
[2025-03-14 19:55:57,562][model][INFO] - Training step 41200 loss 0.01360216736793518
[2025-03-14 19:56:37,959][model][INFO] - Training step 41360 loss 0.018830131739377975
[2025-03-14 19:57:18,418][model][INFO] - Training step 41520 loss 0.04901547357439995
[2025-03-14 19:57:59,610][model][INFO] - Training step 41680 loss 0.002880438696593046
[2025-03-14 19:58:40,462][model][INFO] - Training step 41840 loss 0.0247997734695673
[2025-03-14 19:59:20,798][model][INFO] - Training step 42000 loss 0.03754150867462158
[2025-03-14 19:59:59,607][model][INFO] - Training step 42160 loss 0.2527216374874115
[2025-03-14 20:00:39,478][model][INFO] - Training step 42320 loss 0.0014895825879648328
[2025-03-14 20:01:22,513][model][INFO] - Training step 42480 loss 0.26118090748786926
[2025-03-14 20:02:03,618][model][INFO] - Training step 42640 loss 0.023379288613796234
[2025-03-14 20:02:43,472][model][INFO] - Training step 42800 loss 0.23098768293857574
[2025-03-14 20:03:24,799][model][INFO] - Training step 42960 loss 0.016435202211141586
[2025-03-14 20:04:06,394][model][INFO] - Training step 43120 loss 0.040864020586013794
[2025-03-14 20:04:47,082][model][INFO] - Training step 43280 loss 0.006484261713922024
[2025-03-14 20:05:27,824][model][INFO] - Training step 43440 loss 0.04288961738348007
[2025-03-14 20:06:07,252][model][INFO] - Training step 43600 loss 0.014558116905391216
[2025-03-14 20:06:47,705][model][INFO] - Training step 43760 loss 0.023908384144306183
[2025-03-14 20:07:28,418][model][INFO] - Training step 43920 loss 0.0701754093170166
[2025-03-14 20:08:09,225][model][INFO] - Training step 44080 loss 0.03717022389173508
[2025-03-14 20:08:51,216][model][INFO] - Training step 44240 loss 0.02775907889008522
[2025-03-14 20:09:30,874][model][INFO] - Training step 44400 loss 0.25012266635894775
[2025-03-14 20:10:10,596][model][INFO] - Training step 44560 loss 0.025099236518144608
[2025-03-14 20:10:51,357][model][INFO] - Training step 44720 loss 0.013795943930745125
[2025-03-14 20:11:30,271][model][INFO] - Training step 44880 loss 0.04395844414830208
[2025-03-14 20:12:11,566][model][INFO] - Training step 45040 loss 0.023809485137462616
[2025-03-14 20:12:51,877][model][INFO] - Training step 45200 loss 0.03552048280835152
[2025-03-14 20:13:32,467][model][INFO] - Training step 45360 loss 0.022316578775644302
[2025-03-14 20:14:13,372][model][INFO] - Training step 45520 loss 0.007878128439188004
[2025-03-14 20:14:54,208][model][INFO] - Training step 45680 loss 0.007229645736515522
[2025-03-14 20:15:34,281][model][INFO] - Training step 45840 loss 0.06214277073740959
[2025-03-14 20:16:14,820][model][INFO] - Training step 46000 loss 0.03922995924949646
[2025-03-14 20:16:57,231][model][INFO] - Training step 46160 loss 0.00489560142159462
[2025-03-14 20:17:39,636][model][INFO] - Training step 46320 loss 0.004126853309571743
[2025-03-14 20:18:20,077][model][INFO] - Training step 46480 loss 0.007543413899838924
[2025-03-14 20:18:59,899][model][INFO] - Training step 46640 loss 0.06666382402181625
[2025-03-14 20:19:41,668][model][INFO] - Training step 46800 loss 0.005698442924767733
[2025-03-14 20:20:22,106][model][INFO] - Training step 46960 loss 0.03950962424278259
[2025-03-14 20:21:01,629][model][INFO] - Training step 47120 loss 0.08394506573677063
[2025-03-14 20:21:42,724][model][INFO] - Training step 47280 loss 0.015982314944267273
[2025-03-14 20:22:21,995][model][INFO] - Training step 47440 loss 0.03878533095121384
[2025-03-14 20:23:03,446][model][INFO] - Training step 47600 loss 0.025722289457917213
[2025-03-14 20:23:45,331][model][INFO] - Training step 47760 loss 0.045558977872133255
[2025-03-14 20:24:25,553][model][INFO] - Training step 47920 loss 0.2627522945404053
[2025-03-14 20:25:06,732][model][INFO] - Training step 48080 loss 0.24886736273765564
[2025-03-14 20:25:46,288][model][INFO] - Training step 48240 loss 0.021641608327627182
[2025-03-14 20:26:27,272][model][INFO] - Training step 48400 loss 0.0375511609017849
[2025-03-14 20:27:08,128][model][INFO] - Training step 48560 loss 0.05484524741768837
[2025-03-14 20:27:48,494][model][INFO] - Training step 48720 loss 0.0019401232711970806
[2025-03-14 20:28:28,388][model][INFO] - Training step 48880 loss 0.015060005709528923
[2025-03-14 20:29:09,326][model][INFO] - Training step 49040 loss 0.027838625013828278
[2025-03-14 20:29:50,994][model][INFO] - Training step 49200 loss 0.029291769489645958
[2025-03-14 20:30:31,121][model][INFO] - Training step 49360 loss 0.030808182433247566
[2025-03-14 20:31:12,152][model][INFO] - Training step 49520 loss 0.036442238837480545
[2025-03-14 20:31:52,010][model][INFO] - Training step 49680 loss 0.015223870053887367
[2025-03-14 20:32:33,992][model][INFO] - Training step 49840 loss 0.06391269713640213
[2025-03-14 20:33:15,517][model][INFO] - Training step 50000 loss 0.04184821993112564
[2025-03-14 20:33:56,136][model][INFO] - Training step 50160 loss 0.25760090351104736
[2025-03-14 20:34:38,522][model][INFO] - Training step 50320 loss 0.0193743035197258
[2025-03-14 20:35:18,315][model][INFO] - Training step 50480 loss 0.0400562658905983
[2025-03-14 20:35:58,716][model][INFO] - Training step 50640 loss 0.014563929289579391
[2025-03-14 20:41:46,482][model][INFO] - Training step 0 loss 0.2487366646528244
[2025-03-14 20:42:26,662][model][INFO] - Training step 160 loss 0.020838452503085136
[2025-03-14 20:43:07,443][model][INFO] - Training step 320 loss 0.004079875536262989
[2025-03-14 20:43:48,846][model][INFO] - Training step 480 loss 0.023252196609973907
[2025-03-14 20:44:29,233][model][INFO] - Training step 640 loss 0.023620877414941788
[2025-03-14 20:45:10,608][model][INFO] - Training step 800 loss 0.053623951971530914
[2025-03-14 20:45:52,181][model][INFO] - Training step 960 loss 0.019748127087950706
[2025-03-14 20:46:31,396][model][INFO] - Training step 1120 loss 0.00785786472260952
[2025-03-14 20:47:13,645][model][INFO] - Training step 1280 loss 0.004994558170437813
[2025-03-14 20:47:54,138][model][INFO] - Training step 1440 loss 0.029689624905586243
[2025-03-14 20:48:35,137][model][INFO] - Training step 1600 loss 0.045811139047145844
[2025-03-14 20:49:14,793][model][INFO] - Training step 1760 loss 0.045922353863716125
[2025-03-14 20:49:54,374][model][INFO] - Training step 1920 loss 0.022206980735063553
[2025-03-14 20:50:34,630][model][INFO] - Training step 2080 loss 0.24697214365005493
[2025-03-14 20:51:15,645][model][INFO] - Training step 2240 loss 0.023487690836191177
[2025-03-14 20:51:54,106][model][INFO] - Training step 2400 loss 0.016234125941991806
[2025-03-14 20:52:34,094][model][INFO] - Training step 2560 loss 0.04059494659304619
[2025-03-14 20:53:15,770][model][INFO] - Training step 2720 loss 0.015383097343146801
[2025-03-14 20:53:55,985][model][INFO] - Training step 2880 loss 0.24949845671653748
[2025-03-14 20:54:36,779][model][INFO] - Training step 3040 loss 0.022319339215755463
[2025-03-14 20:55:17,863][model][INFO] - Training step 3200 loss 0.09563717246055603
[2025-03-14 20:55:59,375][model][INFO] - Training step 3360 loss 0.007321780547499657
[2025-03-14 20:56:41,249][model][INFO] - Training step 3520 loss 0.25613933801651
[2025-03-14 20:57:22,505][model][INFO] - Training step 3680 loss 0.029781784862279892
[2025-03-14 20:58:02,201][model][INFO] - Training step 3840 loss 0.23989218473434448
[2025-03-14 20:58:46,037][model][INFO] - Training step 4000 loss 0.002011920791119337
[2025-03-14 20:59:26,987][model][INFO] - Training step 4160 loss 0.0029793393332511187
[2025-03-14 21:00:09,179][model][INFO] - Training step 4320 loss 0.04224797338247299
[2025-03-14 21:00:50,810][model][INFO] - Training step 4480 loss 0.20483148097991943
[2025-03-14 21:01:31,151][model][INFO] - Training step 4640 loss 0.24861957132816315
[2025-03-14 21:02:10,539][model][INFO] - Training step 4800 loss 0.032698433846235275
[2025-03-14 21:02:50,115][model][INFO] - Training step 4960 loss 0.010479593649506569
[2025-03-14 21:03:31,112][model][INFO] - Training step 5120 loss 0.006371668539941311
[2025-03-14 21:04:11,937][model][INFO] - Training step 5280 loss 0.009503105655312538
[2025-03-14 21:04:53,572][model][INFO] - Training step 5440 loss 0.004498466849327087
[2025-03-14 21:05:34,451][model][INFO] - Training step 5600 loss 0.024440351873636246
[2025-03-14 21:06:15,373][model][INFO] - Training step 5760 loss 0.023287219926714897
[2025-03-14 21:06:56,514][model][INFO] - Training step 5920 loss 0.018717380240559578
[2025-03-14 21:07:36,815][model][INFO] - Training step 6080 loss 0.021629218012094498
[2025-03-14 21:08:17,870][model][INFO] - Training step 6240 loss 0.23110157251358032
[2025-03-14 21:08:58,849][model][INFO] - Training step 6400 loss 0.27320438623428345
[2025-03-14 21:09:40,116][model][INFO] - Training step 6560 loss 0.0024806519504636526
[2025-03-14 21:10:22,084][model][INFO] - Training step 6720 loss 0.007701999973505735
[2025-03-14 21:11:02,826][model][INFO] - Training step 6880 loss 0.24419164657592773
[2025-03-14 21:11:43,547][model][INFO] - Training step 7040 loss 0.2853515148162842
[2025-03-14 21:12:25,500][model][INFO] - Training step 7200 loss 0.24471241235733032
[2025-03-14 21:13:06,587][model][INFO] - Training step 7360 loss 0.040884830057621
[2025-03-14 21:13:46,458][model][INFO] - Training step 7520 loss 0.028960440307855606
[2025-03-14 21:14:27,487][model][INFO] - Training step 7680 loss 0.0520857498049736
[2025-03-14 21:15:07,089][model][INFO] - Training step 7840 loss 0.027771778404712677
[2025-03-14 21:15:48,017][model][INFO] - Training step 8000 loss 0.006835831329226494
[2025-03-14 21:16:30,013][model][INFO] - Training step 8160 loss 0.002668204251676798
[2025-03-14 21:17:08,780][model][INFO] - Training step 8320 loss 0.015156501904129982
[2025-03-14 21:17:49,249][model][INFO] - Training step 8480 loss 0.15201109647750854
[2025-03-14 21:18:31,105][model][INFO] - Training step 8640 loss 0.03193603456020355
[2025-03-14 21:19:10,091][model][INFO] - Training step 8800 loss 0.18357518315315247
[2025-03-14 21:19:50,683][model][INFO] - Training step 8960 loss 0.0233718641102314
[2025-03-14 21:20:31,081][model][INFO] - Training step 9120 loss 0.025181302800774574
[2025-03-14 21:21:11,086][model][INFO] - Training step 9280 loss 0.17815551161766052
[2025-03-14 21:21:50,234][model][INFO] - Training step 9440 loss 0.044852450489997864
[2025-03-14 21:22:30,099][model][INFO] - Training step 9600 loss 0.015320800244808197
[2025-03-14 21:23:10,360][model][INFO] - Training step 9760 loss 0.016921186819672585
[2025-03-14 21:23:51,133][model][INFO] - Training step 9920 loss 0.02667352557182312
[2025-03-14 21:24:31,297][model][INFO] - Training step 10080 loss 0.2600966691970825
[2025-03-14 21:25:11,571][model][INFO] - Training step 10240 loss 0.015093774534761906
[2025-03-14 21:25:53,328][model][INFO] - Training step 10400 loss 0.029702898114919662
[2025-03-14 21:26:34,116][model][INFO] - Training step 10560 loss 0.036179907619953156
[2025-03-14 21:27:13,274][model][INFO] - Training step 10720 loss 0.01412181742489338
[2025-03-14 21:27:53,443][model][INFO] - Training step 10880 loss 0.032638609409332275
[2025-03-14 21:28:34,244][model][INFO] - Training step 11040 loss 0.022443508729338646
[2025-03-14 21:29:14,358][model][INFO] - Training step 11200 loss 0.08604073524475098
[2025-03-14 21:29:55,520][model][INFO] - Training step 11360 loss 0.030391093343496323
[2025-03-14 21:30:36,734][model][INFO] - Training step 11520 loss 0.03832770138978958
[2025-03-14 21:31:16,851][model][INFO] - Training step 11680 loss 0.03138525411486626
[2025-03-14 21:31:57,147][model][INFO] - Training step 11840 loss 0.0225246399641037
[2025-03-14 21:32:38,456][model][INFO] - Training step 12000 loss 0.20009109377861023
[2025-03-14 21:33:19,185][model][INFO] - Training step 12160 loss 0.19509662687778473
[2025-03-14 21:33:59,486][model][INFO] - Training step 12320 loss 0.03230840712785721
[2025-03-14 21:34:38,940][model][INFO] - Training step 12480 loss 0.021494969725608826
[2025-03-14 21:35:17,780][model][INFO] - Training step 12640 loss 0.024438701570034027
[2025-03-14 21:35:58,575][model][INFO] - Training step 12800 loss 0.02257322520017624
[2025-03-14 21:36:40,179][model][INFO] - Training step 12960 loss 0.03285767883062363
[2025-03-14 21:37:20,131][model][INFO] - Training step 13120 loss 0.25930631160736084
[2025-03-14 21:38:02,031][model][INFO] - Training step 13280 loss 0.013362517580389977
[2025-03-14 21:38:42,158][model][INFO] - Training step 13440 loss 0.07706606388092041
[2025-03-14 21:39:23,310][model][INFO] - Training step 13600 loss 0.020838093012571335
[2025-03-14 21:40:04,033][model][INFO] - Training step 13760 loss 0.034151844680309296
[2025-03-14 21:40:44,344][model][INFO] - Training step 13920 loss 0.2672915756702423
[2025-03-14 21:41:24,104][model][INFO] - Training step 14080 loss 0.017603527754545212
[2025-03-14 21:42:02,879][model][INFO] - Training step 14240 loss 0.08781319856643677
[2025-03-14 21:42:43,696][model][INFO] - Training step 14400 loss 0.010912793688476086
[2025-03-14 21:43:24,054][model][INFO] - Training step 14560 loss 0.24333244562149048
[2025-03-14 21:44:03,521][model][INFO] - Training step 14720 loss 0.2567611336708069
[2025-03-14 21:44:44,473][model][INFO] - Training step 14880 loss 0.22730591893196106
[2025-03-14 21:45:25,700][model][INFO] - Training step 15040 loss 0.041128791868686676
[2025-03-14 21:46:06,870][model][INFO] - Training step 15200 loss 0.01787586882710457
[2025-03-14 21:46:47,315][model][INFO] - Training step 15360 loss 0.00824427418410778
[2025-03-14 21:47:28,162][model][INFO] - Training step 15520 loss 0.013182921335101128
[2025-03-14 21:48:07,815][model][INFO] - Training step 15680 loss 0.2533293068408966
[2025-03-14 21:48:47,459][model][INFO] - Training step 15840 loss 0.03453245759010315
[2025-03-14 21:49:28,369][model][INFO] - Training step 16000 loss 0.020164869725704193
[2025-03-14 21:50:08,007][model][INFO] - Training step 16160 loss 0.246720552444458
[2025-03-14 21:50:48,023][model][INFO] - Training step 16320 loss 0.03907918184995651
[2025-03-14 21:51:27,847][model][INFO] - Training step 16480 loss 0.022410251200199127
[2025-03-14 21:52:08,825][model][INFO] - Training step 16640 loss 0.01904464140534401
[2025-03-14 21:52:48,235][model][INFO] - Training step 16800 loss 0.02853056974709034
[2025-03-14 21:53:29,669][model][INFO] - Training step 16960 loss 0.02561752125620842
[2025-03-14 21:54:10,423][model][INFO] - Training step 17120 loss 0.09916333854198456
[2025-03-14 21:54:51,888][model][INFO] - Training step 17280 loss 0.6338131427764893
[2025-03-14 21:55:30,579][model][INFO] - Training step 17440 loss 0.020714810118079185
[2025-03-14 21:56:11,795][model][INFO] - Training step 17600 loss 0.057827603071928024
[2025-03-14 21:56:51,976][model][INFO] - Training step 17760 loss 0.05003923922777176
[2025-03-14 21:57:31,964][model][INFO] - Training step 17920 loss 0.059918295592069626
[2025-03-14 21:58:12,637][model][INFO] - Training step 18080 loss 0.03265498951077461
[2025-03-14 21:58:54,004][model][INFO] - Training step 18240 loss 0.2862549424171448
[2025-03-14 21:59:34,644][model][INFO] - Training step 18400 loss 0.0025336057879030704
[2025-03-14 22:00:15,338][model][INFO] - Training step 18560 loss 0.27853894233703613
[2025-03-14 22:00:55,041][model][INFO] - Training step 18720 loss 0.039878129959106445
[2025-03-14 22:01:36,642][model][INFO] - Training step 18880 loss 0.014935924671590328
[2025-03-14 22:02:16,974][model][INFO] - Training step 19040 loss 0.026158813387155533
[2025-03-14 22:02:56,462][model][INFO] - Training step 19200 loss 0.034242141991853714
[2025-03-14 22:03:37,019][model][INFO] - Training step 19360 loss 0.04608144611120224
[2025-03-14 22:04:17,511][model][INFO] - Training step 19520 loss 0.006549960933625698
[2025-03-14 22:04:57,915][model][INFO] - Training step 19680 loss 0.026900917291641235
[2025-03-14 22:05:37,930][model][INFO] - Training step 19840 loss 0.02266787365078926
[2025-03-14 22:06:17,095][model][INFO] - Training step 20000 loss 0.007707887329161167
[2025-03-14 22:06:57,377][model][INFO] - Training step 20160 loss 0.25397276878356934
[2025-03-14 22:07:37,021][model][INFO] - Training step 20320 loss 0.07335099577903748
[2025-03-14 22:08:17,612][model][INFO] - Training step 20480 loss 0.008779991418123245
[2025-03-14 22:08:58,617][model][INFO] - Training step 20640 loss 0.250467985868454
[2025-03-14 22:09:39,429][model][INFO] - Training step 20800 loss 0.030272461473941803
[2025-03-14 22:10:20,927][model][INFO] - Training step 20960 loss 0.01640332117676735
[2025-03-14 22:11:01,277][model][INFO] - Training step 21120 loss 0.051775120198726654
[2025-03-14 22:11:41,136][model][INFO] - Training step 21280 loss 0.06367574632167816
[2025-03-14 22:12:21,928][model][INFO] - Training step 21440 loss 0.01928963139653206
[2025-03-14 22:13:01,117][model][INFO] - Training step 21600 loss 0.035143449902534485
[2025-03-14 22:13:41,579][model][INFO] - Training step 21760 loss 0.0028217530343681574
[2025-03-14 22:14:21,518][model][INFO] - Training step 21920 loss 0.016572963446378708
[2025-03-14 22:15:03,188][model][INFO] - Training step 22080 loss 0.0448017343878746
[2025-03-14 22:15:44,931][model][INFO] - Training step 22240 loss 0.025796443223953247
[2025-03-14 22:16:25,654][model][INFO] - Training step 22400 loss 0.0334022156894207
[2025-03-14 22:17:06,601][model][INFO] - Training step 22560 loss 0.18386469781398773
[2025-03-14 22:17:47,248][model][INFO] - Training step 22720 loss 0.03459327667951584
[2025-03-14 22:18:27,662][model][INFO] - Training step 22880 loss 0.008374093100428581
[2025-03-14 22:19:10,177][model][INFO] - Training step 23040 loss 0.04072616994380951
[2025-03-14 22:19:52,135][model][INFO] - Training step 23200 loss 0.11804156005382538
[2025-03-14 22:20:33,935][model][INFO] - Training step 23360 loss 0.03102778270840645
[2025-03-14 22:21:14,177][model][INFO] - Training step 23520 loss 0.24761492013931274
[2025-03-14 22:21:54,861][model][INFO] - Training step 23680 loss 0.04330655187368393
[2025-03-14 22:22:36,918][model][INFO] - Training step 23840 loss 0.0821453332901001
[2025-03-14 22:23:17,456][model][INFO] - Training step 24000 loss 0.02020040526986122
[2025-03-14 22:23:57,683][model][INFO] - Training step 24160 loss 0.020531799644231796
[2025-03-14 22:24:37,505][model][INFO] - Training step 24320 loss 0.023673202842473984
[2025-03-14 22:25:17,339][model][INFO] - Training step 24480 loss 0.008525550365447998
[2025-03-14 22:25:56,152][model][INFO] - Training step 24640 loss 0.031539835035800934
[2025-03-14 22:26:38,114][model][INFO] - Training step 24800 loss 0.10303530842065811
[2025-03-14 22:27:19,642][model][INFO] - Training step 24960 loss 0.022423293441534042
[2025-03-14 22:28:00,810][model][INFO] - Training step 25120 loss 0.08171842992305756
[2025-03-14 22:28:41,098][model][INFO] - Training step 25280 loss 0.013692351058125496
[2025-03-14 22:29:21,084][model][INFO] - Training step 25440 loss 0.026567868888378143
[2025-03-14 22:30:00,132][model][INFO] - Training step 25600 loss 0.0034452849067747593
[2025-03-14 22:30:38,965][model][INFO] - Training step 25760 loss 0.022591959685087204
[2025-03-14 22:31:19,985][model][INFO] - Training step 25920 loss 0.24569576978683472
[2025-03-14 22:31:58,946][model][INFO] - Training step 26080 loss 0.017213527113199234
[2025-03-14 22:32:38,971][model][INFO] - Training step 26240 loss 0.02276947721838951
[2025-03-14 22:33:20,278][model][INFO] - Training step 26400 loss 0.042177941650152206
[2025-03-14 22:34:00,280][model][INFO] - Training step 26560 loss 0.06823977828025818
[2025-03-14 22:34:42,073][model][INFO] - Training step 26720 loss 0.0057861097157001495
[2025-03-14 22:35:21,692][model][INFO] - Training step 26880 loss 0.02455659583210945
[2025-03-14 22:36:01,101][model][INFO] - Training step 27040 loss 0.02601904422044754
[2025-03-14 22:36:40,402][model][INFO] - Training step 27200 loss 0.24969729781150818
[2025-03-14 22:37:19,630][model][INFO] - Training step 27360 loss 0.03414934128522873
[2025-03-14 22:37:59,836][model][INFO] - Training step 27520 loss 0.026116102933883667
[2025-03-14 22:38:41,174][model][INFO] - Training step 27680 loss 0.024494005367159843
[2025-03-14 22:39:21,404][model][INFO] - Training step 27840 loss 0.023610122501850128
[2025-03-14 22:40:01,738][model][INFO] - Training step 28000 loss 0.030862856656312943
[2025-03-14 22:40:42,861][model][INFO] - Training step 28160 loss 0.2452135682106018
[2025-03-14 22:41:22,183][model][INFO] - Training step 28320 loss 0.01753116399049759
[2025-03-14 22:42:01,847][model][INFO] - Training step 28480 loss 0.0441373735666275
[2025-03-14 22:42:41,308][model][INFO] - Training step 28640 loss 0.06463135033845901
[2025-03-14 22:43:21,026][model][INFO] - Training step 28800 loss 0.04997192695736885
[2025-03-14 22:44:02,100][model][INFO] - Training step 28960 loss 0.032014090567827225
[2025-03-14 22:44:41,685][model][INFO] - Training step 29120 loss 0.2526690363883972
[2025-03-14 22:45:21,479][model][INFO] - Training step 29280 loss 0.03134816139936447
[2025-03-14 22:46:02,309][model][INFO] - Training step 29440 loss 0.03392120450735092
[2025-03-14 22:46:41,962][model][INFO] - Training step 29600 loss 0.03816894441843033
[2025-03-14 22:47:22,884][model][INFO] - Training step 29760 loss 0.08486410975456238
[2025-03-14 22:48:04,074][model][INFO] - Training step 29920 loss 0.25070446729660034
[2025-03-14 22:48:45,107][model][INFO] - Training step 30080 loss 0.24708884954452515
[2025-03-14 22:49:24,415][model][INFO] - Training step 30240 loss 0.004282629583030939
[2025-03-14 22:50:04,158][model][INFO] - Training step 30400 loss 0.0281510129570961
[2025-03-14 22:50:43,865][model][INFO] - Training step 30560 loss 0.03395997732877731
[2025-03-14 22:51:22,746][model][INFO] - Training step 30720 loss 0.013226556591689587
[2025-03-14 22:52:02,090][model][INFO] - Training step 30880 loss 0.003955808933824301
[2025-03-14 22:52:42,928][model][INFO] - Training step 31040 loss 0.04923330992460251
[2025-03-14 22:53:22,192][model][INFO] - Training step 31200 loss 0.018215036019682884
[2025-03-14 22:54:03,162][model][INFO] - Training step 31360 loss 0.02803684026002884
[2025-03-14 22:54:42,255][model][INFO] - Training step 31520 loss 0.05273886397480965
[2025-03-14 22:55:22,018][model][INFO] - Training step 31680 loss 0.06936847418546677
[2025-03-14 22:56:03,280][model][INFO] - Training step 31840 loss 0.2616153061389923
[2025-03-14 22:56:45,999][model][INFO] - Training step 32000 loss 0.005057177972048521
[2025-03-14 22:57:25,687][model][INFO] - Training step 32160 loss 0.25256770849227905
[2025-03-14 22:58:06,612][model][INFO] - Training step 32320 loss 0.02977033704519272
[2025-03-14 22:58:46,698][model][INFO] - Training step 32480 loss 0.016355615109205246
[2025-03-14 22:59:27,545][model][INFO] - Training step 32640 loss 0.0287814699113369
[2025-03-14 23:00:07,541][model][INFO] - Training step 32800 loss 0.05634666979312897
[2025-03-14 23:00:49,322][model][INFO] - Training step 32960 loss 0.042269788682460785
[2025-03-14 23:01:29,755][model][INFO] - Training step 33120 loss 0.24912786483764648
[2025-03-14 23:02:10,799][model][INFO] - Training step 33280 loss 0.04471631348133087
[2025-03-14 23:02:50,956][model][INFO] - Training step 33440 loss 0.004539289511740208
[2025-03-14 23:03:31,855][model][INFO] - Training step 33600 loss 0.021666832268238068
[2025-03-14 23:04:12,447][model][INFO] - Training step 33760 loss 0.24767260253429413
[2025-03-14 23:04:53,659][model][INFO] - Training step 33920 loss 0.034731425344944
[2025-03-14 23:05:34,676][model][INFO] - Training step 34080 loss 0.027820326387882233
[2025-03-14 23:06:14,491][model][INFO] - Training step 34240 loss 0.037195831537246704
[2025-03-14 23:06:55,196][model][INFO] - Training step 34400 loss 0.18020354211330414
[2025-03-14 23:07:38,105][model][INFO] - Training step 34560 loss 0.026801856234669685
[2025-03-14 23:08:19,681][model][INFO] - Training step 34720 loss 0.017642617225646973
[2025-03-14 23:09:01,588][model][INFO] - Training step 34880 loss 0.01823384501039982
[2025-03-14 23:09:42,482][model][INFO] - Training step 35040 loss 0.07570117712020874
[2025-03-14 23:10:23,047][model][INFO] - Training step 35200 loss 0.028406208381056786
[2025-03-14 23:11:04,742][model][INFO] - Training step 35360 loss 0.015696506947278976
[2025-03-14 23:11:45,850][model][INFO] - Training step 35520 loss 0.02864690311253071
[2025-03-14 23:12:27,211][model][INFO] - Training step 35680 loss 0.03180569410324097
[2025-03-14 23:13:07,178][model][INFO] - Training step 35840 loss 0.014888975769281387
[2025-03-14 23:13:46,744][model][INFO] - Training step 36000 loss 0.024594249203801155
[2025-03-14 23:14:27,263][model][INFO] - Training step 36160 loss 0.147417351603508
[2025-03-14 23:15:09,620][model][INFO] - Training step 36320 loss 0.010524440556764603
[2025-03-14 23:15:50,460][model][INFO] - Training step 36480 loss 0.23250225186347961
[2025-03-14 23:16:32,249][model][INFO] - Training step 36640 loss 0.02022017538547516
[2025-03-14 23:17:13,696][model][INFO] - Training step 36800 loss 0.005222322419285774
[2025-03-14 23:17:55,199][model][INFO] - Training step 36960 loss 0.009352730587124825
[2025-03-14 23:18:36,472][model][INFO] - Training step 37120 loss 0.003483704524114728
[2025-03-14 23:19:18,650][model][INFO] - Training step 37280 loss 0.02462160214781761
[2025-03-14 23:19:58,203][model][INFO] - Training step 37440 loss 0.031846944242715836
[2025-03-14 23:20:38,460][model][INFO] - Training step 37600 loss 0.022154364734888077
[2025-03-14 23:21:18,561][model][INFO] - Training step 37760 loss 0.003926793113350868
[2025-03-14 23:21:58,557][model][INFO] - Training step 37920 loss 0.011769896373152733
[2025-03-14 23:22:39,054][model][INFO] - Training step 38080 loss 0.029993871226906776
[2025-03-14 23:23:21,207][model][INFO] - Training step 38240 loss 0.005890838801860809
[2025-03-14 23:24:02,579][model][INFO] - Training step 38400 loss 0.030690187588334084
[2025-03-14 23:24:42,624][model][INFO] - Training step 38560 loss 0.24804718792438507
[2025-03-14 23:25:23,966][model][INFO] - Training step 38720 loss 0.03730483725667
[2025-03-14 23:26:03,823][model][INFO] - Training step 38880 loss 0.022290799766778946
[2025-03-14 23:26:45,827][model][INFO] - Training step 39040 loss 0.019396260380744934
[2025-03-14 23:27:26,354][model][INFO] - Training step 39200 loss 0.018480250611901283
[2025-03-14 23:28:07,255][model][INFO] - Training step 39360 loss 0.01856835186481476
[2025-03-14 23:28:47,798][model][INFO] - Training step 39520 loss 0.26685693860054016
[2025-03-14 23:29:28,555][model][INFO] - Training step 39680 loss 0.0174294151365757
[2025-03-14 23:30:09,754][model][INFO] - Training step 39840 loss 0.042932428419589996
[2025-03-14 23:30:51,176][model][INFO] - Training step 40000 loss 0.02020183764398098
[2025-03-14 23:31:31,824][model][INFO] - Training step 40160 loss 0.024621736258268356
[2025-03-14 23:32:12,239][model][INFO] - Training step 40320 loss 0.0028324902523308992
[2025-03-14 23:32:52,452][model][INFO] - Training step 40480 loss 0.2310456931591034
[2025-03-14 23:33:33,485][model][INFO] - Training step 40640 loss 0.24463041126728058
[2025-03-14 23:34:13,398][model][INFO] - Training step 40800 loss 0.2429230809211731
[2025-03-14 23:34:55,164][model][INFO] - Training step 40960 loss 0.021828103810548782
[2025-03-14 23:35:36,069][model][INFO] - Training step 41120 loss 0.0029016665648669004
[2025-03-14 23:36:18,065][model][INFO] - Training step 41280 loss 0.006722983438521624
[2025-03-14 23:36:59,060][model][INFO] - Training step 41440 loss 0.0394090935587883
[2025-03-14 23:37:39,664][model][INFO] - Training step 41600 loss 0.003433498553931713
[2025-03-14 23:38:20,037][model][INFO] - Training step 41760 loss 0.26344895362854004
[2025-03-14 23:39:00,789][model][INFO] - Training step 41920 loss 0.0033293282613158226
[2025-03-14 23:39:42,220][model][INFO] - Training step 42080 loss 0.23738321661949158
[2025-03-14 23:40:21,335][model][INFO] - Training step 42240 loss 0.027350537478923798
[2025-03-14 23:41:02,511][model][INFO] - Training step 42400 loss 0.07470424473285675
[2025-03-14 23:41:42,602][model][INFO] - Training step 42560 loss 0.27350014448165894
[2025-03-14 23:42:24,134][model][INFO] - Training step 42720 loss 0.020801985636353493
[2025-03-14 23:43:04,302][model][INFO] - Training step 42880 loss 0.2467779815196991
[2025-03-14 23:43:44,829][model][INFO] - Training step 43040 loss 0.24653607606887817
[2025-03-14 23:44:25,699][model][INFO] - Training step 43200 loss 0.030287407338619232
[2025-03-14 23:45:06,572][model][INFO] - Training step 43360 loss 0.23939576745033264
[2025-03-14 23:45:47,368][model][INFO] - Training step 43520 loss 0.02841876819729805
[2025-03-14 23:46:27,488][model][INFO] - Training step 43680 loss 0.04810957610607147
[2025-03-14 23:47:07,939][model][INFO] - Training step 43840 loss 0.03244416415691376
[2025-03-14 23:47:46,942][model][INFO] - Training step 44000 loss 0.026280544698238373
[2025-03-14 23:48:28,029][model][INFO] - Training step 44160 loss 0.011819224804639816
[2025-03-14 23:49:08,686][model][INFO] - Training step 44320 loss 0.015240628272294998
[2025-03-14 23:49:49,318][model][INFO] - Training step 44480 loss 0.009306414052844048
[2025-03-14 23:50:27,613][model][INFO] - Training step 44640 loss 0.02125982567667961
[2025-03-14 23:51:07,645][model][INFO] - Training step 44800 loss 0.04873627424240112
[2025-03-14 23:51:49,618][model][INFO] - Training step 44960 loss 0.05567663535475731
[2025-03-14 23:52:30,252][model][INFO] - Training step 45120 loss 0.11751407384872437
[2025-03-14 23:53:10,515][model][INFO] - Training step 45280 loss 0.01979711279273033
[2025-03-14 23:53:51,424][model][INFO] - Training step 45440 loss 0.007868598215281963
[2025-03-14 23:54:32,744][model][INFO] - Training step 45600 loss 0.0220466498285532
[2025-03-14 23:55:14,906][model][INFO] - Training step 45760 loss 0.031587082892656326
[2025-03-14 23:55:56,018][model][INFO] - Training step 45920 loss 0.2631646692752838
[2025-03-14 23:56:37,180][model][INFO] - Training step 46080 loss 0.02292882837355137
[2025-03-14 23:57:18,990][model][INFO] - Training step 46240 loss 0.06877294182777405
[2025-03-14 23:58:00,946][model][INFO] - Training step 46400 loss 0.06607070565223694
[2025-03-14 23:58:39,829][model][INFO] - Training step 46560 loss 0.017889540642499924
[2025-03-14 23:59:21,346][model][INFO] - Training step 46720 loss 0.24553242325782776
[2025-03-15 00:00:03,192][model][INFO] - Training step 46880 loss 0.060850195586681366
[2025-03-15 00:00:43,869][model][INFO] - Training step 47040 loss 0.2626630663871765
[2025-03-15 00:01:25,697][model][INFO] - Training step 47200 loss 0.027394376695156097
[2025-03-15 00:02:06,069][model][INFO] - Training step 47360 loss 0.020482223480939865
[2025-03-15 00:02:48,883][model][INFO] - Training step 47520 loss 0.01405233796685934
[2025-03-15 00:03:31,523][model][INFO] - Training step 47680 loss 0.003567315638065338
[2025-03-15 00:04:11,049][model][INFO] - Training step 47840 loss 0.02440064400434494
[2025-03-15 00:04:51,203][model][INFO] - Training step 48000 loss 0.0026904642581939697
[2025-03-15 00:05:32,795][model][INFO] - Training step 48160 loss 0.001316086039878428
[2025-03-15 00:06:10,768][model][INFO] - Training step 48320 loss 0.054756514728069305
[2025-03-15 00:06:50,790][model][INFO] - Training step 48480 loss 0.05793377012014389
[2025-03-15 00:07:30,612][model][INFO] - Training step 48640 loss 0.022345181554555893
[2025-03-15 00:08:11,208][model][INFO] - Training step 48800 loss 0.24930167198181152
[2025-03-15 00:08:51,698][model][INFO] - Training step 48960 loss 0.011432970874011517
[2025-03-15 00:09:32,644][model][INFO] - Training step 49120 loss 0.026402786374092102
[2025-03-15 00:10:12,674][model][INFO] - Training step 49280 loss 0.05673209950327873
[2025-03-15 00:10:53,270][model][INFO] - Training step 49440 loss 0.25461769104003906
[2025-03-15 00:11:34,275][model][INFO] - Training step 49600 loss 0.0053306398913264275
[2025-03-15 00:12:16,280][model][INFO] - Training step 49760 loss 0.010572350583970547
[2025-03-15 00:12:58,315][model][INFO] - Training step 49920 loss 0.01505313254892826
[2025-03-15 00:13:39,987][model][INFO] - Training step 50080 loss 0.0183944720774889
[2025-03-15 00:14:21,025][model][INFO] - Training step 50240 loss 0.03386935591697693
[2025-03-15 00:15:02,169][model][INFO] - Training step 50400 loss 0.008018058724701405
[2025-03-15 00:15:41,475][model][INFO] - Training step 50560 loss 0.01819663681089878
[2025-03-15 00:16:22,810][model][INFO] - Training step 50720 loss 0.035668157041072845
[2025-03-15 00:22:09,107][model][INFO] - Training step 80 loss 0.039910078048706055
[2025-03-15 00:22:49,700][model][INFO] - Training step 240 loss 0.2333548665046692
[2025-03-15 00:23:30,137][model][INFO] - Training step 400 loss 0.026315748691558838
[2025-03-15 00:24:09,765][model][INFO] - Training step 560 loss 0.018448591232299805
[2025-03-15 00:24:48,599][model][INFO] - Training step 720 loss 0.02327348105609417
[2025-03-15 00:25:28,029][model][INFO] - Training step 880 loss 0.06624189019203186
[2025-03-15 00:26:07,807][model][INFO] - Training step 1040 loss 0.025298278778791428
[2025-03-15 00:26:49,642][model][INFO] - Training step 1200 loss 0.06273454427719116
[2025-03-15 00:27:32,134][model][INFO] - Training step 1360 loss 0.02966168522834778
[2025-03-15 00:28:11,979][model][INFO] - Training step 1520 loss 0.04043099284172058
[2025-03-15 00:28:53,487][model][INFO] - Training step 1680 loss 0.0024954662658274174
[2025-03-15 00:29:33,854][model][INFO] - Training step 1840 loss 0.0338212326169014
[2025-03-15 00:30:13,413][model][INFO] - Training step 2000 loss 0.03588692471385002
[2025-03-15 00:30:53,628][model][INFO] - Training step 2160 loss 0.2380928099155426
[2025-03-15 00:31:34,307][model][INFO] - Training step 2320 loss 0.01960429921746254
[2025-03-15 00:32:16,149][model][INFO] - Training step 2480 loss 0.27129173278808594
[2025-03-15 00:32:55,056][model][INFO] - Training step 2640 loss 0.01893187128007412
[2025-03-15 00:33:36,213][model][INFO] - Training step 2800 loss 0.08820284903049469
[2025-03-15 00:34:17,485][model][INFO] - Training step 2960 loss 0.007164788898080587
[2025-03-15 00:34:58,302][model][INFO] - Training step 3120 loss 0.05410820245742798
[2025-03-15 00:35:38,083][model][INFO] - Training step 3280 loss 0.038017887622117996
[2025-03-15 00:36:18,957][model][INFO] - Training step 3440 loss 0.026925740763545036
[2025-03-15 00:36:58,816][model][INFO] - Training step 3600 loss 0.24747896194458008
[2025-03-15 00:37:38,835][model][INFO] - Training step 3760 loss 0.018695980310440063
[2025-03-15 00:38:18,785][model][INFO] - Training step 3920 loss 0.01582513190805912
[2025-03-15 00:39:00,028][model][INFO] - Training step 4080 loss 0.19390460848808289
[2025-03-15 00:39:40,498][model][INFO] - Training step 4240 loss 0.03258868306875229
[2025-03-15 00:40:21,422][model][INFO] - Training step 4400 loss 0.012479860335588455
[2025-03-15 00:41:03,913][model][INFO] - Training step 4560 loss 0.0883522778749466
[2025-03-15 00:41:43,827][model][INFO] - Training step 4720 loss 0.06203307583928108
[2025-03-15 00:42:23,285][model][INFO] - Training step 4880 loss 0.010889227502048016
[2025-03-15 00:43:04,224][model][INFO] - Training step 5040 loss 0.007117648143321276
[2025-03-15 00:43:45,437][model][INFO] - Training step 5200 loss 0.040831904858350754
[2025-03-15 00:44:25,732][model][INFO] - Training step 5360 loss 0.21619315445423126
[2025-03-15 00:45:05,381][model][INFO] - Training step 5520 loss 0.03853379935026169
[2025-03-15 00:45:46,142][model][INFO] - Training step 5680 loss 0.07728490233421326
[2025-03-15 00:46:26,727][model][INFO] - Training step 5840 loss 0.023448847234249115
[2025-03-15 00:47:08,854][model][INFO] - Training step 6000 loss 0.020498080179095268
[2025-03-15 00:47:47,855][model][INFO] - Training step 6160 loss 0.006827261298894882
[2025-03-15 00:48:29,055][model][INFO] - Training step 6320 loss 0.03692435100674629
[2025-03-15 00:49:09,435][model][INFO] - Training step 6480 loss 0.02366764284670353
[2025-03-15 00:49:51,014][model][INFO] - Training step 6640 loss 0.005730727221816778
[2025-03-15 00:50:30,938][model][INFO] - Training step 6800 loss 0.0026993462815880775
[2025-03-15 00:51:11,145][model][INFO] - Training step 6960 loss 0.024767376482486725
[2025-03-15 00:51:51,867][model][INFO] - Training step 7120 loss 0.002714109141379595
[2025-03-15 00:52:32,083][model][INFO] - Training step 7280 loss 0.012922044843435287
[2025-03-15 00:53:12,165][model][INFO] - Training step 7440 loss 0.020209908485412598
[2025-03-15 00:53:53,035][model][INFO] - Training step 7600 loss 0.029207952320575714
[2025-03-15 00:54:32,667][model][INFO] - Training step 7760 loss 0.0025776412803679705
[2025-03-15 00:55:14,051][model][INFO] - Training step 7920 loss 0.027760639786720276
[2025-03-15 00:55:54,805][model][INFO] - Training step 8080 loss 0.18680450320243835
[2025-03-15 00:56:35,817][model][INFO] - Training step 8240 loss 0.016077684238553047
[2025-03-15 00:57:16,823][model][INFO] - Training step 8400 loss 0.04441746324300766
[2025-03-15 00:57:57,060][model][INFO] - Training step 8560 loss 0.007550141774117947
[2025-03-15 00:58:37,224][model][INFO] - Training step 8720 loss 0.09251571446657181
[2025-03-15 00:59:17,508][model][INFO] - Training step 8880 loss 0.027593251317739487
[2025-03-15 00:59:58,862][model][INFO] - Training step 9040 loss 0.047706156969070435
[2025-03-15 01:00:37,785][model][INFO] - Training step 9200 loss 0.01973826438188553
[2025-03-15 01:01:19,073][model][INFO] - Training step 9360 loss 0.25958770513534546
[2025-03-15 01:01:59,012][model][INFO] - Training step 9520 loss 0.011036751791834831
[2025-03-15 01:02:38,857][model][INFO] - Training step 9680 loss 0.00472396332770586
[2025-03-15 01:03:19,335][model][INFO] - Training step 9840 loss 0.10438497364521027
[2025-03-15 01:03:59,720][model][INFO] - Training step 10000 loss 0.07413113117218018
[2025-03-15 01:04:39,346][model][INFO] - Training step 10160 loss 0.07003507763147354
[2025-03-15 01:05:18,288][model][INFO] - Training step 10320 loss 0.019614387303590775
[2025-03-15 01:06:00,468][model][INFO] - Training step 10480 loss 0.02142910286784172
[2025-03-15 01:06:42,601][model][INFO] - Training step 10640 loss 0.025302022695541382
[2025-03-15 01:07:22,199][model][INFO] - Training step 10800 loss 0.0038169529289007187
[2025-03-15 01:08:02,674][model][INFO] - Training step 10960 loss 0.004025146830826998
[2025-03-15 01:08:43,539][model][INFO] - Training step 11120 loss 0.0235902052372694
[2025-03-15 01:09:22,601][model][INFO] - Training step 11280 loss 0.24780580401420593
[2025-03-15 01:10:01,878][model][INFO] - Training step 11440 loss 0.021089844405651093
[2025-03-15 01:10:42,415][model][INFO] - Training step 11600 loss 0.013233061879873276
[2025-03-15 01:11:23,786][model][INFO] - Training step 11760 loss 0.05962495505809784
[2025-03-15 01:12:04,740][model][INFO] - Training step 11920 loss 0.08812487125396729
[2025-03-15 01:12:47,316][model][INFO] - Training step 12080 loss 0.28510069847106934
[2025-03-15 01:13:27,183][model][INFO] - Training step 12240 loss 0.03429669141769409
[2025-03-15 01:14:07,112][model][INFO] - Training step 12400 loss 0.2329891324043274
[2025-03-15 01:14:46,964][model][INFO] - Training step 12560 loss 0.023676341399550438
[2025-03-15 01:15:27,460][model][INFO] - Training step 12720 loss 0.026869365945458412
[2025-03-15 01:16:08,988][model][INFO] - Training step 12880 loss 0.0032410030253231525
[2025-03-15 01:16:49,899][model][INFO] - Training step 13040 loss 0.23997700214385986
[2025-03-15 01:17:30,828][model][INFO] - Training step 13200 loss 0.028312809765338898
[2025-03-15 01:18:11,831][model][INFO] - Training step 13360 loss 0.06035701185464859
[2025-03-15 01:18:52,850][model][INFO] - Training step 13520 loss 0.02205970138311386
[2025-03-15 01:19:35,822][model][INFO] - Training step 13680 loss 0.01558260340243578
[2025-03-15 01:20:18,331][model][INFO] - Training step 13840 loss 0.03546836972236633
[2025-03-15 01:20:58,296][model][INFO] - Training step 14000 loss 0.021490678191184998
[2025-03-15 01:21:37,919][model][INFO] - Training step 14160 loss 0.02451719343662262
[2025-03-15 01:22:18,373][model][INFO] - Training step 14320 loss 0.03255558758974075
[2025-03-15 01:22:59,014][model][INFO] - Training step 14480 loss 0.018926888704299927
[2025-03-15 01:23:39,247][model][INFO] - Training step 14640 loss 0.23025095462799072
[2025-03-15 01:24:18,483][model][INFO] - Training step 14800 loss 0.03236827254295349
[2025-03-15 01:24:58,098][model][INFO] - Training step 14960 loss 0.095034658908844
[2025-03-15 01:25:38,323][model][INFO] - Training step 15120 loss 0.21498000621795654
[2025-03-15 01:26:18,553][model][INFO] - Training step 15280 loss 0.0019349324284121394
[2025-03-15 01:26:59,792][model][INFO] - Training step 15440 loss 0.007600919343531132
[2025-03-15 01:27:41,377][model][INFO] - Training step 15600 loss 0.05931611359119415
[2025-03-15 01:28:20,982][model][INFO] - Training step 15760 loss 0.30698782205581665
[2025-03-15 01:29:01,156][model][INFO] - Training step 15920 loss 0.24911357462406158
[2025-03-15 01:29:41,888][model][INFO] - Training step 16080 loss 0.25032007694244385
[2025-03-15 01:30:24,684][model][INFO] - Training step 16240 loss 0.026791730895638466
[2025-03-15 01:31:05,894][model][INFO] - Training step 16400 loss 0.02828991785645485
[2025-03-15 01:31:45,859][model][INFO] - Training step 16560 loss 0.03293655440211296
[2025-03-15 01:32:24,968][model][INFO] - Training step 16720 loss 0.02202756144106388
[2025-03-15 01:33:05,572][model][INFO] - Training step 16880 loss 0.018596496433019638
[2025-03-15 01:33:45,900][model][INFO] - Training step 17040 loss 0.06596981734037399
[2025-03-15 01:34:25,993][model][INFO] - Training step 17200 loss 0.037832725793123245
[2025-03-15 01:35:08,118][model][INFO] - Training step 17360 loss 0.016715625301003456
[2025-03-15 01:35:49,111][model][INFO] - Training step 17520 loss 0.04651234671473503
[2025-03-15 01:36:30,824][model][INFO] - Training step 17680 loss 0.039294980466365814
[2025-03-15 01:37:11,400][model][INFO] - Training step 17840 loss 0.25808027386665344
[2025-03-15 01:37:52,915][model][INFO] - Training step 18000 loss 0.026222186163067818
[2025-03-15 01:38:33,830][model][INFO] - Training step 18160 loss 0.02259179763495922
[2025-03-15 01:39:14,409][model][INFO] - Training step 18320 loss 0.02274409681558609
[2025-03-15 01:39:55,015][model][INFO] - Training step 18480 loss 0.0032607540488243103
[2025-03-15 01:40:36,044][model][INFO] - Training step 18640 loss 0.04916614294052124
[2025-03-15 01:41:15,261][model][INFO] - Training step 18800 loss 0.01605214737355709
[2025-03-15 01:41:55,722][model][INFO] - Training step 18960 loss 0.2779538035392761
[2025-03-15 01:42:34,027][model][INFO] - Training step 19120 loss 0.20897024869918823
[2025-03-15 01:43:15,321][model][INFO] - Training step 19280 loss 0.007619128562510014
[2025-03-15 01:43:55,936][model][INFO] - Training step 19440 loss 0.004869326017796993
[2025-03-15 01:44:37,718][model][INFO] - Training step 19600 loss 0.032733794301748276
[2025-03-15 01:45:18,571][model][INFO] - Training step 19760 loss 0.004688727669417858
[2025-03-15 01:46:00,369][model][INFO] - Training step 19920 loss 0.04884236305952072
[2025-03-15 01:46:39,533][model][INFO] - Training step 20080 loss 0.04251876473426819
[2025-03-15 01:47:20,868][model][INFO] - Training step 20240 loss 0.1745964139699936
[2025-03-15 01:47:59,430][model][INFO] - Training step 20400 loss 0.06429906189441681
[2025-03-15 01:48:40,118][model][INFO] - Training step 20560 loss 0.02068847045302391
[2025-03-15 01:49:21,746][model][INFO] - Training step 20720 loss 0.05209353193640709
[2025-03-15 01:50:02,903][model][INFO] - Training step 20880 loss 0.034092389047145844
[2025-03-15 01:50:43,767][model][INFO] - Training step 21040 loss 0.1362970471382141
[2025-03-15 01:51:23,955][model][INFO] - Training step 21200 loss 0.00280209188349545
[2025-03-15 01:52:04,182][model][INFO] - Training step 21360 loss 0.006882977671921253
[2025-03-15 01:52:44,159][model][INFO] - Training step 21520 loss 0.2477782666683197
[2025-03-15 01:53:26,192][model][INFO] - Training step 21680 loss 0.020468169823288918
[2025-03-15 01:54:08,276][model][INFO] - Training step 21840 loss 0.0024338741786777973
[2025-03-15 01:54:47,691][model][INFO] - Training step 22000 loss 0.003516020253300667
[2025-03-15 01:55:26,863][model][INFO] - Training step 22160 loss 0.24294142425060272
[2025-03-15 01:56:06,697][model][INFO] - Training step 22320 loss 0.0035306215286254883
[2025-03-15 01:56:47,478][model][INFO] - Training step 22480 loss 0.2589380145072937
[2025-03-15 01:57:30,254][model][INFO] - Training step 22640 loss 0.007936346344649792
[2025-03-15 01:58:09,935][model][INFO] - Training step 22800 loss 0.25026315450668335
[2025-03-15 01:58:51,982][model][INFO] - Training step 22960 loss 0.016750231385231018
[2025-03-15 01:59:33,109][model][INFO] - Training step 23120 loss 0.14998555183410645
[2025-03-15 02:00:14,098][model][INFO] - Training step 23280 loss 0.0023910580202937126
[2025-03-15 02:00:54,763][model][INFO] - Training step 23440 loss 0.187693789601326
[2025-03-15 02:01:35,746][model][INFO] - Training step 23600 loss 0.003377252724021673
[2025-03-15 02:02:16,042][model][INFO] - Training step 23760 loss 0.2543606162071228
[2025-03-15 02:02:57,035][model][INFO] - Training step 23920 loss 0.0750068873167038
[2025-03-15 02:03:38,481][model][INFO] - Training step 24080 loss 0.08092796057462692
[2025-03-15 02:04:17,511][model][INFO] - Training step 24240 loss 0.008229915052652359
[2025-03-15 02:04:57,346][model][INFO] - Training step 24400 loss 0.2492297738790512
[2025-03-15 02:05:37,243][model][INFO] - Training step 24560 loss 0.25397515296936035
[2025-03-15 02:06:18,042][model][INFO] - Training step 24720 loss 0.01968196965754032
[2025-03-15 02:06:58,548][model][INFO] - Training step 24880 loss 0.00795311015099287
[2025-03-15 02:07:38,888][model][INFO] - Training step 25040 loss 0.005054054781794548
[2025-03-15 02:08:20,422][model][INFO] - Training step 25200 loss 0.016848258674144745
[2025-03-15 02:09:01,070][model][INFO] - Training step 25360 loss 0.2567669749259949
[2025-03-15 02:09:41,142][model][INFO] - Training step 25520 loss 0.029892858117818832
[2025-03-15 02:10:22,345][model][INFO] - Training step 25680 loss 0.010978752747178078
[2025-03-15 02:11:01,476][model][INFO] - Training step 25840 loss 0.09750281274318695
[2025-03-15 02:11:42,581][model][INFO] - Training step 26000 loss 0.29513019323349
[2025-03-15 02:12:22,488][model][INFO] - Training step 26160 loss 0.2559162974357605
[2025-03-15 02:13:05,175][model][INFO] - Training step 26320 loss 0.0051540592685341835
[2025-03-15 02:13:46,711][model][INFO] - Training step 26480 loss 0.15999019145965576
[2025-03-15 02:14:27,947][model][INFO] - Training step 26640 loss 0.03505498543381691
[2025-03-15 02:15:07,546][model][INFO] - Training step 26800 loss 0.010472636669874191
[2025-03-15 02:15:47,358][model][INFO] - Training step 26960 loss 0.03447004035115242
[2025-03-15 02:16:29,329][model][INFO] - Training step 27120 loss 0.07332151383161545
[2025-03-15 02:17:09,167][model][INFO] - Training step 27280 loss 0.17760980129241943
[2025-03-15 02:17:51,470][model][INFO] - Training step 27440 loss 0.03768134117126465
[2025-03-15 02:18:31,306][model][INFO] - Training step 27600 loss 0.11659494787454605
[2025-03-15 02:19:12,166][model][INFO] - Training step 27760 loss 0.006275809369981289
[2025-03-15 02:19:53,952][model][INFO] - Training step 27920 loss 0.020676160231232643
[2025-03-15 02:20:35,216][model][INFO] - Training step 28080 loss 0.2511201500892639
[2025-03-15 02:21:16,220][model][INFO] - Training step 28240 loss 0.2475135624408722
[2025-03-15 02:21:56,190][model][INFO] - Training step 28400 loss 0.057194095104932785
[2025-03-15 02:22:36,452][model][INFO] - Training step 28560 loss 0.027535708621144295
[2025-03-15 02:23:18,049][model][INFO] - Training step 28720 loss 0.010825047269463539
[2025-03-15 02:24:00,146][model][INFO] - Training step 28880 loss 0.004730092827230692
[2025-03-15 02:24:40,788][model][INFO] - Training step 29040 loss 0.020520363003015518
[2025-03-15 02:25:20,654][model][INFO] - Training step 29200 loss 0.04053456336259842
[2025-03-15 02:26:00,954][model][INFO] - Training step 29360 loss 0.008601146750152111
[2025-03-15 02:26:40,949][model][INFO] - Training step 29520 loss 0.0030031537171453238
[2025-03-15 02:27:22,162][model][INFO] - Training step 29680 loss 0.2443310022354126
[2025-03-15 02:28:02,471][model][INFO] - Training step 29840 loss 0.2696489691734314
[2025-03-15 02:28:43,707][model][INFO] - Training step 30000 loss 0.012308420613408089
[2025-03-15 02:29:25,175][model][INFO] - Training step 30160 loss 0.04478738456964493
[2025-03-15 02:30:06,836][model][INFO] - Training step 30320 loss 0.022056102752685547
[2025-03-15 02:30:48,292][model][INFO] - Training step 30480 loss 0.03194286301732063
[2025-03-15 02:31:26,934][model][INFO] - Training step 30640 loss 0.023305300623178482
[2025-03-15 02:32:06,636][model][INFO] - Training step 30800 loss 0.03386193513870239
[2025-03-15 02:32:47,299][model][INFO] - Training step 30960 loss 0.026663366705179214
[2025-03-15 02:33:28,270][model][INFO] - Training step 31120 loss 0.24736139178276062
[2025-03-15 02:34:08,184][model][INFO] - Training step 31280 loss 0.004679569508880377
[2025-03-15 02:34:49,251][model][INFO] - Training step 31440 loss 0.027519015595316887
[2025-03-15 02:35:29,897][model][INFO] - Training step 31600 loss 0.03772993013262749
[2025-03-15 02:36:10,199][model][INFO] - Training step 31760 loss 0.2673960328102112
[2025-03-15 02:36:49,779][model][INFO] - Training step 31920 loss 0.02436070516705513
[2025-03-15 02:37:30,891][model][INFO] - Training step 32080 loss 0.02826862223446369
[2025-03-15 02:38:12,401][model][INFO] - Training step 32240 loss 0.012476816773414612
[2025-03-15 02:38:52,651][model][INFO] - Training step 32400 loss 0.030126947909593582
[2025-03-15 02:39:33,636][model][INFO] - Training step 32560 loss 0.03412214666604996
[2025-03-15 02:40:16,238][model][INFO] - Training step 32720 loss 0.026278547942638397
[2025-03-15 02:40:58,079][model][INFO] - Training step 32880 loss 0.039316847920417786
[2025-03-15 02:41:39,847][model][INFO] - Training step 33040 loss 0.025201041251420975
[2025-03-15 02:42:21,573][model][INFO] - Training step 33200 loss 0.17389003932476044
[2025-03-15 02:43:02,771][model][INFO] - Training step 33360 loss 0.02347651869058609
[2025-03-15 02:43:42,457][model][INFO] - Training step 33520 loss 0.003562737023457885
[2025-03-15 02:44:25,517][model][INFO] - Training step 33680 loss 0.25351226329803467
[2025-03-15 02:45:05,511][model][INFO] - Training step 33840 loss 0.030170153826475143
[2025-03-15 02:45:45,644][model][INFO] - Training step 34000 loss 0.2534094452857971
[2025-03-15 02:46:27,622][model][INFO] - Training step 34160 loss 0.04366719722747803
[2025-03-15 02:47:07,599][model][INFO] - Training step 34320 loss 0.024908455088734627
[2025-03-15 02:47:48,213][model][INFO] - Training step 34480 loss 0.1537644863128662
[2025-03-15 02:48:29,442][model][INFO] - Training step 34640 loss 0.23945960402488708
[2025-03-15 02:49:08,943][model][INFO] - Training step 34800 loss 0.0400020033121109
[2025-03-15 02:49:50,168][model][INFO] - Training step 34960 loss 0.023959416896104813
[2025-03-15 02:50:29,177][model][INFO] - Training step 35120 loss 0.010388612747192383
[2025-03-15 02:51:09,672][model][INFO] - Training step 35280 loss 0.2569732367992401
[2025-03-15 02:51:50,057][model][INFO] - Training step 35440 loss 0.02607872150838375
[2025-03-15 02:52:31,043][model][INFO] - Training step 35600 loss 0.2566680312156677
[2025-03-15 02:53:11,454][model][INFO] - Training step 35760 loss 0.24256634712219238
[2025-03-15 02:53:52,493][model][INFO] - Training step 35920 loss 0.026546210050582886
[2025-03-15 02:54:33,673][model][INFO] - Training step 36080 loss 0.04421210289001465
[2025-03-15 02:55:13,406][model][INFO] - Training step 36240 loss 0.2524597942829132
[2025-03-15 02:55:53,333][model][INFO] - Training step 36400 loss 0.03995782136917114
[2025-03-15 02:56:33,729][model][INFO] - Training step 36560 loss 0.003456046571955085
[2025-03-15 02:57:14,715][model][INFO] - Training step 36720 loss 0.01900522969663143
[2025-03-15 02:57:56,050][model][INFO] - Training step 36880 loss 0.002468361519277096
[2025-03-15 02:58:38,081][model][INFO] - Training step 37040 loss 0.013972507789731026
[2025-03-15 02:59:19,122][model][INFO] - Training step 37200 loss 0.024489376693964005
[2025-03-15 02:59:59,554][model][INFO] - Training step 37360 loss 0.030529677867889404
[2025-03-15 03:00:40,887][model][INFO] - Training step 37520 loss 0.008680932223796844
[2025-03-15 03:01:20,600][model][INFO] - Training step 37680 loss 0.022208668291568756
[2025-03-15 03:02:02,396][model][INFO] - Training step 37840 loss 0.05297185480594635
[2025-03-15 03:02:41,426][model][INFO] - Training step 38000 loss 0.03436695784330368
[2025-03-15 03:03:20,921][model][INFO] - Training step 38160 loss 0.02470635436475277
[2025-03-15 03:04:00,856][model][INFO] - Training step 38320 loss 0.03008454293012619
[2025-03-15 03:04:40,940][model][INFO] - Training step 38480 loss 0.029035259038209915
[2025-03-15 03:05:20,434][model][INFO] - Training step 38640 loss 0.024439193308353424
[2025-03-15 03:06:00,612][model][INFO] - Training step 38800 loss 0.013079531490802765
[2025-03-15 03:06:41,533][model][INFO] - Training step 38960 loss 0.02192004956305027
[2025-03-15 03:07:20,426][model][INFO] - Training step 39120 loss 0.044363632798194885
[2025-03-15 03:08:00,236][model][INFO] - Training step 39280 loss 0.15751470625400543
[2025-03-15 03:08:41,493][model][INFO] - Training step 39440 loss 0.13678693771362305
[2025-03-15 03:09:21,367][model][INFO] - Training step 39600 loss 0.020066596567630768
[2025-03-15 03:10:02,558][model][INFO] - Training step 39760 loss 0.0202629454433918
[2025-03-15 03:10:42,841][model][INFO] - Training step 39920 loss 0.17445454001426697
[2025-03-15 03:11:23,240][model][INFO] - Training step 40080 loss 0.019190054386854172
[2025-03-15 03:12:04,190][model][INFO] - Training step 40240 loss 0.2254398614168167
[2025-03-15 03:12:43,548][model][INFO] - Training step 40400 loss 0.04162934422492981
[2025-03-15 03:13:23,534][model][INFO] - Training step 40560 loss 0.041303690522909164
[2025-03-15 03:14:04,271][model][INFO] - Training step 40720 loss 0.02912532538175583
[2025-03-15 03:14:44,621][model][INFO] - Training step 40880 loss 0.30356884002685547
[2025-03-15 03:15:24,333][model][INFO] - Training step 41040 loss 0.045374393463134766
[2025-03-15 03:16:06,218][model][INFO] - Training step 41200 loss 0.012756146490573883
[2025-03-15 03:16:47,596][model][INFO] - Training step 41360 loss 0.02911902219057083
[2025-03-15 03:17:27,287][model][INFO] - Training step 41520 loss 0.08161553740501404
[2025-03-15 03:18:07,910][model][INFO] - Training step 41680 loss 0.09145846962928772
[2025-03-15 03:18:49,650][model][INFO] - Training step 41840 loss 0.016190938651561737
[2025-03-15 03:19:29,358][model][INFO] - Training step 42000 loss 0.25008511543273926
[2025-03-15 03:20:09,881][model][INFO] - Training step 42160 loss 0.030571307986974716
[2025-03-15 03:20:51,185][model][INFO] - Training step 42320 loss 0.015179533511400223
[2025-03-15 03:21:33,967][model][INFO] - Training step 42480 loss 0.019966838881373405
[2025-03-15 03:22:14,186][model][INFO] - Training step 42640 loss 0.24479535222053528
[2025-03-15 03:22:53,012][model][INFO] - Training step 42800 loss 0.04136615991592407
[2025-03-15 03:23:33,311][model][INFO] - Training step 42960 loss 0.02025631070137024
[2025-03-15 03:24:14,833][model][INFO] - Training step 43120 loss 0.04341977834701538
[2025-03-15 03:24:54,103][model][INFO] - Training step 43280 loss 0.03610331937670708
[2025-03-15 03:25:35,923][model][INFO] - Training step 43440 loss 0.04553947597742081
[2025-03-15 03:26:17,969][model][INFO] - Training step 43600 loss 0.009763979353010654
[2025-03-15 03:26:58,394][model][INFO] - Training step 43760 loss 0.04528738558292389
[2025-03-15 03:27:41,174][model][INFO] - Training step 43920 loss 0.042515553534030914
[2025-03-15 03:28:24,892][model][INFO] - Training step 44080 loss 0.04583103954792023
[2025-03-15 03:29:04,641][model][INFO] - Training step 44240 loss 0.026273787021636963
[2025-03-15 03:29:45,209][model][INFO] - Training step 44400 loss 0.033313021063804626
[2025-03-15 03:30:24,776][model][INFO] - Training step 44560 loss 0.023700453341007233
[2025-03-15 03:31:04,232][model][INFO] - Training step 44720 loss 0.01940351352095604
[2025-03-15 03:31:45,446][model][INFO] - Training step 44880 loss 0.05615215003490448
[2025-03-15 03:32:26,288][model][INFO] - Training step 45040 loss 0.004437319003045559
[2025-03-15 03:33:04,713][model][INFO] - Training step 45200 loss 0.013982048258185387
[2025-03-15 03:33:46,762][model][INFO] - Training step 45360 loss 0.02680542692542076
[2025-03-15 03:34:27,171][model][INFO] - Training step 45520 loss 0.007656595204025507
[2025-03-15 03:35:07,297][model][INFO] - Training step 45680 loss 0.2531622052192688
[2025-03-15 03:35:48,566][model][INFO] - Training step 45840 loss 0.0046326033771038055
[2025-03-15 03:36:27,998][model][INFO] - Training step 46000 loss 0.11645057797431946
[2025-03-15 03:37:09,792][model][INFO] - Training step 46160 loss 0.25831925868988037
[2025-03-15 03:37:51,236][model][INFO] - Training step 46320 loss 0.04674050211906433
[2025-03-15 03:38:32,198][model][INFO] - Training step 46480 loss 0.022788479924201965
[2025-03-15 03:39:13,203][model][INFO] - Training step 46640 loss 0.20509940385818481
[2025-03-15 03:39:54,044][model][INFO] - Training step 46800 loss 0.029407784342765808
[2025-03-15 03:40:34,047][model][INFO] - Training step 46960 loss 0.0357692688703537
[2025-03-15 03:41:14,873][model][INFO] - Training step 47120 loss 0.03736090660095215
[2025-03-15 03:41:55,774][model][INFO] - Training step 47280 loss 0.0023341537453234196
[2025-03-15 03:42:37,868][model][INFO] - Training step 47440 loss 0.25252586603164673
[2025-03-15 03:43:18,552][model][INFO] - Training step 47600 loss 0.03755857050418854
[2025-03-15 03:43:59,472][model][INFO] - Training step 47760 loss 0.03415345400571823
[2025-03-15 03:44:41,840][model][INFO] - Training step 47920 loss 0.24941036105155945
[2025-03-15 03:45:22,954][model][INFO] - Training step 48080 loss 0.2586067020893097
[2025-03-15 03:46:02,137][model][INFO] - Training step 48240 loss 0.004954259842634201
[2025-03-15 03:46:41,759][model][INFO] - Training step 48400 loss 0.006424413062632084
[2025-03-15 03:47:23,118][model][INFO] - Training step 48560 loss 0.25190308690071106
[2025-03-15 03:48:04,932][model][INFO] - Training step 48720 loss 0.02621489018201828
[2025-03-15 03:48:45,367][model][INFO] - Training step 48880 loss 0.015656031668186188
[2025-03-15 03:49:25,251][model][INFO] - Training step 49040 loss 0.03195834904909134
[2025-03-15 03:50:06,372][model][INFO] - Training step 49200 loss 0.02713800221681595
[2025-03-15 03:50:47,345][model][INFO] - Training step 49360 loss 0.25265586376190186
[2025-03-15 03:51:29,074][model][INFO] - Training step 49520 loss 0.032049041241407394
[2025-03-15 03:52:08,865][model][INFO] - Training step 49680 loss 0.011763432063162327
[2025-03-15 03:52:49,556][model][INFO] - Training step 49840 loss 0.09729446470737457
[2025-03-15 03:53:31,214][model][INFO] - Training step 50000 loss 0.02529546432197094
[2025-03-15 03:54:13,034][model][INFO] - Training step 50160 loss 0.024869490414857864
[2025-03-15 03:54:54,332][model][INFO] - Training step 50320 loss 0.018953852355480194
[2025-03-15 03:55:34,655][model][INFO] - Training step 50480 loss 0.06505131721496582
[2025-03-15 03:56:13,436][model][INFO] - Training step 50640 loss 0.24604296684265137
[2025-03-15 04:01:58,681][model][INFO] - Training step 0 loss 0.24404478073120117
[2025-03-15 04:02:39,797][model][INFO] - Training step 160 loss 0.01324019581079483
[2025-03-15 04:03:21,199][model][INFO] - Training step 320 loss 0.11010323464870453
[2025-03-15 04:04:02,274][model][INFO] - Training step 480 loss 0.018847066909074783
[2025-03-15 04:04:43,251][model][INFO] - Training step 640 loss 0.2558647394180298
[2025-03-15 04:05:23,697][model][INFO] - Training step 800 loss 0.003682676237076521
[2025-03-15 04:06:03,593][model][INFO] - Training step 960 loss 0.018073035404086113
[2025-03-15 04:06:43,232][model][INFO] - Training step 1120 loss 0.05726566165685654
[2025-03-15 04:07:22,301][model][INFO] - Training step 1280 loss 0.012901745736598969
[2025-03-15 04:08:00,931][model][INFO] - Training step 1440 loss 0.028991054743528366
[2025-03-15 04:08:40,490][model][INFO] - Training step 1600 loss 0.09521624445915222
[2025-03-15 04:09:21,132][model][INFO] - Training step 1760 loss 0.032312437891960144
[2025-03-15 04:10:01,077][model][INFO] - Training step 1920 loss 0.007306242361664772
[2025-03-15 04:10:41,718][model][INFO] - Training step 2080 loss 0.22705835103988647
[2025-03-15 04:11:22,255][model][INFO] - Training step 2240 loss 0.018954604864120483
[2025-03-15 04:12:01,483][model][INFO] - Training step 2400 loss 0.055226244032382965
[2025-03-15 04:12:41,027][model][INFO] - Training step 2560 loss 0.2577871084213257
[2025-03-15 04:13:23,391][model][INFO] - Training step 2720 loss 0.019271114841103554
[2025-03-15 04:14:04,582][model][INFO] - Training step 2880 loss 0.018620792776346207
[2025-03-15 04:14:46,115][model][INFO] - Training step 3040 loss 0.022007470950484276
[2025-03-15 04:15:28,171][model][INFO] - Training step 3200 loss 0.00390752125531435
[2025-03-15 04:16:08,571][model][INFO] - Training step 3360 loss 0.2852346897125244
[2025-03-15 04:16:50,305][model][INFO] - Training step 3520 loss 0.006610039621591568
[2025-03-15 04:17:31,536][model][INFO] - Training step 3680 loss 0.0045784758403897285
[2025-03-15 04:18:12,487][model][INFO] - Training step 3840 loss 0.035240963101387024
[2025-03-15 04:18:53,879][model][INFO] - Training step 4000 loss 0.0355435274541378
[2025-03-15 04:19:34,184][model][INFO] - Training step 4160 loss 0.012071357108652592
[2025-03-15 04:20:15,573][model][INFO] - Training step 4320 loss 0.06441810727119446
[2025-03-15 04:20:59,533][model][INFO] - Training step 4480 loss 0.0022578812204301357
[2025-03-15 04:21:40,457][model][INFO] - Training step 4640 loss 0.005600610747933388
[2025-03-15 04:22:19,455][model][INFO] - Training step 4800 loss 0.002500282134860754
[2025-03-15 04:23:00,865][model][INFO] - Training step 4960 loss 0.008373236283659935
[2025-03-15 04:23:42,666][model][INFO] - Training step 5120 loss 0.6791408061981201
[2025-03-15 04:24:23,613][model][INFO] - Training step 5280 loss 0.007006887812167406
[2025-03-15 04:25:03,511][model][INFO] - Training step 5440 loss 0.03828055411577225
[2025-03-15 04:25:42,148][model][INFO] - Training step 5600 loss 0.014745278283953667
[2025-03-15 04:26:23,324][model][INFO] - Training step 5760 loss 0.019846461713314056
[2025-03-15 04:27:05,219][model][INFO] - Training step 5920 loss 0.018725186586380005
[2025-03-15 04:27:45,401][model][INFO] - Training step 6080 loss 0.004784200806170702
[2025-03-15 04:28:27,734][model][INFO] - Training step 6240 loss 0.23943471908569336
[2025-03-15 04:29:09,721][model][INFO] - Training step 6400 loss 0.020929105579853058
[2025-03-15 04:29:50,127][model][INFO] - Training step 6560 loss 0.004344838671386242
[2025-03-15 04:30:31,137][model][INFO] - Training step 6720 loss 0.007981667295098305
[2025-03-15 04:31:11,705][model][INFO] - Training step 6880 loss 0.08109880983829498
[2025-03-15 04:31:52,965][model][INFO] - Training step 7040 loss 0.2589621841907501
[2025-03-15 04:32:34,946][model][INFO] - Training step 7200 loss 0.014529531821608543
[2025-03-15 04:33:14,025][model][INFO] - Training step 7360 loss 0.029243268072605133
[2025-03-15 04:33:55,866][model][INFO] - Training step 7520 loss 0.029774457216262817
[2025-03-15 04:34:37,043][model][INFO] - Training step 7680 loss 0.10424283146858215
[2025-03-15 04:35:18,592][model][INFO] - Training step 7840 loss 0.02812529355287552
[2025-03-15 04:36:00,702][model][INFO] - Training step 8000 loss 0.0032894471660256386
[2025-03-15 04:36:41,213][model][INFO] - Training step 8160 loss 0.00268270680680871
[2025-03-15 04:37:21,372][model][INFO] - Training step 8320 loss 0.003795426106080413
[2025-03-15 04:38:01,641][model][INFO] - Training step 8480 loss 0.11584115773439407
[2025-03-15 04:38:42,450][model][INFO] - Training step 8640 loss 0.015164089389145374
[2025-03-15 04:39:22,132][model][INFO] - Training step 8800 loss 0.024031460285186768
[2025-03-15 04:40:01,806][model][INFO] - Training step 8960 loss 0.5092258453369141
[2025-03-15 04:40:41,898][model][INFO] - Training step 9120 loss 0.06351394206285477
[2025-03-15 04:41:22,068][model][INFO] - Training step 9280 loss 0.041789710521698
[2025-03-15 04:42:03,090][model][INFO] - Training step 9440 loss 0.014095289632678032
[2025-03-15 04:42:42,387][model][INFO] - Training step 9600 loss 0.050143174827098846
[2025-03-15 04:43:24,548][model][INFO] - Training step 9760 loss 0.2356477975845337
[2025-03-15 04:44:05,493][model][INFO] - Training step 9920 loss 0.024993933737277985
[2025-03-15 04:44:46,764][model][INFO] - Training step 10080 loss 0.17213518917560577
[2025-03-15 04:45:27,573][model][INFO] - Training step 10240 loss 0.00346075976267457
[2025-03-15 04:46:07,732][model][INFO] - Training step 10400 loss 0.07180532813072205
[2025-03-15 04:46:48,692][model][INFO] - Training step 10560 loss 0.15663978457450867
[2025-03-15 04:47:28,873][model][INFO] - Training step 10720 loss 0.16513431072235107
[2025-03-15 04:48:10,432][model][INFO] - Training step 10880 loss 0.00781804695725441
[2025-03-15 04:48:49,833][model][INFO] - Training step 11040 loss 0.027338672429323196
[2025-03-15 04:49:30,010][model][INFO] - Training step 11200 loss 0.06155256927013397
[2025-03-15 04:50:10,715][model][INFO] - Training step 11360 loss 0.03110126033425331
[2025-03-15 04:50:51,050][model][INFO] - Training step 11520 loss 0.02548929862678051
[2025-03-15 04:51:32,621][model][INFO] - Training step 11680 loss 0.03937269747257233
[2025-03-15 04:52:13,931][model][INFO] - Training step 11840 loss 0.03125571459531784
[2025-03-15 04:52:54,449][model][INFO] - Training step 12000 loss 0.035650379955768585
[2025-03-15 04:53:35,722][model][INFO] - Training step 12160 loss 0.07610057294368744
[2025-03-15 04:54:16,987][model][INFO] - Training step 12320 loss 0.2423442006111145
[2025-03-15 04:54:58,381][model][INFO] - Training step 12480 loss 0.022604499012231827
[2025-03-15 04:55:39,168][model][INFO] - Training step 12640 loss 0.10350793600082397
[2025-03-15 04:56:19,765][model][INFO] - Training step 12800 loss 0.02012477070093155
[2025-03-15 04:57:01,129][model][INFO] - Training step 12960 loss 0.017774946987628937
[2025-03-15 04:57:41,504][model][INFO] - Training step 13120 loss 0.013644421473145485
[2025-03-15 04:58:22,435][model][INFO] - Training step 13280 loss 0.00452464260160923
[2025-03-15 04:59:00,975][model][INFO] - Training step 13440 loss 0.06952717900276184
[2025-03-15 04:59:41,419][model][INFO] - Training step 13600 loss 0.023099925369024277
[2025-03-15 05:00:22,971][model][INFO] - Training step 13760 loss 0.07125867903232574
[2025-03-15 05:01:03,308][model][INFO] - Training step 13920 loss 0.079988032579422
[2025-03-15 05:01:44,234][model][INFO] - Training step 14080 loss 0.0157740768045187
[2025-03-15 05:02:23,988][model][INFO] - Training step 14240 loss 0.11318214237689972
[2025-03-15 05:03:05,682][model][INFO] - Training step 14400 loss 0.014817412942647934
[2025-03-15 05:03:46,692][model][INFO] - Training step 14560 loss 0.014931371435523033
[2025-03-15 05:04:27,271][model][INFO] - Training step 14720 loss 0.015142221003770828
[2025-03-15 05:05:08,131][model][INFO] - Training step 14880 loss 0.03572341799736023
[2025-03-15 05:05:50,486][model][INFO] - Training step 15040 loss 0.16935661435127258
[2025-03-15 05:06:32,641][model][INFO] - Training step 15200 loss 0.020240148529410362
[2025-03-15 05:07:12,979][model][INFO] - Training step 15360 loss 0.013766394928097725
[2025-03-15 05:07:55,653][model][INFO] - Training step 15520 loss 0.01437431387603283
[2025-03-15 05:08:37,110][model][INFO] - Training step 15680 loss 0.006158147007226944
[2025-03-15 05:09:18,039][model][INFO] - Training step 15840 loss 0.04121958091855049
[2025-03-15 05:10:00,126][model][INFO] - Training step 16000 loss 0.012791897170245647
[2025-03-15 05:10:40,986][model][INFO] - Training step 16160 loss 0.0212855264544487
[2025-03-15 05:11:20,141][model][INFO] - Training step 16320 loss 0.09531325846910477
[2025-03-15 05:12:00,407][model][INFO] - Training step 16480 loss 0.01632513478398323
[2025-03-15 05:12:42,505][model][INFO] - Training step 16640 loss 0.37854424118995667
[2025-03-15 05:13:22,924][model][INFO] - Training step 16800 loss 0.05876442790031433
[2025-03-15 05:14:04,362][model][INFO] - Training step 16960 loss 0.1038922667503357
[2025-03-15 05:14:45,668][model][INFO] - Training step 17120 loss 0.07123267650604248
[2025-03-15 05:15:26,890][model][INFO] - Training step 17280 loss 0.611052393913269
[2025-03-15 05:16:06,936][model][INFO] - Training step 17440 loss 0.03392453119158745
[2025-03-15 05:16:47,430][model][INFO] - Training step 17600 loss 0.05025656148791313
[2025-03-15 05:17:27,771][model][INFO] - Training step 17760 loss 0.03238999843597412
[2025-03-15 05:18:08,259][model][INFO] - Training step 17920 loss 0.269576758146286
[2025-03-15 05:18:47,880][model][INFO] - Training step 18080 loss 0.04716479778289795
[2025-03-15 05:19:27,642][model][INFO] - Training step 18240 loss 0.03306695073843002
[2025-03-15 05:20:09,340][model][INFO] - Training step 18400 loss 0.2562599182128906
[2025-03-15 05:20:48,808][model][INFO] - Training step 18560 loss 0.09579907357692719
[2025-03-15 05:21:29,550][model][INFO] - Training step 18720 loss 0.05003023147583008
[2025-03-15 05:22:09,869][model][INFO] - Training step 18880 loss 0.01770610734820366
[2025-03-15 05:22:49,743][model][INFO] - Training step 19040 loss 0.03123651258647442
[2025-03-15 05:23:30,989][model][INFO] - Training step 19200 loss 0.02521742507815361
[2025-03-15 05:24:10,407][model][INFO] - Training step 19360 loss 0.025334114208817482
[2025-03-15 05:24:51,361][model][INFO] - Training step 19520 loss 0.004430624656379223
[2025-03-15 05:25:32,479][model][INFO] - Training step 19680 loss 0.029132889583706856
[2025-03-15 05:26:11,449][model][INFO] - Training step 19840 loss 0.04287164658308029
[2025-03-15 05:26:52,227][model][INFO] - Training step 20000 loss 0.005637041758745909
[2025-03-15 05:27:33,080][model][INFO] - Training step 20160 loss 0.06355848908424377
[2025-03-15 05:28:13,714][model][INFO] - Training step 20320 loss 0.028081834316253662
[2025-03-15 05:28:53,249][model][INFO] - Training step 20480 loss 0.01782231777906418
[2025-03-15 05:29:33,744][model][INFO] - Training step 20640 loss 0.0217343270778656
[2025-03-15 05:30:14,659][model][INFO] - Training step 20800 loss 0.2133370190858841
[2025-03-15 05:30:55,327][model][INFO] - Training step 20960 loss 0.01703830435872078
[2025-03-15 05:31:36,998][model][INFO] - Training step 21120 loss 0.06489798426628113
[2025-03-15 05:32:17,042][model][INFO] - Training step 21280 loss 0.02020723931491375
[2025-03-15 05:32:57,847][model][INFO] - Training step 21440 loss 0.007699459791183472
[2025-03-15 05:33:38,501][model][INFO] - Training step 21600 loss 0.2488035261631012
[2025-03-15 05:34:19,822][model][INFO] - Training step 21760 loss 0.2656711935997009
[2025-03-15 05:34:59,157][model][INFO] - Training step 21920 loss 0.04253310710191727
[2025-03-15 05:35:40,078][model][INFO] - Training step 22080 loss 0.049461353570222855
[2025-03-15 05:36:18,939][model][INFO] - Training step 22240 loss 0.034945160150527954
[2025-03-15 05:37:00,410][model][INFO] - Training step 22400 loss 0.2281971424818039
[2025-03-15 05:37:40,502][model][INFO] - Training step 22560 loss 0.03578053414821625
[2025-03-15 05:38:21,092][model][INFO] - Training step 22720 loss 0.043782852590084076
[2025-03-15 05:39:01,485][model][INFO] - Training step 22880 loss 0.02002980001270771
[2025-03-15 05:39:42,097][model][INFO] - Training step 23040 loss 0.0393880158662796
[2025-03-15 05:40:21,842][model][INFO] - Training step 23200 loss 0.07927624881267548
[2025-03-15 05:41:02,412][model][INFO] - Training step 23360 loss 0.005187069997191429
[2025-03-15 05:41:44,392][model][INFO] - Training step 23520 loss 0.03345770388841629
[2025-03-15 05:42:24,887][model][INFO] - Training step 23680 loss 0.027090121060609818
[2025-03-15 05:43:06,522][model][INFO] - Training step 23840 loss 0.017718978226184845
[2025-03-15 05:43:48,152][model][INFO] - Training step 24000 loss 0.0066826301626861095
[2025-03-15 05:44:27,311][model][INFO] - Training step 24160 loss 0.02334904484450817
[2025-03-15 05:45:07,152][model][INFO] - Training step 24320 loss 0.02472136914730072
[2025-03-15 05:45:48,409][model][INFO] - Training step 24480 loss 0.008364975452423096
[2025-03-15 05:46:27,500][model][INFO] - Training step 24640 loss 0.007792079821228981
[2025-03-15 05:47:09,439][model][INFO] - Training step 24800 loss 0.08550161123275757
[2025-03-15 05:47:52,001][model][INFO] - Training step 24960 loss 0.01817276142537594
[2025-03-15 05:48:33,175][model][INFO] - Training step 25120 loss 0.007586418651044369
[2025-03-15 05:49:14,042][model][INFO] - Training step 25280 loss 0.2690854072570801
[2025-03-15 05:49:54,720][model][INFO] - Training step 25440 loss 0.02716815285384655
[2025-03-15 05:50:35,526][model][INFO] - Training step 25600 loss 0.18985819816589355
[2025-03-15 05:51:14,843][model][INFO] - Training step 25760 loss 0.02467900514602661
[2025-03-15 05:51:55,464][model][INFO] - Training step 25920 loss 0.02382751554250717
[2025-03-15 05:52:35,303][model][INFO] - Training step 26080 loss 0.023537853732705116
[2025-03-15 05:53:15,731][model][INFO] - Training step 26240 loss 0.003460630774497986
[2025-03-15 05:53:57,045][model][INFO] - Training step 26400 loss 0.023251622915267944
[2025-03-15 05:54:37,400][model][INFO] - Training step 26560 loss 0.014738624915480614
[2025-03-15 05:55:17,087][model][INFO] - Training step 26720 loss 0.23217199742794037
[2025-03-15 05:55:59,207][model][INFO] - Training step 26880 loss 0.02785826101899147
[2025-03-15 05:56:39,144][model][INFO] - Training step 27040 loss 0.007133948616683483
[2025-03-15 05:57:20,009][model][INFO] - Training step 27200 loss 0.24056875705718994
[2025-03-15 05:58:02,377][model][INFO] - Training step 27360 loss 0.06211404502391815
[2025-03-15 05:58:43,317][model][INFO] - Training step 27520 loss 0.0048363362438976765
[2025-03-15 05:59:25,327][model][INFO] - Training step 27680 loss 0.2518661916255951
[2025-03-15 06:00:05,768][model][INFO] - Training step 27840 loss 0.23840650916099548
[2025-03-15 06:00:46,570][model][INFO] - Training step 28000 loss 0.01917501538991928
[2025-03-15 06:01:27,892][model][INFO] - Training step 28160 loss 0.24459318816661835
[2025-03-15 06:02:08,152][model][INFO] - Training step 28320 loss 0.2516225576400757
[2025-03-15 06:02:48,377][model][INFO] - Training step 28480 loss 0.1631104052066803
[2025-03-15 06:03:29,661][model][INFO] - Training step 28640 loss 0.0038998182862997055
[2025-03-15 06:04:09,358][model][INFO] - Training step 28800 loss 0.12048006802797318
[2025-03-15 06:04:50,372][model][INFO] - Training step 28960 loss 0.03633628040552139
[2025-03-15 06:05:30,760][model][INFO] - Training step 29120 loss 0.0035097310319542885
[2025-03-15 06:06:12,099][model][INFO] - Training step 29280 loss 0.04413553327322006
[2025-03-15 06:06:52,564][model][INFO] - Training step 29440 loss 0.01684415154159069
[2025-03-15 06:07:32,872][model][INFO] - Training step 29600 loss 0.06813382357358932
[2025-03-15 06:08:12,368][model][INFO] - Training step 29760 loss 0.09821104258298874
[2025-03-15 06:08:52,986][model][INFO] - Training step 29920 loss 0.26556527614593506
[2025-03-15 06:09:33,088][model][INFO] - Training step 30080 loss 0.022680062800645828
[2025-03-15 06:10:13,116][model][INFO] - Training step 30240 loss 0.030329417437314987
[2025-03-15 06:10:55,984][model][INFO] - Training step 30400 loss 0.027791865170001984
[2025-03-15 06:11:36,453][model][INFO] - Training step 30560 loss 0.28524667024612427
[2025-03-15 06:12:14,546][model][INFO] - Training step 30720 loss 0.01033506728708744
[2025-03-15 06:12:54,789][model][INFO] - Training step 30880 loss 0.2566600441932678
[2025-03-15 06:13:35,505][model][INFO] - Training step 31040 loss 0.24841362237930298
[2025-03-15 06:14:15,740][model][INFO] - Training step 31200 loss 0.025623686611652374
[2025-03-15 06:14:55,862][model][INFO] - Training step 31360 loss 0.06613394618034363
[2025-03-15 06:15:37,465][model][INFO] - Training step 31520 loss 0.0092332623898983
[2025-03-15 06:16:19,367][model][INFO] - Training step 31680 loss 0.023730862885713577
[2025-03-15 06:16:58,720][model][INFO] - Training step 31840 loss 0.008458361029624939
[2025-03-15 06:17:38,786][model][INFO] - Training step 32000 loss 0.12397654354572296
[2025-03-15 06:18:20,423][model][INFO] - Training step 32160 loss 0.004989856854081154
[2025-03-15 06:19:00,026][model][INFO] - Training step 32320 loss 0.02757539227604866
[2025-03-15 06:19:39,876][model][INFO] - Training step 32480 loss 0.020634429529309273
[2025-03-15 06:20:22,897][model][INFO] - Training step 32640 loss 0.17192703485488892
[2025-03-15 06:21:03,814][model][INFO] - Training step 32800 loss 0.055718906223773956
[2025-03-15 06:21:44,226][model][INFO] - Training step 32960 loss 0.003977808635681868
[2025-03-15 06:22:24,432][model][INFO] - Training step 33120 loss 0.005384805146604776
[2025-03-15 06:23:04,902][model][INFO] - Training step 33280 loss 0.03985557705163956
[2025-03-15 06:23:45,339][model][INFO] - Training step 33440 loss 0.10191123932600021
[2025-03-15 06:24:26,147][model][INFO] - Training step 33600 loss 0.02161245048046112
[2025-03-15 06:25:06,779][model][INFO] - Training step 33760 loss 0.024718590080738068
[2025-03-15 06:25:49,295][model][INFO] - Training step 33920 loss 0.07034087181091309
[2025-03-15 06:26:30,033][model][INFO] - Training step 34080 loss 0.0033499060664325953
[2025-03-15 06:27:09,809][model][INFO] - Training step 34240 loss 0.025381755083799362
[2025-03-15 06:27:50,149][model][INFO] - Training step 34400 loss 0.044552721083164215
[2025-03-15 06:28:29,734][model][INFO] - Training step 34560 loss 0.03307721018791199
[2025-03-15 06:29:12,129][model][INFO] - Training step 34720 loss 0.018720727413892746
[2025-03-15 06:29:53,106][model][INFO] - Training step 34880 loss 0.2335093468427658
[2025-03-15 06:30:34,715][model][INFO] - Training step 35040 loss 0.022226281464099884
[2025-03-15 06:31:13,998][model][INFO] - Training step 35200 loss 0.0389225035905838
[2025-03-15 06:31:54,803][model][INFO] - Training step 35360 loss 0.03415913134813309
[2025-03-15 06:32:36,665][model][INFO] - Training step 35520 loss 0.0508599728345871
[2025-03-15 06:33:16,620][model][INFO] - Training step 35680 loss 0.0903225839138031
[2025-03-15 06:33:57,286][model][INFO] - Training step 35840 loss 0.014637760818004608
[2025-03-15 06:34:38,983][model][INFO] - Training step 36000 loss 0.025355082005262375
[2025-03-15 06:35:18,629][model][INFO] - Training step 36160 loss 0.0052118077874183655
[2025-03-15 06:36:02,685][model][INFO] - Training step 36320 loss 0.02425791323184967
[2025-03-15 06:36:42,723][model][INFO] - Training step 36480 loss 0.019269606098532677
[2025-03-15 06:37:23,609][model][INFO] - Training step 36640 loss 0.23060640692710876
[2025-03-15 06:38:04,993][model][INFO] - Training step 36800 loss 0.026684606447815895
[2025-03-15 06:38:46,950][model][INFO] - Training step 36960 loss 0.010091005824506283
[2025-03-15 06:39:26,659][model][INFO] - Training step 37120 loss 0.0190303735435009
[2025-03-15 06:40:08,967][model][INFO] - Training step 37280 loss 0.04546653479337692
[2025-03-15 06:40:49,940][model][INFO] - Training step 37440 loss 0.011741943657398224
[2025-03-15 06:41:28,968][model][INFO] - Training step 37600 loss 0.2379525750875473
[2025-03-15 06:42:09,357][model][INFO] - Training step 37760 loss 0.02247127890586853
[2025-03-15 06:42:50,661][model][INFO] - Training step 37920 loss 0.013580679893493652
[2025-03-15 06:43:31,215][model][INFO] - Training step 38080 loss 0.005181056447327137
[2025-03-15 06:44:12,477][model][INFO] - Training step 38240 loss 0.053253985941410065
[2025-03-15 06:44:53,751][model][INFO] - Training step 38400 loss 0.024966537952423096
[2025-03-15 06:45:33,694][model][INFO] - Training step 38560 loss 0.006334192119538784
[2025-03-15 06:46:14,733][model][INFO] - Training step 38720 loss 0.049331147223711014
[2025-03-15 06:46:55,939][model][INFO] - Training step 38880 loss 0.03885090351104736
[2025-03-15 06:47:36,874][model][INFO] - Training step 39040 loss 0.01490788348019123
[2025-03-15 06:48:16,797][model][INFO] - Training step 39200 loss 0.1822812855243683
[2025-03-15 06:48:55,756][model][INFO] - Training step 39360 loss 0.026241853833198547
[2025-03-15 06:49:35,787][model][INFO] - Training step 39520 loss 0.25619378685951233
[2025-03-15 06:50:15,718][model][INFO] - Training step 39680 loss 0.05574721097946167
[2025-03-15 06:50:57,561][model][INFO] - Training step 39840 loss 0.033154863864183426
[2025-03-15 06:51:37,843][model][INFO] - Training step 40000 loss 0.031151674687862396
[2025-03-15 06:52:19,661][model][INFO] - Training step 40160 loss 0.1293945610523224
[2025-03-15 06:53:01,007][model][INFO] - Training step 40320 loss 0.02464628964662552
[2025-03-15 06:53:42,585][model][INFO] - Training step 40480 loss 0.24694131314754486
[2025-03-15 06:54:23,317][model][INFO] - Training step 40640 loss 0.06075214594602585
[2025-03-15 06:55:03,015][model][INFO] - Training step 40800 loss 0.009992731735110283
[2025-03-15 06:55:41,472][model][INFO] - Training step 40960 loss 0.2414124310016632
[2025-03-15 06:56:22,060][model][INFO] - Training step 41120 loss 0.011215073987841606
[2025-03-15 06:57:02,894][model][INFO] - Training step 41280 loss 0.03539159893989563
[2025-03-15 06:57:42,482][model][INFO] - Training step 41440 loss 0.2455712854862213
[2025-03-15 06:58:23,503][model][INFO] - Training step 41600 loss 0.02285592630505562
[2025-03-15 06:59:05,448][model][INFO] - Training step 41760 loss 0.035852544009685516
[2025-03-15 06:59:46,830][model][INFO] - Training step 41920 loss 0.005575970280915499
[2025-03-15 07:00:28,308][model][INFO] - Training step 42080 loss 0.2689991593360901
[2025-03-15 07:01:08,413][model][INFO] - Training step 42240 loss 0.2582490146160126
[2025-03-15 07:01:48,682][model][INFO] - Training step 42400 loss 0.044517118483781815
[2025-03-15 07:02:28,288][model][INFO] - Training step 42560 loss 0.019460277631878853
[2025-03-15 07:03:09,038][model][INFO] - Training step 42720 loss 0.2629162669181824
[2025-03-15 07:03:49,953][model][INFO] - Training step 42880 loss 0.049725212156772614
[2025-03-15 07:04:31,143][model][INFO] - Training step 43040 loss 0.030179493129253387
[2025-03-15 07:05:10,512][model][INFO] - Training step 43200 loss 0.03389279544353485
[2025-03-15 07:05:51,511][model][INFO] - Training step 43360 loss 0.24973905086517334
[2025-03-15 07:06:32,189][model][INFO] - Training step 43520 loss 0.1759730726480484
[2025-03-15 07:07:12,388][model][INFO] - Training step 43680 loss 0.01841551437973976
[2025-03-15 07:07:53,325][model][INFO] - Training step 43840 loss 0.024386096745729446
[2025-03-15 07:08:34,749][model][INFO] - Training step 44000 loss 0.025204110890626907
[2025-03-15 07:09:16,540][model][INFO] - Training step 44160 loss 0.038899246603250504
[2025-03-15 07:09:56,891][model][INFO] - Training step 44320 loss 0.017401494085788727
[2025-03-15 07:10:37,196][model][INFO] - Training step 44480 loss 0.012436309829354286
[2025-03-15 07:11:16,646][model][INFO] - Training step 44640 loss 0.06100866571068764
[2025-03-15 07:11:56,877][model][INFO] - Training step 44800 loss 0.25466448068618774
[2025-03-15 07:12:37,729][model][INFO] - Training step 44960 loss 0.032760076224803925
[2025-03-15 07:13:18,743][model][INFO] - Training step 45120 loss 0.006735589355230331
[2025-03-15 07:14:00,406][model][INFO] - Training step 45280 loss 0.027451736852526665
[2025-03-15 07:14:42,818][model][INFO] - Training step 45440 loss 0.2238183617591858
[2025-03-15 07:15:23,201][model][INFO] - Training step 45600 loss 0.02276051789522171
[2025-03-15 07:16:04,690][model][INFO] - Training step 45760 loss 0.045838721096515656
[2025-03-15 07:16:46,757][model][INFO] - Training step 45920 loss 0.032253727316856384
[2025-03-15 07:17:29,452][model][INFO] - Training step 46080 loss 0.05431867390871048
[2025-03-15 07:18:09,915][model][INFO] - Training step 46240 loss 0.02156195044517517
[2025-03-15 07:18:49,692][model][INFO] - Training step 46400 loss 0.009498223662376404
[2025-03-15 07:19:29,669][model][INFO] - Training step 46560 loss 0.02484630048274994
[2025-03-15 07:20:09,836][model][INFO] - Training step 46720 loss 0.023713162168860435
[2025-03-15 07:20:50,175][model][INFO] - Training step 46880 loss 0.022588089108467102
[2025-03-15 07:21:31,452][model][INFO] - Training step 47040 loss 0.2066449373960495
[2025-03-15 07:22:13,085][model][INFO] - Training step 47200 loss 0.25835084915161133
[2025-03-15 07:22:54,063][model][INFO] - Training step 47360 loss 0.05138483643531799
[2025-03-15 07:23:35,036][model][INFO] - Training step 47520 loss 0.09816579520702362
[2025-03-15 07:24:16,436][model][INFO] - Training step 47680 loss 0.025912616401910782
[2025-03-15 07:24:57,558][model][INFO] - Training step 47840 loss 0.0313337966799736
[2025-03-15 07:25:38,325][model][INFO] - Training step 48000 loss 0.04086310416460037
[2025-03-15 07:26:19,795][model][INFO] - Training step 48160 loss 0.07991240918636322
[2025-03-15 07:27:00,350][model][INFO] - Training step 48320 loss 0.017729420214891434
[2025-03-15 07:27:39,806][model][INFO] - Training step 48480 loss 0.25055214762687683
[2025-03-15 07:28:19,093][model][INFO] - Training step 48640 loss 0.02172182686626911
[2025-03-15 07:29:01,450][model][INFO] - Training step 48800 loss 0.026966582983732224
[2025-03-15 07:29:41,501][model][INFO] - Training step 48960 loss 0.012091949582099915
[2025-03-15 07:30:22,377][model][INFO] - Training step 49120 loss 0.020843887701630592
[2025-03-15 07:31:03,215][model][INFO] - Training step 49280 loss 0.07619176805019379
[2025-03-15 07:31:43,582][model][INFO] - Training step 49440 loss 0.024656236171722412
[2025-03-15 07:32:24,664][model][INFO] - Training step 49600 loss 0.026329651474952698
[2025-03-15 07:33:07,474][model][INFO] - Training step 49760 loss 0.01131785474717617
[2025-03-15 07:33:47,907][model][INFO] - Training step 49920 loss 0.012276450172066689
[2025-03-15 07:34:29,849][model][INFO] - Training step 50080 loss 0.006761770695447922
[2025-03-15 07:35:09,525][model][INFO] - Training step 50240 loss 0.012100517749786377
[2025-03-15 07:35:49,391][model][INFO] - Training step 50400 loss 0.045976653695106506
[2025-03-15 07:36:29,843][model][INFO] - Training step 50560 loss 0.013377307914197445
[2025-03-15 07:37:10,451][model][INFO] - Training step 50720 loss 0.020423557609319687
[2025-03-15 07:42:57,193][model][INFO] - Training step 80 loss 0.07133594900369644
[2025-03-15 07:43:39,527][model][INFO] - Training step 240 loss 0.03096826933324337
[2025-03-15 07:44:19,668][model][INFO] - Training step 400 loss 0.19116738438606262
[2025-03-15 07:44:59,462][model][INFO] - Training step 560 loss 0.2584500312805176
[2025-03-15 07:45:40,056][model][INFO] - Training step 720 loss 0.0030159801244735718
[2025-03-15 07:46:20,149][model][INFO] - Training step 880 loss 0.030209697782993317
[2025-03-15 07:46:59,675][model][INFO] - Training step 1040 loss 0.015034204348921776
[2025-03-15 07:47:42,318][model][INFO] - Training step 1200 loss 0.44701725244522095
[2025-03-15 07:48:24,877][model][INFO] - Training step 1360 loss 0.006023157387971878
[2025-03-15 07:49:05,127][model][INFO] - Training step 1520 loss 0.04291202500462532
[2025-03-15 07:49:44,878][model][INFO] - Training step 1680 loss 0.022022951394319534
[2025-03-15 07:50:24,646][model][INFO] - Training step 1840 loss 0.006728637032210827
[2025-03-15 07:51:05,734][model][INFO] - Training step 2000 loss 0.005405371077358723
[2025-03-15 07:51:46,201][model][INFO] - Training step 2160 loss 0.08519738912582397
[2025-03-15 07:52:28,245][model][INFO] - Training step 2320 loss 0.1040484607219696
[2025-03-15 07:53:08,403][model][INFO] - Training step 2480 loss 0.03520028293132782
[2025-03-15 07:53:50,125][model][INFO] - Training step 2640 loss 0.02430856227874756
[2025-03-15 07:54:30,486][model][INFO] - Training step 2800 loss 0.036181069910526276
[2025-03-15 07:55:11,895][model][INFO] - Training step 2960 loss 0.0056337108835577965
[2025-03-15 07:55:52,325][model][INFO] - Training step 3120 loss 0.003087875433266163
[2025-03-15 07:56:32,698][model][INFO] - Training step 3280 loss 0.026053495705127716
[2025-03-15 07:57:13,869][model][INFO] - Training step 3440 loss 0.23720279335975647
[2025-03-15 07:57:54,836][model][INFO] - Training step 3600 loss 0.04954688251018524
[2025-03-15 07:58:36,126][model][INFO] - Training step 3760 loss 0.0285171065479517
[2025-03-15 07:59:16,978][model][INFO] - Training step 3920 loss 0.011498968116939068
[2025-03-15 07:59:57,942][model][INFO] - Training step 4080 loss 0.07056676596403122
[2025-03-15 08:00:39,359][model][INFO] - Training step 4240 loss 0.007231207564473152
[2025-03-15 08:01:20,280][model][INFO] - Training step 4400 loss 0.012948972173035145
[2025-03-15 08:02:00,787][model][INFO] - Training step 4560 loss 0.02643485926091671
[2025-03-15 08:02:42,009][model][INFO] - Training step 4720 loss 0.025321252644062042
[2025-03-15 08:03:22,270][model][INFO] - Training step 4880 loss 0.02743738889694214
[2025-03-15 08:04:02,921][model][INFO] - Training step 5040 loss 0.0016445321962237358
[2025-03-15 08:04:42,908][model][INFO] - Training step 5200 loss 0.0053624967113137245
[2025-03-15 08:05:23,341][model][INFO] - Training step 5360 loss 0.25446879863739014
[2025-03-15 08:06:03,607][model][INFO] - Training step 5520 loss 0.09992703795433044
[2025-03-15 08:06:43,228][model][INFO] - Training step 5680 loss 0.06797938048839569
[2025-03-15 08:07:23,839][model][INFO] - Training step 5840 loss 0.023289471864700317
[2025-03-15 08:08:05,406][model][INFO] - Training step 6000 loss 0.009782359004020691
[2025-03-15 08:08:45,041][model][INFO] - Training step 6160 loss 0.13966971635818481
[2025-03-15 08:09:25,090][model][INFO] - Training step 6320 loss 0.045053835958242416
[2025-03-15 08:10:07,059][model][INFO] - Training step 6480 loss 0.25663870573043823
[2025-03-15 08:10:47,375][model][INFO] - Training step 6640 loss 0.2613068222999573
[2025-03-15 08:11:27,410][model][INFO] - Training step 6800 loss 0.015231247060000896
[2025-03-15 08:12:08,393][model][INFO] - Training step 6960 loss 0.021123748272657394
[2025-03-15 08:12:49,565][model][INFO] - Training step 7120 loss 0.003303233301267028
[2025-03-15 08:13:29,433][model][INFO] - Training step 7280 loss 0.25598886609077454
[2025-03-15 08:14:09,907][model][INFO] - Training step 7440 loss 0.015050988644361496
[2025-03-15 08:14:50,839][model][INFO] - Training step 7600 loss 0.02347424067556858
[2025-03-15 08:15:31,634][model][INFO] - Training step 7760 loss 0.06562121212482452
[2025-03-15 08:16:12,515][model][INFO] - Training step 7920 loss 0.005083169788122177
[2025-03-15 08:16:52,963][model][INFO] - Training step 8080 loss 0.03687145560979843
[2025-03-15 08:17:33,142][model][INFO] - Training step 8240 loss 0.03417893871665001
[2025-03-15 08:18:13,669][model][INFO] - Training step 8400 loss 0.03207454830408096
[2025-03-15 08:18:54,344][model][INFO] - Training step 8560 loss 0.058880701661109924
[2025-03-15 08:19:34,889][model][INFO] - Training step 8720 loss 0.025676148012280464
[2025-03-15 08:20:17,387][model][INFO] - Training step 8880 loss 0.013786358758807182
[2025-03-15 08:20:57,373][model][INFO] - Training step 9040 loss 0.016548920422792435
[2025-03-15 08:21:37,327][model][INFO] - Training step 9200 loss 0.2608550786972046
[2025-03-15 08:22:17,474][model][INFO] - Training step 9360 loss 0.05146470665931702
[2025-03-15 08:22:59,228][model][INFO] - Training step 9520 loss 0.02337106689810753
[2025-03-15 08:23:40,329][model][INFO] - Training step 9680 loss 0.21590951085090637
[2025-03-15 08:24:23,326][model][INFO] - Training step 9840 loss 0.03793817758560181
[2025-03-15 08:25:03,127][model][INFO] - Training step 10000 loss 0.24433186650276184
[2025-03-15 08:25:43,375][model][INFO] - Training step 10160 loss 0.031661152839660645
[2025-03-15 08:26:22,245][model][INFO] - Training step 10320 loss 0.023719577118754387
[2025-03-15 08:27:02,571][model][INFO] - Training step 10480 loss 0.24693584442138672
[2025-03-15 08:27:44,234][model][INFO] - Training step 10640 loss 0.03976549580693245
[2025-03-15 08:28:24,689][model][INFO] - Training step 10800 loss 0.029817119240760803
[2025-03-15 08:29:06,301][model][INFO] - Training step 10960 loss 0.07206996530294418
[2025-03-15 08:29:46,747][model][INFO] - Training step 11120 loss 0.030196018517017365
[2025-03-15 08:30:27,774][model][INFO] - Training step 11280 loss 0.024053271859884262
[2025-03-15 08:31:07,765][model][INFO] - Training step 11440 loss 0.02619992569088936
[2025-03-15 08:31:48,949][model][INFO] - Training step 11600 loss 0.011944709345698357
[2025-03-15 08:32:29,619][model][INFO] - Training step 11760 loss 0.02905144914984703
[2025-03-15 08:33:07,977][model][INFO] - Training step 11920 loss 0.05358651280403137
[2025-03-15 08:33:49,373][model][INFO] - Training step 12080 loss 0.0331304557621479
[2025-03-15 08:34:29,559][model][INFO] - Training step 12240 loss 0.03813578933477402
[2025-03-15 08:35:09,368][model][INFO] - Training step 12400 loss 0.019860558211803436
[2025-03-15 08:35:49,184][model][INFO] - Training step 12560 loss 0.021847719326615334
[2025-03-15 08:36:29,737][model][INFO] - Training step 12720 loss 0.13376843929290771
[2025-03-15 08:37:12,080][model][INFO] - Training step 12880 loss 0.002843504771590233
[2025-03-15 08:37:52,579][model][INFO] - Training step 13040 loss 0.023695938289165497
[2025-03-15 08:38:33,107][model][INFO] - Training step 13200 loss 0.280539870262146
[2025-03-15 08:39:13,839][model][INFO] - Training step 13360 loss 0.0734369158744812
[2025-03-15 08:39:53,706][model][INFO] - Training step 13520 loss 0.05184171348810196
[2025-03-15 08:40:34,188][model][INFO] - Training step 13680 loss 0.2713398337364197
[2025-03-15 08:41:16,029][model][INFO] - Training step 13840 loss 0.027685409411787987
[2025-03-15 08:41:57,141][model][INFO] - Training step 14000 loss 0.09939257800579071
[2025-03-15 08:42:36,732][model][INFO] - Training step 14160 loss 0.027545243501663208
[2025-03-15 08:43:16,767][model][INFO] - Training step 14320 loss 0.023374270647764206
[2025-03-15 08:43:57,482][model][INFO] - Training step 14480 loss 0.015470851212739944
[2025-03-15 08:44:38,185][model][INFO] - Training step 14640 loss 0.02444058656692505
[2025-03-15 08:45:18,121][model][INFO] - Training step 14800 loss 0.032049208879470825
[2025-03-15 08:45:58,494][model][INFO] - Training step 14960 loss 0.2910565733909607
[2025-03-15 08:46:38,560][model][INFO] - Training step 15120 loss 0.03381813317537308
[2025-03-15 08:47:18,706][model][INFO] - Training step 15280 loss 0.003923728596419096
[2025-03-15 08:47:59,910][model][INFO] - Training step 15440 loss 0.020998608320951462
[2025-03-15 08:48:41,423][model][INFO] - Training step 15600 loss 0.12817305326461792
[2025-03-15 08:49:24,369][model][INFO] - Training step 15760 loss 0.02446652576327324
[2025-03-15 08:50:04,368][model][INFO] - Training step 15920 loss 0.03201596066355705
[2025-03-15 08:50:45,458][model][INFO] - Training step 16080 loss 0.0021145218051970005
[2025-03-15 08:51:26,987][model][INFO] - Training step 16240 loss 0.026118222624063492
[2025-03-15 08:52:07,291][model][INFO] - Training step 16400 loss 0.027670230716466904
[2025-03-15 08:52:48,810][model][INFO] - Training step 16560 loss 0.03583817929029465
[2025-03-15 08:53:28,953][model][INFO] - Training step 16720 loss 0.021612249314785004
[2025-03-15 08:54:09,197][model][INFO] - Training step 16880 loss 0.019639015197753906
[2025-03-15 08:54:50,194][model][INFO] - Training step 17040 loss 0.05789349600672722
[2025-03-15 08:55:30,692][model][INFO] - Training step 17200 loss 0.08162949979305267
[2025-03-15 08:56:11,404][model][INFO] - Training step 17360 loss 0.024831566959619522
[2025-03-15 08:56:51,619][model][INFO] - Training step 17520 loss 0.05371743440628052
[2025-03-15 08:57:32,918][model][INFO] - Training step 17680 loss 0.024085447192192078
[2025-03-15 08:58:11,693][model][INFO] - Training step 17840 loss 0.08008167892694473
[2025-03-15 08:58:52,815][model][INFO] - Training step 18000 loss 0.2199646532535553
[2025-03-15 08:59:34,408][model][INFO] - Training step 18160 loss 0.044611915946006775
[2025-03-15 09:00:15,067][model][INFO] - Training step 18320 loss 0.24360120296478271
[2025-03-15 09:00:54,832][model][INFO] - Training step 18480 loss 0.02612321637570858
[2025-03-15 09:01:37,461][model][INFO] - Training step 18640 loss 0.050490058958530426
[2025-03-15 09:02:18,271][model][INFO] - Training step 18800 loss 0.011152496561408043
[2025-03-15 09:02:58,339][model][INFO] - Training step 18960 loss 0.0056335413828492165
[2025-03-15 09:03:38,718][model][INFO] - Training step 19120 loss 0.01759779453277588
[2025-03-15 09:04:19,181][model][INFO] - Training step 19280 loss 0.022125467658042908
[2025-03-15 09:04:58,513][model][INFO] - Training step 19440 loss 0.22807368636131287
[2025-03-15 09:05:40,169][model][INFO] - Training step 19600 loss 0.02769700065255165
[2025-03-15 09:06:21,896][model][INFO] - Training step 19760 loss 0.027333226054906845
[2025-03-15 09:07:02,416][model][INFO] - Training step 19920 loss 0.2622852623462677
[2025-03-15 09:07:43,540][model][INFO] - Training step 20080 loss 0.2593512535095215
[2025-03-15 09:08:24,359][model][INFO] - Training step 20240 loss 0.032467782497406006
[2025-03-15 09:09:06,407][model][INFO] - Training step 20400 loss 0.16639383137226105
[2025-03-15 09:09:46,787][model][INFO] - Training step 20560 loss 0.020887402817606926
[2025-03-15 09:10:28,198][model][INFO] - Training step 20720 loss 0.002450549043715
[2025-03-15 09:11:08,583][model][INFO] - Training step 20880 loss 0.020556502044200897
[2025-03-15 09:11:49,897][model][INFO] - Training step 21040 loss 0.029342297464609146
[2025-03-15 09:12:30,493][model][INFO] - Training step 21200 loss 0.030147280544042587
[2025-03-15 09:13:11,473][model][INFO] - Training step 21360 loss 0.03933706507086754
[2025-03-15 09:13:51,672][model][INFO] - Training step 21520 loss 0.008610442280769348
[2025-03-15 09:14:32,953][model][INFO] - Training step 21680 loss 0.06965628266334534
[2025-03-15 09:15:12,476][model][INFO] - Training step 21840 loss 0.019104205071926117
[2025-03-15 09:15:52,223][model][INFO] - Training step 22000 loss 0.04305034503340721
[2025-03-15 09:16:32,347][model][INFO] - Training step 22160 loss 0.0729036033153534
[2025-03-15 09:17:12,432][model][INFO] - Training step 22320 loss 0.005455951206386089
[2025-03-15 09:17:53,947][model][INFO] - Training step 22480 loss 0.008880110457539558
[2025-03-15 09:18:36,503][model][INFO] - Training step 22640 loss 0.010390616953372955
[2025-03-15 09:19:16,919][model][INFO] - Training step 22800 loss 0.25123459100723267
[2025-03-15 09:19:58,669][model][INFO] - Training step 22960 loss 0.02014622464776039
[2025-03-15 09:20:38,820][model][INFO] - Training step 23120 loss 0.024632437154650688
[2025-03-15 09:21:19,801][model][INFO] - Training step 23280 loss 0.24606949090957642
[2025-03-15 09:22:00,300][model][INFO] - Training step 23440 loss 0.027079997584223747
[2025-03-15 09:22:41,002][model][INFO] - Training step 23600 loss 0.3409116268157959
[2025-03-15 09:23:21,486][model][INFO] - Training step 23760 loss 0.0315186008810997
[2025-03-15 09:24:02,396][model][INFO] - Training step 23920 loss 0.027650956064462662
[2025-03-15 09:24:43,853][model][INFO] - Training step 24080 loss 0.0019070622511208057
[2025-03-15 09:25:23,470][model][INFO] - Training step 24240 loss 0.027247309684753418
[2025-03-15 09:26:03,640][model][INFO] - Training step 24400 loss 0.021197985857725143
[2025-03-15 09:26:43,386][model][INFO] - Training step 24560 loss 0.24389496445655823
[2025-03-15 09:27:23,754][model][INFO] - Training step 24720 loss 0.26017439365386963
[2025-03-15 09:28:04,444][model][INFO] - Training step 24880 loss 0.25661134719848633
[2025-03-15 09:28:45,086][model][INFO] - Training step 25040 loss 0.03688572347164154
[2025-03-15 09:29:26,305][model][INFO] - Training step 25200 loss 0.14029833674430847
[2025-03-15 09:30:06,855][model][INFO] - Training step 25360 loss 0.25121647119522095
[2025-03-15 09:30:46,483][model][INFO] - Training step 25520 loss 0.03252587467432022
[2025-03-15 09:31:28,186][model][INFO] - Training step 25680 loss 0.015058260411024094
[2025-03-15 09:32:08,616][model][INFO] - Training step 25840 loss 0.035162486135959625
[2025-03-15 09:32:49,030][model][INFO] - Training step 26000 loss 0.052034445106983185
[2025-03-15 09:33:30,102][model][INFO] - Training step 26160 loss 0.020742543041706085
[2025-03-15 09:34:10,538][model][INFO] - Training step 26320 loss 0.04908338189125061
[2025-03-15 09:34:50,620][model][INFO] - Training step 26480 loss 0.033811695873737335
[2025-03-15 09:35:31,297][model][INFO] - Training step 26640 loss 0.03248003497719765
[2025-03-15 09:36:11,681][model][INFO] - Training step 26800 loss 0.010776852257549763
[2025-03-15 09:36:53,429][model][INFO] - Training step 26960 loss 0.020302636548876762
[2025-03-15 09:37:33,643][model][INFO] - Training step 27120 loss 0.03503969684243202
[2025-03-15 09:38:14,262][model][INFO] - Training step 27280 loss 0.26907747983932495
[2025-03-15 09:38:53,804][model][INFO] - Training step 27440 loss 0.03899897634983063
[2025-03-15 09:39:33,935][model][INFO] - Training step 27600 loss 0.08714434504508972
[2025-03-15 09:40:13,680][model][INFO] - Training step 27760 loss 0.026917636394500732
[2025-03-15 09:40:53,023][model][INFO] - Training step 27920 loss 0.013819935731589794
[2025-03-15 09:41:33,233][model][INFO] - Training step 28080 loss 0.005849031265825033
[2025-03-15 09:42:14,814][model][INFO] - Training step 28240 loss 0.1757546216249466
[2025-03-15 09:42:53,855][model][INFO] - Training step 28400 loss 0.14717790484428406
[2025-03-15 09:43:34,495][model][INFO] - Training step 28560 loss 0.023321200162172318
[2025-03-15 09:44:13,794][model][INFO] - Training step 28720 loss 0.07876807451248169
[2025-03-15 09:44:55,394][model][INFO] - Training step 28880 loss 0.03407851606607437
[2025-03-15 09:45:36,496][model][INFO] - Training step 29040 loss 0.004564232192933559
[2025-03-15 09:46:18,203][model][INFO] - Training step 29200 loss 0.08227181434631348
[2025-03-15 09:47:00,174][model][INFO] - Training step 29360 loss 0.02510792389512062
[2025-03-15 09:47:41,515][model][INFO] - Training step 29520 loss 0.04561289772391319
[2025-03-15 09:48:23,702][model][INFO] - Training step 29680 loss 0.028809672221541405
[2025-03-15 09:49:04,774][model][INFO] - Training step 29840 loss 0.004191548563539982
[2025-03-15 09:49:46,277][model][INFO] - Training step 30000 loss 0.014192856848239899
[2025-03-15 09:50:27,967][model][INFO] - Training step 30160 loss 0.24311861395835876
[2025-03-15 09:51:07,229][model][INFO] - Training step 30320 loss 0.0262393057346344
[2025-03-15 09:51:48,588][model][INFO] - Training step 30480 loss 0.01593397743999958
[2025-03-15 09:52:30,244][model][INFO] - Training step 30640 loss 0.05221044644713402
[2025-03-15 09:53:09,671][model][INFO] - Training step 30800 loss 0.03270098194479942
[2025-03-15 09:53:49,175][model][INFO] - Training step 30960 loss 0.23883894085884094
[2025-03-15 09:54:31,577][model][INFO] - Training step 31120 loss 0.032180123031139374
[2025-03-15 09:55:12,619][model][INFO] - Training step 31280 loss 0.03515012562274933
[2025-03-15 09:55:53,164][model][INFO] - Training step 31440 loss 0.039791710674762726
[2025-03-15 09:56:33,668][model][INFO] - Training step 31600 loss 0.02594270370900631
[2025-03-15 09:57:15,285][model][INFO] - Training step 31760 loss 0.10014864802360535
[2025-03-15 09:57:55,540][model][INFO] - Training step 31920 loss 0.02933722361922264
[2025-03-15 09:58:36,276][model][INFO] - Training step 32080 loss 0.00959993340075016
[2025-03-15 09:59:18,075][model][INFO] - Training step 32240 loss 0.0018359423847869039
[2025-03-15 09:59:59,914][model][INFO] - Training step 32400 loss 0.05641918256878853
[2025-03-15 10:00:40,366][model][INFO] - Training step 32560 loss 0.16729474067687988
[2025-03-15 10:01:21,390][model][INFO] - Training step 32720 loss 0.16458117961883545
[2025-03-15 10:02:01,955][model][INFO] - Training step 32880 loss 0.10696914792060852
[2025-03-15 10:02:41,944][model][INFO] - Training step 33040 loss 0.025049064308404922
[2025-03-15 10:03:23,932][model][INFO] - Training step 33200 loss 0.02146878093481064
[2025-03-15 10:04:04,468][model][INFO] - Training step 33360 loss 0.2554857134819031
[2025-03-15 10:04:45,457][model][INFO] - Training step 33520 loss 0.040692366659641266
[2025-03-15 10:05:24,808][model][INFO] - Training step 33680 loss 0.009345341473817825
[2025-03-15 10:06:05,252][model][INFO] - Training step 33840 loss 0.020263349637389183
[2025-03-15 10:06:45,198][model][INFO] - Training step 34000 loss 0.012759268283843994
[2025-03-15 10:07:27,123][model][INFO] - Training step 34160 loss 0.2625002861022949
[2025-03-15 10:08:07,795][model][INFO] - Training step 34320 loss 0.006072797812521458
[2025-03-15 10:08:49,502][model][INFO] - Training step 34480 loss 0.033484384417533875
[2025-03-15 10:09:29,763][model][INFO] - Training step 34640 loss 0.18798458576202393
[2025-03-15 10:10:10,265][model][INFO] - Training step 34800 loss 0.018306750804185867
[2025-03-15 10:10:52,018][model][INFO] - Training step 34960 loss 0.2553132176399231
[2025-03-15 10:11:32,856][model][INFO] - Training step 35120 loss 0.008065624162554741
[2025-03-15 10:12:13,668][model][INFO] - Training step 35280 loss 0.03442281857132912
[2025-03-15 10:12:54,135][model][INFO] - Training step 35440 loss 0.013975197449326515
[2025-03-15 10:13:35,576][model][INFO] - Training step 35600 loss 0.036570824682712555
[2025-03-15 10:14:15,296][model][INFO] - Training step 35760 loss 0.01878804713487625
[2025-03-15 10:14:54,828][model][INFO] - Training step 35920 loss 0.06878885626792908
[2025-03-15 10:15:36,121][model][INFO] - Training step 36080 loss 0.034936241805553436
[2025-03-15 10:16:17,103][model][INFO] - Training step 36240 loss 0.016336696222424507
[2025-03-15 10:16:57,565][model][INFO] - Training step 36400 loss 0.02033282443881035
[2025-03-15 10:17:39,359][model][INFO] - Training step 36560 loss 0.01672942191362381
[2025-03-15 10:18:19,866][model][INFO] - Training step 36720 loss 0.0071739135310053825
[2025-03-15 10:19:01,988][model][INFO] - Training step 36880 loss 0.016497526317834854
[2025-03-15 10:19:43,323][model][INFO] - Training step 37040 loss 0.020676152780652046
[2025-03-15 10:20:23,895][model][INFO] - Training step 37200 loss 0.04177247732877731
[2025-03-15 10:21:05,319][model][INFO] - Training step 37360 loss 0.03194958344101906
[2025-03-15 10:21:46,556][model][INFO] - Training step 37520 loss 0.01068384200334549
[2025-03-15 10:22:27,181][model][INFO] - Training step 37680 loss 0.24485889077186584
[2025-03-15 10:23:07,663][model][INFO] - Training step 37840 loss 0.2586209177970886
[2025-03-15 10:23:47,407][model][INFO] - Training step 38000 loss 0.24728845059871674
[2025-03-15 10:24:29,128][model][INFO] - Training step 38160 loss 0.021203581243753433
[2025-03-15 10:25:08,965][model][INFO] - Training step 38320 loss 0.051353201270103455
[2025-03-15 10:25:50,963][model][INFO] - Training step 38480 loss 0.05903366580605507
[2025-03-15 10:26:30,391][model][INFO] - Training step 38640 loss 0.035235852003097534
[2025-03-15 10:27:11,062][model][INFO] - Training step 38800 loss 0.011533686891198158
[2025-03-15 10:27:51,584][model][INFO] - Training step 38960 loss 0.03372110426425934
[2025-03-15 10:28:31,202][model][INFO] - Training step 39120 loss 0.020336836576461792
[2025-03-15 10:29:12,017][model][INFO] - Training step 39280 loss 0.029276510700583458
[2025-03-15 10:29:53,678][model][INFO] - Training step 39440 loss 0.249277263879776
[2025-03-15 10:30:33,990][model][INFO] - Training step 39600 loss 0.029654841870069504
[2025-03-15 10:31:15,164][model][INFO] - Training step 39760 loss 0.24800732731819153
[2025-03-15 10:31:56,503][model][INFO] - Training step 39920 loss 0.018749404698610306
[2025-03-15 10:32:37,413][model][INFO] - Training step 40080 loss 0.023133546113967896
[2025-03-15 10:33:18,941][model][INFO] - Training step 40240 loss 0.024769077077507973
[2025-03-15 10:34:00,037][model][INFO] - Training step 40400 loss 0.08051314949989319
[2025-03-15 10:34:41,649][model][INFO] - Training step 40560 loss 0.024511853232979774
[2025-03-15 10:35:22,504][model][INFO] - Training step 40720 loss 0.02729738876223564
[2025-03-15 10:36:04,146][model][INFO] - Training step 40880 loss 0.015442381612956524
[2025-03-15 10:36:43,242][model][INFO] - Training step 41040 loss 0.13312500715255737
[2025-03-15 10:37:23,857][model][INFO] - Training step 41200 loss 0.0017482134280726314
[2025-03-15 10:38:05,379][model][INFO] - Training step 41360 loss 0.09383158385753632
[2025-03-15 10:38:45,354][model][INFO] - Training step 41520 loss 0.040842991322278976
[2025-03-15 10:39:25,981][model][INFO] - Training step 41680 loss 0.0553346648812294
[2025-03-15 10:40:07,830][model][INFO] - Training step 41840 loss 0.023660272359848022
[2025-03-15 10:40:48,862][model][INFO] - Training step 42000 loss 0.04320606589317322
[2025-03-15 10:41:30,713][model][INFO] - Training step 42160 loss 0.024988722056150436
[2025-03-15 10:42:11,068][model][INFO] - Training step 42320 loss 0.012818567454814911
[2025-03-15 10:42:51,468][model][INFO] - Training step 42480 loss 0.018255064263939857
[2025-03-15 10:43:32,031][model][INFO] - Training step 42640 loss 0.07099530100822449
[2025-03-15 10:44:13,093][model][INFO] - Training step 42800 loss 0.01753893680870533
[2025-03-15 10:44:53,342][model][INFO] - Training step 42960 loss 0.02137504518032074
[2025-03-15 10:45:33,168][model][INFO] - Training step 43120 loss 0.03911176323890686
[2025-03-15 10:46:13,288][model][INFO] - Training step 43280 loss 0.2502167224884033
[2025-03-15 10:46:55,933][model][INFO] - Training step 43440 loss 0.002326077548786998
[2025-03-15 10:47:35,197][model][INFO] - Training step 43600 loss 0.010897362604737282
[2025-03-15 10:48:15,954][model][INFO] - Training step 43760 loss 0.04360067844390869
[2025-03-15 10:48:55,596][model][INFO] - Training step 43920 loss 0.0462307333946228
[2025-03-15 10:49:36,125][model][INFO] - Training step 44080 loss 0.005369104910641909
[2025-03-15 10:50:16,645][model][INFO] - Training step 44240 loss 0.021700803190469742
[2025-03-15 10:50:57,680][model][INFO] - Training step 44400 loss 0.10455544292926788
[2025-03-15 10:51:36,872][model][INFO] - Training step 44560 loss 0.024913810193538666
[2025-03-15 10:52:17,010][model][INFO] - Training step 44720 loss 0.019826460629701614
[2025-03-15 10:52:57,621][model][INFO] - Training step 44880 loss 0.00514440331608057
[2025-03-15 10:53:38,117][model][INFO] - Training step 45040 loss 0.04078131914138794
[2025-03-15 10:54:18,741][model][INFO] - Training step 45200 loss 0.05211704596877098
[2025-03-15 10:55:00,289][model][INFO] - Training step 45360 loss 0.16054818034172058
[2025-03-15 10:55:39,358][model][INFO] - Training step 45520 loss 0.06275705993175507
[2025-03-15 10:56:21,226][model][INFO] - Training step 45680 loss 0.010537046939134598
[2025-03-15 10:57:03,202][model][INFO] - Training step 45840 loss 0.06468498706817627
[2025-03-15 10:57:43,179][model][INFO] - Training step 46000 loss 0.03610741347074509
[2025-03-15 10:58:23,156][model][INFO] - Training step 46160 loss 0.06802524626255035
[2025-03-15 10:59:04,318][model][INFO] - Training step 46320 loss 0.025949154049158096
[2025-03-15 10:59:44,958][model][INFO] - Training step 46480 loss 0.013037512078881264
[2025-03-15 11:00:24,387][model][INFO] - Training step 46640 loss 0.039424799382686615
[2025-03-15 11:01:04,249][model][INFO] - Training step 46800 loss 0.2418995201587677
[2025-03-15 11:01:44,855][model][INFO] - Training step 46960 loss 0.031138364225625992
[2025-03-15 11:02:24,544][model][INFO] - Training step 47120 loss 0.1502828598022461
[2025-03-15 11:03:03,928][model][INFO] - Training step 47280 loss 0.0173223614692688
[2025-03-15 11:03:44,800][model][INFO] - Training step 47440 loss 0.051284417510032654
[2025-03-15 11:04:27,217][model][INFO] - Training step 47600 loss 0.0071293143555521965
[2025-03-15 11:05:08,830][model][INFO] - Training step 47760 loss 0.10814285278320312
[2025-03-15 11:05:47,930][model][INFO] - Training step 47920 loss 0.15065407752990723
[2025-03-15 11:06:28,238][model][INFO] - Training step 48080 loss 0.2618511915206909
[2025-03-15 11:07:07,827][model][INFO] - Training step 48240 loss 0.05075468868017197
[2025-03-15 11:07:47,416][model][INFO] - Training step 48400 loss 0.054617516696453094
[2025-03-15 11:08:27,768][model][INFO] - Training step 48560 loss 0.2517337203025818
[2025-03-15 11:09:08,770][model][INFO] - Training step 48720 loss 0.015507472679018974
[2025-03-15 11:09:49,070][model][INFO] - Training step 48880 loss 0.015202246606349945
[2025-03-15 11:10:29,353][model][INFO] - Training step 49040 loss 0.007097917143255472
[2025-03-15 11:11:12,050][model][INFO] - Training step 49200 loss 0.0207580104470253
[2025-03-15 11:11:53,272][model][INFO] - Training step 49360 loss 0.24005648493766785
[2025-03-15 11:12:33,074][model][INFO] - Training step 49520 loss 0.15898653864860535
[2025-03-15 11:13:13,005][model][INFO] - Training step 49680 loss 0.010886892676353455
[2025-03-15 11:13:53,573][model][INFO] - Training step 49840 loss 0.003460068954154849
[2025-03-15 11:14:33,642][model][INFO] - Training step 50000 loss 0.003057509660720825
[2025-03-15 11:15:14,184][model][INFO] - Training step 50160 loss 0.013443699106574059
[2025-03-15 11:15:53,707][model][INFO] - Training step 50320 loss 0.018330490216612816
[2025-03-15 11:16:34,198][model][INFO] - Training step 50480 loss 0.0076231807470321655
[2025-03-15 11:17:13,871][model][INFO] - Training step 50640 loss 0.01834738440811634
[2025-03-15 11:23:03,113][model][INFO] - Training step 0 loss 0.006768413353711367
[2025-03-15 11:23:44,602][model][INFO] - Training step 160 loss 0.02591880038380623
[2025-03-15 11:24:25,229][model][INFO] - Training step 320 loss 0.04613759368658066
[2025-03-15 11:25:06,422][model][INFO] - Training step 480 loss 0.02024458721280098
[2025-03-15 11:25:47,336][model][INFO] - Training step 640 loss 0.2635112404823303
[2025-03-15 11:26:28,940][model][INFO] - Training step 800 loss 0.00539408391341567
[2025-03-15 11:27:09,233][model][INFO] - Training step 960 loss 0.0161589365452528
[2025-03-15 11:27:49,082][model][INFO] - Training step 1120 loss 0.04526530206203461
[2025-03-15 11:28:29,887][model][INFO] - Training step 1280 loss 0.03148102015256882
[2025-03-15 11:29:09,723][model][INFO] - Training step 1440 loss 0.026889052242040634
[2025-03-15 11:29:50,558][model][INFO] - Training step 1600 loss 0.07412120699882507
[2025-03-15 11:30:30,852][model][INFO] - Training step 1760 loss 0.03712216019630432
[2025-03-15 11:31:10,331][model][INFO] - Training step 1920 loss 0.017433686181902885
[2025-03-15 11:31:52,817][model][INFO] - Training step 2080 loss 0.026386603713035583
[2025-03-15 11:32:32,242][model][INFO] - Training step 2240 loss 0.015996159985661507
[2025-03-15 11:33:12,942][model][INFO] - Training step 2400 loss 0.014403837732970715
[2025-03-15 11:33:52,900][model][INFO] - Training step 2560 loss 0.03816015273332596
[2025-03-15 11:34:32,883][model][INFO] - Training step 2720 loss 0.015621762722730637
[2025-03-15 11:35:14,186][model][INFO] - Training step 2880 loss 0.005470822565257549
[2025-03-15 11:35:55,199][model][INFO] - Training step 3040 loss 0.02229394018650055
[2025-03-15 11:36:36,238][model][INFO] - Training step 3200 loss 0.013540573418140411
[2025-03-15 11:37:17,085][model][INFO] - Training step 3360 loss 0.07565896213054657
[2025-03-15 11:37:58,043][model][INFO] - Training step 3520 loss 0.07375103235244751
[2025-03-15 11:38:40,072][model][INFO] - Training step 3680 loss 0.022074658423662186
[2025-03-15 11:39:19,946][model][INFO] - Training step 3840 loss 0.02600299008190632
[2025-03-15 11:40:00,650][model][INFO] - Training step 4000 loss 0.03835725411772728
[2025-03-15 11:40:41,219][model][INFO] - Training step 4160 loss 0.020431146025657654
[2025-03-15 11:41:21,333][model][INFO] - Training step 4320 loss 0.25267282128334045
[2025-03-15 11:42:01,651][model][INFO] - Training step 4480 loss 0.024818185716867447
[2025-03-15 11:42:42,617][model][INFO] - Training step 4640 loss 0.0014762550126761198
[2025-03-15 11:43:22,498][model][INFO] - Training step 4800 loss 0.38076651096343994
[2025-03-15 11:44:02,487][model][INFO] - Training step 4960 loss 0.014331614598631859
[2025-03-15 11:44:43,943][model][INFO] - Training step 5120 loss 0.13162648677825928
[2025-03-15 11:45:25,196][model][INFO] - Training step 5280 loss 0.00807531550526619
[2025-03-15 11:46:06,103][model][INFO] - Training step 5440 loss 0.2504561245441437
[2025-03-15 11:46:45,937][model][INFO] - Training step 5600 loss 0.017861109226942062
[2025-03-15 11:47:26,897][model][INFO] - Training step 5760 loss 0.2793201208114624
[2025-03-15 11:48:08,981][model][INFO] - Training step 5920 loss 0.024998512119054794
[2025-03-15 11:48:48,733][model][INFO] - Training step 6080 loss 0.018965288996696472
[2025-03-15 11:49:29,732][model][INFO] - Training step 6240 loss 0.03627542778849602
[2025-03-15 11:50:13,341][model][INFO] - Training step 6400 loss 0.021606270223855972
[2025-03-15 11:50:55,416][model][INFO] - Training step 6560 loss 0.010181708261370659
[2025-03-15 11:51:35,292][model][INFO] - Training step 6720 loss 0.25903987884521484
[2025-03-15 11:52:15,377][model][INFO] - Training step 6880 loss 0.08487164974212646
[2025-03-15 11:52:56,667][model][INFO] - Training step 7040 loss 0.01656571961939335
[2025-03-15 11:53:38,969][model][INFO] - Training step 7200 loss 0.01835329458117485
[2025-03-15 11:54:21,507][model][INFO] - Training step 7360 loss 0.024104269221425056
[2025-03-15 11:55:01,957][model][INFO] - Training step 7520 loss 0.03868017718195915
[2025-03-15 11:55:42,364][model][INFO] - Training step 7680 loss 0.24755215644836426
[2025-03-15 11:56:23,986][model][INFO] - Training step 7840 loss 0.03175915405154228
[2025-03-15 11:57:04,955][model][INFO] - Training step 8000 loss 0.2388329952955246
[2025-03-15 11:57:46,267][model][INFO] - Training step 8160 loss 0.033706147223711014
[2025-03-15 11:58:28,028][model][INFO] - Training step 8320 loss 0.02315186709165573
[2025-03-15 11:59:09,298][model][INFO] - Training step 8480 loss 0.06112679839134216
[2025-03-15 11:59:49,110][model][INFO] - Training step 8640 loss 0.11187945306301117
[2025-03-15 12:00:29,585][model][INFO] - Training step 8800 loss 0.019259538501501083
[2025-03-15 12:01:09,102][model][INFO] - Training step 8960 loss 0.1393008828163147
[2025-03-15 12:01:49,216][model][INFO] - Training step 9120 loss 0.027337100356817245
[2025-03-15 12:02:30,392][model][INFO] - Training step 9280 loss 0.02618711069226265
[2025-03-15 12:03:10,477][model][INFO] - Training step 9440 loss 0.03673524409532547
[2025-03-15 12:03:51,219][model][INFO] - Training step 9600 loss 0.015102524310350418
[2025-03-15 12:04:32,008][model][INFO] - Training step 9760 loss 0.22732692956924438
[2025-03-15 12:05:10,828][model][INFO] - Training step 9920 loss 0.02836739830672741
[2025-03-15 12:05:51,071][model][INFO] - Training step 10080 loss 0.002544575836509466
[2025-03-15 12:06:31,883][model][INFO] - Training step 10240 loss 0.013095920905470848
[2025-03-15 12:07:13,109][model][INFO] - Training step 10400 loss 0.002328258939087391
[2025-03-15 12:07:54,455][model][INFO] - Training step 10560 loss 0.09113547205924988
[2025-03-15 12:08:34,751][model][INFO] - Training step 10720 loss 0.01202402077615261
[2025-03-15 12:09:15,972][model][INFO] - Training step 10880 loss 0.03430360183119774
[2025-03-15 12:09:56,428][model][INFO] - Training step 11040 loss 0.023814309388399124
[2025-03-15 12:10:36,349][model][INFO] - Training step 11200 loss 0.008438864722847939
[2025-03-15 12:11:16,082][model][INFO] - Training step 11360 loss 0.025625940412282944
[2025-03-15 12:11:57,238][model][INFO] - Training step 11520 loss 0.26018214225769043
[2025-03-15 12:12:38,250][model][INFO] - Training step 11680 loss 0.0502476692199707
[2025-03-15 12:13:20,225][model][INFO] - Training step 11840 loss 0.015630368143320084
[2025-03-15 12:14:00,308][model][INFO] - Training step 12000 loss 0.025809885933995247
[2025-03-15 12:14:42,331][model][INFO] - Training step 12160 loss 0.001832340145483613
[2025-03-15 12:15:22,434][model][INFO] - Training step 12320 loss 0.0492846705019474
[2025-03-15 12:16:03,311][model][INFO] - Training step 12480 loss 0.03739205747842789
[2025-03-15 12:16:43,941][model][INFO] - Training step 12640 loss 0.027335768565535545
[2025-03-15 12:17:24,030][model][INFO] - Training step 12800 loss 0.04537414386868477
[2025-03-15 12:18:05,274][model][INFO] - Training step 12960 loss 0.024114202708005905
[2025-03-15 12:18:47,644][model][INFO] - Training step 13120 loss 0.006732197478413582
[2025-03-15 12:19:28,235][model][INFO] - Training step 13280 loss 0.024065379053354263
[2025-03-15 12:20:07,965][model][INFO] - Training step 13440 loss 0.5168729424476624
[2025-03-15 12:20:49,052][model][INFO] - Training step 13600 loss 0.013668530620634556
[2025-03-15 12:21:30,316][model][INFO] - Training step 13760 loss 0.02892010658979416
[2025-03-15 12:22:11,254][model][INFO] - Training step 13920 loss 0.04788919538259506
[2025-03-15 12:22:51,196][model][INFO] - Training step 14080 loss 0.014927810057997704
[2025-03-15 12:23:31,777][model][INFO] - Training step 14240 loss 0.003831663401797414
[2025-03-15 12:24:12,490][model][INFO] - Training step 14400 loss 0.006806609686464071
[2025-03-15 12:24:52,796][model][INFO] - Training step 14560 loss 0.24875614047050476
[2025-03-15 12:25:33,279][model][INFO] - Training step 14720 loss 0.01621011458337307
[2025-03-15 12:26:14,326][model][INFO] - Training step 14880 loss 0.09503746032714844
[2025-03-15 12:26:54,947][model][INFO] - Training step 15040 loss 0.03201013803482056
[2025-03-15 12:27:36,233][model][INFO] - Training step 15200 loss 0.024332750588655472
[2025-03-15 12:28:17,566][model][INFO] - Training step 15360 loss 0.04307837784290314
[2025-03-15 12:28:58,507][model][INFO] - Training step 15520 loss 0.026088520884513855
[2025-03-15 12:29:39,311][model][INFO] - Training step 15680 loss 0.025768518447875977
[2025-03-15 12:30:20,086][model][INFO] - Training step 15840 loss 0.24904324114322662
[2025-03-15 12:31:00,279][model][INFO] - Training step 16000 loss 0.004724948666989803
[2025-03-15 12:31:41,276][model][INFO] - Training step 16160 loss 0.010199866257607937
[2025-03-15 12:32:23,322][model][INFO] - Training step 16320 loss 0.034202203154563904
[2025-03-15 12:33:04,193][model][INFO] - Training step 16480 loss 0.018394531682133675
[2025-03-15 12:33:45,422][model][INFO] - Training step 16640 loss 0.37521088123321533
[2025-03-15 12:34:25,939][model][INFO] - Training step 16800 loss 0.04962729662656784
[2025-03-15 12:35:07,763][model][INFO] - Training step 16960 loss 0.026647347956895828
[2025-03-15 12:35:47,994][model][INFO] - Training step 17120 loss 0.25533801317214966
[2025-03-15 12:36:29,822][model][INFO] - Training step 17280 loss 0.6053908467292786
[2025-03-15 12:37:11,140][model][INFO] - Training step 17440 loss 0.0026633902452886105
[2025-03-15 12:37:52,642][model][INFO] - Training step 17600 loss 0.26716119050979614
[2025-03-15 12:38:34,433][model][INFO] - Training step 17760 loss 0.08527059853076935
[2025-03-15 12:39:14,848][model][INFO] - Training step 17920 loss 0.13658595085144043
[2025-03-15 12:39:56,165][model][INFO] - Training step 18080 loss 0.04120723158121109
[2025-03-15 12:40:36,879][model][INFO] - Training step 18240 loss 0.03222699463367462
[2025-03-15 12:41:18,000][model][INFO] - Training step 18400 loss 0.027364466339349747
[2025-03-15 12:41:58,309][model][INFO] - Training step 18560 loss 0.07000337541103363
[2025-03-15 12:42:37,688][model][INFO] - Training step 18720 loss 0.0446234866976738
[2025-03-15 12:43:17,866][model][INFO] - Training step 18880 loss 0.06808964908123016
[2025-03-15 12:43:58,843][model][INFO] - Training step 19040 loss 0.0014848123537376523
[2025-03-15 12:44:39,617][model][INFO] - Training step 19200 loss 0.1384759247303009
[2025-03-15 12:45:19,048][model][INFO] - Training step 19360 loss 0.005216742400079966
[2025-03-15 12:45:59,740][model][INFO] - Training step 19520 loss 0.08695042133331299
[2025-03-15 12:46:41,337][model][INFO] - Training step 19680 loss 0.10257267951965332
[2025-03-15 12:47:21,944][model][INFO] - Training step 19840 loss 0.05096519738435745
[2025-03-15 12:48:01,878][model][INFO] - Training step 20000 loss 0.036907028406858444
[2025-03-15 12:48:42,414][model][INFO] - Training step 20160 loss 0.02211424522101879
[2025-03-15 12:49:22,943][model][INFO] - Training step 20320 loss 0.04451719671487808
[2025-03-15 12:50:02,340][model][INFO] - Training step 20480 loss 0.2559020519256592
[2025-03-15 12:50:41,900][model][INFO] - Training step 20640 loss 0.022647732868790627
[2025-03-15 12:51:23,874][model][INFO] - Training step 20800 loss 0.25248873233795166
[2025-03-15 12:52:05,719][model][INFO] - Training step 20960 loss 0.01985570602118969
[2025-03-15 12:52:47,813][model][INFO] - Training step 21120 loss 0.13622993230819702
[2025-03-15 12:53:28,489][model][INFO] - Training step 21280 loss 0.10094878077507019
[2025-03-15 12:54:09,994][model][INFO] - Training step 21440 loss 0.016073644161224365
[2025-03-15 12:54:50,561][model][INFO] - Training step 21600 loss 0.029657192528247833
[2025-03-15 12:55:31,193][model][INFO] - Training step 21760 loss 0.2551769018173218
[2025-03-15 12:56:10,214][model][INFO] - Training step 21920 loss 0.24926413595676422
[2025-03-15 12:56:50,858][model][INFO] - Training step 22080 loss 0.05146356299519539
[2025-03-15 12:57:31,531][model][INFO] - Training step 22240 loss 0.006059378385543823
[2025-03-15 12:58:13,279][model][INFO] - Training step 22400 loss 0.2416994422674179
[2025-03-15 12:58:53,750][model][INFO] - Training step 22560 loss 0.02527431771159172
[2025-03-15 12:59:33,983][model][INFO] - Training step 22720 loss 0.04133101552724838
[2025-03-15 13:00:14,275][model][INFO] - Training step 22880 loss 0.033584725111722946
[2025-03-15 13:00:55,875][model][INFO] - Training step 23040 loss 0.005952514708042145
[2025-03-15 13:01:37,348][model][INFO] - Training step 23200 loss 0.03516204655170441
[2025-03-15 13:02:18,422][model][INFO] - Training step 23360 loss 0.03121616318821907
[2025-03-15 13:02:59,647][model][INFO] - Training step 23520 loss 0.06814120709896088
[2025-03-15 13:03:40,609][model][INFO] - Training step 23680 loss 0.07250222563743591
[2025-03-15 13:04:21,495][model][INFO] - Training step 23840 loss 0.018812797963619232
[2025-03-15 13:05:01,097][model][INFO] - Training step 24000 loss 0.025120150297880173
[2025-03-15 13:05:41,446][model][INFO] - Training step 24160 loss 0.021248839795589447
[2025-03-15 13:06:24,194][model][INFO] - Training step 24320 loss 0.03479371592402458
[2025-03-15 13:07:06,605][model][INFO] - Training step 24480 loss 0.008825456723570824
[2025-03-15 13:07:45,327][model][INFO] - Training step 24640 loss 0.2602199614048004
[2025-03-15 13:08:25,208][model][INFO] - Training step 24800 loss 0.20441505312919617
[2025-03-15 13:09:06,796][model][INFO] - Training step 24960 loss 0.010907985270023346
[2025-03-15 13:09:47,375][model][INFO] - Training step 25120 loss 0.25228142738342285
[2025-03-15 13:10:27,524][model][INFO] - Training step 25280 loss 0.25959914922714233
[2025-03-15 13:11:07,605][model][INFO] - Training step 25440 loss 0.23882456123828888
[2025-03-15 13:11:47,677][model][INFO] - Training step 25600 loss 0.24743816256523132
[2025-03-15 13:12:26,927][model][INFO] - Training step 25760 loss 0.019909122958779335
[2025-03-15 13:13:08,163][model][INFO] - Training step 25920 loss 0.1083764135837555
[2025-03-15 13:13:48,606][model][INFO] - Training step 26080 loss 0.009708056226372719
[2025-03-15 13:14:30,388][model][INFO] - Training step 26240 loss 0.07108190655708313
[2025-03-15 13:15:12,262][model][INFO] - Training step 26400 loss 0.02412772923707962
[2025-03-15 13:15:54,283][model][INFO] - Training step 26560 loss 0.01928984373807907
[2025-03-15 13:16:35,259][model][INFO] - Training step 26720 loss 0.018123844638466835
[2025-03-15 13:17:15,896][model][INFO] - Training step 26880 loss 0.03197242319583893
[2025-03-15 13:17:56,464][model][INFO] - Training step 27040 loss 0.25856250524520874
[2025-03-15 13:18:36,699][model][INFO] - Training step 27200 loss 0.016819976270198822
[2025-03-15 13:19:17,017][model][INFO] - Training step 27360 loss 0.03628069907426834
[2025-03-15 13:19:59,032][model][INFO] - Training step 27520 loss 0.11829935014247894
[2025-03-15 13:20:39,105][model][INFO] - Training step 27680 loss 0.02082543633878231
[2025-03-15 13:21:20,011][model][INFO] - Training step 27840 loss 0.02303425222635269
[2025-03-15 13:22:01,693][model][INFO] - Training step 28000 loss 0.004966455511748791
[2025-03-15 13:22:43,594][model][INFO] - Training step 28160 loss 0.003755924990400672
[2025-03-15 13:23:23,850][model][INFO] - Training step 28320 loss 0.017394276335835457
[2025-03-15 13:24:05,324][model][INFO] - Training step 28480 loss 0.14717985689640045
[2025-03-15 13:24:45,299][model][INFO] - Training step 28640 loss 0.031303778290748596
[2025-03-15 13:25:25,927][model][INFO] - Training step 28800 loss 0.03261649236083031
[2025-03-15 13:26:07,648][model][INFO] - Training step 28960 loss 0.12504792213439941
[2025-03-15 13:26:48,536][model][INFO] - Training step 29120 loss 0.24657326936721802
[2025-03-15 13:27:29,602][model][INFO] - Training step 29280 loss 0.0034595364704728127
[2025-03-15 13:28:08,946][model][INFO] - Training step 29440 loss 0.015897586941719055
[2025-03-15 13:28:49,292][model][INFO] - Training step 29600 loss 0.003771926974877715
[2025-03-15 13:29:31,749][model][INFO] - Training step 29760 loss 0.1734279990196228
[2025-03-15 13:30:10,931][model][INFO] - Training step 29920 loss 0.24810034036636353
[2025-03-15 13:30:53,797][model][INFO] - Training step 30080 loss 0.022542636841535568
[2025-03-15 13:31:35,218][model][INFO] - Training step 30240 loss 0.24354317784309387
[2025-03-15 13:32:15,619][model][INFO] - Training step 30400 loss 0.033115193247795105
[2025-03-15 13:32:55,962][model][INFO] - Training step 30560 loss 0.019404441118240356
[2025-03-15 13:33:35,056][model][INFO] - Training step 30720 loss 0.06708796322345734
[2025-03-15 13:34:14,133][model][INFO] - Training step 30880 loss 0.006818554829806089
[2025-03-15 13:34:54,157][model][INFO] - Training step 31040 loss 0.05743921548128128
[2025-03-15 13:35:35,405][model][INFO] - Training step 31200 loss 0.08827584981918335
[2025-03-15 13:36:14,919][model][INFO] - Training step 31360 loss 0.024786297231912613
[2025-03-15 13:36:54,748][model][INFO] - Training step 31520 loss 0.05514639616012573
[2025-03-15 13:37:34,951][model][INFO] - Training step 31680 loss 0.023947158828377724
[2025-03-15 13:38:15,373][model][INFO] - Training step 31840 loss 0.0034365826286375523
[2025-03-15 13:38:56,423][model][INFO] - Training step 32000 loss 0.0262250155210495
[2025-03-15 13:39:36,495][model][INFO] - Training step 32160 loss 0.029629521071910858
[2025-03-15 13:40:17,162][model][INFO] - Training step 32320 loss 0.05289176106452942
[2025-03-15 13:40:57,299][model][INFO] - Training step 32480 loss 0.023143775761127472
[2025-03-15 13:41:37,667][model][INFO] - Training step 32640 loss 0.029069412499666214
[2025-03-15 13:42:19,826][model][INFO] - Training step 32800 loss 0.24956488609313965
[2025-03-15 13:43:03,202][model][INFO] - Training step 32960 loss 0.002215968444943428
[2025-03-15 13:43:43,919][model][INFO] - Training step 33120 loss 0.023856520652770996
[2025-03-15 13:44:24,938][model][INFO] - Training step 33280 loss 0.0041647846810519695
[2025-03-15 13:45:05,483][model][INFO] - Training step 33440 loss 0.0018805882427841425
[2025-03-15 13:45:46,894][model][INFO] - Training step 33600 loss 0.04176934063434601
[2025-03-15 13:46:28,173][model][INFO] - Training step 33760 loss 0.04058646410703659
[2025-03-15 13:47:09,116][model][INFO] - Training step 33920 loss 0.02067655883729458
[2025-03-15 13:47:48,994][model][INFO] - Training step 34080 loss 0.017757225781679153
[2025-03-15 13:48:29,508][model][INFO] - Training step 34240 loss 0.08935391157865524
[2025-03-15 13:49:11,780][model][INFO] - Training step 34400 loss 0.024463875219225883
[2025-03-15 13:49:53,077][model][INFO] - Training step 34560 loss 0.02557968720793724
[2025-03-15 13:50:34,013][model][INFO] - Training step 34720 loss 0.029553059488534927
[2025-03-15 13:51:14,663][model][INFO] - Training step 34880 loss 0.006018162239342928
[2025-03-15 13:51:57,349][model][INFO] - Training step 35040 loss 0.0037351460196077824
[2025-03-15 13:52:38,579][model][INFO] - Training step 35200 loss 0.006400515325367451
[2025-03-15 13:53:18,509][model][INFO] - Training step 35360 loss 0.25125980377197266
[2025-03-15 13:53:59,236][model][INFO] - Training step 35520 loss 0.00538519024848938
[2025-03-15 13:54:39,049][model][INFO] - Training step 35680 loss 0.042999736964702606
[2025-03-15 13:55:19,944][model][INFO] - Training step 35840 loss 0.02835989184677601
[2025-03-15 13:56:00,492][model][INFO] - Training step 36000 loss 0.24860642850399017
[2025-03-15 13:56:40,859][model][INFO] - Training step 36160 loss 0.048000626266002655
[2025-03-15 13:57:22,442][model][INFO] - Training step 36320 loss 0.01642756536602974
[2025-03-15 13:58:01,941][model][INFO] - Training step 36480 loss 0.004911944270133972
[2025-03-15 13:58:42,590][model][INFO] - Training step 36640 loss 0.2401396930217743
[2025-03-15 13:59:22,157][model][INFO] - Training step 36800 loss 0.060536373406648636
[2025-03-15 14:00:03,977][model][INFO] - Training step 36960 loss 0.019804373383522034
[2025-03-15 14:00:45,459][model][INFO] - Training step 37120 loss 0.020739413797855377
[2025-03-15 14:01:26,637][model][INFO] - Training step 37280 loss 0.0223415307700634
[2025-03-15 14:02:06,912][model][INFO] - Training step 37440 loss 0.0680830180644989
[2025-03-15 14:02:47,858][model][INFO] - Training step 37600 loss 0.006053130142390728
[2025-03-15 14:03:27,492][model][INFO] - Training step 37760 loss 0.037475310266017914
[2025-03-15 14:04:08,461][model][INFO] - Training step 37920 loss 0.014649521559476852
[2025-03-15 14:04:48,655][model][INFO] - Training step 38080 loss 0.2543109655380249
[2025-03-15 14:05:30,988][model][INFO] - Training step 38240 loss 0.018932664766907692
[2025-03-15 14:06:10,797][model][INFO] - Training step 38400 loss 0.1523384153842926
[2025-03-15 14:06:50,072][model][INFO] - Training step 38560 loss 0.25779223442077637
[2025-03-15 14:07:31,388][model][INFO] - Training step 38720 loss 0.02968808077275753
[2025-03-15 14:08:10,476][model][INFO] - Training step 38880 loss 0.0024168004747480154
[2025-03-15 14:08:51,677][model][INFO] - Training step 39040 loss 0.018200598657131195
[2025-03-15 14:09:32,278][model][INFO] - Training step 39200 loss 0.007051845081150532
[2025-03-15 14:10:14,141][model][INFO] - Training step 39360 loss 0.2568948268890381
[2025-03-15 14:10:54,820][model][INFO] - Training step 39520 loss 0.023355312645435333
[2025-03-15 14:11:35,459][model][INFO] - Training step 39680 loss 0.026975471526384354
[2025-03-15 14:12:16,260][model][INFO] - Training step 39840 loss 0.2476317584514618
[2025-03-15 14:12:56,653][model][INFO] - Training step 40000 loss 0.022224776446819305
[2025-03-15 14:13:38,176][model][INFO] - Training step 40160 loss 0.25878918170928955
[2025-03-15 14:14:19,265][model][INFO] - Training step 40320 loss 0.0295577235519886
[2025-03-15 14:15:00,543][model][INFO] - Training step 40480 loss 0.032916463911533356
[2025-03-15 14:15:41,770][model][INFO] - Training step 40640 loss 0.0886792242527008
[2025-03-15 14:16:21,367][model][INFO] - Training step 40800 loss 0.016196759417653084
[2025-03-15 14:17:01,205][model][INFO] - Training step 40960 loss 0.2571917474269867
[2025-03-15 14:17:41,813][model][INFO] - Training step 41120 loss 0.011471777223050594
[2025-03-15 14:18:23,875][model][INFO] - Training step 41280 loss 0.2542305588722229
[2025-03-15 14:19:03,711][model][INFO] - Training step 41440 loss 0.040598608553409576
[2025-03-15 14:19:44,264][model][INFO] - Training step 41600 loss 0.24855703115463257
[2025-03-15 14:20:24,299][model][INFO] - Training step 41760 loss 0.2553844451904297
[2025-03-15 14:21:05,661][model][INFO] - Training step 41920 loss 0.022785276174545288
[2025-03-15 14:21:46,234][model][INFO] - Training step 42080 loss 0.008373728021979332
[2025-03-15 14:22:26,623][model][INFO] - Training step 42240 loss 0.003555883886292577
[2025-03-15 14:23:06,467][model][INFO] - Training step 42400 loss 0.25795865058898926
[2025-03-15 14:23:47,883][model][INFO] - Training step 42560 loss 0.2665373682975769
[2025-03-15 14:24:28,412][model][INFO] - Training step 42720 loss 0.016263853758573532
[2025-03-15 14:25:08,254][model][INFO] - Training step 42880 loss 0.029898442327976227
[2025-03-15 14:25:48,271][model][INFO] - Training step 43040 loss 0.2274254858493805
[2025-03-15 14:26:28,966][model][INFO] - Training step 43200 loss 0.02779364213347435
[2025-03-15 14:27:09,163][model][INFO] - Training step 43360 loss 0.03399762511253357
[2025-03-15 14:27:49,780][model][INFO] - Training step 43520 loss 0.04740655794739723
[2025-03-15 14:28:31,127][model][INFO] - Training step 43680 loss 0.24428147077560425
[2025-03-15 14:29:11,872][model][INFO] - Training step 43840 loss 0.2635500431060791
[2025-03-15 14:29:52,748][model][INFO] - Training step 44000 loss 0.2515958547592163
[2025-03-15 14:30:34,970][model][INFO] - Training step 44160 loss 0.010112494230270386
[2025-03-15 14:31:15,874][model][INFO] - Training step 44320 loss 0.005029942840337753
[2025-03-15 14:31:56,917][model][INFO] - Training step 44480 loss 0.2557297348976135
[2025-03-15 14:32:37,834][model][INFO] - Training step 44640 loss 0.03082890436053276
[2025-03-15 14:33:19,512][model][INFO] - Training step 44800 loss 0.019950784742832184
[2025-03-15 14:33:58,853][model][INFO] - Training step 44960 loss 0.034297384321689606
[2025-03-15 14:34:38,813][model][INFO] - Training step 45120 loss 0.03272012621164322
[2025-03-15 14:35:19,225][model][INFO] - Training step 45280 loss 0.03173030540347099
[2025-03-15 14:36:00,254][model][INFO] - Training step 45440 loss 0.0026608314365148544
[2025-03-15 14:36:41,906][model][INFO] - Training step 45600 loss 0.030239582061767578
[2025-03-15 14:37:24,133][model][INFO] - Training step 45760 loss 0.25840169191360474
[2025-03-15 14:38:03,448][model][INFO] - Training step 45920 loss 0.04834901541471481
[2025-03-15 14:38:43,834][model][INFO] - Training step 46080 loss 0.24953237175941467
[2025-03-15 14:39:23,416][model][INFO] - Training step 46240 loss 0.022557225078344345
[2025-03-15 14:40:07,990][model][INFO] - Training step 46400 loss 0.008321241475641727
[2025-03-15 14:40:48,464][model][INFO] - Training step 46560 loss 0.027630053460597992
[2025-03-15 14:41:29,592][model][INFO] - Training step 46720 loss 0.10696199536323547
[2025-03-15 14:42:09,955][model][INFO] - Training step 46880 loss 0.024630580097436905
[2025-03-15 14:42:49,535][model][INFO] - Training step 47040 loss 0.03474985808134079
[2025-03-15 14:43:31,230][model][INFO] - Training step 47200 loss 0.2657902240753174
[2025-03-15 14:44:10,645][model][INFO] - Training step 47360 loss 0.07518285512924194
[2025-03-15 14:44:50,901][model][INFO] - Training step 47520 loss 0.02840678207576275
[2025-03-15 14:45:31,886][model][INFO] - Training step 47680 loss 0.2851393222808838
[2025-03-15 14:46:12,376][model][INFO] - Training step 47840 loss 0.017171479761600494
[2025-03-15 14:46:52,869][model][INFO] - Training step 48000 loss 0.043700553476810455
[2025-03-15 14:47:33,361][model][INFO] - Training step 48160 loss 0.25482723116874695
[2025-03-15 14:48:13,821][model][INFO] - Training step 48320 loss 0.2656812071800232
[2025-03-15 14:48:55,541][model][INFO] - Training step 48480 loss 0.016586072742938995
[2025-03-15 14:49:35,173][model][INFO] - Training step 48640 loss 0.023114394396543503
[2025-03-15 14:50:15,514][model][INFO] - Training step 48800 loss 0.002689550630748272
[2025-03-15 14:50:55,743][model][INFO] - Training step 48960 loss 0.01110764779150486
[2025-03-15 14:51:37,479][model][INFO] - Training step 49120 loss 0.020479675382375717
[2025-03-15 14:52:17,947][model][INFO] - Training step 49280 loss 0.057095967233181
[2025-03-15 14:52:59,823][model][INFO] - Training step 49440 loss 0.042274899780750275
[2025-03-15 14:53:42,318][model][INFO] - Training step 49600 loss 0.0257664006203413
[2025-03-15 14:54:23,761][model][INFO] - Training step 49760 loss 0.05272122472524643
[2025-03-15 14:55:05,185][model][INFO] - Training step 49920 loss 0.014148985967040062
[2025-03-15 14:55:46,114][model][INFO] - Training step 50080 loss 0.018237590789794922
[2025-03-15 14:56:26,449][model][INFO] - Training step 50240 loss 0.012248894199728966
[2025-03-15 14:57:06,873][model][INFO] - Training step 50400 loss 0.023675432428717613
[2025-03-15 14:57:47,485][model][INFO] - Training step 50560 loss 0.015566347166895866
[2025-03-15 14:58:27,732][model][INFO] - Training step 50720 loss 0.2546095848083496
[2025-03-15 15:04:15,351][model][INFO] - Training step 80 loss 0.007005202583968639
[2025-03-15 15:04:55,300][model][INFO] - Training step 240 loss 0.062282636761665344
[2025-03-15 15:05:36,282][model][INFO] - Training step 400 loss 0.025180641561746597
[2025-03-15 15:06:14,767][model][INFO] - Training step 560 loss 0.021702531725168228
[2025-03-15 15:06:55,106][model][INFO] - Training step 720 loss 0.02390141412615776
[2025-03-15 15:07:36,127][model][INFO] - Training step 880 loss 0.02285604178905487
[2025-03-15 15:08:15,903][model][INFO] - Training step 1040 loss 0.006158893462270498
[2025-03-15 15:08:56,050][model][INFO] - Training step 1200 loss 0.44208773970603943
[2025-03-15 15:09:37,333][model][INFO] - Training step 1360 loss 0.03415302187204361
[2025-03-15 15:10:17,323][model][INFO] - Training step 1520 loss 0.25120216608047485
[2025-03-15 15:10:58,764][model][INFO] - Training step 1680 loss 0.020831545814871788
[2025-03-15 15:11:40,039][model][INFO] - Training step 1840 loss 0.2565503716468811
[2025-03-15 15:12:19,931][model][INFO] - Training step 2000 loss 0.04315518960356712
[2025-03-15 15:12:59,518][model][INFO] - Training step 2160 loss 0.01795351505279541
[2025-03-15 15:13:39,282][model][INFO] - Training step 2320 loss 0.029101068153977394
[2025-03-15 15:14:21,015][model][INFO] - Training step 2480 loss 0.018438670784235
[2025-03-15 15:15:00,397][model][INFO] - Training step 2640 loss 0.019533075392246246
[2025-03-15 15:15:40,425][model][INFO] - Training step 2800 loss 0.08751879632472992
[2025-03-15 15:16:21,907][model][INFO] - Training step 2960 loss 0.03507412225008011
[2025-03-15 15:17:01,253][model][INFO] - Training step 3120 loss 0.6536025404930115
[2025-03-15 15:17:40,962][model][INFO] - Training step 3280 loss 0.027683936059474945
[2025-03-15 15:18:21,215][model][INFO] - Training step 3440 loss 0.022770263254642487
[2025-03-15 15:19:01,475][model][INFO] - Training step 3600 loss 0.006067702546715736
[2025-03-15 15:19:42,353][model][INFO] - Training step 3760 loss 0.018453573808073997
[2025-03-15 15:20:23,198][model][INFO] - Training step 3920 loss 0.01550897303968668
[2025-03-15 15:21:04,206][model][INFO] - Training step 4080 loss 0.00734785757958889
[2025-03-15 15:21:45,828][model][INFO] - Training step 4240 loss 0.03320147097110748
[2025-03-15 15:22:25,452][model][INFO] - Training step 4400 loss 0.007373945787549019
[2025-03-15 15:23:06,117][model][INFO] - Training step 4560 loss 0.007236157078295946
[2025-03-15 15:23:46,947][model][INFO] - Training step 4720 loss 0.25872090458869934
[2025-03-15 15:24:25,463][model][INFO] - Training step 4880 loss 0.01394714042544365
[2025-03-15 15:25:05,463][model][INFO] - Training step 5040 loss 0.28194350004196167
[2025-03-15 15:25:46,740][model][INFO] - Training step 5200 loss 0.040911369025707245
[2025-03-15 15:26:28,556][model][INFO] - Training step 5360 loss 0.24043837189674377
[2025-03-15 15:27:08,404][model][INFO] - Training step 5520 loss 0.2776532769203186
[2025-03-15 15:27:47,838][model][INFO] - Training step 5680 loss 0.017767246812582016
[2025-03-15 15:28:29,846][model][INFO] - Training step 5840 loss 0.00960411224514246
[2025-03-15 15:29:10,839][model][INFO] - Training step 6000 loss 0.007673269137740135
[2025-03-15 15:29:51,865][model][INFO] - Training step 6160 loss 0.019974879920482635
[2025-03-15 15:30:34,092][model][INFO] - Training step 6320 loss 0.27719590067863464
[2025-03-15 15:31:15,514][model][INFO] - Training step 6480 loss 0.037642017006874084
[2025-03-15 15:31:57,855][model][INFO] - Training step 6640 loss 0.009258673526346684
[2025-03-15 15:32:38,498][model][INFO] - Training step 6800 loss 0.017495781183242798
[2025-03-15 15:33:19,482][model][INFO] - Training step 6960 loss 0.022422276437282562
[2025-03-15 15:34:00,499][model][INFO] - Training step 7120 loss 0.004396708682179451
[2025-03-15 15:34:43,427][model][INFO] - Training step 7280 loss 0.02571830525994301
[2025-03-15 15:35:25,857][model][INFO] - Training step 7440 loss 0.02052999660372734
[2025-03-15 15:36:07,830][model][INFO] - Training step 7600 loss 0.052958838641643524
[2025-03-15 15:36:48,182][model][INFO] - Training step 7760 loss 0.004825570620596409
[2025-03-15 15:37:28,800][model][INFO] - Training step 7920 loss 0.25115567445755005
[2025-03-15 15:38:08,964][model][INFO] - Training step 8080 loss 0.03227125108242035
[2025-03-15 15:38:50,441][model][INFO] - Training step 8240 loss 0.03320295363664627
[2025-03-15 15:39:30,598][model][INFO] - Training step 8400 loss 0.06460657715797424
[2025-03-15 15:40:10,305][model][INFO] - Training step 8560 loss 0.028889868408441544
[2025-03-15 15:40:50,518][model][INFO] - Training step 8720 loss 0.019951093941926956
[2025-03-15 15:41:31,178][model][INFO] - Training step 8880 loss 0.26427358388900757
[2025-03-15 15:42:11,083][model][INFO] - Training step 9040 loss 0.03145168721675873
[2025-03-15 15:42:49,985][model][INFO] - Training step 9200 loss 0.018595509231090546
[2025-03-15 15:43:31,291][model][INFO] - Training step 9360 loss 0.10045579075813293
[2025-03-15 15:44:11,387][model][INFO] - Training step 9520 loss 0.013874941505491734
[2025-03-15 15:44:52,605][model][INFO] - Training step 9680 loss 0.09540073573589325
[2025-03-15 15:45:34,126][model][INFO] - Training step 9840 loss 0.05739618092775345
[2025-03-15 15:46:13,013][model][INFO] - Training step 10000 loss 0.24610796570777893
[2025-03-15 15:46:54,820][model][INFO] - Training step 10160 loss 0.015560824424028397
[2025-03-15 15:47:35,611][model][INFO] - Training step 10320 loss 0.014918725937604904
[2025-03-15 15:48:17,214][model][INFO] - Training step 10480 loss 0.004731686785817146
[2025-03-15 15:48:56,715][model][INFO] - Training step 10640 loss 0.004986352287232876
[2025-03-15 15:49:37,169][model][INFO] - Training step 10800 loss 0.10336773097515106
[2025-03-15 15:50:17,972][model][INFO] - Training step 10960 loss 0.04982328414916992
[2025-03-15 15:50:58,335][model][INFO] - Training step 11120 loss 0.030050847679376602
[2025-03-15 15:51:38,127][model][INFO] - Training step 11280 loss 0.022511422634124756
[2025-03-15 15:52:19,311][model][INFO] - Training step 11440 loss 0.2651275396347046
[2025-03-15 15:52:59,172][model][INFO] - Training step 11600 loss 0.01171847153455019
[2025-03-15 15:53:39,924][model][INFO] - Training step 11760 loss 0.048117127269506454
[2025-03-15 15:54:19,878][model][INFO] - Training step 11920 loss 0.003951739519834518
[2025-03-15 15:54:59,052][model][INFO] - Training step 12080 loss 0.02971526049077511
[2025-03-15 15:55:39,077][model][INFO] - Training step 12240 loss 0.0345822349190712
[2025-03-15 15:56:18,858][model][INFO] - Training step 12400 loss 0.04640179127454758
[2025-03-15 15:57:00,487][model][INFO] - Training step 12560 loss 0.00455813342705369
[2025-03-15 15:57:41,405][model][INFO] - Training step 12720 loss 0.24209628999233246
[2025-03-15 15:58:22,798][model][INFO] - Training step 12880 loss 0.020233290269970894
[2025-03-15 15:59:03,850][model][INFO] - Training step 13040 loss 0.11958138644695282
[2025-03-15 15:59:44,897][model][INFO] - Training step 13200 loss 0.027268361300230026
[2025-03-15 16:00:27,144][model][INFO] - Training step 13360 loss 0.04513333737850189
[2025-03-15 16:01:07,611][model][INFO] - Training step 13520 loss 0.03406165540218353
[2025-03-15 16:01:48,282][model][INFO] - Training step 13680 loss 0.005461797583848238
[2025-03-15 16:02:29,105][model][INFO] - Training step 13840 loss 0.017995193600654602
[2025-03-15 16:03:09,047][model][INFO] - Training step 14000 loss 0.024330034852027893
[2025-03-15 16:03:48,917][model][INFO] - Training step 14160 loss 0.019299257546663284
[2025-03-15 16:04:29,784][model][INFO] - Training step 14320 loss 0.25432854890823364
[2025-03-15 16:05:10,145][model][INFO] - Training step 14480 loss 0.2374841868877411
[2025-03-15 16:05:51,488][model][INFO] - Training step 14640 loss 0.016047243028879166
[2025-03-15 16:06:31,978][model][INFO] - Training step 14800 loss 0.24564051628112793
[2025-03-15 16:07:13,426][model][INFO] - Training step 14960 loss 0.01837494596838951
[2025-03-15 16:07:54,289][model][INFO] - Training step 15120 loss 0.014835186302661896
[2025-03-15 16:08:34,455][model][INFO] - Training step 15280 loss 0.025254085659980774
[2025-03-15 16:09:15,361][model][INFO] - Training step 15440 loss 0.012886233627796173
[2025-03-15 16:09:55,921][model][INFO] - Training step 15600 loss 0.04981701076030731
[2025-03-15 16:10:37,282][model][INFO] - Training step 15760 loss 0.002996917115524411
[2025-03-15 16:11:17,198][model][INFO] - Training step 15920 loss 0.2559269070625305
[2025-03-15 16:11:57,493][model][INFO] - Training step 16080 loss 0.002233033301308751
[2025-03-15 16:12:37,260][model][INFO] - Training step 16240 loss 0.2041231095790863
[2025-03-15 16:13:17,175][model][INFO] - Training step 16400 loss 0.0375651940703392
[2025-03-15 16:13:59,180][model][INFO] - Training step 16560 loss 0.006798760034143925
[2025-03-15 16:14:39,615][model][INFO] - Training step 16720 loss 0.0228546392172575
[2025-03-15 16:15:19,677][model][INFO] - Training step 16880 loss 0.24629434943199158
[2025-03-15 16:16:00,369][model][INFO] - Training step 17040 loss 0.47900837659835815
[2025-03-15 16:16:41,979][model][INFO] - Training step 17200 loss 0.09262119978666306
[2025-03-15 16:17:22,988][model][INFO] - Training step 17360 loss 0.032175928354263306
[2025-03-15 16:18:03,354][model][INFO] - Training step 17520 loss 0.0251548383384943
[2025-03-15 16:18:44,611][model][INFO] - Training step 17680 loss 0.021234925836324692
[2025-03-15 16:19:24,233][model][INFO] - Training step 17840 loss 0.008855004794895649
[2025-03-15 16:20:05,823][model][INFO] - Training step 18000 loss 0.08282260596752167
[2025-03-15 16:20:48,035][model][INFO] - Training step 18160 loss 0.03179814666509628
[2025-03-15 16:21:28,887][model][INFO] - Training step 18320 loss 0.03211262822151184
[2025-03-15 16:22:09,962][model][INFO] - Training step 18480 loss 0.004312402568757534
[2025-03-15 16:22:51,454][model][INFO] - Training step 18640 loss 0.032612256705760956
[2025-03-15 16:23:31,133][model][INFO] - Training step 18800 loss 0.012170249596238136
[2025-03-15 16:24:10,966][model][INFO] - Training step 18960 loss 0.03105768747627735
[2025-03-15 16:24:52,137][model][INFO] - Training step 19120 loss 0.08249271661043167
[2025-03-15 16:25:32,613][model][INFO] - Training step 19280 loss 0.1303798258304596
[2025-03-15 16:26:13,269][model][INFO] - Training step 19440 loss 0.026593174785375595
[2025-03-15 16:26:54,662][model][INFO] - Training step 19600 loss 0.03687209635972977
[2025-03-15 16:27:36,029][model][INFO] - Training step 19760 loss 0.2643290162086487
[2025-03-15 16:28:18,515][model][INFO] - Training step 19920 loss 0.04278843104839325
[2025-03-15 16:28:58,788][model][INFO] - Training step 20080 loss 0.038993071764707565
[2025-03-15 16:29:39,883][model][INFO] - Training step 20240 loss 0.019542299211025238
[2025-03-15 16:30:21,181][model][INFO] - Training step 20400 loss 0.042494889348745346
[2025-03-15 16:31:02,168][model][INFO] - Training step 20560 loss 0.01646323688328266
[2025-03-15 16:31:43,809][model][INFO] - Training step 20720 loss 0.039367906749248505
[2025-03-15 16:32:24,057][model][INFO] - Training step 20880 loss 0.1518620252609253
[2025-03-15 16:33:04,221][model][INFO] - Training step 21040 loss 0.006906346417963505
[2025-03-15 16:33:44,860][model][INFO] - Training step 21200 loss 0.02200378105044365
[2025-03-15 16:34:25,234][model][INFO] - Training step 21360 loss 0.03844137489795685
[2025-03-15 16:35:05,153][model][INFO] - Training step 21520 loss 0.07952915132045746
[2025-03-15 16:35:45,850][model][INFO] - Training step 21680 loss 0.01916608214378357
[2025-03-15 16:36:26,536][model][INFO] - Training step 21840 loss 0.0024352865293622017
[2025-03-15 16:37:07,766][model][INFO] - Training step 22000 loss 0.02841988578438759
[2025-03-15 16:37:47,753][model][INFO] - Training step 22160 loss 0.02592768892645836
[2025-03-15 16:38:28,522][model][INFO] - Training step 22320 loss 0.021884439513087273
[2025-03-15 16:39:10,541][model][INFO] - Training step 22480 loss 0.004464690573513508
[2025-03-15 16:39:51,153][model][INFO] - Training step 22640 loss 0.016518540680408478
[2025-03-15 16:40:32,322][model][INFO] - Training step 22800 loss 0.020582828670740128
[2025-03-15 16:41:13,082][model][INFO] - Training step 22960 loss 0.021286480128765106
[2025-03-15 16:41:53,294][model][INFO] - Training step 23120 loss 0.021669350564479828
[2025-03-15 16:42:33,381][model][INFO] - Training step 23280 loss 0.016381382942199707
[2025-03-15 16:43:16,551][model][INFO] - Training step 23440 loss 0.2509124279022217
[2025-03-15 16:43:56,641][model][INFO] - Training step 23600 loss 0.34122103452682495
[2025-03-15 16:44:37,613][model][INFO] - Training step 23760 loss 0.020037658512592316
[2025-03-15 16:45:19,359][model][INFO] - Training step 23920 loss 0.008152369409799576
[2025-03-15 16:45:59,393][model][INFO] - Training step 24080 loss 0.04013344272971153
[2025-03-15 16:46:38,974][model][INFO] - Training step 24240 loss 0.020423728972673416
[2025-03-15 16:47:19,527][model][INFO] - Training step 24400 loss 0.022117648273706436
[2025-03-15 16:48:00,614][model][INFO] - Training step 24560 loss 0.10834145545959473
[2025-03-15 16:48:40,691][model][INFO] - Training step 24720 loss 0.030082184821367264
[2025-03-15 16:49:21,982][model][INFO] - Training step 24880 loss 0.009027955122292042
[2025-03-15 16:50:01,152][model][INFO] - Training step 25040 loss 0.18011003732681274
[2025-03-15 16:50:41,890][model][INFO] - Training step 25200 loss 0.048690810799598694
[2025-03-15 16:51:23,797][model][INFO] - Training step 25360 loss 0.25811511278152466
[2025-03-15 16:52:04,310][model][INFO] - Training step 25520 loss 0.06942349672317505
[2025-03-15 16:52:44,348][model][INFO] - Training step 25680 loss 0.01185695268213749
[2025-03-15 16:53:25,603][model][INFO] - Training step 25840 loss 0.06485395133495331
[2025-03-15 16:54:06,427][model][INFO] - Training step 26000 loss 0.08367942273616791
[2025-03-15 16:54:46,814][model][INFO] - Training step 26160 loss 0.005282145459204912
[2025-03-15 16:55:27,709][model][INFO] - Training step 26320 loss 0.0034910005051642656
[2025-03-15 16:56:09,365][model][INFO] - Training step 26480 loss 0.2437058836221695
[2025-03-15 16:56:50,317][model][INFO] - Training step 26640 loss 0.0403018519282341
[2025-03-15 16:57:31,088][model][INFO] - Training step 26800 loss 0.03817422688007355
[2025-03-15 16:58:12,048][model][INFO] - Training step 26960 loss 0.02120203524827957
[2025-03-15 16:58:52,689][model][INFO] - Training step 27120 loss 0.06750702857971191
[2025-03-15 16:59:33,379][model][INFO] - Training step 27280 loss 0.09103024005889893
[2025-03-15 17:00:13,919][model][INFO] - Training step 27440 loss 0.27266925573349
[2025-03-15 17:00:53,717][model][INFO] - Training step 27600 loss 0.057310789823532104
[2025-03-15 17:01:36,118][model][INFO] - Training step 27760 loss 0.16146187484264374
[2025-03-15 17:02:16,380][model][INFO] - Training step 27920 loss 0.03230578452348709
[2025-03-15 17:02:58,260][model][INFO] - Training step 28080 loss 0.02750086411833763
[2025-03-15 17:03:38,490][model][INFO] - Training step 28240 loss 0.2419908344745636
[2025-03-15 17:04:19,808][model][INFO] - Training step 28400 loss 0.2623906135559082
[2025-03-15 17:05:00,592][model][INFO] - Training step 28560 loss 0.26438236236572266
[2025-03-15 17:05:41,446][model][INFO] - Training step 28720 loss 0.008762824349105358
[2025-03-15 17:06:22,139][model][INFO] - Training step 28880 loss 0.014559266157448292
[2025-03-15 17:07:01,438][model][INFO] - Training step 29040 loss 0.2507169544696808
[2025-03-15 17:07:42,271][model][INFO] - Training step 29200 loss 0.013581369072198868
[2025-03-15 17:08:23,742][model][INFO] - Training step 29360 loss 0.006507224403321743
[2025-03-15 17:09:03,421][model][INFO] - Training step 29520 loss 0.11813269555568695
[2025-03-15 17:09:43,819][model][INFO] - Training step 29680 loss 0.03927553445100784
[2025-03-15 17:10:25,412][model][INFO] - Training step 29840 loss 0.2682441771030426
[2025-03-15 17:11:06,788][model][INFO] - Training step 30000 loss 0.010958092287182808
[2025-03-15 17:11:48,053][model][INFO] - Training step 30160 loss 0.010397122241556644
[2025-03-15 17:12:30,399][model][INFO] - Training step 30320 loss 0.022108664736151695
[2025-03-15 17:13:11,221][model][INFO] - Training step 30480 loss 0.2568114101886749
[2025-03-15 17:13:49,853][model][INFO] - Training step 30640 loss 0.03020866960287094
[2025-03-15 17:14:28,986][model][INFO] - Training step 30800 loss 0.04344121366739273
[2025-03-15 17:15:10,304][model][INFO] - Training step 30960 loss 0.01860635355114937
[2025-03-15 17:15:51,350][model][INFO] - Training step 31120 loss 0.05697944760322571
[2025-03-15 17:16:32,937][model][INFO] - Training step 31280 loss 0.03636130318045616
[2025-03-15 17:17:12,476][model][INFO] - Training step 31440 loss 0.028454167768359184
[2025-03-15 17:17:52,940][model][INFO] - Training step 31600 loss 0.2590402066707611
[2025-03-15 17:18:34,299][model][INFO] - Training step 31760 loss 0.039113059639930725
[2025-03-15 17:19:13,932][model][INFO] - Training step 31920 loss 0.026816092431545258
[2025-03-15 17:19:54,992][model][INFO] - Training step 32080 loss 0.02498825266957283
[2025-03-15 17:20:35,876][model][INFO] - Training step 32240 loss 0.03998193144798279
[2025-03-15 17:21:15,872][model][INFO] - Training step 32400 loss 0.2460424304008484
[2025-03-15 17:21:57,651][model][INFO] - Training step 32560 loss 0.02883773483335972
[2025-03-15 17:22:38,213][model][INFO] - Training step 32720 loss 0.2536128759384155
[2025-03-15 17:23:18,767][model][INFO] - Training step 32880 loss 0.04813627153635025
[2025-03-15 17:23:59,082][model][INFO] - Training step 33040 loss 0.02414649724960327
[2025-03-15 17:24:39,190][model][INFO] - Training step 33200 loss 0.02427416294813156
[2025-03-15 17:25:19,382][model][INFO] - Training step 33360 loss 0.25639623403549194
[2025-03-15 17:26:02,283][model][INFO] - Training step 33520 loss 0.0506063848733902
[2025-03-15 17:26:44,375][model][INFO] - Training step 33680 loss 0.2523176372051239
[2025-03-15 17:27:26,578][model][INFO] - Training step 33840 loss 0.019592441618442535
[2025-03-15 17:28:07,057][model][INFO] - Training step 34000 loss 0.015139209106564522
[2025-03-15 17:28:48,085][model][INFO] - Training step 34160 loss 0.0458594411611557
[2025-03-15 17:29:28,657][model][INFO] - Training step 34320 loss 0.01792130619287491
[2025-03-15 17:30:09,730][model][INFO] - Training step 34480 loss 0.07923509180545807
[2025-03-15 17:30:50,223][model][INFO] - Training step 34640 loss 0.00438285805284977
[2025-03-15 17:31:30,017][model][INFO] - Training step 34800 loss 0.021457623690366745
[2025-03-15 17:32:11,458][model][INFO] - Training step 34960 loss 0.1881721019744873
[2025-03-15 17:32:51,955][model][INFO] - Training step 35120 loss 0.00776259321719408
[2025-03-15 17:33:31,234][model][INFO] - Training step 35280 loss 0.02392324060201645
[2025-03-15 17:34:11,389][model][INFO] - Training step 35440 loss 0.012549390085041523
[2025-03-15 17:34:52,821][model][INFO] - Training step 35600 loss 0.0052115959115326405
[2025-03-15 17:35:33,178][model][INFO] - Training step 35760 loss 0.021306775510311127
[2025-03-15 17:36:12,502][model][INFO] - Training step 35920 loss 0.2505607008934021
[2025-03-15 17:36:52,636][model][INFO] - Training step 36080 loss 0.036907706409692764
[2025-03-15 17:37:33,980][model][INFO] - Training step 36240 loss 0.25595569610595703
[2025-03-15 17:38:15,846][model][INFO] - Training step 36400 loss 0.2536439299583435
[2025-03-15 17:38:57,422][model][INFO] - Training step 36560 loss 0.007417704910039902
[2025-03-15 17:39:37,844][model][INFO] - Training step 36720 loss 0.007137318607419729
[2025-03-15 17:40:19,590][model][INFO] - Training step 36880 loss 0.0717366635799408
[2025-03-15 17:40:59,480][model][INFO] - Training step 37040 loss 0.0705454871058464
[2025-03-15 17:41:39,789][model][INFO] - Training step 37200 loss 0.027982346713542938
[2025-03-15 17:42:20,799][model][INFO] - Training step 37360 loss 0.02125752717256546
[2025-03-15 17:43:01,307][model][INFO] - Training step 37520 loss 0.021574605256319046
[2025-03-15 17:43:41,340][model][INFO] - Training step 37680 loss 0.06250415742397308
[2025-03-15 17:44:22,532][model][INFO] - Training step 37840 loss 0.03873930871486664
[2025-03-15 17:45:02,625][model][INFO] - Training step 38000 loss 0.2314261496067047
[2025-03-15 17:45:43,019][model][INFO] - Training step 38160 loss 0.029733994975686073
[2025-03-15 17:46:23,275][model][INFO] - Training step 38320 loss 0.02995222434401512
[2025-03-15 17:47:04,209][model][INFO] - Training step 38480 loss 0.028016015887260437
[2025-03-15 17:47:44,393][model][INFO] - Training step 38640 loss 0.26321941614151
[2025-03-15 17:48:23,136][model][INFO] - Training step 38800 loss 0.06183581426739693
[2025-03-15 17:49:03,863][model][INFO] - Training step 38960 loss 0.019791215658187866
[2025-03-15 17:49:44,042][model][INFO] - Training step 39120 loss 0.052989132702350616
[2025-03-15 17:50:25,008][model][INFO] - Training step 39280 loss 0.005843810737133026
[2025-03-15 17:51:05,748][model][INFO] - Training step 39440 loss 0.24827517569065094
[2025-03-15 17:51:47,643][model][INFO] - Training step 39600 loss 0.10003088414669037
[2025-03-15 17:52:27,663][model][INFO] - Training step 39760 loss 0.026846952736377716
[2025-03-15 17:53:08,732][model][INFO] - Training step 39920 loss 0.02192547731101513
[2025-03-15 17:53:49,111][model][INFO] - Training step 40080 loss 0.013155430555343628
[2025-03-15 17:54:29,405][model][INFO] - Training step 40240 loss 0.04754049330949783
[2025-03-15 17:55:11,058][model][INFO] - Training step 40400 loss 0.007506336085498333
[2025-03-15 17:55:53,554][model][INFO] - Training step 40560 loss 0.032498784363269806
[2025-03-15 17:56:33,914][model][INFO] - Training step 40720 loss 0.03265203535556793
[2025-03-15 17:57:16,406][model][INFO] - Training step 40880 loss 0.014880877919495106
[2025-03-15 17:57:57,326][model][INFO] - Training step 41040 loss 0.03208724409341812
[2025-03-15 17:58:38,978][model][INFO] - Training step 41200 loss 0.08200784027576447
[2025-03-15 17:59:19,999][model][INFO] - Training step 41360 loss 0.2539501190185547
[2025-03-15 17:59:59,018][model][INFO] - Training step 41520 loss 0.03266391530632973
[2025-03-15 18:00:39,513][model][INFO] - Training step 41680 loss 0.07839744538068771
[2025-03-15 18:01:20,376][model][INFO] - Training step 41840 loss 0.011029019020497799
[2025-03-15 18:02:00,832][model][INFO] - Training step 42000 loss 0.0540769025683403
[2025-03-15 18:02:41,743][model][INFO] - Training step 42160 loss 0.005606471560895443
[2025-03-15 18:03:22,946][model][INFO] - Training step 42320 loss 0.012163443490862846
[2025-03-15 18:04:03,243][model][INFO] - Training step 42480 loss 0.24028237164020538
[2025-03-15 18:04:42,835][model][INFO] - Training step 42640 loss 0.02171226218342781
[2025-03-15 18:05:23,935][model][INFO] - Training step 42800 loss 0.025577757507562637
[2025-03-15 18:06:03,995][model][INFO] - Training step 42960 loss 0.04343327879905701
[2025-03-15 18:06:47,535][model][INFO] - Training step 43120 loss 0.03851670026779175
[2025-03-15 18:07:27,259][model][INFO] - Training step 43280 loss 0.04785006493330002
[2025-03-15 18:08:08,957][model][INFO] - Training step 43440 loss 0.004877530969679356
[2025-03-15 18:08:48,375][model][INFO] - Training step 43600 loss 0.004749445244669914
[2025-03-15 18:09:30,504][model][INFO] - Training step 43760 loss 0.20764800906181335
[2025-03-15 18:10:09,911][model][INFO] - Training step 43920 loss 0.03382086753845215
[2025-03-15 18:10:50,167][model][INFO] - Training step 44080 loss 0.027918856590986252
[2025-03-15 18:11:30,475][model][INFO] - Training step 44240 loss 0.032914675772190094
[2025-03-15 18:12:10,059][model][INFO] - Training step 44400 loss 0.02912762761116028
[2025-03-15 18:12:50,409][model][INFO] - Training step 44560 loss 0.0035895034670829773
[2025-03-15 18:13:31,219][model][INFO] - Training step 44720 loss 0.018287230283021927
[2025-03-15 18:14:11,498][model][INFO] - Training step 44880 loss 0.040967077016830444
[2025-03-15 18:14:51,327][model][INFO] - Training step 45040 loss 0.25861841440200806
[2025-03-15 18:15:31,671][model][INFO] - Training step 45200 loss 0.014398411847651005
[2025-03-15 18:16:13,293][model][INFO] - Training step 45360 loss 0.019053351134061813
[2025-03-15 18:16:53,589][model][INFO] - Training step 45520 loss 0.0355643630027771
[2025-03-15 18:17:36,187][model][INFO] - Training step 45680 loss 0.011167855933308601
[2025-03-15 18:18:15,011][model][INFO] - Training step 45840 loss 0.0791572630405426
[2025-03-15 18:18:56,269][model][INFO] - Training step 46000 loss 0.07745656371116638
[2025-03-15 18:19:36,459][model][INFO] - Training step 46160 loss 0.030009636655449867
[2025-03-15 18:20:17,117][model][INFO] - Training step 46320 loss 0.02814536727964878
[2025-03-15 18:20:57,667][model][INFO] - Training step 46480 loss 0.05289343744516373
[2025-03-15 18:21:37,338][model][INFO] - Training step 46640 loss 0.16171923279762268
[2025-03-15 18:22:18,557][model][INFO] - Training step 46800 loss 0.03668837994337082
[2025-03-15 18:23:00,707][model][INFO] - Training step 46960 loss 0.0303325392305851
[2025-03-15 18:23:42,351][model][INFO] - Training step 47120 loss 0.06499317288398743
[2025-03-15 18:24:23,039][model][INFO] - Training step 47280 loss 0.03630762919783592
[2025-03-15 18:25:03,556][model][INFO] - Training step 47440 loss 0.012897053733468056
[2025-03-15 18:25:43,091][model][INFO] - Training step 47600 loss 0.06882643699645996
[2025-03-15 18:26:24,308][model][INFO] - Training step 47760 loss 0.24645689129829407
[2025-03-15 18:27:04,435][model][INFO] - Training step 47920 loss 0.030886178836226463
[2025-03-15 18:27:47,144][model][INFO] - Training step 48080 loss 0.2580052316188812
[2025-03-15 18:28:27,367][model][INFO] - Training step 48240 loss 0.016342798247933388
[2025-03-15 18:29:07,439][model][INFO] - Training step 48400 loss 0.24986052513122559
[2025-03-15 18:29:47,968][model][INFO] - Training step 48560 loss 0.030436813831329346
[2025-03-15 18:30:28,518][model][INFO] - Training step 48720 loss 0.01909470185637474
[2025-03-15 18:31:08,157][model][INFO] - Training step 48880 loss 0.039869070053100586
[2025-03-15 18:31:48,697][model][INFO] - Training step 49040 loss 0.007803872227668762
[2025-03-15 18:32:28,704][model][INFO] - Training step 49200 loss 0.01711810752749443
[2025-03-15 18:33:09,137][model][INFO] - Training step 49360 loss 0.02216397598385811
[2025-03-15 18:33:50,465][model][INFO] - Training step 49520 loss 0.002705233171582222
[2025-03-15 18:34:29,644][model][INFO] - Training step 49680 loss 0.014062510803341866
[2025-03-15 18:35:10,421][model][INFO] - Training step 49840 loss 0.1611732840538025
[2025-03-15 18:35:51,469][model][INFO] - Training step 50000 loss 0.04301585257053375
[2025-03-15 18:36:31,435][model][INFO] - Training step 50160 loss 0.014149945229291916
[2025-03-15 18:37:12,865][model][INFO] - Training step 50320 loss 0.0024602171033620834
[2025-03-15 18:37:53,421][model][INFO] - Training step 50480 loss 0.006209287792444229
[2025-03-15 18:38:33,791][model][INFO] - Training step 50640 loss 0.0019331849180161953
[2025-03-15 18:44:20,065][model][INFO] - Training step 0 loss 0.18966072797775269
[2025-03-15 18:45:00,368][model][INFO] - Training step 160 loss 0.24877777695655823
[2025-03-15 18:45:40,212][model][INFO] - Training step 320 loss 0.026368845254182816
[2025-03-15 18:46:20,929][model][INFO] - Training step 480 loss 0.05725186690688133
[2025-03-15 18:47:00,148][model][INFO] - Training step 640 loss 0.25286656618118286
[2025-03-15 18:47:40,480][model][INFO] - Training step 800 loss 0.028764210641384125
[2025-03-15 18:48:20,693][model][INFO] - Training step 960 loss 0.015112319961190224
[2025-03-15 18:49:00,090][model][INFO] - Training step 1120 loss 0.03706015273928642
[2025-03-15 18:49:40,428][model][INFO] - Training step 1280 loss 0.24936097860336304
[2025-03-15 18:50:20,440][model][INFO] - Training step 1440 loss 0.024621501564979553
[2025-03-15 18:51:01,348][model][INFO] - Training step 1600 loss 0.26806309819221497
[2025-03-15 18:51:40,980][model][INFO] - Training step 1760 loss 0.026127878576517105
[2025-03-15 18:52:19,969][model][INFO] - Training step 1920 loss 0.010534759610891342
[2025-03-15 18:52:59,963][model][INFO] - Training step 2080 loss 0.011586112901568413
[2025-03-15 18:53:40,146][model][INFO] - Training step 2240 loss 0.022494595497846603
[2025-03-15 18:54:20,626][model][INFO] - Training step 2400 loss 0.03915189206600189
[2025-03-15 18:55:01,398][model][INFO] - Training step 2560 loss 0.09068053960800171
[2025-03-15 18:55:43,049][model][INFO] - Training step 2720 loss 0.015030499547719955
[2025-03-15 18:56:23,983][model][INFO] - Training step 2880 loss 0.2482789009809494
[2025-03-15 18:57:04,090][model][INFO] - Training step 3040 loss 0.04862970858812332
[2025-03-15 18:57:43,110][model][INFO] - Training step 3200 loss 0.0046292757615447044
[2025-03-15 18:58:24,351][model][INFO] - Training step 3360 loss 0.031495802104473114
[2025-03-15 18:59:05,241][model][INFO] - Training step 3520 loss 0.027091603726148605
[2025-03-15 18:59:46,024][model][INFO] - Training step 3680 loss 0.02643180638551712
[2025-03-15 19:00:25,972][model][INFO] - Training step 3840 loss 0.025132328271865845
[2025-03-15 19:01:05,738][model][INFO] - Training step 4000 loss 0.04135335236787796
[2025-03-15 19:01:46,035][model][INFO] - Training step 4160 loss 0.003919477574527264
[2025-03-15 19:02:27,741][model][INFO] - Training step 4320 loss 0.005425240844488144
[2025-03-15 19:03:08,326][model][INFO] - Training step 4480 loss 0.008407538756728172
[2025-03-15 19:03:49,263][model][INFO] - Training step 4640 loss 0.03684133291244507
[2025-03-15 19:04:30,945][model][INFO] - Training step 4800 loss 0.37762922048568726
[2025-03-15 19:05:12,096][model][INFO] - Training step 4960 loss 0.027715101838111877
[2025-03-15 19:05:53,187][model][INFO] - Training step 5120 loss 0.36168888211250305
[2025-03-15 19:06:34,614][model][INFO] - Training step 5280 loss 0.007450804114341736
[2025-03-15 19:07:13,813][model][INFO] - Training step 5440 loss 0.03924092650413513
[2025-03-15 19:07:52,797][model][INFO] - Training step 5600 loss 0.264126181602478
[2025-03-15 19:08:32,660][model][INFO] - Training step 5760 loss 0.018492672592401505
[2025-03-15 19:09:13,711][model][INFO] - Training step 5920 loss 0.0019421265460550785
[2025-03-15 19:09:55,863][model][INFO] - Training step 6080 loss 0.029707368463277817
[2025-03-15 19:10:37,296][model][INFO] - Training step 6240 loss 0.011996196582913399
[2025-03-15 19:11:18,175][model][INFO] - Training step 6400 loss 0.003956160508096218
[2025-03-15 19:11:58,862][model][INFO] - Training step 6560 loss 0.004932878538966179
[2025-03-15 19:12:39,439][model][INFO] - Training step 6720 loss 0.006804220378398895
[2025-03-15 19:13:20,350][model][INFO] - Training step 6880 loss 0.25685036182403564
[2025-03-15 19:14:00,314][model][INFO] - Training step 7040 loss 0.017715265974402428
[2025-03-15 19:14:41,425][model][INFO] - Training step 7200 loss 0.01301129162311554
[2025-03-15 19:15:22,083][model][INFO] - Training step 7360 loss 0.02701212838292122
[2025-03-15 19:16:05,258][model][INFO] - Training step 7520 loss 0.24293237924575806
[2025-03-15 19:16:45,920][model][INFO] - Training step 7680 loss 0.022052224725484848
[2025-03-15 19:17:26,291][model][INFO] - Training step 7840 loss 0.02358240634202957
[2025-03-15 19:18:07,622][model][INFO] - Training step 8000 loss 0.006504010409116745
[2025-03-15 19:18:47,402][model][INFO] - Training step 8160 loss 0.012149076908826828
[2025-03-15 19:19:27,347][model][INFO] - Training step 8320 loss 0.005559183657169342
[2025-03-15 19:20:06,941][model][INFO] - Training step 8480 loss 0.1814945936203003
[2025-03-15 19:20:47,347][model][INFO] - Training step 8640 loss 0.028567219153046608
[2025-03-15 19:21:28,964][model][INFO] - Training step 8800 loss 0.019836101680994034
[2025-03-15 19:22:08,649][model][INFO] - Training step 8960 loss 0.0381302535533905
[2025-03-15 19:22:48,500][model][INFO] - Training step 9120 loss 0.24474716186523438
[2025-03-15 19:23:29,108][model][INFO] - Training step 9280 loss 0.0294648464769125
[2025-03-15 19:24:09,486][model][INFO] - Training step 9440 loss 0.09956694394350052
[2025-03-15 19:24:50,109][model][INFO] - Training step 9600 loss 0.01587563380599022
[2025-03-15 19:25:30,808][model][INFO] - Training step 9760 loss 0.028891978785395622
[2025-03-15 19:26:12,464][model][INFO] - Training step 9920 loss 0.014494694769382477
[2025-03-15 19:26:53,674][model][INFO] - Training step 10080 loss 0.25449806451797485
[2025-03-15 19:27:33,297][model][INFO] - Training step 10240 loss 0.013165673241019249
[2025-03-15 19:28:14,339][model][INFO] - Training step 10400 loss 0.042252734303474426
[2025-03-15 19:28:56,590][model][INFO] - Training step 10560 loss 0.8925867080688477
[2025-03-15 19:29:37,409][model][INFO] - Training step 10720 loss 0.01969209685921669
[2025-03-15 19:30:18,630][model][INFO] - Training step 10880 loss 0.033446215093135834
[2025-03-15 19:31:00,169][model][INFO] - Training step 11040 loss 0.02301989123225212
[2025-03-15 19:31:40,211][model][INFO] - Training step 11200 loss 0.02038407325744629
[2025-03-15 19:32:21,920][model][INFO] - Training step 11360 loss 0.2405063509941101
[2025-03-15 19:33:02,463][model][INFO] - Training step 11520 loss 0.020164186134934425
[2025-03-15 19:33:43,180][model][INFO] - Training step 11680 loss 0.0020369028206914663
[2025-03-15 19:34:24,083][model][INFO] - Training step 11840 loss 0.24160078167915344
[2025-03-15 19:35:03,686][model][INFO] - Training step 12000 loss 0.24133020639419556
[2025-03-15 19:35:44,395][model][INFO] - Training step 12160 loss 0.047018468379974365
[2025-03-15 19:36:22,868][model][INFO] - Training step 12320 loss 0.13144923746585846
[2025-03-15 19:37:02,390][model][INFO] - Training step 12480 loss 0.04191591590642929
[2025-03-15 19:37:42,513][model][INFO] - Training step 12640 loss 0.032382622361183167
[2025-03-15 19:38:22,912][model][INFO] - Training step 12800 loss 0.01993381604552269
[2025-03-15 19:39:05,321][model][INFO] - Training step 12960 loss 0.014016404747962952
[2025-03-15 19:39:45,080][model][INFO] - Training step 13120 loss 0.24810698628425598
[2025-03-15 19:40:26,122][model][INFO] - Training step 13280 loss 0.005641248542815447
[2025-03-15 19:41:05,484][model][INFO] - Training step 13440 loss 0.008227156475186348
[2025-03-15 19:41:45,506][model][INFO] - Training step 13600 loss 0.02149350941181183
[2025-03-15 19:42:27,520][model][INFO] - Training step 13760 loss 0.009848954156041145
[2025-03-15 19:43:07,668][model][INFO] - Training step 13920 loss 0.2739975154399872
[2025-03-15 19:43:49,164][model][INFO] - Training step 14080 loss 0.04789705574512482
[2025-03-15 19:44:27,982][model][INFO] - Training step 14240 loss 0.06677970290184021
[2025-03-15 19:45:07,466][model][INFO] - Training step 14400 loss 0.007484397850930691
[2025-03-15 19:45:47,413][model][INFO] - Training step 14560 loss 0.02070469968020916
[2025-03-15 19:46:27,861][model][INFO] - Training step 14720 loss 0.015280703082680702
[2025-03-15 19:47:08,745][model][INFO] - Training step 14880 loss 0.0020136067178100348
[2025-03-15 19:47:50,258][model][INFO] - Training step 15040 loss 0.341239333152771
[2025-03-15 19:48:31,281][model][INFO] - Training step 15200 loss 0.028201241046190262
[2025-03-15 19:49:10,734][model][INFO] - Training step 15360 loss 0.008424783125519753
[2025-03-15 19:49:51,302][model][INFO] - Training step 15520 loss 0.019777920097112656
[2025-03-15 19:50:32,153][model][INFO] - Training step 15680 loss 0.10024784505367279
[2025-03-15 19:51:13,689][model][INFO] - Training step 15840 loss 0.04653964936733246
[2025-03-15 19:51:54,303][model][INFO] - Training step 16000 loss 0.01734253764152527
[2025-03-15 19:52:34,129][model][INFO] - Training step 16160 loss 0.06050308048725128
[2025-03-15 19:53:14,560][model][INFO] - Training step 16320 loss 0.028096895664930344
[2025-03-15 19:53:54,386][model][INFO] - Training step 16480 loss 0.016422931104898453
[2025-03-15 19:54:35,550][model][INFO] - Training step 16640 loss 0.0067427027970552444
[2025-03-15 19:55:15,953][model][INFO] - Training step 16800 loss 0.2689869701862335
[2025-03-15 19:55:56,435][model][INFO] - Training step 16960 loss 0.02730516903102398
[2025-03-15 19:56:36,630][model][INFO] - Training step 17120 loss 0.02820238657295704
[2025-03-15 19:57:16,438][model][INFO] - Training step 17280 loss 0.01971968077123165
[2025-03-15 19:57:56,487][model][INFO] - Training step 17440 loss 0.1508573293685913
[2025-03-15 19:58:37,991][model][INFO] - Training step 17600 loss 0.02733597159385681
[2025-03-15 19:59:21,178][model][INFO] - Training step 17760 loss 0.0025496867019683123
[2025-03-15 20:00:02,044][model][INFO] - Training step 17920 loss 0.05423535779118538
[2025-03-15 20:00:42,478][model][INFO] - Training step 18080 loss 0.027607392519712448
[2025-03-15 20:01:22,717][model][INFO] - Training step 18240 loss 0.044620003551244736
[2025-03-15 20:02:03,263][model][INFO] - Training step 18400 loss 0.03125089779496193
[2025-03-15 20:02:44,222][model][INFO] - Training step 18560 loss 0.017995359376072884
[2025-03-15 20:03:25,443][model][INFO] - Training step 18720 loss 0.0713152140378952
[2025-03-15 20:04:07,905][model][INFO] - Training step 18880 loss 0.02588997781276703
[2025-03-15 20:04:47,256][model][INFO] - Training step 19040 loss 0.06339821964502335
[2025-03-15 20:05:27,972][model][INFO] - Training step 19200 loss 0.027166930958628654
[2025-03-15 20:06:07,736][model][INFO] - Training step 19360 loss 0.0019272782374173403
[2025-03-15 20:06:49,548][model][INFO] - Training step 19520 loss 0.21722003817558289
[2025-03-15 20:07:31,363][model][INFO] - Training step 19680 loss 0.043441567569971085
[2025-03-15 20:08:10,220][model][INFO] - Training step 19840 loss 0.03217951953411102
[2025-03-15 20:08:51,850][model][INFO] - Training step 20000 loss 0.23340335488319397
[2025-03-15 20:09:31,860][model][INFO] - Training step 20160 loss 0.25079798698425293
[2025-03-15 20:10:13,070][model][INFO] - Training step 20320 loss 0.030399680137634277
[2025-03-15 20:10:53,579][model][INFO] - Training step 20480 loss 0.02988973818719387
[2025-03-15 20:11:35,006][model][INFO] - Training step 20640 loss 0.02370411530137062
[2025-03-15 20:12:15,505][model][INFO] - Training step 20800 loss 0.03332195430994034
[2025-03-15 20:12:56,730][model][INFO] - Training step 20960 loss 0.03611191362142563
[2025-03-15 20:13:38,650][model][INFO] - Training step 21120 loss 0.008117405697703362
[2025-03-15 20:14:20,766][model][INFO] - Training step 21280 loss 0.2516224980354309
[2025-03-15 20:15:01,387][model][INFO] - Training step 21440 loss 0.008398834615945816
[2025-03-15 20:15:42,256][model][INFO] - Training step 21600 loss 0.061767883598804474
[2025-03-15 20:16:23,031][model][INFO] - Training step 21760 loss 0.024573031812906265
[2025-03-15 20:17:03,593][model][INFO] - Training step 21920 loss 0.01674344204366207
[2025-03-15 20:17:43,691][model][INFO] - Training step 22080 loss 0.05540357530117035
[2025-03-15 20:18:24,821][model][INFO] - Training step 22240 loss 0.07010605931282043
[2025-03-15 20:19:05,439][model][INFO] - Training step 22400 loss 0.02413134276866913
[2025-03-15 20:19:45,253][model][INFO] - Training step 22560 loss 0.005744989030063152
[2025-03-15 20:20:25,081][model][INFO] - Training step 22720 loss 0.014926780946552753
[2025-03-15 20:21:03,978][model][INFO] - Training step 22880 loss 0.014525903388857841
[2025-03-15 20:21:44,972][model][INFO] - Training step 23040 loss 0.24935466051101685
[2025-03-15 20:22:26,245][model][INFO] - Training step 23200 loss 0.03888847678899765
[2025-03-15 20:23:08,055][model][INFO] - Training step 23360 loss 0.034388042986392975
[2025-03-15 20:23:48,696][model][INFO] - Training step 23520 loss 0.25261637568473816
[2025-03-15 20:24:28,946][model][INFO] - Training step 23680 loss 0.258392870426178
[2025-03-15 20:25:09,187][model][INFO] - Training step 23840 loss 0.24130865931510925
[2025-03-15 20:25:49,882][model][INFO] - Training step 24000 loss 0.021401019766926765
[2025-03-15 20:26:29,854][model][INFO] - Training step 24160 loss 0.02436428889632225
[2025-03-15 20:27:10,090][model][INFO] - Training step 24320 loss 0.021722860634326935
[2025-03-15 20:27:51,025][model][INFO] - Training step 24480 loss 0.004446026869118214
[2025-03-15 20:28:32,441][model][INFO] - Training step 24640 loss 0.04145921766757965
[2025-03-15 20:29:12,689][model][INFO] - Training step 24800 loss 0.045462287962436676
[2025-03-15 20:29:53,994][model][INFO] - Training step 24960 loss 0.2701990604400635
[2025-03-15 20:30:34,888][model][INFO] - Training step 25120 loss 0.14109450578689575
[2025-03-15 20:31:14,047][model][INFO] - Training step 25280 loss 0.01626356691122055
[2025-03-15 20:31:56,124][model][INFO] - Training step 25440 loss 0.017760291695594788
[2025-03-15 20:32:36,912][model][INFO] - Training step 25600 loss 0.062855064868927
[2025-03-15 20:33:17,140][model][INFO] - Training step 25760 loss 0.04388909786939621
[2025-03-15 20:33:58,680][model][INFO] - Training step 25920 loss 0.02457316219806671
[2025-03-15 20:34:39,524][model][INFO] - Training step 26080 loss 0.017655469477176666
[2025-03-15 20:35:19,943][model][INFO] - Training step 26240 loss 0.10345950722694397
[2025-03-15 20:36:00,999][model][INFO] - Training step 26400 loss 0.24780496954917908
[2025-03-15 20:36:41,410][model][INFO] - Training step 26560 loss 0.25506240129470825
[2025-03-15 20:37:22,254][model][INFO] - Training step 26720 loss 0.23707884550094604
[2025-03-15 20:38:02,641][model][INFO] - Training step 26880 loss 0.025200216099619865
[2025-03-15 20:38:43,654][model][INFO] - Training step 27040 loss 0.03141990303993225
[2025-03-15 20:39:24,614][model][INFO] - Training step 27200 loss 0.006122192833572626
[2025-03-15 20:40:05,854][model][INFO] - Training step 27360 loss 0.027222100645303726
[2025-03-15 20:40:47,428][model][INFO] - Training step 27520 loss 0.032308533787727356
[2025-03-15 20:41:27,047][model][INFO] - Training step 27680 loss 0.07956025749444962
[2025-03-15 20:42:08,572][model][INFO] - Training step 27840 loss 0.020050030201673508
[2025-03-15 20:42:48,947][model][INFO] - Training step 28000 loss 0.01726703532040119
[2025-03-15 20:43:30,622][model][INFO] - Training step 28160 loss 0.020633354783058167
[2025-03-15 20:44:11,091][model][INFO] - Training step 28320 loss 0.02370826154947281
[2025-03-15 20:44:51,716][model][INFO] - Training step 28480 loss 0.03499998897314072
[2025-03-15 20:45:33,489][model][INFO] - Training step 28640 loss 0.005839739926159382
[2025-03-15 20:46:14,482][model][INFO] - Training step 28800 loss 0.04650347679853439
[2025-03-15 20:46:55,917][model][INFO] - Training step 28960 loss 0.2558016777038574
[2025-03-15 20:47:36,837][model][INFO] - Training step 29120 loss 0.032917723059654236
[2025-03-15 20:48:20,193][model][INFO] - Training step 29280 loss 0.03648991137742996
[2025-03-15 20:48:59,624][model][INFO] - Training step 29440 loss 0.31763747334480286
[2025-03-15 20:49:40,665][model][INFO] - Training step 29600 loss 0.08195540308952332
[2025-03-15 20:50:21,027][model][INFO] - Training step 29760 loss 0.252838671207428
[2025-03-15 20:51:02,962][model][INFO] - Training step 29920 loss 0.02400893345475197
[2025-03-15 20:51:43,521][model][INFO] - Training step 30080 loss 0.014336585998535156
[2025-03-15 20:52:22,688][model][INFO] - Training step 30240 loss 0.02667010948061943
[2025-03-15 20:53:03,908][model][INFO] - Training step 30400 loss 0.028385542333126068
[2025-03-15 20:53:44,486][model][INFO] - Training step 30560 loss 0.017882224172353745
[2025-03-15 20:54:23,764][model][INFO] - Training step 30720 loss 0.010145902633666992
[2025-03-15 20:55:03,134][model][INFO] - Training step 30880 loss 0.025459256023168564
[2025-03-15 20:55:45,183][model][INFO] - Training step 31040 loss 0.021855082362890244
[2025-03-15 20:56:25,572][model][INFO] - Training step 31200 loss 0.0040656025521457195
[2025-03-15 20:57:07,265][model][INFO] - Training step 31360 loss 0.02215060591697693
[2025-03-15 20:57:47,598][model][INFO] - Training step 31520 loss 0.008986257947981358
[2025-03-15 20:58:28,384][model][INFO] - Training step 31680 loss 0.023601919412612915
[2025-03-15 20:59:08,219][model][INFO] - Training step 31840 loss 0.001150917261838913
[2025-03-15 20:59:49,103][model][INFO] - Training step 32000 loss 0.24740858376026154
[2025-03-15 21:00:29,898][model][INFO] - Training step 32160 loss 0.25475767254829407
[2025-03-15 21:01:10,542][model][INFO] - Training step 32320 loss 0.0029374035075306892
[2025-03-15 21:01:50,507][model][INFO] - Training step 32480 loss 0.10093224048614502
[2025-03-15 21:02:31,408][model][INFO] - Training step 32640 loss 0.2424532175064087
[2025-03-15 21:03:12,773][model][INFO] - Training step 32800 loss 0.08325205743312836
[2025-03-15 21:03:54,289][model][INFO] - Training step 32960 loss 0.021896466612815857
[2025-03-15 21:04:33,834][model][INFO] - Training step 33120 loss 0.08332130312919617
[2025-03-15 21:05:14,273][model][INFO] - Training step 33280 loss 0.06708098948001862
[2025-03-15 21:05:56,299][model][INFO] - Training step 33440 loss 0.023564128205180168
[2025-03-15 21:06:37,144][model][INFO] - Training step 33600 loss 0.005263349041342735
[2025-03-15 21:07:18,847][model][INFO] - Training step 33760 loss 0.029097534716129303
[2025-03-15 21:07:59,222][model][INFO] - Training step 33920 loss 0.250968337059021
[2025-03-15 21:08:39,198][model][INFO] - Training step 34080 loss 0.24130570888519287
[2025-03-15 21:09:20,222][model][INFO] - Training step 34240 loss 0.24637028574943542
[2025-03-15 21:10:01,370][model][INFO] - Training step 34400 loss 0.23551082611083984
[2025-03-15 21:10:42,443][model][INFO] - Training step 34560 loss 0.025200286880135536
[2025-03-15 21:11:23,772][model][INFO] - Training step 34720 loss 0.016365809366106987
[2025-03-15 21:12:04,163][model][INFO] - Training step 34880 loss 0.0036726382095366716
[2025-03-15 21:12:45,716][model][INFO] - Training step 35040 loss 0.025218229740858078
[2025-03-15 21:13:26,019][model][INFO] - Training step 35200 loss 0.002995688235387206
[2025-03-15 21:14:07,030][model][INFO] - Training step 35360 loss 0.24981698393821716
[2025-03-15 21:14:47,295][model][INFO] - Training step 35520 loss 0.019178131595253944
[2025-03-15 21:15:27,255][model][INFO] - Training step 35680 loss 0.038070522248744965
[2025-03-15 21:16:06,546][model][INFO] - Training step 35840 loss 0.015242786146700382
[2025-03-15 21:16:47,534][model][INFO] - Training step 36000 loss 0.025041934102773666
[2025-03-15 21:17:27,268][model][INFO] - Training step 36160 loss 0.004487602040171623
[2025-03-15 21:18:07,414][model][INFO] - Training step 36320 loss 0.01227470301091671
[2025-03-15 21:18:47,905][model][INFO] - Training step 36480 loss 0.021495528519153595
[2025-03-15 21:19:29,566][model][INFO] - Training step 36640 loss 0.001515876967459917
[2025-03-15 21:20:10,286][model][INFO] - Training step 36800 loss 0.02571748197078705
[2025-03-15 21:20:50,922][model][INFO] - Training step 36960 loss 0.009285069070756435
[2025-03-15 21:21:31,300][model][INFO] - Training step 37120 loss 0.022792667150497437
[2025-03-15 21:22:12,497][model][INFO] - Training step 37280 loss 0.26227080821990967
[2025-03-15 21:22:52,472][model][INFO] - Training step 37440 loss 0.03503848612308502
[2025-03-15 21:23:32,119][model][INFO] - Training step 37600 loss 0.050974275916814804
[2025-03-15 21:24:13,688][model][INFO] - Training step 37760 loss 0.28008589148521423
[2025-03-15 21:24:55,123][model][INFO] - Training step 37920 loss 0.014183558523654938
[2025-03-15 21:25:36,429][model][INFO] - Training step 38080 loss 0.02654923126101494
[2025-03-15 21:26:18,756][model][INFO] - Training step 38240 loss 0.024865925312042236
[2025-03-15 21:26:59,385][model][INFO] - Training step 38400 loss 0.24050083756446838
[2025-03-15 21:27:40,347][model][INFO] - Training step 38560 loss 0.1492888331413269
[2025-03-15 21:28:20,325][model][INFO] - Training step 38720 loss 0.21254561841487885
[2025-03-15 21:29:01,264][model][INFO] - Training step 38880 loss 0.11794592440128326
[2025-03-15 21:29:40,643][model][INFO] - Training step 39040 loss 0.008627288043498993
[2025-03-15 21:30:20,953][model][INFO] - Training step 39200 loss 0.20028142631053925
[2025-03-15 21:31:01,001][model][INFO] - Training step 39360 loss 0.2153526395559311
[2025-03-15 21:31:41,744][model][INFO] - Training step 39520 loss 0.09576810896396637
[2025-03-15 21:32:21,239][model][INFO] - Training step 39680 loss 0.016658559441566467
[2025-03-15 21:33:03,080][model][INFO] - Training step 39840 loss 0.03042219579219818
[2025-03-15 21:33:44,128][model][INFO] - Training step 40000 loss 0.24718371033668518
[2025-03-15 21:34:25,035][model][INFO] - Training step 40160 loss 0.04631207510828972
[2025-03-15 21:35:06,026][model][INFO] - Training step 40320 loss 0.03702691197395325
[2025-03-15 21:35:45,314][model][INFO] - Training step 40480 loss 0.10154320299625397
[2025-03-15 21:36:25,814][model][INFO] - Training step 40640 loss 0.034834593534469604
[2025-03-15 21:37:06,424][model][INFO] - Training step 40800 loss 0.2395528256893158
[2025-03-15 21:37:47,975][model][INFO] - Training step 40960 loss 0.27108341455459595
[2025-03-15 21:38:30,029][model][INFO] - Training step 41120 loss 0.012023098766803741
[2025-03-15 21:39:10,819][model][INFO] - Training step 41280 loss 0.02731739915907383
[2025-03-15 21:39:50,439][model][INFO] - Training step 41440 loss 0.2397560179233551
[2025-03-15 21:40:29,939][model][INFO] - Training step 41600 loss 0.023989509791135788
[2025-03-15 21:41:12,032][model][INFO] - Training step 41760 loss 0.26233774423599243
[2025-03-15 21:41:52,513][model][INFO] - Training step 41920 loss 0.24816635251045227
[2025-03-15 21:42:33,690][model][INFO] - Training step 42080 loss 0.25004589557647705
[2025-03-15 21:43:14,543][model][INFO] - Training step 42240 loss 0.1648646891117096
[2025-03-15 21:43:55,537][model][INFO] - Training step 42400 loss 0.03738526999950409
[2025-03-15 21:44:35,642][model][INFO] - Training step 42560 loss 0.2779022455215454
[2025-03-15 21:45:17,544][model][INFO] - Training step 42720 loss 0.28435760736465454
[2025-03-15 21:45:58,132][model][INFO] - Training step 42880 loss 0.03273759037256241
[2025-03-15 21:46:37,988][model][INFO] - Training step 43040 loss 0.015519902110099792
[2025-03-15 21:47:17,356][model][INFO] - Training step 43200 loss 0.31623655557632446
[2025-03-15 21:47:58,357][model][INFO] - Training step 43360 loss 0.04066991060972214
[2025-03-15 21:48:37,751][model][INFO] - Training step 43520 loss 0.067867711186409
[2025-03-15 21:49:17,125][model][INFO] - Training step 43680 loss 0.020678628236055374
[2025-03-15 21:49:56,257][model][INFO] - Training step 43840 loss 0.022821586579084396
[2025-03-15 21:50:37,721][model][INFO] - Training step 44000 loss 0.04309388995170593
[2025-03-15 21:51:19,455][model][INFO] - Training step 44160 loss 0.019480882212519646
[2025-03-15 21:51:59,529][model][INFO] - Training step 44320 loss 0.02204037457704544
[2025-03-15 21:52:40,024][model][INFO] - Training step 44480 loss 0.015016552060842514
[2025-03-15 21:53:20,713][model][INFO] - Training step 44640 loss 0.018177013844251633
[2025-03-15 21:54:01,431][model][INFO] - Training step 44800 loss 0.09792806953191757
[2025-03-15 21:54:40,907][model][INFO] - Training step 44960 loss 0.021823886781930923
[2025-03-15 21:55:22,082][model][INFO] - Training step 45120 loss 0.047674402594566345
[2025-03-15 21:56:02,957][model][INFO] - Training step 45280 loss 0.05536060407757759
[2025-03-15 21:56:46,134][model][INFO] - Training step 45440 loss 0.00941263698041439
[2025-03-15 21:57:25,701][model][INFO] - Training step 45600 loss 0.022763779386878014
[2025-03-15 21:58:07,120][model][INFO] - Training step 45760 loss 0.03342243283987045
[2025-03-15 21:58:46,397][model][INFO] - Training step 45920 loss 0.03987923637032509
[2025-03-15 21:59:28,639][model][INFO] - Training step 46080 loss 0.020603805780410767
[2025-03-15 22:00:10,267][model][INFO] - Training step 46240 loss 0.02360915020108223
[2025-03-15 22:00:51,911][model][INFO] - Training step 46400 loss 0.013051901012659073
[2025-03-15 22:01:31,444][model][INFO] - Training step 46560 loss 0.013477452099323273
[2025-03-15 22:02:13,438][model][INFO] - Training step 46720 loss 0.17444559931755066
[2025-03-15 22:02:53,399][model][INFO] - Training step 46880 loss 0.031721457839012146
[2025-03-15 22:03:34,237][model][INFO] - Training step 47040 loss 0.03437947481870651
[2025-03-15 22:04:14,817][model][INFO] - Training step 47200 loss 0.011622542515397072
[2025-03-15 22:04:54,615][model][INFO] - Training step 47360 loss 0.2543574273586273
[2025-03-15 22:05:33,868][model][INFO] - Training step 47520 loss 0.25361067056655884
[2025-03-15 22:06:14,155][model][INFO] - Training step 47680 loss 0.03079999051988125
[2025-03-15 22:06:55,312][model][INFO] - Training step 47840 loss 0.017078397795557976
[2025-03-15 22:07:35,248][model][INFO] - Training step 48000 loss 0.25508198142051697
[2025-03-15 22:08:16,787][model][INFO] - Training step 48160 loss 0.2766721546649933
[2025-03-15 22:08:57,428][model][INFO] - Training step 48320 loss 0.018569298088550568
[2025-03-15 22:09:37,827][model][INFO] - Training step 48480 loss 0.014527278952300549
[2025-03-15 22:10:18,160][model][INFO] - Training step 48640 loss 0.026184145361185074
[2025-03-15 22:10:58,706][model][INFO] - Training step 48800 loss 0.024759292602539062
[2025-03-15 22:11:39,359][model][INFO] - Training step 48960 loss 0.25075459480285645
[2025-03-15 22:12:19,737][model][INFO] - Training step 49120 loss 0.003967937082052231
[2025-03-15 22:13:01,579][model][INFO] - Training step 49280 loss 0.0037588102277368307
[2025-03-15 22:13:41,379][model][INFO] - Training step 49440 loss 0.021627582609653473
[2025-03-15 22:14:22,541][model][INFO] - Training step 49600 loss 0.04817403107881546
[2025-03-15 22:15:03,873][model][INFO] - Training step 49760 loss 0.040428996086120605
[2025-03-15 22:15:43,849][model][INFO] - Training step 49920 loss 0.014322565868496895
[2025-03-15 22:16:24,793][model][INFO] - Training step 50080 loss 0.015552589669823647
[2025-03-15 22:17:05,913][model][INFO] - Training step 50240 loss 0.009023066610097885
[2025-03-15 22:17:45,960][model][INFO] - Training step 50400 loss 0.021989209577441216
[2025-03-15 22:18:26,844][model][INFO] - Training step 50560 loss 0.02347741276025772
[2025-03-15 22:19:06,869][model][INFO] - Training step 50720 loss 0.022008132189512253
[2025-03-15 22:24:51,889][model][INFO] - Training step 80 loss 0.2566746473312378
[2025-03-15 22:25:33,336][model][INFO] - Training step 240 loss 0.0030707810074090958
[2025-03-15 22:26:14,245][model][INFO] - Training step 400 loss 0.05072872340679169
[2025-03-15 22:26:54,605][model][INFO] - Training step 560 loss 0.018051166087388992
[2025-03-15 22:27:35,351][model][INFO] - Training step 720 loss 0.04017570614814758
[2025-03-15 22:28:15,519][model][INFO] - Training step 880 loss 0.024728041142225266
[2025-03-15 22:28:55,186][model][INFO] - Training step 1040 loss 0.04920679330825806
[2025-03-15 22:29:34,403][model][INFO] - Training step 1200 loss 0.026015736162662506
[2025-03-15 22:30:15,680][model][INFO] - Training step 1360 loss 0.02363620139658451
[2025-03-15 22:30:55,258][model][INFO] - Training step 1520 loss 0.032629337161779404
[2025-03-15 22:31:35,326][model][INFO] - Training step 1680 loss 0.01689816638827324
[2025-03-15 22:32:14,941][model][INFO] - Training step 1840 loss 0.02916666865348816
[2025-03-15 22:32:55,326][model][INFO] - Training step 2000 loss 0.03566274791955948
[2025-03-15 22:33:35,650][model][INFO] - Training step 2160 loss 0.04026450961828232
[2025-03-15 22:34:14,362][model][INFO] - Training step 2320 loss 0.01976720616221428
[2025-03-15 22:34:55,379][model][INFO] - Training step 2480 loss 0.01935717649757862
[2025-03-15 22:35:36,047][model][INFO] - Training step 2640 loss 0.022650301456451416
[2025-03-15 22:36:16,186][model][INFO] - Training step 2800 loss 0.0312286838889122
[2025-03-15 22:36:57,184][model][INFO] - Training step 2960 loss 0.024146094918251038
[2025-03-15 22:37:37,907][model][INFO] - Training step 3120 loss 0.004740381613373756
[2025-03-15 22:38:19,349][model][INFO] - Training step 3280 loss 0.011082072742283344
[2025-03-15 22:39:01,072][model][INFO] - Training step 3440 loss 0.003252108348533511
[2025-03-15 22:39:39,814][model][INFO] - Training step 3600 loss 0.01716742105782032
[2025-03-15 22:40:22,347][model][INFO] - Training step 3760 loss 0.01922624371945858
[2025-03-15 22:41:02,849][model][INFO] - Training step 3920 loss 0.014169787988066673
[2025-03-15 22:41:44,053][model][INFO] - Training step 4080 loss 0.024881547316908836
[2025-03-15 22:42:24,875][model][INFO] - Training step 4240 loss 0.2508200407028198
[2025-03-15 22:43:04,391][model][INFO] - Training step 4400 loss 0.25434526801109314
[2025-03-15 22:43:46,145][model][INFO] - Training step 4560 loss 0.026712961494922638
[2025-03-15 22:44:27,724][model][INFO] - Training step 4720 loss 0.021248340606689453
[2025-03-15 22:45:09,724][model][INFO] - Training step 4880 loss 0.006722080521285534
[2025-03-15 22:45:50,733][model][INFO] - Training step 5040 loss 0.08168485760688782
[2025-03-15 22:46:30,838][model][INFO] - Training step 5200 loss 0.11548170447349548
[2025-03-15 22:47:11,787][model][INFO] - Training step 5360 loss 0.03732983395457268
[2025-03-15 22:47:53,457][model][INFO] - Training step 5520 loss 0.2889383137226105
[2025-03-15 22:48:33,297][model][INFO] - Training step 5680 loss 0.01763501763343811
[2025-03-15 22:49:14,082][model][INFO] - Training step 5840 loss 0.017687471583485603
[2025-03-15 22:49:55,641][model][INFO] - Training step 6000 loss 0.02988315559923649
[2025-03-15 22:50:36,467][model][INFO] - Training step 6160 loss 0.02197597548365593
[2025-03-15 22:51:16,315][model][INFO] - Training step 6320 loss 0.02497417852282524
[2025-03-15 22:51:56,806][model][INFO] - Training step 6480 loss 0.004255006555467844
[2025-03-15 22:52:38,144][model][INFO] - Training step 6640 loss 0.00539486575871706
[2025-03-15 22:53:19,250][model][INFO] - Training step 6800 loss 0.006356151774525642
[2025-03-15 22:54:00,492][model][INFO] - Training step 6960 loss 0.07058548927307129
[2025-03-15 22:54:41,530][model][INFO] - Training step 7120 loss 0.043042100965976715
[2025-03-15 22:55:22,221][model][INFO] - Training step 7280 loss 0.07775235921144485
[2025-03-15 22:56:03,060][model][INFO] - Training step 7440 loss 0.10323245078325272
[2025-03-15 22:56:43,764][model][INFO] - Training step 7600 loss 0.03055902197957039
[2025-03-15 22:57:25,268][model][INFO] - Training step 7760 loss 0.23078909516334534
[2025-03-15 22:58:06,087][model][INFO] - Training step 7920 loss 0.08290297538042068
[2025-03-15 22:58:46,737][model][INFO] - Training step 8080 loss 0.03066614270210266
[2025-03-15 22:59:27,586][model][INFO] - Training step 8240 loss 0.26815542578697205
[2025-03-15 23:00:07,970][model][INFO] - Training step 8400 loss 0.0034255231730639935
[2025-03-15 23:00:48,990][model][INFO] - Training step 8560 loss 0.2581620216369629
[2025-03-15 23:01:29,092][model][INFO] - Training step 8720 loss 0.02120627835392952
[2025-03-15 23:02:08,844][model][INFO] - Training step 8880 loss 0.01471758633852005
[2025-03-15 23:02:47,864][model][INFO] - Training step 9040 loss 0.025962702929973602
[2025-03-15 23:03:26,839][model][INFO] - Training step 9200 loss 0.26613765954971313
[2025-03-15 23:04:07,757][model][INFO] - Training step 9360 loss 0.023712322115898132
[2025-03-15 23:04:47,402][model][INFO] - Training step 9520 loss 0.018541179597377777
[2025-03-15 23:05:27,471][model][INFO] - Training step 9680 loss 0.035338394343853
[2025-03-15 23:06:06,946][model][INFO] - Training step 9840 loss 0.04001154005527496
[2025-03-15 23:06:48,958][model][INFO] - Training step 10000 loss 0.013637460768222809
[2025-03-15 23:07:30,199][model][INFO] - Training step 10160 loss 0.08460874110460281
[2025-03-15 23:08:09,145][model][INFO] - Training step 10320 loss 0.2759104371070862
[2025-03-15 23:08:50,102][model][INFO] - Training step 10480 loss 0.2479473203420639
[2025-03-15 23:09:29,970][model][INFO] - Training step 10640 loss 0.27991098165512085
[2025-03-15 23:10:11,362][model][INFO] - Training step 10800 loss 0.029467523097991943
[2025-03-15 23:10:51,780][model][INFO] - Training step 10960 loss 0.08906973898410797
[2025-03-15 23:11:31,605][model][INFO] - Training step 11120 loss 0.2399885654449463
[2025-03-15 23:12:12,060][model][INFO] - Training step 11280 loss 0.03398110717535019
[2025-03-15 23:12:52,893][model][INFO] - Training step 11440 loss 0.02301819995045662
[2025-03-15 23:13:32,729][model][INFO] - Training step 11600 loss 0.24590054154396057
[2025-03-15 23:14:13,955][model][INFO] - Training step 11760 loss 0.03461553901433945
[2025-03-15 23:14:54,066][model][INFO] - Training step 11920 loss 0.045076459646224976
[2025-03-15 23:15:36,340][model][INFO] - Training step 12080 loss 0.09647568315267563
[2025-03-15 23:16:16,278][model][INFO] - Training step 12240 loss 0.01083221472799778
[2025-03-15 23:16:55,213][model][INFO] - Training step 12400 loss 0.025493942201137543
[2025-03-15 23:17:36,065][model][INFO] - Training step 12560 loss 0.005607828963547945
[2025-03-15 23:18:15,732][model][INFO] - Training step 12720 loss 0.0050426060333848
[2025-03-15 23:18:54,892][model][INFO] - Training step 12880 loss 0.01560171041637659
[2025-03-15 23:19:34,386][model][INFO] - Training step 13040 loss 0.023924391716718674
[2025-03-15 23:20:15,534][model][INFO] - Training step 13200 loss 0.029295749962329865
[2025-03-15 23:20:56,256][model][INFO] - Training step 13360 loss 0.07356147468090057
[2025-03-15 23:21:37,033][model][INFO] - Training step 13520 loss 0.00986484531313181
[2025-03-15 23:22:16,948][model][INFO] - Training step 13680 loss 0.013620257377624512
[2025-03-15 23:22:58,123][model][INFO] - Training step 13840 loss 0.02269940823316574
[2025-03-15 23:23:38,386][model][INFO] - Training step 14000 loss 0.018448710441589355
[2025-03-15 23:24:19,253][model][INFO] - Training step 14160 loss 0.022693060338497162
[2025-03-15 23:25:00,489][model][INFO] - Training step 14320 loss 0.03511936962604523
[2025-03-15 23:25:41,043][model][INFO] - Training step 14480 loss 0.23494771122932434
[2025-03-15 23:26:22,162][model][INFO] - Training step 14640 loss 0.01632777974009514
[2025-03-15 23:27:03,075][model][INFO] - Training step 14800 loss 0.2582778036594391
[2025-03-15 23:27:44,101][model][INFO] - Training step 14960 loss 0.016149748116731644
[2025-03-15 23:28:24,738][model][INFO] - Training step 15120 loss 0.021338988095521927
[2025-03-15 23:29:04,111][model][INFO] - Training step 15280 loss 0.026389896869659424
[2025-03-15 23:29:45,191][model][INFO] - Training step 15440 loss 0.01201845332980156
[2025-03-15 23:30:24,651][model][INFO] - Training step 15600 loss 0.07924245297908783
[2025-03-15 23:31:06,668][model][INFO] - Training step 15760 loss 0.059749484062194824
[2025-03-15 23:31:47,338][model][INFO] - Training step 15920 loss 0.026889853179454803
[2025-03-15 23:32:26,143][model][INFO] - Training step 16080 loss 0.014703799039125443
[2025-03-15 23:33:07,124][model][INFO] - Training step 16240 loss 0.24315312504768372
[2025-03-15 23:33:48,216][model][INFO] - Training step 16400 loss 0.046759456396102905
[2025-03-15 23:34:29,985][model][INFO] - Training step 16560 loss 0.07527615129947662
[2025-03-15 23:35:10,541][model][INFO] - Training step 16720 loss 0.001435058075003326
[2025-03-15 23:35:51,984][model][INFO] - Training step 16880 loss 0.1407199203968048
[2025-03-15 23:36:33,313][model][INFO] - Training step 17040 loss 2.996095895767212
[2025-03-15 23:37:13,652][model][INFO] - Training step 17200 loss 0.26540225744247437
[2025-03-15 23:37:53,172][model][INFO] - Training step 17360 loss 0.2634599804878235
[2025-03-15 23:38:34,677][model][INFO] - Training step 17520 loss 0.04338613897562027
[2025-03-15 23:39:14,801][model][INFO] - Training step 17680 loss 0.023369230329990387
[2025-03-15 23:39:54,005][model][INFO] - Training step 17840 loss 0.14141543209552765
[2025-03-15 23:40:32,568][model][INFO] - Training step 18000 loss 0.033926233649253845
[2025-03-15 23:41:14,399][model][INFO] - Training step 18160 loss 0.2639412581920624
[2025-03-15 23:41:54,980][model][INFO] - Training step 18320 loss 0.025196395814418793
[2025-03-15 23:42:36,266][model][INFO] - Training step 18480 loss 0.027323679998517036
[2025-03-15 23:43:17,755][model][INFO] - Training step 18640 loss 0.02542760595679283
[2025-03-15 23:43:59,236][model][INFO] - Training step 18800 loss 0.005057870876044035
[2025-03-15 23:44:40,325][model][INFO] - Training step 18960 loss 0.2716028392314911
[2025-03-15 23:45:20,794][model][INFO] - Training step 19120 loss 0.21589963138103485
[2025-03-15 23:46:01,804][model][INFO] - Training step 19280 loss 0.03209604322910309
[2025-03-15 23:46:42,603][model][INFO] - Training step 19440 loss 0.20832741260528564
[2025-03-15 23:47:23,650][model][INFO] - Training step 19600 loss 0.03200908750295639
[2025-03-15 23:48:01,958][model][INFO] - Training step 19760 loss 0.024551741778850555
[2025-03-15 23:48:41,657][model][INFO] - Training step 19920 loss 0.07177016139030457
[2025-03-15 23:49:23,795][model][INFO] - Training step 20080 loss 0.04009982943534851
[2025-03-15 23:50:03,237][model][INFO] - Training step 20240 loss 0.018625468015670776
[2025-03-15 23:50:43,607][model][INFO] - Training step 20400 loss 0.04611114412546158
[2025-03-15 23:51:24,283][model][INFO] - Training step 20560 loss 0.03895382210612297
[2025-03-15 23:52:07,098][model][INFO] - Training step 20720 loss 0.0026907003484666348
[2025-03-15 23:52:47,050][model][INFO] - Training step 20880 loss 0.07963144779205322
[2025-03-15 23:53:27,698][model][INFO] - Training step 21040 loss 0.026362305507063866
[2025-03-15 23:54:07,886][model][INFO] - Training step 21200 loss 0.021351590752601624
[2025-03-15 23:54:47,762][model][INFO] - Training step 21360 loss 0.05631027743220329
[2025-03-15 23:55:27,179][model][INFO] - Training step 21520 loss 0.2422933578491211
[2025-03-15 23:56:06,579][model][INFO] - Training step 21680 loss 0.22858497500419617
[2025-03-15 23:56:47,209][model][INFO] - Training step 21840 loss 0.04573047161102295
[2025-03-15 23:57:26,851][model][INFO] - Training step 22000 loss 0.2304077446460724
[2025-03-15 23:58:07,152][model][INFO] - Training step 22160 loss 0.04202301427721977
[2025-03-15 23:58:48,222][model][INFO] - Training step 22320 loss 0.02997349575161934
[2025-03-15 23:59:30,973][model][INFO] - Training step 22480 loss 0.009581060148775578
[2025-03-16 00:00:10,458][model][INFO] - Training step 22640 loss 0.012325037270784378
[2025-03-16 00:00:51,132][model][INFO] - Training step 22800 loss 0.02950659766793251
[2025-03-16 00:01:31,393][model][INFO] - Training step 22960 loss 0.017131423577666283
[2025-03-16 00:02:10,526][model][INFO] - Training step 23120 loss 0.023027662187814713
[2025-03-16 00:02:52,288][model][INFO] - Training step 23280 loss 0.02479126863181591
[2025-03-16 00:03:32,189][model][INFO] - Training step 23440 loss 0.24855168163776398
[2025-03-16 00:04:12,958][model][INFO] - Training step 23600 loss 0.04004993662238121
[2025-03-16 00:04:54,185][model][INFO] - Training step 23760 loss 0.04315114766359329
[2025-03-16 00:05:35,441][model][INFO] - Training step 23920 loss 0.028412479907274246
[2025-03-16 00:06:16,162][model][INFO] - Training step 24080 loss 0.03417103737592697
[2025-03-16 00:06:56,442][model][INFO] - Training step 24240 loss 0.05056965723633766
[2025-03-16 00:07:37,489][model][INFO] - Training step 24400 loss 0.23358705639839172
[2025-03-16 00:08:18,384][model][INFO] - Training step 24560 loss 0.2402825951576233
[2025-03-16 00:09:00,128][model][INFO] - Training step 24720 loss 0.25083497166633606
[2025-03-16 00:09:42,594][model][INFO] - Training step 24880 loss 0.032010164111852646
[2025-03-16 00:10:23,401][model][INFO] - Training step 25040 loss 0.014863143675029278
[2025-03-16 00:11:02,986][model][INFO] - Training step 25200 loss 0.015385918319225311
[2025-03-16 00:11:42,711][model][INFO] - Training step 25360 loss 0.03059106133878231
[2025-03-16 00:12:22,335][model][INFO] - Training step 25520 loss 0.05343768000602722
[2025-03-16 00:13:04,320][model][INFO] - Training step 25680 loss 0.08832062780857086
[2025-03-16 00:13:43,830][model][INFO] - Training step 25840 loss 0.037620652467012405
[2025-03-16 00:14:23,617][model][INFO] - Training step 26000 loss 0.04933852329850197
[2025-03-16 00:15:03,704][model][INFO] - Training step 26160 loss 0.026129528880119324
[2025-03-16 00:15:46,948][model][INFO] - Training step 26320 loss 0.24784860014915466
[2025-03-16 00:16:28,717][model][INFO] - Training step 26480 loss 0.24726766347885132
[2025-03-16 00:17:10,092][model][INFO] - Training step 26640 loss 0.025028757750988007
[2025-03-16 00:17:50,904][model][INFO] - Training step 26800 loss 0.03106994554400444
[2025-03-16 00:18:31,245][model][INFO] - Training step 26960 loss 0.023638833314180374
[2025-03-16 00:19:12,241][model][INFO] - Training step 27120 loss 0.1633019596338272
[2025-03-16 00:19:52,865][model][INFO] - Training step 27280 loss 0.038446396589279175
[2025-03-16 00:20:33,388][model][INFO] - Training step 27440 loss 0.03158094361424446
[2025-03-16 00:21:13,365][model][INFO] - Training step 27600 loss 0.04379492998123169
[2025-03-16 00:21:53,361][model][INFO] - Training step 27760 loss 0.08217187225818634
[2025-03-16 00:22:33,347][model][INFO] - Training step 27920 loss 0.01717410609126091
[2025-03-16 00:23:13,935][model][INFO] - Training step 28080 loss 0.03104225918650627
[2025-03-16 00:23:54,703][model][INFO] - Training step 28240 loss 0.05822240561246872
[2025-03-16 00:24:34,949][model][INFO] - Training step 28400 loss 0.05100598186254501
[2025-03-16 00:25:16,606][model][INFO] - Training step 28560 loss 0.26232412457466125
[2025-03-16 00:25:56,074][model][INFO] - Training step 28720 loss 0.011876123026013374
[2025-03-16 00:26:38,448][model][INFO] - Training step 28880 loss 0.009005101397633553
[2025-03-16 00:27:19,175][model][INFO] - Training step 29040 loss 0.12662431597709656
[2025-03-16 00:27:59,917][model][INFO] - Training step 29200 loss 0.034847721457481384
[2025-03-16 00:28:40,599][model][INFO] - Training step 29360 loss 0.0065644048154354095
[2025-03-16 00:29:21,369][model][INFO] - Training step 29520 loss 0.16376107931137085
[2025-03-16 00:30:01,993][model][INFO] - Training step 29680 loss 0.026798464357852936
[2025-03-16 00:30:43,025][model][INFO] - Training step 29840 loss 0.027755800634622574
[2025-03-16 00:31:23,863][model][INFO] - Training step 30000 loss 0.25027570128440857
[2025-03-16 00:32:02,767][model][INFO] - Training step 30160 loss 0.24240005016326904
[2025-03-16 00:32:43,641][model][INFO] - Training step 30320 loss 0.019587822258472443
[2025-03-16 00:33:24,970][model][INFO] - Training step 30480 loss 0.0050892760045826435
[2025-03-16 00:34:03,748][model][INFO] - Training step 30640 loss 0.006798090413212776
[2025-03-16 00:34:44,890][model][INFO] - Training step 30800 loss 0.25280338525772095
[2025-03-16 00:35:25,489][model][INFO] - Training step 30960 loss 0.018740957602858543
[2025-03-16 00:36:05,245][model][INFO] - Training step 31120 loss 0.005682666786015034
[2025-03-16 00:36:45,257][model][INFO] - Training step 31280 loss 0.029104530811309814
[2025-03-16 00:37:25,796][model][INFO] - Training step 31440 loss 0.02686774730682373
[2025-03-16 00:38:05,946][model][INFO] - Training step 31600 loss 0.04588814824819565
[2025-03-16 00:38:46,775][model][INFO] - Training step 31760 loss 0.03803486377000809
[2025-03-16 00:39:27,665][model][INFO] - Training step 31920 loss 0.06105474382638931
[2025-03-16 00:40:08,867][model][INFO] - Training step 32080 loss 0.023822147399187088
[2025-03-16 00:40:49,182][model][INFO] - Training step 32240 loss 0.015515622682869434
[2025-03-16 00:41:30,651][model][INFO] - Training step 32400 loss 0.005351189523935318
[2025-03-16 00:42:11,645][model][INFO] - Training step 32560 loss 0.024117011576890945
[2025-03-16 00:42:52,241][model][INFO] - Training step 32720 loss 0.02217850834131241
[2025-03-16 00:43:33,422][model][INFO] - Training step 32880 loss 0.025578919798135757
[2025-03-16 00:44:12,712][model][INFO] - Training step 33040 loss 0.024031803011894226
[2025-03-16 00:44:52,291][model][INFO] - Training step 33200 loss 0.022882666438817978
[2025-03-16 00:45:33,899][model][INFO] - Training step 33360 loss 0.016632864251732826
[2025-03-16 00:46:13,342][model][INFO] - Training step 33520 loss 0.06168784946203232
[2025-03-16 00:46:53,276][model][INFO] - Training step 33680 loss 0.008479686453938484
[2025-03-16 00:47:32,632][model][INFO] - Training step 33840 loss 0.024484027177095413
[2025-03-16 00:48:13,539][model][INFO] - Training step 34000 loss 0.02433355525135994
[2025-03-16 00:48:54,066][model][INFO] - Training step 34160 loss 0.0785287618637085
[2025-03-16 00:49:34,671][model][INFO] - Training step 34320 loss 0.020107369869947433
[2025-03-16 00:50:15,232][model][INFO] - Training step 34480 loss 0.031383953988552094
[2025-03-16 00:50:56,056][model][INFO] - Training step 34640 loss 0.028333894908428192
[2025-03-16 00:51:36,436][model][INFO] - Training step 34800 loss 0.07232022285461426
[2025-03-16 00:52:18,722][model][INFO] - Training step 34960 loss 0.029689712449908257
[2025-03-16 00:52:58,515][model][INFO] - Training step 35120 loss 0.27281731367111206
[2025-03-16 00:53:39,311][model][INFO] - Training step 35280 loss 0.004090789705514908
[2025-03-16 00:54:21,500][model][INFO] - Training step 35440 loss 0.0058548422530293465
[2025-03-16 00:55:01,207][model][INFO] - Training step 35600 loss 0.03280412405729294
[2025-03-16 00:55:41,441][model][INFO] - Training step 35760 loss 0.01756783202290535
[2025-03-16 00:56:23,092][model][INFO] - Training step 35920 loss 0.2569180727005005
[2025-03-16 00:57:02,521][model][INFO] - Training step 36080 loss 0.12256864458322525
[2025-03-16 00:57:43,349][model][INFO] - Training step 36240 loss 0.0037723027635365725
[2025-03-16 00:58:26,567][model][INFO] - Training step 36400 loss 0.25847503542900085
[2025-03-16 00:59:08,136][model][INFO] - Training step 36560 loss 0.00463077099993825
[2025-03-16 00:59:49,336][model][INFO] - Training step 36720 loss 0.26818931102752686
[2025-03-16 01:00:29,944][model][INFO] - Training step 36880 loss 0.1346173882484436
[2025-03-16 01:01:11,849][model][INFO] - Training step 37040 loss 0.015933766961097717
[2025-03-16 01:01:53,022][model][INFO] - Training step 37200 loss 0.04981480538845062
[2025-03-16 01:02:35,027][model][INFO] - Training step 37360 loss 0.024518895894289017
[2025-03-16 01:03:12,866][model][INFO] - Training step 37520 loss 0.2458135187625885
[2025-03-16 01:03:54,250][model][INFO] - Training step 37680 loss 0.027803685516119003
[2025-03-16 01:04:35,293][model][INFO] - Training step 37840 loss 0.06741698831319809
[2025-03-16 01:05:15,758][model][INFO] - Training step 38000 loss 0.25982654094696045
[2025-03-16 01:05:58,441][model][INFO] - Training step 38160 loss 0.0267772413790226
[2025-03-16 01:06:39,007][model][INFO] - Training step 38320 loss 0.04271933436393738
[2025-03-16 01:07:19,839][model][INFO] - Training step 38480 loss 0.003923288080841303
[2025-03-16 01:07:59,992][model][INFO] - Training step 38640 loss 0.26155585050582886
[2025-03-16 01:08:39,830][model][INFO] - Training step 38800 loss 0.021517205983400345
[2025-03-16 01:09:21,923][model][INFO] - Training step 38960 loss 0.017718615010380745
[2025-03-16 01:10:01,512][model][INFO] - Training step 39120 loss 0.024708935990929604
[2025-03-16 01:10:42,553][model][INFO] - Training step 39280 loss 0.2519672214984894
[2025-03-16 01:11:24,731][model][INFO] - Training step 39440 loss 0.2512925863265991
[2025-03-16 01:12:04,488][model][INFO] - Training step 39600 loss 0.01801532506942749
[2025-03-16 01:12:44,736][model][INFO] - Training step 39760 loss 0.2517915368080139
[2025-03-16 01:13:25,248][model][INFO] - Training step 39920 loss 0.031113391742110252
[2025-03-16 01:14:07,817][model][INFO] - Training step 40080 loss 0.0032575144432485104
[2025-03-16 01:14:48,906][model][INFO] - Training step 40240 loss 0.24143335223197937
[2025-03-16 01:15:30,238][model][INFO] - Training step 40400 loss 0.02455868385732174
[2025-03-16 01:16:11,290][model][INFO] - Training step 40560 loss 0.03190998733043671
[2025-03-16 01:16:52,053][model][INFO] - Training step 40720 loss 0.0015135726425796747
[2025-03-16 01:17:32,482][model][INFO] - Training step 40880 loss 0.015750467777252197
[2025-03-16 01:18:14,307][model][INFO] - Training step 41040 loss 0.2419707179069519
[2025-03-16 01:18:54,701][model][INFO] - Training step 41200 loss 0.013421762734651566
[2025-03-16 01:19:35,934][model][INFO] - Training step 41360 loss 0.011167538352310658
[2025-03-16 01:20:18,281][model][INFO] - Training step 41520 loss 0.03244350850582123
[2025-03-16 01:20:59,376][model][INFO] - Training step 41680 loss 0.0023868833668529987
[2025-03-16 01:21:39,915][model][INFO] - Training step 41840 loss 0.01114188227802515
[2025-03-16 01:22:18,976][model][INFO] - Training step 42000 loss 0.034575119614601135
[2025-03-16 01:22:59,548][model][INFO] - Training step 42160 loss 0.024012885987758636
[2025-03-16 01:23:39,638][model][INFO] - Training step 42320 loss 0.012227021157741547
[2025-03-16 01:24:20,343][model][INFO] - Training step 42480 loss 0.24566391110420227
[2025-03-16 01:25:00,982][model][INFO] - Training step 42640 loss 0.017539605498313904
[2025-03-16 01:25:41,817][model][INFO] - Training step 42800 loss 0.02512715384364128
[2025-03-16 01:26:23,378][model][INFO] - Training step 42960 loss 0.023751530796289444
[2025-03-16 01:27:03,820][model][INFO] - Training step 43120 loss 0.03872976079583168
[2025-03-16 01:27:44,512][model][INFO] - Training step 43280 loss 0.051468417048454285
[2025-03-16 01:28:24,521][model][INFO] - Training step 43440 loss 0.04277533292770386
[2025-03-16 01:29:06,092][model][INFO] - Training step 43600 loss 0.01019327249377966
[2025-03-16 01:29:46,211][model][INFO] - Training step 43760 loss 0.012817835435271263
[2025-03-16 01:30:26,325][model][INFO] - Training step 43920 loss 0.06633350998163223
[2025-03-16 01:31:06,763][model][INFO] - Training step 44080 loss 0.03004143200814724
[2025-03-16 01:31:47,723][model][INFO] - Training step 44240 loss 0.2546607553958893
[2025-03-16 01:32:29,452][model][INFO] - Training step 44400 loss 0.029984407126903534
[2025-03-16 01:33:09,747][model][INFO] - Training step 44560 loss 0.004575203638523817
[2025-03-16 01:33:50,975][model][INFO] - Training step 44720 loss 0.2624841034412384
[2025-03-16 01:34:29,916][model][INFO] - Training step 44880 loss 0.0429016575217247
[2025-03-16 01:35:11,903][model][INFO] - Training step 45040 loss 0.027154427021741867
[2025-03-16 01:35:50,920][model][INFO] - Training step 45200 loss 0.2460935264825821
[2025-03-16 01:36:32,887][model][INFO] - Training step 45360 loss 0.020855486392974854
[2025-03-16 01:37:13,667][model][INFO] - Training step 45520 loss 0.22900527715682983
[2025-03-16 01:37:54,067][model][INFO] - Training step 45680 loss 0.03622004762291908
[2025-03-16 01:38:34,734][model][INFO] - Training step 45840 loss 0.26538169384002686
[2025-03-16 01:39:15,282][model][INFO] - Training step 46000 loss 0.054688479751348495
[2025-03-16 01:39:56,843][model][INFO] - Training step 46160 loss 0.12805120646953583
[2025-03-16 01:40:37,442][model][INFO] - Training step 46320 loss 0.019685717299580574
[2025-03-16 01:41:18,044][model][INFO] - Training step 46480 loss 0.011692358180880547
[2025-03-16 01:41:57,499][model][INFO] - Training step 46640 loss 0.033058248460292816
[2025-03-16 01:42:39,155][model][INFO] - Training step 46800 loss 0.030784334987401962
[2025-03-16 01:43:19,253][model][INFO] - Training step 46960 loss 0.039192862808704376
[2025-03-16 01:43:59,008][model][INFO] - Training step 47120 loss 0.006524472497403622
[2025-03-16 01:44:39,723][model][INFO] - Training step 47280 loss 0.01969025656580925
[2025-03-16 01:45:20,884][model][INFO] - Training step 47440 loss 0.24541547894477844
[2025-03-16 01:46:02,220][model][INFO] - Training step 47600 loss 0.24866750836372375
[2025-03-16 01:46:43,379][model][INFO] - Training step 47760 loss 0.11029041558504105
[2025-03-16 01:47:24,567][model][INFO] - Training step 47920 loss 0.010326707735657692
[2025-03-16 01:48:05,982][model][INFO] - Training step 48080 loss 0.0036024702712893486
[2025-03-16 01:48:46,194][model][INFO] - Training step 48240 loss 0.004501309245824814
[2025-03-16 01:49:26,757][model][INFO] - Training step 48400 loss 0.04889746382832527
[2025-03-16 01:50:07,575][model][INFO] - Training step 48560 loss 0.04239165037870407
[2025-03-16 01:50:48,690][model][INFO] - Training step 48720 loss 0.03691719472408295
[2025-03-16 01:51:30,613][model][INFO] - Training step 48880 loss 0.0062844231724739075
[2025-03-16 01:52:11,813][model][INFO] - Training step 49040 loss 0.06185571849346161
[2025-03-16 01:52:51,526][model][INFO] - Training step 49200 loss 0.011579226702451706
[2025-03-16 01:53:31,202][model][INFO] - Training step 49360 loss 0.02937968075275421
[2025-03-16 01:54:12,481][model][INFO] - Training step 49520 loss 0.03508180379867554
[2025-03-16 01:54:53,396][model][INFO] - Training step 49680 loss 0.00613452959805727
[2025-03-16 01:55:34,962][model][INFO] - Training step 49840 loss 0.00790067482739687
[2025-03-16 01:56:14,046][model][INFO] - Training step 50000 loss 0.02928021177649498
[2025-03-16 01:56:53,997][model][INFO] - Training step 50160 loss 0.05260799452662468
[2025-03-16 01:57:33,846][model][INFO] - Training step 50320 loss 0.0037347027100622654
[2025-03-16 01:58:13,991][model][INFO] - Training step 50480 loss 0.036883458495140076
[2025-03-16 01:58:53,392][model][INFO] - Training step 50640 loss 0.012175407260656357
[2025-03-16 02:04:40,691][model][INFO] - Training step 0 loss 0.004270697012543678
[2025-03-16 02:05:20,600][model][INFO] - Training step 160 loss 0.02946961298584938
[2025-03-16 02:06:01,239][model][INFO] - Training step 320 loss 0.026488494127988815
[2025-03-16 02:06:42,486][model][INFO] - Training step 480 loss 0.24776440858840942
[2025-03-16 02:07:23,793][model][INFO] - Training step 640 loss 0.020583640784025192
[2025-03-16 02:08:04,108][model][INFO] - Training step 800 loss 0.2796185612678528
[2025-03-16 02:08:46,842][model][INFO] - Training step 960 loss 0.24293386936187744
[2025-03-16 02:09:27,154][model][INFO] - Training step 1120 loss 0.23683996498584747
[2025-03-16 02:10:08,696][model][INFO] - Training step 1280 loss 0.013662030920386314
[2025-03-16 02:10:47,890][model][INFO] - Training step 1440 loss 0.1327974498271942
[2025-03-16 02:11:28,694][model][INFO] - Training step 1600 loss 0.03813645988702774
[2025-03-16 02:12:08,886][model][INFO] - Training step 1760 loss 0.023059379309415817
[2025-03-16 02:12:48,793][model][INFO] - Training step 1920 loss 0.016018344089388847
[2025-03-16 02:13:30,418][model][INFO] - Training step 2080 loss 0.02188825234770775
[2025-03-16 02:14:10,519][model][INFO] - Training step 2240 loss 0.006842457689344883
[2025-03-16 02:14:51,234][model][INFO] - Training step 2400 loss 0.018014289438724518
[2025-03-16 02:15:32,880][model][INFO] - Training step 2560 loss 0.15490874648094177
[2025-03-16 02:16:13,544][model][INFO] - Training step 2720 loss 0.01596996560692787
[2025-03-16 02:16:53,679][model][INFO] - Training step 2880 loss 0.24954736232757568
[2025-03-16 02:17:32,779][model][INFO] - Training step 3040 loss 0.023408759385347366
[2025-03-16 02:18:13,949][model][INFO] - Training step 3200 loss 0.019209451973438263
[2025-03-16 02:18:53,990][model][INFO] - Training step 3360 loss 0.25797438621520996
[2025-03-16 02:19:33,815][model][INFO] - Training step 3520 loss 0.025881461799144745
[2025-03-16 02:20:15,561][model][INFO] - Training step 3680 loss 0.02592276781797409
[2025-03-16 02:20:55,436][model][INFO] - Training step 3840 loss 0.023320980370044708
[2025-03-16 02:21:37,289][model][INFO] - Training step 4000 loss 0.25659510493278503
[2025-03-16 02:22:18,841][model][INFO] - Training step 4160 loss 0.256248414516449
[2025-03-16 02:23:00,153][model][INFO] - Training step 4320 loss 0.06394936144351959
[2025-03-16 02:23:41,837][model][INFO] - Training step 4480 loss 0.02291950397193432
[2025-03-16 02:24:22,543][model][INFO] - Training step 4640 loss 0.03681018948554993
[2025-03-16 02:25:02,235][model][INFO] - Training step 4800 loss 0.029129255563020706
[2025-03-16 02:25:41,800][model][INFO] - Training step 4960 loss 0.01133275218307972
[2025-03-16 02:26:23,073][model][INFO] - Training step 5120 loss 0.04086870700120926
[2025-03-16 02:27:02,768][model][INFO] - Training step 5280 loss 0.023869410157203674
[2025-03-16 02:27:42,466][model][INFO] - Training step 5440 loss 0.12648433446884155
[2025-03-16 02:28:21,305][model][INFO] - Training step 5600 loss 0.2660125494003296
[2025-03-16 02:29:01,328][model][INFO] - Training step 5760 loss 0.027944762259721756
[2025-03-16 02:29:43,974][model][INFO] - Training step 5920 loss 0.01827441155910492
[2025-03-16 02:30:24,563][model][INFO] - Training step 6080 loss 0.01706262305378914
[2025-03-16 02:31:04,572][model][INFO] - Training step 6240 loss 0.015543945133686066
[2025-03-16 02:31:46,257][model][INFO] - Training step 6400 loss 0.25881844758987427
[2025-03-16 02:32:26,135][model][INFO] - Training step 6560 loss 0.09216892719268799
[2025-03-16 02:33:06,781][model][INFO] - Training step 6720 loss 0.005832497030496597
[2025-03-16 02:33:48,011][model][INFO] - Training step 6880 loss 0.2609032690525055
[2025-03-16 02:34:28,222][model][INFO] - Training step 7040 loss 0.018296070396900177
[2025-03-16 02:35:09,551][model][INFO] - Training step 7200 loss 0.24578963220119476
[2025-03-16 02:35:49,837][model][INFO] - Training step 7360 loss 0.03243093192577362
[2025-03-16 02:36:29,970][model][INFO] - Training step 7520 loss 0.02819567546248436
[2025-03-16 02:37:10,203][model][INFO] - Training step 7680 loss 0.17337357997894287
[2025-03-16 02:37:50,818][model][INFO] - Training step 7840 loss 0.022930804640054703
[2025-03-16 02:38:31,956][model][INFO] - Training step 8000 loss 0.08427590131759644
[2025-03-16 02:39:11,888][model][INFO] - Training step 8160 loss 0.019245576113462448
[2025-03-16 02:39:52,712][model][INFO] - Training step 8320 loss 0.02117963880300522
[2025-03-16 02:40:33,610][model][INFO] - Training step 8480 loss 0.05176737904548645
[2025-03-16 02:41:15,169][model][INFO] - Training step 8640 loss 0.014323864132165909
[2025-03-16 02:41:54,757][model][INFO] - Training step 8800 loss 0.004109739791601896
[2025-03-16 02:42:35,158][model][INFO] - Training step 8960 loss 0.06131475418806076
[2025-03-16 02:43:15,200][model][INFO] - Training step 9120 loss 0.05452961102128029
[2025-03-16 02:43:55,839][model][INFO] - Training step 9280 loss 0.04033922404050827
[2025-03-16 02:44:35,508][model][INFO] - Training step 9440 loss 0.2457772195339203
[2025-03-16 02:45:14,800][model][INFO] - Training step 9600 loss 0.03180915117263794
[2025-03-16 02:45:56,337][model][INFO] - Training step 9760 loss 0.02292700484395027
[2025-03-16 02:46:36,013][model][INFO] - Training step 9920 loss 0.006177566014230251
[2025-03-16 02:47:17,325][model][INFO] - Training step 10080 loss 0.004283405840396881
[2025-03-16 02:47:58,829][model][INFO] - Training step 10240 loss 0.012500863522291183
[2025-03-16 02:48:39,951][model][INFO] - Training step 10400 loss 0.02446877211332321
[2025-03-16 02:49:20,864][model][INFO] - Training step 10560 loss 0.06805962324142456
[2025-03-16 02:50:01,282][model][INFO] - Training step 10720 loss 0.013811927288770676
[2025-03-16 02:50:42,206][model][INFO] - Training step 10880 loss 0.03270949423313141
[2025-03-16 02:51:22,477][model][INFO] - Training step 11040 loss 0.002723755780607462
[2025-03-16 02:52:03,031][model][INFO] - Training step 11200 loss 0.020975157618522644
[2025-03-16 02:52:42,545][model][INFO] - Training step 11360 loss 0.0221584290266037
[2025-03-16 02:53:22,695][model][INFO] - Training step 11520 loss 0.004081905819475651
[2025-03-16 02:54:04,149][model][INFO] - Training step 11680 loss 0.06295741349458694
[2025-03-16 02:54:45,561][model][INFO] - Training step 11840 loss 0.043647248297929764
[2025-03-16 02:55:25,411][model][INFO] - Training step 12000 loss 0.028964713215827942
[2025-03-16 02:56:06,931][model][INFO] - Training step 12160 loss 0.025764688849449158
[2025-03-16 02:56:46,580][model][INFO] - Training step 12320 loss 0.248604416847229
[2025-03-16 02:57:27,435][model][INFO] - Training step 12480 loss 0.026992633938789368
[2025-03-16 02:58:07,761][model][INFO] - Training step 12640 loss 0.006403182167559862
[2025-03-16 02:58:48,255][model][INFO] - Training step 12800 loss 0.07224895060062408
[2025-03-16 02:59:29,409][model][INFO] - Training step 12960 loss 0.024243280291557312
[2025-03-16 03:00:10,645][model][INFO] - Training step 13120 loss 0.0073427981697022915
[2025-03-16 03:00:52,353][model][INFO] - Training step 13280 loss 0.02072000317275524
[2025-03-16 03:01:32,447][model][INFO] - Training step 13440 loss 0.03910698741674423
[2025-03-16 03:02:13,038][model][INFO] - Training step 13600 loss 0.0300581194460392
[2025-03-16 03:02:54,636][model][INFO] - Training step 13760 loss 0.0632535070180893
[2025-03-16 03:03:35,709][model][INFO] - Training step 13920 loss 0.00707187270745635
[2025-03-16 03:04:17,174][model][INFO] - Training step 14080 loss 0.01745745539665222
[2025-03-16 03:04:57,871][model][INFO] - Training step 14240 loss 0.045477837324142456
[2025-03-16 03:05:39,379][model][INFO] - Training step 14400 loss 0.008300560526549816
[2025-03-16 03:06:20,129][model][INFO] - Training step 14560 loss 0.05794369801878929
[2025-03-16 03:07:00,458][model][INFO] - Training step 14720 loss 0.010546981357038021
[2025-03-16 03:07:40,621][model][INFO] - Training step 14880 loss 0.03943902254104614
[2025-03-16 03:08:19,855][model][INFO] - Training step 15040 loss 0.09521441161632538
[2025-03-16 03:08:59,411][model][INFO] - Training step 15200 loss 0.017366906628012657
[2025-03-16 03:09:40,003][model][INFO] - Training step 15360 loss 0.004256441257894039
[2025-03-16 03:10:20,193][model][INFO] - Training step 15520 loss 0.019511563703417778
[2025-03-16 03:11:00,271][model][INFO] - Training step 15680 loss 0.26235437393188477
[2025-03-16 03:11:41,639][model][INFO] - Training step 15840 loss 0.2481052577495575
[2025-03-16 03:12:20,611][model][INFO] - Training step 16000 loss 0.016336731612682343
[2025-03-16 03:13:02,568][model][INFO] - Training step 16160 loss 0.21709445118904114
[2025-03-16 03:13:42,978][model][INFO] - Training step 16320 loss 0.0037965448573231697
[2025-03-16 03:14:22,703][model][INFO] - Training step 16480 loss 0.016888532787561417
[2025-03-16 03:15:02,337][model][INFO] - Training step 16640 loss 0.10683826357126236
[2025-03-16 03:15:42,700][model][INFO] - Training step 16800 loss 0.24600788950920105
[2025-03-16 03:16:22,457][model][INFO] - Training step 16960 loss 0.04347345605492592
[2025-03-16 03:17:04,179][model][INFO] - Training step 17120 loss 0.002815611893311143
[2025-03-16 03:17:45,316][model][INFO] - Training step 17280 loss 0.022768190130591393
[2025-03-16 03:18:26,476][model][INFO] - Training step 17440 loss 0.0046718236990273
[2025-03-16 03:19:09,405][model][INFO] - Training step 17600 loss 0.266914963722229
[2025-03-16 03:19:49,610][model][INFO] - Training step 17760 loss 0.0029175179079174995
[2025-03-16 03:20:30,130][model][INFO] - Training step 17920 loss 0.2635069489479065
[2025-03-16 03:21:11,255][model][INFO] - Training step 18080 loss 0.23130488395690918
[2025-03-16 03:21:52,396][model][INFO] - Training step 18240 loss 0.281856507062912
[2025-03-16 03:22:34,072][model][INFO] - Training step 18400 loss 0.027731694281101227
[2025-03-16 03:23:13,851][model][INFO] - Training step 18560 loss 0.039058491587638855
[2025-03-16 03:23:55,662][model][INFO] - Training step 18720 loss 0.022360824048519135
[2025-03-16 03:24:36,818][model][INFO] - Training step 18880 loss 0.2709294557571411
[2025-03-16 03:25:17,854][model][INFO] - Training step 19040 loss 0.005926911719143391
[2025-03-16 03:25:58,608][model][INFO] - Training step 19200 loss 0.03812410682439804
[2025-03-16 03:26:39,775][model][INFO] - Training step 19360 loss 0.2381628304719925
[2025-03-16 03:27:21,044][model][INFO] - Training step 19520 loss 0.2261911779642105
[2025-03-16 03:28:01,261][model][INFO] - Training step 19680 loss 0.03460326045751572
[2025-03-16 03:28:42,386][model][INFO] - Training step 19840 loss 0.02034774422645569
[2025-03-16 03:29:21,963][model][INFO] - Training step 20000 loss 0.2238304316997528
[2025-03-16 03:30:02,262][model][INFO] - Training step 20160 loss 0.04898161441087723
[2025-03-16 03:30:43,573][model][INFO] - Training step 20320 loss 0.1896584928035736
[2025-03-16 03:31:24,116][model][INFO] - Training step 20480 loss 0.03294369950890541
[2025-03-16 03:32:04,707][model][INFO] - Training step 20640 loss 0.05817248672246933
[2025-03-16 03:32:45,713][model][INFO] - Training step 20800 loss 0.03532494977116585
[2025-03-16 03:33:27,596][model][INFO] - Training step 20960 loss 0.04622964560985565
[2025-03-16 03:34:08,692][model][INFO] - Training step 21120 loss 0.23078086972236633
[2025-03-16 03:34:50,226][model][INFO] - Training step 21280 loss 0.0171225406229496
[2025-03-16 03:35:30,058][model][INFO] - Training step 21440 loss 0.25038695335388184
[2025-03-16 03:36:10,242][model][INFO] - Training step 21600 loss 0.043244920670986176
[2025-03-16 03:36:51,764][model][INFO] - Training step 21760 loss 0.022703832015395164
[2025-03-16 03:37:31,765][model][INFO] - Training step 21920 loss 0.02123415097594261
[2025-03-16 03:38:12,761][model][INFO] - Training step 22080 loss 0.2512891888618469
[2025-03-16 03:38:53,141][model][INFO] - Training step 22240 loss 0.03211280331015587
[2025-03-16 03:39:34,287][model][INFO] - Training step 22400 loss 0.029919713735580444
[2025-03-16 03:40:15,761][model][INFO] - Training step 22560 loss 0.03274022042751312
[2025-03-16 03:40:56,179][model][INFO] - Training step 22720 loss 0.013066107407212257
[2025-03-16 03:41:37,277][model][INFO] - Training step 22880 loss 0.027032319456338882
[2025-03-16 03:42:18,521][model][INFO] - Training step 23040 loss 0.049802377820014954
[2025-03-16 03:42:59,075][model][INFO] - Training step 23200 loss 0.03552572429180145
[2025-03-16 03:43:40,339][model][INFO] - Training step 23360 loss 0.24743586778640747
[2025-03-16 03:44:21,436][model][INFO] - Training step 23520 loss 0.24331408739089966
[2025-03-16 03:45:03,154][model][INFO] - Training step 23680 loss 0.031435929238796234
[2025-03-16 03:45:44,909][model][INFO] - Training step 23840 loss 0.2463611662387848
[2025-03-16 03:46:25,374][model][INFO] - Training step 24000 loss 0.13317115604877472
[2025-03-16 03:47:05,668][model][INFO] - Training step 24160 loss 0.027960501611232758
[2025-03-16 03:47:46,086][model][INFO] - Training step 24320 loss 0.26404619216918945
[2025-03-16 03:48:26,932][model][INFO] - Training step 24480 loss 0.014289855025708675
[2025-03-16 03:49:07,614][model][INFO] - Training step 24640 loss 0.045555245131254196
[2025-03-16 03:49:47,963][model][INFO] - Training step 24800 loss 0.04188404977321625
[2025-03-16 03:50:29,005][model][INFO] - Training step 24960 loss 0.10830879211425781
[2025-03-16 03:51:11,199][model][INFO] - Training step 25120 loss 0.2501811981201172
[2025-03-16 03:51:51,875][model][INFO] - Training step 25280 loss 0.016606150195002556
[2025-03-16 03:52:31,617][model][INFO] - Training step 25440 loss 0.015610994771122932
[2025-03-16 03:53:12,571][model][INFO] - Training step 25600 loss 0.03530792519450188
[2025-03-16 03:53:52,213][model][INFO] - Training step 25760 loss 0.05283385515213013
[2025-03-16 03:54:32,946][model][INFO] - Training step 25920 loss 0.02525186911225319
[2025-03-16 03:55:12,962][model][INFO] - Training step 26080 loss 0.24945417046546936
[2025-03-16 03:55:54,435][model][INFO] - Training step 26240 loss 0.020550385117530823
[2025-03-16 03:56:35,555][model][INFO] - Training step 26400 loss 0.037976521998643875
[2025-03-16 03:57:16,258][model][INFO] - Training step 26560 loss 0.004976820666342974
[2025-03-16 03:57:56,340][model][INFO] - Training step 26720 loss 0.016202591359615326
[2025-03-16 03:58:37,889][model][INFO] - Training step 26880 loss 0.02314775064587593
[2025-03-16 03:59:17,710][model][INFO] - Training step 27040 loss 0.02315465360879898
[2025-03-16 03:59:57,755][model][INFO] - Training step 27200 loss 0.023924527689814568
[2025-03-16 04:00:38,696][model][INFO] - Training step 27360 loss 0.03384169191122055
[2025-03-16 04:01:20,741][model][INFO] - Training step 27520 loss 0.040585488080978394
[2025-03-16 04:02:02,786][model][INFO] - Training step 27680 loss 0.25990891456604004
[2025-03-16 04:02:43,610][model][INFO] - Training step 27840 loss 0.034573040902614594
[2025-03-16 04:03:23,399][model][INFO] - Training step 28000 loss 0.031145822256803513
[2025-03-16 04:04:04,026][model][INFO] - Training step 28160 loss 0.012046572752296925
[2025-03-16 04:04:45,274][model][INFO] - Training step 28320 loss 0.023808546364307404
[2025-03-16 04:05:24,894][model][INFO] - Training step 28480 loss 0.033564493060112
[2025-03-16 04:06:05,852][model][INFO] - Training step 28640 loss 0.032219257205724716
[2025-03-16 04:06:44,759][model][INFO] - Training step 28800 loss 0.10317448526620865
[2025-03-16 04:07:24,306][model][INFO] - Training step 28960 loss 0.2575954794883728
[2025-03-16 04:08:04,641][model][INFO] - Training step 29120 loss 0.006571016274392605
[2025-03-16 04:08:46,358][model][INFO] - Training step 29280 loss 0.029922502115368843
[2025-03-16 04:09:27,796][model][INFO] - Training step 29440 loss 0.017561007291078568
[2025-03-16 04:10:08,911][model][INFO] - Training step 29600 loss 0.16692566871643066
[2025-03-16 04:10:49,623][model][INFO] - Training step 29760 loss 0.033165961503982544
[2025-03-16 04:11:31,107][model][INFO] - Training step 29920 loss 0.02379518747329712
[2025-03-16 04:12:12,317][model][INFO] - Training step 30080 loss 0.014888888224959373
[2025-03-16 04:12:50,838][model][INFO] - Training step 30240 loss 0.04348178207874298
[2025-03-16 04:13:32,591][model][INFO] - Training step 30400 loss 0.026686785742640495
[2025-03-16 04:14:14,363][model][INFO] - Training step 30560 loss 0.3098617494106293
[2025-03-16 04:14:53,513][model][INFO] - Training step 30720 loss 0.020079590380191803
[2025-03-16 04:15:32,270][model][INFO] - Training step 30880 loss 0.08318279683589935
[2025-03-16 04:16:12,709][model][INFO] - Training step 31040 loss 0.002589928451925516
[2025-03-16 04:16:51,850][model][INFO] - Training step 31200 loss 0.017856933176517487
[2025-03-16 04:17:32,734][model][INFO] - Training step 31360 loss 0.2447570413351059
[2025-03-16 04:18:13,040][model][INFO] - Training step 31520 loss 0.05635382607579231
[2025-03-16 04:18:53,428][model][INFO] - Training step 31680 loss 0.023453833535313606
[2025-03-16 04:19:33,757][model][INFO] - Training step 31840 loss 0.005511839408427477
[2025-03-16 04:20:16,381][model][INFO] - Training step 32000 loss 0.11874926090240479
[2025-03-16 04:20:56,586][model][INFO] - Training step 32160 loss 0.030676227062940598
[2025-03-16 04:21:38,235][model][INFO] - Training step 32320 loss 0.0325528159737587
[2025-03-16 04:22:20,328][model][INFO] - Training step 32480 loss 0.0490216426551342
[2025-03-16 04:23:01,462][model][INFO] - Training step 32640 loss 0.03298544883728027
[2025-03-16 04:23:42,508][model][INFO] - Training step 32800 loss 0.05270879715681076
[2025-03-16 04:24:23,907][model][INFO] - Training step 32960 loss 0.24948649108409882
[2025-03-16 04:25:03,249][model][INFO] - Training step 33120 loss 0.041086576879024506
[2025-03-16 04:25:44,514][model][INFO] - Training step 33280 loss 0.04335016384720802
[2025-03-16 04:26:24,506][model][INFO] - Training step 33440 loss 0.0028870529495179653
[2025-03-16 04:27:06,407][model][INFO] - Training step 33600 loss 0.018757358193397522
[2025-03-16 04:27:47,648][model][INFO] - Training step 33760 loss 0.02512829750776291
[2025-03-16 04:28:28,113][model][INFO] - Training step 33920 loss 0.038698699325323105
[2025-03-16 04:29:08,130][model][INFO] - Training step 34080 loss 0.01686304435133934
[2025-03-16 04:29:48,391][model][INFO] - Training step 34240 loss 0.022824741899967194
[2025-03-16 04:30:29,914][model][INFO] - Training step 34400 loss 0.03822406008839607
[2025-03-16 04:31:11,486][model][INFO] - Training step 34560 loss 0.2492567002773285
[2025-03-16 04:31:52,913][model][INFO] - Training step 34720 loss 0.06552848219871521
[2025-03-16 04:32:32,958][model][INFO] - Training step 34880 loss 0.006138121243566275
[2025-03-16 04:33:14,373][model][INFO] - Training step 35040 loss 0.042043644934892654
[2025-03-16 04:33:55,723][model][INFO] - Training step 35200 loss 0.024710865691304207
[2025-03-16 04:34:37,115][model][INFO] - Training step 35360 loss 0.016656767576932907
[2025-03-16 04:35:18,673][model][INFO] - Training step 35520 loss 0.022638842463493347
[2025-03-16 04:35:59,861][model][INFO] - Training step 35680 loss 0.2532655596733093
[2025-03-16 04:36:41,175][model][INFO] - Training step 35840 loss 0.01413789950311184
[2025-03-16 04:37:22,476][model][INFO] - Training step 36000 loss 0.02340792864561081
[2025-03-16 04:38:03,567][model][INFO] - Training step 36160 loss 0.005802753381431103
[2025-03-16 04:38:43,495][model][INFO] - Training step 36320 loss 0.048619337379932404
[2025-03-16 04:39:24,334][model][INFO] - Training step 36480 loss 0.016223229467868805
[2025-03-16 04:40:04,098][model][INFO] - Training step 36640 loss 0.03122473880648613
[2025-03-16 04:40:44,965][model][INFO] - Training step 36800 loss 0.002844893140718341
[2025-03-16 04:41:25,706][model][INFO] - Training step 36960 loss 0.009422682225704193
[2025-03-16 04:42:05,855][model][INFO] - Training step 37120 loss 0.016856882721185684
[2025-03-16 04:42:48,800][model][INFO] - Training step 37280 loss 0.024450913071632385
[2025-03-16 04:43:29,766][model][INFO] - Training step 37440 loss 0.2318141758441925
[2025-03-16 04:44:10,649][model][INFO] - Training step 37600 loss 0.02060050144791603
[2025-03-16 04:44:51,455][model][INFO] - Training step 37760 loss 0.023091748356819153
[2025-03-16 04:45:32,961][model][INFO] - Training step 37920 loss 0.01462959311902523
[2025-03-16 04:46:12,138][model][INFO] - Training step 38080 loss 0.03864186257123947
[2025-03-16 04:46:54,012][model][INFO] - Training step 38240 loss 0.020683055743575096
[2025-03-16 04:47:33,679][model][INFO] - Training step 38400 loss 0.026194274425506592
[2025-03-16 04:48:13,236][model][INFO] - Training step 38560 loss 0.2577342987060547
[2025-03-16 04:48:55,380][model][INFO] - Training step 38720 loss 0.01011085044592619
[2025-03-16 04:49:36,636][model][INFO] - Training step 38880 loss 0.01039179228246212
[2025-03-16 04:50:18,725][model][INFO] - Training step 39040 loss 0.2539946734905243
[2025-03-16 04:50:59,073][model][INFO] - Training step 39200 loss 0.24762177467346191
[2025-03-16 04:51:39,877][model][INFO] - Training step 39360 loss 0.16040872037410736
[2025-03-16 04:52:20,593][model][INFO] - Training step 39520 loss 0.02197558432817459
[2025-03-16 04:53:00,132][model][INFO] - Training step 39680 loss 0.020107708871364594
[2025-03-16 04:53:41,483][model][INFO] - Training step 39840 loss 0.02651912346482277
[2025-03-16 04:54:21,359][model][INFO] - Training step 40000 loss 0.005588415078818798
[2025-03-16 04:55:03,426][model][INFO] - Training step 40160 loss 0.25777825713157654
[2025-03-16 04:55:43,514][model][INFO] - Training step 40320 loss 0.021716993302106857
[2025-03-16 04:56:22,573][model][INFO] - Training step 40480 loss 0.004797315690666437
[2025-03-16 04:57:04,043][model][INFO] - Training step 40640 loss 0.021923262625932693
[2025-03-16 04:57:43,080][model][INFO] - Training step 40800 loss 0.008806757628917694
[2025-03-16 04:58:22,793][model][INFO] - Training step 40960 loss 0.007544735912233591
[2025-03-16 04:59:02,952][model][INFO] - Training step 41120 loss 0.007537929341197014
[2025-03-16 04:59:43,856][model][INFO] - Training step 41280 loss 0.0036460217088460922
[2025-03-16 05:00:23,752][model][INFO] - Training step 41440 loss 0.04198931157588959
[2025-03-16 05:01:05,390][model][INFO] - Training step 41600 loss 0.04066592827439308
[2025-03-16 05:01:45,676][model][INFO] - Training step 41760 loss 0.02198740839958191
[2025-03-16 05:02:26,129][model][INFO] - Training step 41920 loss 0.020030908286571503
[2025-03-16 05:03:06,804][model][INFO] - Training step 42080 loss 0.043643273413181305
[2025-03-16 05:03:48,296][model][INFO] - Training step 42240 loss 0.2523113489151001
[2025-03-16 05:04:27,447][model][INFO] - Training step 42400 loss 0.031393542885780334
[2025-03-16 05:05:08,695][model][INFO] - Training step 42560 loss 0.005173089448362589
[2025-03-16 05:05:49,424][model][INFO] - Training step 42720 loss 0.00976787693798542
[2025-03-16 05:06:29,799][model][INFO] - Training step 42880 loss 0.005140571389347315
[2025-03-16 05:07:10,114][model][INFO] - Training step 43040 loss 0.03277955949306488
[2025-03-16 05:07:49,172][model][INFO] - Training step 43200 loss 0.06749683618545532
[2025-03-16 05:08:28,858][model][INFO] - Training step 43360 loss 0.038134023547172546
[2025-03-16 05:09:10,539][model][INFO] - Training step 43520 loss 0.05321230739355087
[2025-03-16 05:09:53,925][model][INFO] - Training step 43680 loss 0.01741994172334671
[2025-03-16 05:10:34,079][model][INFO] - Training step 43840 loss 0.2667442858219147
[2025-03-16 05:11:15,137][model][INFO] - Training step 44000 loss 0.023231446743011475
[2025-03-16 05:11:54,629][model][INFO] - Training step 44160 loss 0.011243253014981747
[2025-03-16 05:12:34,916][model][INFO] - Training step 44320 loss 0.2488880157470703
[2025-03-16 05:13:15,171][model][INFO] - Training step 44480 loss 0.005548746325075626
[2025-03-16 05:13:54,417][model][INFO] - Training step 44640 loss 0.01657523214817047
[2025-03-16 05:14:36,749][model][INFO] - Training step 44800 loss 0.09868123382329941
[2025-03-16 05:15:17,051][model][INFO] - Training step 44960 loss 0.02369592897593975
[2025-03-16 05:15:56,249][model][INFO] - Training step 45120 loss 0.10538089275360107
[2025-03-16 05:16:38,294][model][INFO] - Training step 45280 loss 0.02142566442489624
[2025-03-16 05:17:19,905][model][INFO] - Training step 45440 loss 0.05679186061024666
[2025-03-16 05:18:00,683][model][INFO] - Training step 45600 loss 0.021210379898548126
[2025-03-16 05:18:41,031][model][INFO] - Training step 45760 loss 0.26311641931533813
[2025-03-16 05:19:20,718][model][INFO] - Training step 45920 loss 0.032193757593631744
[2025-03-16 05:20:01,196][model][INFO] - Training step 46080 loss 0.01947597786784172
[2025-03-16 05:20:41,494][model][INFO] - Training step 46240 loss 0.03190534561872482
[2025-03-16 05:21:23,294][model][INFO] - Training step 46400 loss 0.007886848412454128
[2025-03-16 05:22:02,551][model][INFO] - Training step 46560 loss 0.2631986141204834
[2025-03-16 05:22:42,759][model][INFO] - Training step 46720 loss 0.0619068443775177
[2025-03-16 05:23:23,817][model][INFO] - Training step 46880 loss 0.042428158223629
[2025-03-16 05:24:04,791][model][INFO] - Training step 47040 loss 0.002191895851865411
[2025-03-16 05:24:45,049][model][INFO] - Training step 47200 loss 0.018842186778783798
[2025-03-16 05:25:26,395][model][INFO] - Training step 47360 loss 0.2514631748199463
[2025-03-16 05:26:06,709][model][INFO] - Training step 47520 loss 0.045738335698843
[2025-03-16 05:26:47,579][model][INFO] - Training step 47680 loss 0.028708267956972122
[2025-03-16 05:27:27,228][model][INFO] - Training step 47840 loss 0.007213234901428223
[2025-03-16 05:28:07,157][model][INFO] - Training step 48000 loss 0.03999442234635353
[2025-03-16 05:28:50,611][model][INFO] - Training step 48160 loss 0.01998821832239628
[2025-03-16 05:29:31,413][model][INFO] - Training step 48320 loss 0.24704095721244812
[2025-03-16 05:30:11,914][model][INFO] - Training step 48480 loss 0.2463912069797516
[2025-03-16 05:30:51,363][model][INFO] - Training step 48640 loss 0.005674452055245638
[2025-03-16 05:31:31,226][model][INFO] - Training step 48800 loss 0.0051489705219864845
[2025-03-16 05:32:13,945][model][INFO] - Training step 48960 loss 0.011089233681559563
[2025-03-16 05:32:53,504][model][INFO] - Training step 49120 loss 0.035837773233652115
[2025-03-16 05:33:34,538][model][INFO] - Training step 49280 loss 0.15998050570487976
[2025-03-16 05:34:13,649][model][INFO] - Training step 49440 loss 0.03737541660666466
[2025-03-16 05:34:54,759][model][INFO] - Training step 49600 loss 0.04047892242670059
[2025-03-16 05:35:35,876][model][INFO] - Training step 49760 loss 0.04937712848186493
[2025-03-16 05:36:18,620][model][INFO] - Training step 49920 loss 0.01196361891925335
[2025-03-16 05:36:58,990][model][INFO] - Training step 50080 loss 0.025070996955037117
[2025-03-16 05:37:39,985][model][INFO] - Training step 50240 loss 0.004133016802370548
[2025-03-16 05:38:19,559][model][INFO] - Training step 50400 loss 0.06576026976108551
[2025-03-16 05:38:59,387][model][INFO] - Training step 50560 loss 0.25854605436325073
[2025-03-16 05:39:39,394][model][INFO] - Training step 50720 loss 0.0028992583975195885
[2025-03-16 05:45:26,476][model][INFO] - Training step 80 loss 0.0627686083316803
[2025-03-16 05:46:08,233][model][INFO] - Training step 240 loss 0.02108224295079708
[2025-03-16 05:46:49,063][model][INFO] - Training step 400 loss 0.2482532411813736
[2025-03-16 05:47:28,839][model][INFO] - Training step 560 loss 0.06871747970581055
[2025-03-16 05:48:08,738][model][INFO] - Training step 720 loss 0.10225334763526917
[2025-03-16 05:48:49,722][model][INFO] - Training step 880 loss 0.004225270822644234
[2025-03-16 05:49:29,324][model][INFO] - Training step 1040 loss 0.057224053889513016
[2025-03-16 05:50:09,569][model][INFO] - Training step 1200 loss 0.0044320570304989815
[2025-03-16 05:50:49,835][model][INFO] - Training step 1360 loss 0.0031407771166414022
[2025-03-16 05:51:29,477][model][INFO] - Training step 1520 loss 0.02991989627480507
[2025-03-16 05:52:09,950][model][INFO] - Training step 1680 loss 0.25084197521209717
[2025-03-16 05:52:49,767][model][INFO] - Training step 1840 loss 0.03498762845993042
[2025-03-16 05:53:31,183][model][INFO] - Training step 2000 loss 0.03543314337730408
[2025-03-16 05:54:12,482][model][INFO] - Training step 2160 loss 0.026884248480200768
[2025-03-16 05:54:51,465][model][INFO] - Training step 2320 loss 0.018204815685749054
[2025-03-16 05:55:31,476][model][INFO] - Training step 2480 loss 0.006510957144200802
[2025-03-16 05:56:12,160][model][INFO] - Training step 2640 loss 0.2524121403694153
[2025-03-16 05:56:53,142][model][INFO] - Training step 2800 loss 0.03275010734796524
[2025-03-16 05:57:33,416][model][INFO] - Training step 2960 loss 0.030319292098283768
[2025-03-16 05:58:14,073][model][INFO] - Training step 3120 loss 0.06049607694149017
[2025-03-16 05:58:55,175][model][INFO] - Training step 3280 loss 0.02647223323583603
[2025-03-16 05:59:35,531][model][INFO] - Training step 3440 loss 0.02414683811366558
[2025-03-16 06:00:16,328][model][INFO] - Training step 3600 loss 0.24472491443157196
[2025-03-16 06:00:58,086][model][INFO] - Training step 3760 loss 0.021356850862503052
[2025-03-16 06:01:38,627][model][INFO] - Training step 3920 loss 0.013562345877289772
[2025-03-16 06:02:18,861][model][INFO] - Training step 4080 loss 0.0313493087887764
[2025-03-16 06:02:58,630][model][INFO] - Training step 4240 loss 0.007884413935244083
[2025-03-16 06:03:39,687][model][INFO] - Training step 4400 loss 0.2519983649253845
[2025-03-16 06:04:19,680][model][INFO] - Training step 4560 loss 0.02404508739709854
[2025-03-16 06:05:00,093][model][INFO] - Training step 4720 loss 0.15014728903770447
[2025-03-16 06:05:40,823][model][INFO] - Training step 4880 loss 0.016885340213775635
[2025-03-16 06:06:22,046][model][INFO] - Training step 5040 loss 0.028667397797107697
[2025-03-16 06:07:03,011][model][INFO] - Training step 5200 loss 0.25401389598846436
[2025-03-16 06:07:43,298][model][INFO] - Training step 5360 loss 0.061113711446523666
[2025-03-16 06:08:22,604][model][INFO] - Training step 5520 loss 0.03676997497677803
[2025-03-16 06:09:02,784][model][INFO] - Training step 5680 loss 0.24599763751029968
[2025-03-16 06:09:43,061][model][INFO] - Training step 5840 loss 0.01848534494638443
[2025-03-16 06:10:25,368][model][INFO] - Training step 6000 loss 0.0036803316324949265
[2025-03-16 06:11:07,540][model][INFO] - Training step 6160 loss 0.018049877136945724
[2025-03-16 06:11:48,624][model][INFO] - Training step 6320 loss 0.005430515855550766
[2025-03-16 06:12:30,922][model][INFO] - Training step 6480 loss 0.24860399961471558
[2025-03-16 06:13:11,333][model][INFO] - Training step 6640 loss 0.005345513112843037
[2025-03-16 06:13:52,331][model][INFO] - Training step 6800 loss 0.0056975525803864
[2025-03-16 06:14:34,115][model][INFO] - Training step 6960 loss 0.004634182434529066
[2025-03-16 06:15:13,715][model][INFO] - Training step 7120 loss 0.03076918050646782
[2025-03-16 06:15:54,822][model][INFO] - Training step 7280 loss 0.024144072085618973
[2025-03-16 06:16:34,960][model][INFO] - Training step 7440 loss 0.02440938726067543
[2025-03-16 06:17:14,798][model][INFO] - Training step 7600 loss 0.03411588817834854
[2025-03-16 06:17:55,123][model][INFO] - Training step 7760 loss 0.025824077427387238
[2025-03-16 06:18:35,916][model][INFO] - Training step 7920 loss 0.029171831905841827
[2025-03-16 06:19:16,364][model][INFO] - Training step 8080 loss 0.001879479386843741
[2025-03-16 06:19:57,491][model][INFO] - Training step 8240 loss 0.01674043759703636
[2025-03-16 06:20:37,679][model][INFO] - Training step 8400 loss 0.02946823462843895
[2025-03-16 06:21:16,644][model][INFO] - Training step 8560 loss 0.016713755205273628
[2025-03-16 06:21:57,715][model][INFO] - Training step 8720 loss 0.06358478963375092
[2025-03-16 06:22:38,730][model][INFO] - Training step 8880 loss 0.015067096799612045
[2025-03-16 06:23:20,472][model][INFO] - Training step 9040 loss 0.014259123243391514
[2025-03-16 06:24:00,993][model][INFO] - Training step 9200 loss 0.25816941261291504
[2025-03-16 06:24:42,668][model][INFO] - Training step 9360 loss 0.028373725712299347
[2025-03-16 06:25:22,539][model][INFO] - Training step 9520 loss 0.0095026521012187
[2025-03-16 06:26:04,532][model][INFO] - Training step 9680 loss 0.16129645705223083
[2025-03-16 06:26:46,548][model][INFO] - Training step 9840 loss 0.04618506133556366
[2025-03-16 06:27:28,653][model][INFO] - Training step 10000 loss 0.03900223970413208
[2025-03-16 06:28:09,658][model][INFO] - Training step 10160 loss 0.010762052610516548
[2025-03-16 06:28:48,800][model][INFO] - Training step 10320 loss 0.01516159251332283
[2025-03-16 06:29:30,226][model][INFO] - Training step 10480 loss 0.03493907302618027
[2025-03-16 06:30:10,925][model][INFO] - Training step 10640 loss 0.06090180575847626
[2025-03-16 06:30:51,923][model][INFO] - Training step 10800 loss 0.004353283904492855
[2025-03-16 06:31:32,079][model][INFO] - Training step 10960 loss 0.05200163275003433
[2025-03-16 06:32:13,457][model][INFO] - Training step 11120 loss 0.016058828681707382
[2025-03-16 06:32:52,998][model][INFO] - Training step 11280 loss 0.02064189501106739
[2025-03-16 06:33:32,968][model][INFO] - Training step 11440 loss 0.03621707856655121
[2025-03-16 06:34:12,996][model][INFO] - Training step 11600 loss 0.25022247433662415
[2025-03-16 06:34:55,645][model][INFO] - Training step 11760 loss 0.08303949981927872
[2025-03-16 06:35:34,821][model][INFO] - Training step 11920 loss 0.0027324813418090343
[2025-03-16 06:36:15,454][model][INFO] - Training step 12080 loss 0.03242023289203644
[2025-03-16 06:36:56,291][model][INFO] - Training step 12240 loss 0.05429892987012863
[2025-03-16 06:37:35,652][model][INFO] - Training step 12400 loss 0.004374331329017878
[2025-03-16 06:38:15,603][model][INFO] - Training step 12560 loss 0.028460625559091568
[2025-03-16 06:38:57,466][model][INFO] - Training step 12720 loss 0.012604350224137306
[2025-03-16 06:39:37,421][model][INFO] - Training step 12880 loss 0.015627987682819366
[2025-03-16 06:40:18,214][model][INFO] - Training step 13040 loss 0.08681747317314148
[2025-03-16 06:40:58,325][model][INFO] - Training step 13200 loss 0.006256042513996363
[2025-03-16 06:41:39,652][model][INFO] - Training step 13360 loss 0.03993244469165802
[2025-03-16 06:42:18,921][model][INFO] - Training step 13520 loss 0.022028353065252304
[2025-03-16 06:42:59,766][model][INFO] - Training step 13680 loss 0.0724484771490097
[2025-03-16 06:43:41,179][model][INFO] - Training step 13840 loss 0.034056179225444794
[2025-03-16 06:44:21,730][model][INFO] - Training step 14000 loss 0.06014682352542877
[2025-03-16 06:45:02,001][model][INFO] - Training step 14160 loss 0.25288015604019165
[2025-03-16 06:45:44,400][model][INFO] - Training step 14320 loss 0.022024502977728844
[2025-03-16 06:46:24,860][model][INFO] - Training step 14480 loss 0.01526693906635046
[2025-03-16 06:47:04,862][model][INFO] - Training step 14640 loss 0.016076963394880295
[2025-03-16 06:47:44,854][model][INFO] - Training step 14800 loss 0.008102125488221645
[2025-03-16 06:48:27,230][model][INFO] - Training step 14960 loss 0.09319070726633072
[2025-03-16 06:49:06,724][model][INFO] - Training step 15120 loss 0.0020868557039648294
[2025-03-16 06:49:48,725][model][INFO] - Training step 15280 loss 0.03363692760467529
[2025-03-16 06:50:29,599][model][INFO] - Training step 15440 loss 0.013906583189964294
[2025-03-16 06:51:10,535][model][INFO] - Training step 15600 loss 0.2675376236438751
[2025-03-16 06:51:52,275][model][INFO] - Training step 15760 loss 0.030676234513521194
[2025-03-16 06:52:31,944][model][INFO] - Training step 15920 loss 0.00506807304918766
[2025-03-16 06:53:12,346][model][INFO] - Training step 16080 loss 0.014071591198444366
[2025-03-16 06:53:53,830][model][INFO] - Training step 16240 loss 0.039725758135318756
[2025-03-16 06:54:35,486][model][INFO] - Training step 16400 loss 0.1279599517583847
[2025-03-16 06:55:15,327][model][INFO] - Training step 16560 loss 0.041441045701503754
[2025-03-16 06:55:55,195][model][INFO] - Training step 16720 loss 0.021584628149867058
[2025-03-16 06:56:34,651][model][INFO] - Training step 16880 loss 0.06681890785694122
[2025-03-16 06:57:14,776][model][INFO] - Training step 17040 loss 0.07951909303665161
[2025-03-16 06:57:55,044][model][INFO] - Training step 17200 loss 0.04480668157339096
[2025-03-16 06:58:35,999][model][INFO] - Training step 17360 loss 0.013032941147685051
[2025-03-16 06:59:17,088][model][INFO] - Training step 17520 loss 0.2584986984729767
[2025-03-16 06:59:58,585][model][INFO] - Training step 17680 loss 0.2500302195549011
[2025-03-16 07:00:39,040][model][INFO] - Training step 17840 loss 0.25779038667678833
[2025-03-16 07:01:20,660][model][INFO] - Training step 18000 loss 0.036391761153936386
[2025-03-16 07:02:00,580][model][INFO] - Training step 18160 loss 0.09459980577230453
[2025-03-16 07:02:40,412][model][INFO] - Training step 18320 loss 0.024012889713048935
[2025-03-16 07:03:22,501][model][INFO] - Training step 18480 loss 0.04693128168582916
[2025-03-16 07:04:04,383][model][INFO] - Training step 18640 loss 0.008764730766415596
[2025-03-16 07:04:44,646][model][INFO] - Training step 18800 loss 0.014128927141427994
[2025-03-16 07:05:23,778][model][INFO] - Training step 18960 loss 0.1021854504942894
[2025-03-16 07:06:04,425][model][INFO] - Training step 19120 loss 0.016196664422750473
[2025-03-16 07:06:44,152][model][INFO] - Training step 19280 loss 0.024143021553754807
[2025-03-16 07:07:24,721][model][INFO] - Training step 19440 loss 0.039509937167167664
[2025-03-16 07:08:06,340][model][INFO] - Training step 19600 loss 0.25453341007232666
[2025-03-16 07:08:47,566][model][INFO] - Training step 19760 loss 0.03176538646221161
[2025-03-16 07:09:29,428][model][INFO] - Training step 19920 loss 0.25729915499687195
[2025-03-16 07:10:09,788][model][INFO] - Training step 20080 loss 0.05752047896385193
[2025-03-16 07:10:49,303][model][INFO] - Training step 20240 loss 0.02086118794977665
[2025-03-16 07:11:30,364][model][INFO] - Training step 20400 loss 0.0020710371900349855
[2025-03-16 07:12:12,061][model][INFO] - Training step 20560 loss 0.04466870427131653
[2025-03-16 07:12:53,355][model][INFO] - Training step 20720 loss 0.2559915781021118
[2025-03-16 07:13:35,264][model][INFO] - Training step 20880 loss 0.004713689908385277
[2025-03-16 07:14:16,291][model][INFO] - Training step 21040 loss 0.025452304631471634
[2025-03-16 07:14:57,075][model][INFO] - Training step 21200 loss 0.2590855360031128
[2025-03-16 07:15:37,865][model][INFO] - Training step 21360 loss 0.04633807763457298
[2025-03-16 07:16:18,626][model][INFO] - Training step 21520 loss 0.025940867140889168
[2025-03-16 07:16:59,390][model][INFO] - Training step 21680 loss 0.10836082696914673
[2025-03-16 07:17:38,286][model][INFO] - Training step 21840 loss 0.003264273051172495
[2025-03-16 07:18:18,964][model][INFO] - Training step 22000 loss 0.029829202219843864
[2025-03-16 07:19:00,525][model][INFO] - Training step 22160 loss 0.02389153465628624
[2025-03-16 07:19:40,925][model][INFO] - Training step 22320 loss 0.0367426723241806
[2025-03-16 07:20:20,452][model][INFO] - Training step 22480 loss 0.007469202857464552
[2025-03-16 07:21:00,861][model][INFO] - Training step 22640 loss 0.12136812508106232
[2025-03-16 07:21:41,183][model][INFO] - Training step 22800 loss 0.08205677568912506
[2025-03-16 07:22:21,948][model][INFO] - Training step 22960 loss 0.09705932438373566
[2025-03-16 07:23:03,227][model][INFO] - Training step 23120 loss 0.03037525899708271
[2025-03-16 07:23:43,748][model][INFO] - Training step 23280 loss 0.23305846750736237
[2025-03-16 07:24:24,262][model][INFO] - Training step 23440 loss 0.023908302187919617
[2025-03-16 07:25:03,945][model][INFO] - Training step 23600 loss 0.045223966240882874
[2025-03-16 07:25:44,715][model][INFO] - Training step 23760 loss 0.25741082429885864
[2025-03-16 07:26:26,449][model][INFO] - Training step 23920 loss 0.026435578241944313
[2025-03-16 07:27:06,114][model][INFO] - Training step 24080 loss 0.21522361040115356
[2025-03-16 07:27:46,002][model][INFO] - Training step 24240 loss 0.022768381983041763
[2025-03-16 07:28:26,502][model][INFO] - Training step 24400 loss 0.01986636593937874
[2025-03-16 07:29:08,749][model][INFO] - Training step 24560 loss 0.08484082669019699
[2025-03-16 07:29:49,153][model][INFO] - Training step 24720 loss 0.02058228850364685
[2025-03-16 07:30:30,938][model][INFO] - Training step 24880 loss 0.009042231366038322
[2025-03-16 07:31:11,765][model][INFO] - Training step 25040 loss 0.04958413541316986
[2025-03-16 07:31:52,620][model][INFO] - Training step 25200 loss 0.029122095555067062
[2025-03-16 07:32:35,361][model][INFO] - Training step 25360 loss 0.02899613231420517
[2025-03-16 07:33:14,478][model][INFO] - Training step 25520 loss 0.031401727348566055
[2025-03-16 07:33:55,027][model][INFO] - Training step 25680 loss 0.019026994705200195
[2025-03-16 07:34:33,560][model][INFO] - Training step 25840 loss 0.03937983140349388
[2025-03-16 07:35:15,072][model][INFO] - Training step 26000 loss 0.08066771924495697
[2025-03-16 07:35:55,305][model][INFO] - Training step 26160 loss 0.025834567844867706
[2025-03-16 07:36:36,134][model][INFO] - Training step 26320 loss 0.026464328169822693
[2025-03-16 07:37:17,297][model][INFO] - Training step 26480 loss 0.00788604374974966
[2025-03-16 07:37:58,666][model][INFO] - Training step 26640 loss 0.024888943880796432
[2025-03-16 07:38:39,536][model][INFO] - Training step 26800 loss 0.2816016674041748
[2025-03-16 07:39:20,073][model][INFO] - Training step 26960 loss 0.14528444409370422
[2025-03-16 07:40:00,363][model][INFO] - Training step 27120 loss 0.01840321347117424
[2025-03-16 07:40:42,072][model][INFO] - Training step 27280 loss 0.042887791991233826
[2025-03-16 07:41:21,998][model][INFO] - Training step 27440 loss 0.2771621346473694
[2025-03-16 07:42:01,322][model][INFO] - Training step 27600 loss 0.10262629389762878
[2025-03-16 07:42:40,642][model][INFO] - Training step 27760 loss 0.006623770110309124
[2025-03-16 07:43:19,968][model][INFO] - Training step 27920 loss 0.25374776124954224
[2025-03-16 07:44:00,498][model][INFO] - Training step 28080 loss 0.031064316630363464
[2025-03-16 07:44:40,875][model][INFO] - Training step 28240 loss 0.2893288731575012
[2025-03-16 07:45:21,255][model][INFO] - Training step 28400 loss 0.04632880911231041
[2025-03-16 07:46:03,652][model][INFO] - Training step 28560 loss 0.022916331887245178
[2025-03-16 07:46:43,520][model][INFO] - Training step 28720 loss 0.01848866418004036
[2025-03-16 07:47:24,134][model][INFO] - Training step 28880 loss 0.008820788934826851
[2025-03-16 07:48:04,620][model][INFO] - Training step 29040 loss 0.03304671868681908
[2025-03-16 07:48:45,428][model][INFO] - Training step 29200 loss 0.012456202879548073
[2025-03-16 07:49:25,830][model][INFO] - Training step 29360 loss 0.00584807712584734
[2025-03-16 07:50:06,268][model][INFO] - Training step 29520 loss 0.049098484218120575
[2025-03-16 07:50:46,298][model][INFO] - Training step 29680 loss 0.026533618569374084
[2025-03-16 07:51:26,611][model][INFO] - Training step 29840 loss 0.04227782040834427
[2025-03-16 07:52:07,730][model][INFO] - Training step 30000 loss 0.003104293718934059
[2025-03-16 07:52:47,641][model][INFO] - Training step 30160 loss 0.03709298372268677
[2025-03-16 07:53:28,838][model][INFO] - Training step 30320 loss 0.06869629770517349
[2025-03-16 07:54:09,274][model][INFO] - Training step 30480 loss 0.017320498824119568
[2025-03-16 07:54:48,170][model][INFO] - Training step 30640 loss 0.03337789326906204
[2025-03-16 07:55:28,365][model][INFO] - Training step 30800 loss 0.034429699182510376
[2025-03-16 07:56:08,643][model][INFO] - Training step 30960 loss 0.01808875985443592
[2025-03-16 07:56:48,267][model][INFO] - Training step 31120 loss 0.03919091075658798
[2025-03-16 07:57:28,158][model][INFO] - Training step 31280 loss 0.03416828811168671
[2025-03-16 07:58:08,857][model][INFO] - Training step 31440 loss 0.03617526590824127
[2025-03-16 07:58:48,830][model][INFO] - Training step 31600 loss 0.027843980118632317
[2025-03-16 07:59:29,733][model][INFO] - Training step 31760 loss 0.037797555327415466
[2025-03-16 08:00:10,719][model][INFO] - Training step 31920 loss 0.05359630286693573
[2025-03-16 08:00:53,910][model][INFO] - Training step 32080 loss 0.02028336562216282
[2025-03-16 08:01:33,918][model][INFO] - Training step 32240 loss 0.02204880863428116
[2025-03-16 08:02:13,963][model][INFO] - Training step 32400 loss 0.03236033767461777
[2025-03-16 08:02:54,081][model][INFO] - Training step 32560 loss 0.24446114897727966
[2025-03-16 08:03:35,157][model][INFO] - Training step 32720 loss 0.25129109621047974
[2025-03-16 08:04:16,089][model][INFO] - Training step 32880 loss 0.023471567779779434
[2025-03-16 08:04:55,798][model][INFO] - Training step 33040 loss 0.040751270949840546
[2025-03-16 08:05:35,537][model][INFO] - Training step 33200 loss 0.020603276789188385
[2025-03-16 08:06:15,648][model][INFO] - Training step 33360 loss 0.2564166784286499
[2025-03-16 08:06:57,426][model][INFO] - Training step 33520 loss 0.04202369600534439
[2025-03-16 08:07:38,869][model][INFO] - Training step 33680 loss 0.2589511573314667
[2025-03-16 08:08:19,502][model][INFO] - Training step 33840 loss 0.01651982218027115
[2025-03-16 08:09:00,069][model][INFO] - Training step 34000 loss 0.25702106952667236
[2025-03-16 08:09:41,566][model][INFO] - Training step 34160 loss 0.03956066071987152
[2025-03-16 08:10:21,986][model][INFO] - Training step 34320 loss 0.25272539258003235
[2025-03-16 08:11:03,087][model][INFO] - Training step 34480 loss 0.00794044230133295
[2025-03-16 08:11:43,303][model][INFO] - Training step 34640 loss 0.030817393213510513
[2025-03-16 08:12:23,512][model][INFO] - Training step 34800 loss 0.019437335431575775
[2025-03-16 08:13:03,425][model][INFO] - Training step 34960 loss 0.05109429359436035
[2025-03-16 08:13:42,920][model][INFO] - Training step 35120 loss 0.008104616776108742
[2025-03-16 08:14:23,182][model][INFO] - Training step 35280 loss 0.2601826786994934
[2025-03-16 08:15:04,090][model][INFO] - Training step 35440 loss 0.25136685371398926
[2025-03-16 08:15:44,765][model][INFO] - Training step 35600 loss 0.030972525477409363
[2025-03-16 08:16:24,749][model][INFO] - Training step 35760 loss 0.02002890221774578
[2025-03-16 08:17:03,916][model][INFO] - Training step 35920 loss 0.029515238478779793
[2025-03-16 08:17:44,787][model][INFO] - Training step 36080 loss 0.19846269488334656
[2025-03-16 08:18:25,440][model][INFO] - Training step 36240 loss 0.01679326593875885
[2025-03-16 08:19:05,260][model][INFO] - Training step 36400 loss 0.007526824250817299
[2025-03-16 08:19:46,828][model][INFO] - Training step 36560 loss 0.018798034638166428
[2025-03-16 08:20:28,231][model][INFO] - Training step 36720 loss 0.008312283083796501
[2025-03-16 08:21:08,648][model][INFO] - Training step 36880 loss 0.004879076965153217
[2025-03-16 08:21:49,766][model][INFO] - Training step 37040 loss 0.006813323590904474
[2025-03-16 08:22:31,562][model][INFO] - Training step 37200 loss 0.025950077921152115
[2025-03-16 08:23:11,500][model][INFO] - Training step 37360 loss 0.019812772050499916
[2025-03-16 08:23:53,812][model][INFO] - Training step 37520 loss 0.009539451450109482
[2025-03-16 08:24:34,283][model][INFO] - Training step 37680 loss 0.2578660845756531
[2025-03-16 08:25:12,054][model][INFO] - Training step 37840 loss 0.032023265957832336
[2025-03-16 08:25:51,169][model][INFO] - Training step 38000 loss 0.025787096470594406
[2025-03-16 08:26:30,028][model][INFO] - Training step 38160 loss 0.020419366657733917
[2025-03-16 08:27:10,659][model][INFO] - Training step 38320 loss 0.029926564544439316
[2025-03-16 08:27:51,227][model][INFO] - Training step 38480 loss 0.042839184403419495
[2025-03-16 08:28:31,753][model][INFO] - Training step 38640 loss 0.021509457379579544
[2025-03-16 08:29:11,644][model][INFO] - Training step 38800 loss 0.010412411764264107
[2025-03-16 08:29:52,568][model][INFO] - Training step 38960 loss 0.020767901092767715
[2025-03-16 08:30:32,154][model][INFO] - Training step 39120 loss 0.020541293546557426
[2025-03-16 08:31:11,907][model][INFO] - Training step 39280 loss 0.2354397177696228
[2025-03-16 08:31:51,814][model][INFO] - Training step 39440 loss 0.01274535059928894
[2025-03-16 08:32:34,524][model][INFO] - Training step 39600 loss 0.0263846293091774
[2025-03-16 08:33:16,548][model][INFO] - Training step 39760 loss 0.020059846341609955
[2025-03-16 08:33:58,777][model][INFO] - Training step 39920 loss 0.03529410809278488
[2025-03-16 08:34:38,757][model][INFO] - Training step 40080 loss 0.012302935123443604
[2025-03-16 08:35:19,725][model][INFO] - Training step 40240 loss 0.042041338980197906
[2025-03-16 08:36:02,150][model][INFO] - Training step 40400 loss 0.11053832620382309
[2025-03-16 08:36:44,119][model][INFO] - Training step 40560 loss 0.02477768063545227
[2025-03-16 08:37:24,689][model][INFO] - Training step 40720 loss 0.25143876671791077
[2025-03-16 08:38:05,442][model][INFO] - Training step 40880 loss 0.014517467468976974
[2025-03-16 08:38:46,691][model][INFO] - Training step 41040 loss 0.24251586198806763
[2025-03-16 08:39:26,231][model][INFO] - Training step 41200 loss 0.02950676530599594
[2025-03-16 08:40:07,741][model][INFO] - Training step 41360 loss 0.007337798364460468
[2025-03-16 08:40:49,973][model][INFO] - Training step 41520 loss 0.04872922599315643
[2025-03-16 08:41:29,488][model][INFO] - Training step 41680 loss 0.09127745032310486
[2025-03-16 08:42:10,607][model][INFO] - Training step 41840 loss 0.005304895341396332
[2025-03-16 08:42:51,901][model][INFO] - Training step 42000 loss 0.14565905928611755
[2025-03-16 08:43:32,380][model][INFO] - Training step 42160 loss 0.26231908798217773
[2025-03-16 08:44:12,421][model][INFO] - Training step 42320 loss 0.012726535089313984
[2025-03-16 08:44:51,986][model][INFO] - Training step 42480 loss 0.020842481404542923
[2025-03-16 08:45:31,690][model][INFO] - Training step 42640 loss 0.01566511206328869
[2025-03-16 08:46:13,145][model][INFO] - Training step 42800 loss 0.01776592992246151
[2025-03-16 08:46:53,110][model][INFO] - Training step 42960 loss 0.2622959315776825
[2025-03-16 08:47:34,444][model][INFO] - Training step 43120 loss 0.05156548321247101
[2025-03-16 08:48:15,975][model][INFO] - Training step 43280 loss 0.2552679777145386
[2025-03-16 08:48:55,967][model][INFO] - Training step 43440 loss 0.04071177542209625
[2025-03-16 08:49:36,754][model][INFO] - Training step 43600 loss 0.02378569357097149
[2025-03-16 08:50:17,604][model][INFO] - Training step 43760 loss 0.07251147925853729
[2025-03-16 08:50:59,574][model][INFO] - Training step 43920 loss 0.0032359445467591286
[2025-03-16 08:51:40,346][model][INFO] - Training step 44080 loss 0.03261321783065796
[2025-03-16 08:52:22,516][model][INFO] - Training step 44240 loss 0.022957244887948036
[2025-03-16 08:53:03,533][model][INFO] - Training step 44400 loss 0.08128553628921509
[2025-03-16 08:53:44,230][model][INFO] - Training step 44560 loss 0.2592511475086212
[2025-03-16 08:54:24,918][model][INFO] - Training step 44720 loss 0.030483625829219818
[2025-03-16 08:55:04,285][model][INFO] - Training step 44880 loss 0.05794574320316315
[2025-03-16 08:55:44,700][model][INFO] - Training step 45040 loss 0.04652487486600876
[2025-03-16 08:56:24,438][model][INFO] - Training step 45200 loss 0.009478227235376835
[2025-03-16 08:57:06,441][model][INFO] - Training step 45360 loss 0.01794240064918995
[2025-03-16 08:57:46,938][model][INFO] - Training step 45520 loss 0.007547476328909397
[2025-03-16 08:58:27,268][model][INFO] - Training step 45680 loss 0.009767120704054832
[2025-03-16 08:59:08,113][model][INFO] - Training step 45840 loss 0.2669665217399597
[2025-03-16 08:59:51,169][model][INFO] - Training step 46000 loss 0.04472925886511803
[2025-03-16 09:00:31,168][model][INFO] - Training step 46160 loss 0.045928046107292175
[2025-03-16 09:01:11,976][model][INFO] - Training step 46320 loss 0.0013809612719342113
[2025-03-16 09:01:52,816][model][INFO] - Training step 46480 loss 0.01137462630867958
[2025-03-16 09:02:32,327][model][INFO] - Training step 46640 loss 0.03907052427530289
[2025-03-16 09:03:11,477][model][INFO] - Training step 46800 loss 0.10316169261932373
[2025-03-16 09:03:51,988][model][INFO] - Training step 46960 loss 0.06989432871341705
[2025-03-16 09:04:33,299][model][INFO] - Training step 47120 loss 0.2636364698410034
[2025-03-16 09:05:14,684][model][INFO] - Training step 47280 loss 0.00279242149554193
[2025-03-16 09:05:55,121][model][INFO] - Training step 47440 loss 0.013902856037020683
[2025-03-16 09:06:35,386][model][INFO] - Training step 47600 loss 0.05357582867145538
[2025-03-16 09:07:15,370][model][INFO] - Training step 47760 loss 0.04045891389250755
[2025-03-16 09:07:55,713][model][INFO] - Training step 47920 loss 0.10958325862884521
[2025-03-16 09:08:36,612][model][INFO] - Training step 48080 loss 0.04543266445398331
[2025-03-16 09:09:17,250][model][INFO] - Training step 48240 loss 0.0037786434404551983
[2025-03-16 09:09:57,938][model][INFO] - Training step 48400 loss 0.17156362533569336
[2025-03-16 09:10:38,149][model][INFO] - Training step 48560 loss 0.0017902932595461607
[2025-03-16 09:11:18,778][model][INFO] - Training step 48720 loss 0.01624196767807007
[2025-03-16 09:11:58,933][model][INFO] - Training step 48880 loss 0.01901330053806305
[2025-03-16 09:12:39,124][model][INFO] - Training step 49040 loss 0.021137021481990814
[2025-03-16 09:13:20,151][model][INFO] - Training step 49200 loss 0.22915148735046387
[2025-03-16 09:14:02,469][model][INFO] - Training step 49360 loss 0.11210321635007858
[2025-03-16 09:14:42,603][model][INFO] - Training step 49520 loss 0.03752227872610092
[2025-03-16 09:15:23,181][model][INFO] - Training step 49680 loss 0.25736454129219055
[2025-03-16 09:16:04,560][model][INFO] - Training step 49840 loss 0.3331497609615326
[2025-03-16 09:16:44,661][model][INFO] - Training step 50000 loss 0.03057555854320526
[2025-03-16 09:17:25,099][model][INFO] - Training step 50160 loss 0.014113038778305054
[2025-03-16 09:18:05,715][model][INFO] - Training step 50320 loss 0.01708623394370079
[2025-03-16 09:18:45,905][model][INFO] - Training step 50480 loss 0.008172931149601936
[2025-03-16 09:19:26,207][model][INFO] - Training step 50640 loss 0.0059256358072161674
[2025-03-16 09:25:04,158][model][INFO] - Training step 0 loss 0.020962700247764587
[2025-03-16 09:25:43,848][model][INFO] - Training step 160 loss 0.022765416651964188
[2025-03-16 09:26:25,077][model][INFO] - Training step 320 loss 0.0023088897578418255
[2025-03-16 09:27:04,064][model][INFO] - Training step 480 loss 0.12348394840955734
[2025-03-16 09:27:43,607][model][INFO] - Training step 640 loss 0.026689201593399048
[2025-03-16 09:28:22,982][model][INFO] - Training step 800 loss 0.26666051149368286
[2025-03-16 09:29:04,101][model][INFO] - Training step 960 loss 0.012869986705482006
[2025-03-16 09:29:42,540][model][INFO] - Training step 1120 loss 0.08164612203836441
[2025-03-16 09:30:22,670][model][INFO] - Training step 1280 loss 0.006863255053758621
[2025-03-16 09:31:02,941][model][INFO] - Training step 1440 loss 0.006809655111283064
[2025-03-16 09:31:41,983][model][INFO] - Training step 1600 loss 0.04285962134599686
[2025-03-16 09:32:22,494][model][INFO] - Training step 1760 loss 0.1432315707206726
[2025-03-16 09:33:02,671][model][INFO] - Training step 1920 loss 0.02744535356760025
[2025-03-16 09:33:42,684][model][INFO] - Training step 2080 loss 0.04467149078845978
[2025-03-16 09:34:22,721][model][INFO] - Training step 2240 loss 0.04705357551574707
[2025-03-16 09:35:02,685][model][INFO] - Training step 2400 loss 0.014011573046445847
[2025-03-16 09:35:42,586][model][INFO] - Training step 2560 loss 0.04516565054655075
[2025-03-16 09:36:23,255][model][INFO] - Training step 2720 loss 0.21087566018104553
[2025-03-16 09:37:02,019][model][INFO] - Training step 2880 loss 0.053317055106163025
[2025-03-16 09:37:42,070][model][INFO] - Training step 3040 loss 0.02784634381532669
[2025-03-16 09:38:22,425][model][INFO] - Training step 3200 loss 0.06383438408374786
[2025-03-16 09:39:03,316][model][INFO] - Training step 3360 loss 0.025372233241796494
[2025-03-16 09:39:42,620][model][INFO] - Training step 3520 loss 0.06009075045585632
[2025-03-16 09:40:22,822][model][INFO] - Training step 3680 loss 0.028636902570724487
[2025-03-16 09:41:03,005][model][INFO] - Training step 3840 loss 0.03008238971233368
[2025-03-16 09:41:43,816][model][INFO] - Training step 4000 loss 0.045759253203868866
[2025-03-16 09:42:26,527][model][INFO] - Training step 4160 loss 0.2632952332496643
[2025-03-16 09:43:05,798][model][INFO] - Training step 4320 loss 0.02379273995757103
[2025-03-16 09:43:45,645][model][INFO] - Training step 4480 loss 0.007594151422381401
[2025-03-16 09:44:26,774][model][INFO] - Training step 4640 loss 0.04537850618362427
[2025-03-16 09:45:04,901][model][INFO] - Training step 4800 loss 0.17743618786334991
[2025-03-16 09:45:44,558][model][INFO] - Training step 4960 loss 0.011082785204052925
[2025-03-16 09:46:25,682][model][INFO] - Training step 5120 loss 0.3030737042427063
[2025-03-16 09:47:06,346][model][INFO] - Training step 5280 loss 0.022606607526540756
[2025-03-16 09:47:47,685][model][INFO] - Training step 5440 loss 0.0721861720085144
[2025-03-16 09:48:27,831][model][INFO] - Training step 5600 loss 0.10981210321187973
[2025-03-16 09:49:07,991][model][INFO] - Training step 5760 loss 0.27346155047416687
[2025-03-16 09:49:47,907][model][INFO] - Training step 5920 loss 0.017946738749742508
[2025-03-16 09:50:27,760][model][INFO] - Training step 6080 loss 0.2552286684513092
[2025-03-16 09:51:08,238][model][INFO] - Training step 6240 loss 0.014748910441994667
[2025-03-16 09:51:48,892][model][INFO] - Training step 6400 loss 0.021363157778978348
[2025-03-16 09:52:28,225][model][INFO] - Training step 6560 loss 0.02442166581749916
[2025-03-16 09:53:08,673][model][INFO] - Training step 6720 loss 0.2743299603462219
[2025-03-16 09:53:50,788][model][INFO] - Training step 6880 loss 0.03901189938187599
[2025-03-16 09:54:30,988][model][INFO] - Training step 7040 loss 0.007165629416704178
[2025-03-16 09:55:10,834][model][INFO] - Training step 7200 loss 0.019577840343117714
[2025-03-16 09:55:50,111][model][INFO] - Training step 7360 loss 0.03235059976577759
[2025-03-16 09:56:29,981][model][INFO] - Training step 7520 loss 0.060099050402641296
[2025-03-16 09:57:10,593][model][INFO] - Training step 7680 loss 0.0033118363935500383
[2025-03-16 09:57:50,817][model][INFO] - Training step 7840 loss 0.022261817008256912
[2025-03-16 09:58:30,891][model][INFO] - Training step 8000 loss 0.029576603323221207
[2025-03-16 09:59:10,832][model][INFO] - Training step 8160 loss 0.024998042732477188
[2025-03-16 09:59:51,495][model][INFO] - Training step 8320 loss 0.006272232159972191
[2025-03-16 10:00:30,781][model][INFO] - Training step 8480 loss 0.1496836394071579
[2025-03-16 10:01:11,849][model][INFO] - Training step 8640 loss 0.11293768882751465
[2025-03-16 10:01:51,293][model][INFO] - Training step 8800 loss 0.25522321462631226
[2025-03-16 10:02:31,686][model][INFO] - Training step 8960 loss 0.6568513512611389
[2025-03-16 10:03:12,294][model][INFO] - Training step 9120 loss 0.09537246823310852
[2025-03-16 10:03:52,330][model][INFO] - Training step 9280 loss 0.022918716073036194
[2025-03-16 10:04:33,226][model][INFO] - Training step 9440 loss 0.007841822691261768
[2025-03-16 10:05:12,648][model][INFO] - Training step 9600 loss 0.005558430682867765
[2025-03-16 10:05:53,960][model][INFO] - Training step 9760 loss 0.002132823457941413
[2025-03-16 10:06:34,633][model][INFO] - Training step 9920 loss 0.04113662987947464
[2025-03-16 10:07:17,157][model][INFO] - Training step 10080 loss 0.25516486167907715
[2025-03-16 10:07:57,188][model][INFO] - Training step 10240 loss 0.016044702380895615
[2025-03-16 10:08:37,412][model][INFO] - Training step 10400 loss 0.017193792387843132
[2025-03-16 10:09:18,085][model][INFO] - Training step 10560 loss 0.031555742025375366
[2025-03-16 10:09:57,914][model][INFO] - Training step 10720 loss 0.017230864614248276
[2025-03-16 10:10:37,165][model][INFO] - Training step 10880 loss 0.03923698514699936
[2025-03-16 10:11:16,961][model][INFO] - Training step 11040 loss 0.030076129361987114
[2025-03-16 10:11:56,637][model][INFO] - Training step 11200 loss 0.005237632431089878
[2025-03-16 10:12:36,376][model][INFO] - Training step 11360 loss 0.0438365638256073
[2025-03-16 10:13:17,640][model][INFO] - Training step 11520 loss 0.030287031084299088
[2025-03-16 10:13:58,912][model][INFO] - Training step 11680 loss 0.004179610870778561
[2025-03-16 10:14:39,701][model][INFO] - Training step 11840 loss 0.0020483219996094704
[2025-03-16 10:15:20,140][model][INFO] - Training step 12000 loss 0.030843820422887802
[2025-03-16 10:15:59,170][model][INFO] - Training step 12160 loss 0.023595258593559265
[2025-03-16 10:16:37,678][model][INFO] - Training step 12320 loss 0.0859639048576355
[2025-03-16 10:17:18,568][model][INFO] - Training step 12480 loss 0.029588617384433746
[2025-03-16 10:17:57,304][model][INFO] - Training step 12640 loss 0.02310994826257229
[2025-03-16 10:18:37,212][model][INFO] - Training step 12800 loss 0.2502754330635071
[2025-03-16 10:19:17,009][model][INFO] - Training step 12960 loss 0.012747230008244514
[2025-03-16 10:19:56,207][model][INFO] - Training step 13120 loss 0.03354695811867714
[2025-03-16 10:20:35,190][model][INFO] - Training step 13280 loss 0.025744710117578506
[2025-03-16 10:21:14,541][model][INFO] - Training step 13440 loss 0.07417099922895432
[2025-03-16 10:21:53,991][model][INFO] - Training step 13600 loss 0.04229141026735306
[2025-03-16 10:22:34,373][model][INFO] - Training step 13760 loss 0.07077077031135559
[2025-03-16 10:23:14,249][model][INFO] - Training step 13920 loss 0.1700797975063324
[2025-03-16 10:23:54,876][model][INFO] - Training step 14080 loss 0.04818221926689148
[2025-03-16 10:24:34,505][model][INFO] - Training step 14240 loss 0.09782347083091736
[2025-03-16 10:25:15,741][model][INFO] - Training step 14400 loss 0.007698878645896912
[2025-03-16 10:25:55,664][model][INFO] - Training step 14560 loss 0.026357635855674744
[2025-03-16 10:26:34,571][model][INFO] - Training step 14720 loss 0.020016271620988846
[2025-03-16 10:27:14,560][model][INFO] - Training step 14880 loss 0.2141910046339035
[2025-03-16 10:27:55,955][model][INFO] - Training step 15040 loss 0.03131532296538353
[2025-03-16 10:28:35,713][model][INFO] - Training step 15200 loss 0.016538936644792557
[2025-03-16 10:29:16,437][model][INFO] - Training step 15360 loss 0.004554784391075373
[2025-03-16 10:29:57,742][model][INFO] - Training step 15520 loss 0.014767734333872795
[2025-03-16 10:30:37,994][model][INFO] - Training step 15680 loss 0.0167146697640419
[2025-03-16 10:31:19,477][model][INFO] - Training step 15840 loss 0.24466024339199066
[2025-03-16 10:31:59,049][model][INFO] - Training step 16000 loss 0.012177906930446625
[2025-03-16 10:32:40,744][model][INFO] - Training step 16160 loss 0.049830179661512375
[2025-03-16 10:33:20,295][model][INFO] - Training step 16320 loss 0.2477613389492035
[2025-03-16 10:34:00,154][model][INFO] - Training step 16480 loss 0.01787269487977028
[2025-03-16 10:34:39,352][model][INFO] - Training step 16640 loss 0.3815394341945648
[2025-03-16 10:35:19,417][model][INFO] - Training step 16800 loss 0.26984521746635437
[2025-03-16 10:35:59,891][model][INFO] - Training step 16960 loss 0.01882053166627884
[2025-03-16 10:36:38,547][model][INFO] - Training step 17120 loss 0.039075374603271484
[2025-03-16 10:37:18,761][model][INFO] - Training step 17280 loss 0.08046820759773254
[2025-03-16 10:37:58,471][model][INFO] - Training step 17440 loss 0.05930415540933609
[2025-03-16 10:38:39,684][model][INFO] - Training step 17600 loss 0.029578683897852898
[2025-03-16 10:39:19,947][model][INFO] - Training step 17760 loss 0.028991136699914932
[2025-03-16 10:39:59,685][model][INFO] - Training step 17920 loss 0.1545027494430542
[2025-03-16 10:40:40,200][model][INFO] - Training step 18080 loss 0.02317427471280098
[2025-03-16 10:41:20,211][model][INFO] - Training step 18240 loss 0.0054803756065666676
[2025-03-16 10:42:01,565][model][INFO] - Training step 18400 loss 0.03113357350230217
[2025-03-16 10:42:40,760][model][INFO] - Training step 18560 loss 0.0067459275014698505
[2025-03-16 10:43:21,097][model][INFO] - Training step 18720 loss 0.008099234662950039
[2025-03-16 10:44:02,626][model][INFO] - Training step 18880 loss 0.11370112001895905
[2025-03-16 10:44:42,769][model][INFO] - Training step 19040 loss 0.044080667197704315
[2025-03-16 10:45:21,391][model][INFO] - Training step 19200 loss 0.041338689625263214
[2025-03-16 10:46:01,186][model][INFO] - Training step 19360 loss 0.021756766363978386
[2025-03-16 10:46:40,411][model][INFO] - Training step 19520 loss 0.019369633868336678
[2025-03-16 10:47:19,684][model][INFO] - Training step 19680 loss 0.0329112783074379
[2025-03-16 10:47:59,864][model][INFO] - Training step 19840 loss 0.0051773665472865105
[2025-03-16 10:48:40,605][model][INFO] - Training step 20000 loss 0.0035072299651801586
[2025-03-16 10:49:20,486][model][INFO] - Training step 20160 loss 0.04320984333753586
[2025-03-16 10:50:01,039][model][INFO] - Training step 20320 loss 0.25558751821517944
[2025-03-16 10:50:41,676][model][INFO] - Training step 20480 loss 0.03391331434249878
[2025-03-16 10:51:21,558][model][INFO] - Training step 20640 loss 0.021287959069013596
[2025-03-16 10:52:01,049][model][INFO] - Training step 20800 loss 0.10697004199028015
[2025-03-16 10:52:39,979][model][INFO] - Training step 20960 loss 0.016616586595773697
[2025-03-16 10:53:21,700][model][INFO] - Training step 21120 loss 0.05779486149549484
[2025-03-16 10:54:02,442][model][INFO] - Training step 21280 loss 0.037932880222797394
[2025-03-16 10:54:42,521][model][INFO] - Training step 21440 loss 0.028540898114442825
[2025-03-16 10:55:21,630][model][INFO] - Training step 21600 loss 0.05092296749353409
[2025-03-16 10:56:00,976][model][INFO] - Training step 21760 loss 0.09333306550979614
[2025-03-16 10:56:41,741][model][INFO] - Training step 21920 loss 0.037551891058683395
[2025-03-16 10:57:21,650][model][INFO] - Training step 22080 loss 0.00895642302930355
[2025-03-16 10:58:02,748][model][INFO] - Training step 22240 loss 0.03534596785902977
[2025-03-16 10:58:42,551][model][INFO] - Training step 22400 loss 0.09658867120742798
[2025-03-16 10:59:22,592][model][INFO] - Training step 22560 loss 0.022064823657274246
[2025-03-16 11:00:02,576][model][INFO] - Training step 22720 loss 0.009907180443406105
[2025-03-16 11:00:42,800][model][INFO] - Training step 22880 loss 0.005986317992210388
[2025-03-16 11:01:22,386][model][INFO] - Training step 23040 loss 0.24933111667633057
[2025-03-16 11:02:02,328][model][INFO] - Training step 23200 loss 0.03413480520248413
[2025-03-16 11:02:41,248][model][INFO] - Training step 23360 loss 0.030122365802526474
[2025-03-16 11:03:20,877][model][INFO] - Training step 23520 loss 0.037418290972709656
[2025-03-16 11:04:01,772][model][INFO] - Training step 23680 loss 0.02218526229262352
[2025-03-16 11:04:43,843][model][INFO] - Training step 23840 loss 0.24959200620651245
[2025-03-16 11:05:23,403][model][INFO] - Training step 24000 loss 0.25387755036354065
[2025-03-16 11:06:01,952][model][INFO] - Training step 24160 loss 0.024031303822994232
[2025-03-16 11:06:42,099][model][INFO] - Training step 24320 loss 0.03278469666838646
[2025-03-16 11:07:21,459][model][INFO] - Training step 24480 loss 0.008112248033285141
[2025-03-16 11:08:00,943][model][INFO] - Training step 24640 loss 0.096645787358284
[2025-03-16 11:08:41,132][model][INFO] - Training step 24800 loss 0.03405985236167908
[2025-03-16 11:09:21,151][model][INFO] - Training step 24960 loss 0.2513313591480255
[2025-03-16 11:09:59,850][model][INFO] - Training step 25120 loss 0.12760110199451447
[2025-03-16 11:10:39,925][model][INFO] - Training step 25280 loss 0.021304402500391006
[2025-03-16 11:11:18,922][model][INFO] - Training step 25440 loss 0.01647932454943657
[2025-03-16 11:11:59,229][model][INFO] - Training step 25600 loss 0.03229072690010071
[2025-03-16 11:12:38,922][model][INFO] - Training step 25760 loss 0.006478487979620695
[2025-03-16 11:13:20,349][model][INFO] - Training step 25920 loss 0.005144987255334854
[2025-03-16 11:13:59,837][model][INFO] - Training step 26080 loss 0.05448353290557861
[2025-03-16 11:14:40,426][model][INFO] - Training step 26240 loss 0.019140169024467468
[2025-03-16 11:15:20,327][model][INFO] - Training step 26400 loss 0.01768459752202034
[2025-03-16 11:16:00,282][model][INFO] - Training step 26560 loss 0.012796271592378616
[2025-03-16 11:16:40,856][model][INFO] - Training step 26720 loss 0.011319609358906746
[2025-03-16 11:17:20,951][model][INFO] - Training step 26880 loss 0.005140493158251047
[2025-03-16 11:17:59,920][model][INFO] - Training step 27040 loss 0.005393209867179394
[2025-03-16 11:18:40,109][model][INFO] - Training step 27200 loss 0.019680894911289215
[2025-03-16 11:19:20,244][model][INFO] - Training step 27360 loss 0.030085977166891098
[2025-03-16 11:19:59,177][model][INFO] - Training step 27520 loss 0.2586246132850647
[2025-03-16 11:20:38,168][model][INFO] - Training step 27680 loss 0.0444374680519104
[2025-03-16 11:21:18,794][model][INFO] - Training step 27840 loss 0.24677959084510803
[2025-03-16 11:22:00,282][model][INFO] - Training step 28000 loss 0.023470919579267502
[2025-03-16 11:22:39,271][model][INFO] - Training step 28160 loss 0.05295063555240631
[2025-03-16 11:23:18,246][model][INFO] - Training step 28320 loss 0.005735006183385849
[2025-03-16 11:23:59,525][model][INFO] - Training step 28480 loss 0.028677374124526978
[2025-03-16 11:24:38,711][model][INFO] - Training step 28640 loss 0.23891691863536835
[2025-03-16 11:25:17,699][model][INFO] - Training step 28800 loss 0.03196506202220917
[2025-03-16 11:25:58,273][model][INFO] - Training step 28960 loss 0.005100381560623646
[2025-03-16 11:26:36,926][model][INFO] - Training step 29120 loss 0.04240339249372482
[2025-03-16 11:27:18,427][model][INFO] - Training step 29280 loss 0.2740011215209961
[2025-03-16 11:27:58,306][model][INFO] - Training step 29440 loss 0.019396228715777397
[2025-03-16 11:28:37,712][model][INFO] - Training step 29600 loss 0.07157047092914581
[2025-03-16 11:29:19,231][model][INFO] - Training step 29760 loss 0.03301539272069931
[2025-03-16 11:29:58,357][model][INFO] - Training step 29920 loss 0.24911588430404663
[2025-03-16 11:30:37,984][model][INFO] - Training step 30080 loss 0.2484460473060608
[2025-03-16 11:31:17,207][model][INFO] - Training step 30240 loss 0.07035528123378754
[2025-03-16 11:31:57,382][model][INFO] - Training step 30400 loss 0.030489251017570496
[2025-03-16 11:32:37,593][model][INFO] - Training step 30560 loss 0.017587680369615555
[2025-03-16 11:33:17,381][model][INFO] - Training step 30720 loss 0.008176987059414387
[2025-03-16 11:33:56,487][model][INFO] - Training step 30880 loss 0.25774848461151123
[2025-03-16 11:34:35,444][model][INFO] - Training step 31040 loss 0.05576770007610321
[2025-03-16 11:35:15,597][model][INFO] - Training step 31200 loss 0.24309822916984558
[2025-03-16 11:35:55,514][model][INFO] - Training step 31360 loss 0.022146841511130333
[2025-03-16 11:36:35,887][model][INFO] - Training step 31520 loss 0.05346616357564926
[2025-03-16 11:37:16,038][model][INFO] - Training step 31680 loss 0.2424626648426056
[2025-03-16 11:37:56,728][model][INFO] - Training step 31840 loss 0.014936667867004871
[2025-03-16 11:38:36,446][model][INFO] - Training step 32000 loss 0.030786778777837753
[2025-03-16 11:39:15,899][model][INFO] - Training step 32160 loss 0.10186983644962311
[2025-03-16 11:39:56,059][model][INFO] - Training step 32320 loss 0.06210104748606682
[2025-03-16 11:40:37,883][model][INFO] - Training step 32480 loss 0.25643277168273926
[2025-03-16 11:41:17,729][model][INFO] - Training step 32640 loss 0.11218554526567459
[2025-03-16 11:41:58,069][model][INFO] - Training step 32800 loss 0.0037086079828441143
[2025-03-16 11:42:37,968][model][INFO] - Training step 32960 loss 0.003583534387871623
[2025-03-16 11:43:17,881][model][INFO] - Training step 33120 loss 0.24878597259521484
[2025-03-16 11:43:59,267][model][INFO] - Training step 33280 loss 0.14004845917224884
[2025-03-16 11:44:40,010][model][INFO] - Training step 33440 loss 0.027516866102814674
[2025-03-16 11:45:20,425][model][INFO] - Training step 33600 loss 0.005726419389247894
[2025-03-16 11:46:00,558][model][INFO] - Training step 33760 loss 0.038276974111795425
[2025-03-16 11:46:40,048][model][INFO] - Training step 33920 loss 0.021609308198094368
[2025-03-16 11:47:20,365][model][INFO] - Training step 34080 loss 0.005442054942250252
[2025-03-16 11:48:00,599][model][INFO] - Training step 34240 loss 0.02327488362789154
[2025-03-16 11:48:41,224][model][INFO] - Training step 34400 loss 0.025654261931777
[2025-03-16 11:49:21,328][model][INFO] - Training step 34560 loss 0.1672443449497223
[2025-03-16 11:50:01,831][model][INFO] - Training step 34720 loss 0.017098145559430122
[2025-03-16 11:50:41,308][model][INFO] - Training step 34880 loss 0.24713440239429474
[2025-03-16 11:51:22,979][model][INFO] - Training step 35040 loss 0.002921637147665024
[2025-03-16 11:52:02,825][model][INFO] - Training step 35200 loss 0.2686440944671631
[2025-03-16 11:52:42,542][model][INFO] - Training step 35360 loss 0.24867326021194458
[2025-03-16 11:53:23,418][model][INFO] - Training step 35520 loss 0.03222879022359848
[2025-03-16 11:54:04,180][model][INFO] - Training step 35680 loss 0.25558745861053467
[2025-03-16 11:54:44,030][model][INFO] - Training step 35840 loss 0.061618365347385406
[2025-03-16 11:55:23,555][model][INFO] - Training step 36000 loss 0.021548274904489517
[2025-03-16 11:56:04,481][model][INFO] - Training step 36160 loss 0.039380431175231934
[2025-03-16 11:56:44,796][model][INFO] - Training step 36320 loss 0.015313755720853806
[2025-03-16 11:57:25,329][model][INFO] - Training step 36480 loss 0.08174828439950943
[2025-03-16 11:58:05,135][model][INFO] - Training step 36640 loss 0.01852685585618019
[2025-03-16 11:58:46,782][model][INFO] - Training step 36800 loss 0.022237636148929596
[2025-03-16 11:59:27,975][model][INFO] - Training step 36960 loss 0.008990930393338203
[2025-03-16 12:00:09,309][model][INFO] - Training step 37120 loss 0.015832174569368362
[2025-03-16 12:00:49,717][model][INFO] - Training step 37280 loss 0.008748535998165607
[2025-03-16 12:01:31,402][model][INFO] - Training step 37440 loss 0.038015998899936676
[2025-03-16 12:02:11,900][model][INFO] - Training step 37600 loss 0.05785585194826126
[2025-03-16 12:02:51,459][model][INFO] - Training step 37760 loss 0.006361710838973522
[2025-03-16 12:03:30,569][model][INFO] - Training step 37920 loss 0.011991657316684723
[2025-03-16 12:04:10,554][model][INFO] - Training step 38080 loss 0.007879779674112797
[2025-03-16 12:04:51,442][model][INFO] - Training step 38240 loss 0.25214114785194397
[2025-03-16 12:05:31,545][model][INFO] - Training step 38400 loss 0.025282632559537888
[2025-03-16 12:06:10,196][model][INFO] - Training step 38560 loss 0.02029544487595558
[2025-03-16 12:06:49,697][model][INFO] - Training step 38720 loss 0.25611376762390137
[2025-03-16 12:07:29,340][model][INFO] - Training step 38880 loss 0.02943911775946617
[2025-03-16 12:08:09,191][model][INFO] - Training step 39040 loss 0.02355865389108658
[2025-03-16 12:08:48,672][model][INFO] - Training step 39200 loss 0.03628220409154892
[2025-03-16 12:09:29,329][model][INFO] - Training step 39360 loss 0.26510268449783325
[2025-03-16 12:10:09,650][model][INFO] - Training step 39520 loss 0.004199942108243704
[2025-03-16 12:10:48,807][model][INFO] - Training step 39680 loss 0.26743751764297485
[2025-03-16 12:11:29,146][model][INFO] - Training step 39840 loss 0.005287745967507362
[2025-03-16 12:12:08,445][model][INFO] - Training step 40000 loss 0.03020036593079567
[2025-03-16 12:12:49,501][model][INFO] - Training step 40160 loss 0.1291070282459259
[2025-03-16 12:13:30,131][model][INFO] - Training step 40320 loss 0.041765764355659485
[2025-03-16 12:14:10,662][model][INFO] - Training step 40480 loss 0.2481657713651657
[2025-03-16 12:14:50,933][model][INFO] - Training step 40640 loss 0.026170769706368446
[2025-03-16 12:15:30,017][model][INFO] - Training step 40800 loss 0.018760165199637413
[2025-03-16 12:16:10,737][model][INFO] - Training step 40960 loss 0.01748698577284813
[2025-03-16 12:16:51,265][model][INFO] - Training step 41120 loss 0.012372465804219246
[2025-03-16 12:17:31,603][model][INFO] - Training step 41280 loss 0.026741579174995422
[2025-03-16 12:18:11,698][model][INFO] - Training step 41440 loss 0.007431071251630783
[2025-03-16 12:18:53,554][model][INFO] - Training step 41600 loss 0.03215470910072327
[2025-03-16 12:19:35,162][model][INFO] - Training step 41760 loss 0.0457259863615036
[2025-03-16 12:20:16,025][model][INFO] - Training step 41920 loss 0.031077170744538307
[2025-03-16 12:20:56,530][model][INFO] - Training step 42080 loss 0.0063804881647229195
[2025-03-16 12:21:35,748][model][INFO] - Training step 42240 loss 0.16012148559093475
[2025-03-16 12:22:14,502][model][INFO] - Training step 42400 loss 0.029105501249432564
[2025-03-16 12:22:55,898][model][INFO] - Training step 42560 loss 0.2453230321407318
[2025-03-16 12:23:35,119][model][INFO] - Training step 42720 loss 0.014311268925666809
[2025-03-16 12:24:14,839][model][INFO] - Training step 42880 loss 0.2467561960220337
[2025-03-16 12:24:53,134][model][INFO] - Training step 43040 loss 0.016283849254250526
[2025-03-16 12:25:34,519][model][INFO] - Training step 43200 loss 0.3379097878932953
[2025-03-16 12:26:15,662][model][INFO] - Training step 43360 loss 0.03926496207714081
[2025-03-16 12:26:55,166][model][INFO] - Training step 43520 loss 0.0701739713549614
[2025-03-16 12:27:35,036][model][INFO] - Training step 43680 loss 0.029734883457422256
[2025-03-16 12:28:16,187][model][INFO] - Training step 43840 loss 0.0880478248000145
[2025-03-16 12:28:56,862][model][INFO] - Training step 44000 loss 0.0233038030564785
[2025-03-16 12:29:36,433][model][INFO] - Training step 44160 loss 0.009594263508915901
[2025-03-16 12:30:15,556][model][INFO] - Training step 44320 loss 0.24882487952709198
[2025-03-16 12:30:57,032][model][INFO] - Training step 44480 loss 0.006483648903667927
[2025-03-16 12:31:37,123][model][INFO] - Training step 44640 loss 0.021881375461816788
[2025-03-16 12:32:17,924][model][INFO] - Training step 44800 loss 0.07291507720947266
[2025-03-16 12:32:57,914][model][INFO] - Training step 44960 loss 0.02086590602993965
[2025-03-16 12:33:37,853][model][INFO] - Training step 45120 loss 0.046187542378902435
[2025-03-16 12:34:19,378][model][INFO] - Training step 45280 loss 0.25216013193130493
[2025-03-16 12:34:59,928][model][INFO] - Training step 45440 loss 0.006566652096807957
[2025-03-16 12:35:39,061][model][INFO] - Training step 45600 loss 0.020504478365182877
[2025-03-16 12:36:20,778][model][INFO] - Training step 45760 loss 0.25129443407058716
[2025-03-16 12:37:00,568][model][INFO] - Training step 45920 loss 0.021845867857336998
[2025-03-16 12:37:40,782][model][INFO] - Training step 46080 loss 0.002387690357863903
[2025-03-16 12:38:21,527][model][INFO] - Training step 46240 loss 0.026558905839920044
[2025-03-16 12:39:02,128][model][INFO] - Training step 46400 loss 0.011037403717637062
[2025-03-16 12:39:42,170][model][INFO] - Training step 46560 loss 0.2627677321434021
[2025-03-16 12:40:23,138][model][INFO] - Training step 46720 loss 0.24828732013702393
[2025-03-16 12:41:03,088][model][INFO] - Training step 46880 loss 0.02079758793115616
[2025-03-16 12:41:42,563][model][INFO] - Training step 47040 loss 0.08346693217754364
[2025-03-16 12:42:21,788][model][INFO] - Training step 47200 loss 0.010718229226768017
[2025-03-16 12:43:01,650][model][INFO] - Training step 47360 loss 0.01984213851392269
[2025-03-16 12:43:41,248][model][INFO] - Training step 47520 loss 0.011892812326550484
[2025-03-16 12:44:21,199][model][INFO] - Training step 47680 loss 0.027478519827127457
[2025-03-16 12:44:59,685][model][INFO] - Training step 47840 loss 0.2607850432395935
[2025-03-16 12:45:40,674][model][INFO] - Training step 48000 loss 0.06042691320180893
[2025-03-16 12:46:21,556][model][INFO] - Training step 48160 loss 0.004724346101284027
[2025-03-16 12:47:00,742][model][INFO] - Training step 48320 loss 0.259563148021698
[2025-03-16 12:47:40,447][model][INFO] - Training step 48480 loss 0.0360415056347847
[2025-03-16 12:48:20,771][model][INFO] - Training step 48640 loss 0.001971626188606024
[2025-03-16 12:49:01,320][model][INFO] - Training step 48800 loss 0.020659342408180237
[2025-03-16 12:49:41,505][model][INFO] - Training step 48960 loss 0.006564106792211533
[2025-03-16 12:50:23,281][model][INFO] - Training step 49120 loss 0.014896269887685776
[2025-03-16 12:51:04,993][model][INFO] - Training step 49280 loss 0.02052856609225273
[2025-03-16 12:51:43,734][model][INFO] - Training step 49440 loss 0.024695221334695816
[2025-03-16 12:52:24,236][model][INFO] - Training step 49600 loss 0.045464541763067245
[2025-03-16 12:53:05,611][model][INFO] - Training step 49760 loss 0.06013716012239456
[2025-03-16 12:53:45,406][model][INFO] - Training step 49920 loss 0.017514511942863464
[2025-03-16 12:54:25,159][model][INFO] - Training step 50080 loss 0.0060768043622374535
[2025-03-16 12:55:04,191][model][INFO] - Training step 50240 loss 0.014267963357269764
[2025-03-16 12:55:43,805][model][INFO] - Training step 50400 loss 0.008945493958890438
[2025-03-16 12:56:24,493][model][INFO] - Training step 50560 loss 0.011515913531184196
[2025-03-16 12:57:03,491][model][INFO] - Training step 50720 loss 0.03298228979110718
[2025-03-16 13:02:40,899][model][INFO] - Training step 80 loss 0.043314285576343536
[2025-03-16 13:03:21,787][model][INFO] - Training step 240 loss 0.022536002099514008
[2025-03-16 13:04:02,175][model][INFO] - Training step 400 loss 0.026379484683275223
[2025-03-16 13:04:41,599][model][INFO] - Training step 560 loss 0.021418791264295578
[2025-03-16 13:05:21,406][model][INFO] - Training step 720 loss 0.0046515269204974174
[2025-03-16 13:06:02,546][model][INFO] - Training step 880 loss 0.25433796644210815
[2025-03-16 13:06:42,209][model][INFO] - Training step 1040 loss 0.013405891135334969
[2025-03-16 13:07:22,580][model][INFO] - Training step 1200 loss 0.022593360394239426
[2025-03-16 13:08:03,184][model][INFO] - Training step 1360 loss 0.04939637333154678
[2025-03-16 13:08:43,127][model][INFO] - Training step 1520 loss 0.004121721256524324
[2025-03-16 13:09:23,551][model][INFO] - Training step 1680 loss 0.017812082543969154
[2025-03-16 13:10:02,851][model][INFO] - Training step 1840 loss 0.07320255041122437
[2025-03-16 13:10:43,022][model][INFO] - Training step 2000 loss 0.055082034319639206
[2025-03-16 13:11:22,726][model][INFO] - Training step 2160 loss 0.019037431105971336
[2025-03-16 13:12:02,280][model][INFO] - Training step 2320 loss 0.01545792818069458
[2025-03-16 13:12:41,878][model][INFO] - Training step 2480 loss 0.25081998109817505
[2025-03-16 13:13:22,015][model][INFO] - Training step 2640 loss 0.03229585289955139
[2025-03-16 13:14:01,609][model][INFO] - Training step 2800 loss 0.10776415467262268
[2025-03-16 13:14:42,346][model][INFO] - Training step 2960 loss 0.004583267495036125
[2025-03-16 13:15:22,417][model][INFO] - Training step 3120 loss 0.43962621688842773
[2025-03-16 13:16:03,336][model][INFO] - Training step 3280 loss 0.2110588550567627
[2025-03-16 13:16:43,195][model][INFO] - Training step 3440 loss 0.082156702876091
[2025-03-16 13:17:22,063][model][INFO] - Training step 3600 loss 0.015481410548090935
[2025-03-16 13:18:00,753][model][INFO] - Training step 3760 loss 0.02077394351363182
[2025-03-16 13:18:41,978][model][INFO] - Training step 3920 loss 0.037339404225349426
[2025-03-16 13:19:22,105][model][INFO] - Training step 4080 loss 0.028743188828229904
[2025-03-16 13:20:03,670][model][INFO] - Training step 4240 loss 0.24893784523010254
[2025-03-16 13:20:43,642][model][INFO] - Training step 4400 loss 0.02241940051317215
[2025-03-16 13:21:23,250][model][INFO] - Training step 4560 loss 0.019824722781777382
[2025-03-16 13:22:04,357][model][INFO] - Training step 4720 loss 0.050862766802310944
[2025-03-16 13:22:43,004][model][INFO] - Training step 4880 loss 0.03186167776584625
[2025-03-16 13:23:23,541][model][INFO] - Training step 5040 loss 0.04095946624875069
[2025-03-16 13:24:04,022][model][INFO] - Training step 5200 loss 0.017991438508033752
[2025-03-16 13:24:44,971][model][INFO] - Training step 5360 loss 0.15340650081634521
[2025-03-16 13:25:25,429][model][INFO] - Training step 5520 loss 0.03420387953519821
[2025-03-16 13:26:04,846][model][INFO] - Training step 5680 loss 0.04251287877559662
[2025-03-16 13:26:44,240][model][INFO] - Training step 5840 loss 0.018940523266792297
[2025-03-16 13:27:24,372][model][INFO] - Training step 6000 loss 0.009425502270460129
[2025-03-16 13:28:03,756][model][INFO] - Training step 6160 loss 0.03660499304533005
[2025-03-16 13:28:44,506][model][INFO] - Training step 6320 loss 0.0243559367954731
[2025-03-16 13:29:24,955][model][INFO] - Training step 6480 loss 0.02327370084822178
[2025-03-16 13:30:05,131][model][INFO] - Training step 6640 loss 0.005779310129582882
[2025-03-16 13:30:44,692][model][INFO] - Training step 6800 loss 0.016447607427835464
[2025-03-16 13:31:24,190][model][INFO] - Training step 6960 loss 0.07200044393539429
[2025-03-16 13:32:05,249][model][INFO] - Training step 7120 loss 0.04207585006952286
[2025-03-16 13:32:46,093][model][INFO] - Training step 7280 loss 0.014128904789686203
[2025-03-16 13:33:25,646][model][INFO] - Training step 7440 loss 0.01948588341474533
[2025-03-16 13:34:05,190][model][INFO] - Training step 7600 loss 0.23823758959770203
[2025-03-16 13:34:46,259][model][INFO] - Training step 7760 loss 0.03837394714355469
[2025-03-16 13:35:25,976][model][INFO] - Training step 7920 loss 0.2146872878074646
[2025-03-16 13:36:06,881][model][INFO] - Training step 8080 loss 0.09573222696781158
[2025-03-16 13:36:45,081][model][INFO] - Training step 8240 loss 0.2668808102607727
[2025-03-16 13:37:24,975][model][INFO] - Training step 8400 loss 0.2492857575416565
[2025-03-16 13:38:03,155][model][INFO] - Training step 8560 loss 0.021142400801181793
[2025-03-16 13:38:43,582][model][INFO] - Training step 8720 loss 0.2516646683216095
[2025-03-16 13:39:23,249][model][INFO] - Training step 8880 loss 0.03264226019382477
[2025-03-16 13:40:03,581][model][INFO] - Training step 9040 loss 0.011148140765726566
[2025-03-16 13:40:41,307][model][INFO] - Training step 9200 loss 0.018728315830230713
[2025-03-16 13:41:20,453][model][INFO] - Training step 9360 loss 0.024767901748418808
[2025-03-16 13:42:01,580][model][INFO] - Training step 9520 loss 0.07863381505012512
[2025-03-16 13:42:42,472][model][INFO] - Training step 9680 loss 0.031127288937568665
[2025-03-16 13:43:22,202][model][INFO] - Training step 9840 loss 0.04113873094320297
[2025-03-16 13:44:02,851][model][INFO] - Training step 10000 loss 0.01169666275382042
[2025-03-16 13:44:43,971][model][INFO] - Training step 10160 loss 0.02106304280459881
[2025-03-16 13:45:23,638][model][INFO] - Training step 10320 loss 0.25056543946266174
[2025-03-16 13:46:02,993][model][INFO] - Training step 10480 loss 0.24665150046348572
[2025-03-16 13:46:44,083][model][INFO] - Training step 10640 loss 0.022931989282369614
[2025-03-16 13:47:22,429][model][INFO] - Training step 10800 loss 0.25371843576431274
[2025-03-16 13:48:01,817][model][INFO] - Training step 10960 loss 0.05934028699994087
[2025-03-16 13:48:41,652][model][INFO] - Training step 11120 loss 0.005496876314282417
[2025-03-16 13:49:21,579][model][INFO] - Training step 11280 loss 0.01969957910478115
[2025-03-16 13:50:01,984][model][INFO] - Training step 11440 loss 0.0335870087146759
[2025-03-16 13:50:43,132][model][INFO] - Training step 11600 loss 0.01342778466641903
[2025-03-16 13:51:24,491][model][INFO] - Training step 11760 loss 0.028504623100161552
[2025-03-16 13:52:03,097][model][INFO] - Training step 11920 loss 0.005863819271326065
[2025-03-16 13:52:43,881][model][INFO] - Training step 12080 loss 0.02965271845459938
[2025-03-16 13:53:22,646][model][INFO] - Training step 12240 loss 0.008874138817191124
[2025-03-16 13:54:02,066][model][INFO] - Training step 12400 loss 0.01877257227897644
[2025-03-16 13:54:42,561][model][INFO] - Training step 12560 loss 0.0029233936220407486
[2025-03-16 13:55:21,322][model][INFO] - Training step 12720 loss 0.23651017248630524
[2025-03-16 13:56:01,579][model][INFO] - Training step 12880 loss 0.0563773512840271
[2025-03-16 13:56:40,131][model][INFO] - Training step 13040 loss 0.024860551580786705
[2025-03-16 13:57:20,452][model][INFO] - Training step 13200 loss 0.026379931718111038
[2025-03-16 13:58:00,489][model][INFO] - Training step 13360 loss 0.046789996325969696
[2025-03-16 13:58:40,183][model][INFO] - Training step 13520 loss 0.006814752239733934
[2025-03-16 13:59:21,531][model][INFO] - Training step 13680 loss 0.0037965732626616955
[2025-03-16 14:00:02,280][model][INFO] - Training step 13840 loss 0.07730130851268768
[2025-03-16 14:00:42,817][model][INFO] - Training step 14000 loss 0.025555741041898727
[2025-03-16 14:01:21,533][model][INFO] - Training step 14160 loss 0.07729978859424591
[2025-03-16 14:02:02,594][model][INFO] - Training step 14320 loss 0.016240734606981277
[2025-03-16 14:02:43,404][model][INFO] - Training step 14480 loss 0.017361333593726158
[2025-03-16 14:03:23,210][model][INFO] - Training step 14640 loss 0.023710379377007484
[2025-03-16 14:04:02,465][model][INFO] - Training step 14800 loss 0.0295771025121212
[2025-03-16 14:04:41,933][model][INFO] - Training step 14960 loss 0.016950273886322975
[2025-03-16 14:05:22,074][model][INFO] - Training step 15120 loss 0.10406503081321716
[2025-03-16 14:06:00,499][model][INFO] - Training step 15280 loss 0.02981121838092804
[2025-03-16 14:06:40,495][model][INFO] - Training step 15440 loss 0.015402723103761673
[2025-03-16 14:07:22,464][model][INFO] - Training step 15600 loss 0.05224939435720444
[2025-03-16 14:08:03,169][model][INFO] - Training step 15760 loss 0.02483386918902397
[2025-03-16 14:08:42,928][model][INFO] - Training step 15920 loss 0.24662643671035767
[2025-03-16 14:09:24,921][model][INFO] - Training step 16080 loss 0.07695001363754272
[2025-03-16 14:10:07,325][model][INFO] - Training step 16240 loss 0.0276957917958498
[2025-03-16 14:10:47,871][model][INFO] - Training step 16400 loss 0.04779475927352905
[2025-03-16 14:11:29,567][model][INFO] - Training step 16560 loss 0.045108530670404434
[2025-03-16 14:12:10,454][model][INFO] - Training step 16720 loss 0.02443116530776024
[2025-03-16 14:12:51,274][model][INFO] - Training step 16880 loss 0.022854197770357132
[2025-03-16 14:13:32,137][model][INFO] - Training step 17040 loss 0.03393641486763954
[2025-03-16 14:14:12,145][model][INFO] - Training step 17200 loss 0.005474396049976349
[2025-03-16 14:14:52,817][model][INFO] - Training step 17360 loss 0.0007603010162711143
[2025-03-16 14:15:32,546][model][INFO] - Training step 17520 loss 0.029132071882486343
[2025-03-16 14:16:11,703][model][INFO] - Training step 17680 loss 0.0487462617456913
[2025-03-16 14:16:51,073][model][INFO] - Training step 17840 loss 0.03307991474866867
[2025-03-16 14:17:30,404][model][INFO] - Training step 18000 loss 0.10092106461524963
[2025-03-16 14:18:10,829][model][INFO] - Training step 18160 loss 0.021627457812428474
[2025-03-16 14:18:50,715][model][INFO] - Training step 18320 loss 0.01979910582304001
[2025-03-16 14:19:32,899][model][INFO] - Training step 18480 loss 0.13983824849128723
[2025-03-16 14:20:13,962][model][INFO] - Training step 18640 loss 0.027042677626013756
[2025-03-16 14:20:54,156][model][INFO] - Training step 18800 loss 0.27514517307281494
[2025-03-16 14:21:33,110][model][INFO] - Training step 18960 loss 0.1201978474855423
[2025-03-16 14:22:11,684][model][INFO] - Training step 19120 loss 0.02392236515879631
[2025-03-16 14:22:52,311][model][INFO] - Training step 19280 loss 0.026371359825134277
[2025-03-16 14:23:33,879][model][INFO] - Training step 19440 loss 0.023674029856920242
[2025-03-16 14:24:13,304][model][INFO] - Training step 19600 loss 0.2543361783027649
[2025-03-16 14:24:53,931][model][INFO] - Training step 19760 loss 0.014828143641352654
[2025-03-16 14:25:35,334][model][INFO] - Training step 19920 loss 0.11464406549930573
[2025-03-16 14:26:15,168][model][INFO] - Training step 20080 loss 0.04023817554116249
[2025-03-16 14:26:54,198][model][INFO] - Training step 20240 loss 0.020549509674310684
[2025-03-16 14:27:34,085][model][INFO] - Training step 20400 loss 0.07655147463083267
[2025-03-16 14:28:15,380][model][INFO] - Training step 20560 loss 0.057432353496551514
[2025-03-16 14:28:55,883][model][INFO] - Training step 20720 loss 0.03580766171216965
[2025-03-16 14:29:35,916][model][INFO] - Training step 20880 loss 0.04646490886807442
[2025-03-16 14:30:16,164][model][INFO] - Training step 21040 loss 0.24767616391181946
[2025-03-16 14:30:56,196][model][INFO] - Training step 21200 loss 0.020960364490747452
[2025-03-16 14:31:34,936][model][INFO] - Training step 21360 loss 0.1297319084405899
[2025-03-16 14:32:15,781][model][INFO] - Training step 21520 loss 0.08853834867477417
[2025-03-16 14:32:56,243][model][INFO] - Training step 21680 loss 0.0050643812865018845
[2025-03-16 14:33:37,334][model][INFO] - Training step 21840 loss 0.01813487708568573
[2025-03-16 14:34:16,391][model][INFO] - Training step 22000 loss 0.23005488514900208
[2025-03-16 14:34:56,342][model][INFO] - Training step 22160 loss 0.24388743937015533
[2025-03-16 14:35:35,548][model][INFO] - Training step 22320 loss 0.24862822890281677
[2025-03-16 14:36:16,092][model][INFO] - Training step 22480 loss 0.021601539105176926
[2025-03-16 14:36:56,414][model][INFO] - Training step 22640 loss 0.01338440552353859
[2025-03-16 14:37:35,313][model][INFO] - Training step 22800 loss 0.23933932185173035
[2025-03-16 14:38:17,010][model][INFO] - Training step 22960 loss 0.016342952847480774
[2025-03-16 14:38:56,446][model][INFO] - Training step 23120 loss 0.019717060029506683
[2025-03-16 14:39:38,592][model][INFO] - Training step 23280 loss 0.002647436922416091
[2025-03-16 14:40:17,864][model][INFO] - Training step 23440 loss 0.07389315962791443
[2025-03-16 14:40:58,473][model][INFO] - Training step 23600 loss 0.03201540187001228
[2025-03-16 14:41:37,313][model][INFO] - Training step 23760 loss 0.034609608352184296
[2025-03-16 14:42:17,740][model][INFO] - Training step 23920 loss 0.04166130721569061
[2025-03-16 14:42:56,449][model][INFO] - Training step 24080 loss 0.03592932969331741
[2025-03-16 14:43:35,886][model][INFO] - Training step 24240 loss 0.020587725564837456
[2025-03-16 14:44:14,406][model][INFO] - Training step 24400 loss 0.04936519265174866
[2025-03-16 14:44:55,065][model][INFO] - Training step 24560 loss 0.10892172157764435
[2025-03-16 14:45:35,287][model][INFO] - Training step 24720 loss 0.012344315648078918
[2025-03-16 14:46:18,229][model][INFO] - Training step 24880 loss 0.015710871666669846
[2025-03-16 14:46:57,908][model][INFO] - Training step 25040 loss 0.2521204352378845
[2025-03-16 14:47:38,388][model][INFO] - Training step 25200 loss 0.01581587642431259
[2025-03-16 14:48:18,491][model][INFO] - Training step 25360 loss 0.026753269135951996
[2025-03-16 14:48:59,092][model][INFO] - Training step 25520 loss 0.028716392815113068
[2025-03-16 14:49:38,260][model][INFO] - Training step 25680 loss 0.01156768947839737
[2025-03-16 14:50:17,711][model][INFO] - Training step 25840 loss 0.05088820308446884
[2025-03-16 14:50:59,782][model][INFO] - Training step 26000 loss 0.06206712871789932
[2025-03-16 14:51:38,421][model][INFO] - Training step 26160 loss 0.03652690351009369
[2025-03-16 14:52:20,293][model][INFO] - Training step 26320 loss 0.02281113713979721
[2025-03-16 14:53:00,901][model][INFO] - Training step 26480 loss 0.031300827860832214
[2025-03-16 14:53:42,016][model][INFO] - Training step 26640 loss 0.07478894293308258
[2025-03-16 14:54:21,106][model][INFO] - Training step 26800 loss 0.01369209960103035
[2025-03-16 14:55:00,590][model][INFO] - Training step 26960 loss 0.025316331535577774
[2025-03-16 14:55:39,925][model][INFO] - Training step 27120 loss 0.014160475693643093
[2025-03-16 14:56:19,837][model][INFO] - Training step 27280 loss 0.07980259507894516
[2025-03-16 14:56:59,223][model][INFO] - Training step 27440 loss 0.033301498740911484
[2025-03-16 14:57:39,205][model][INFO] - Training step 27600 loss 0.06931271404027939
[2025-03-16 14:58:20,619][model][INFO] - Training step 27760 loss 0.024380456656217575
[2025-03-16 14:59:01,066][model][INFO] - Training step 27920 loss 0.25959092378616333
[2025-03-16 14:59:42,094][model][INFO] - Training step 28080 loss 0.036268506199121475
[2025-03-16 15:00:22,510][model][INFO] - Training step 28240 loss 0.253123015165329
[2025-03-16 15:01:01,772][model][INFO] - Training step 28400 loss 0.004864645190536976
[2025-03-16 15:01:40,820][model][INFO] - Training step 28560 loss 0.25959089398384094
[2025-03-16 15:02:20,789][model][INFO] - Training step 28720 loss 0.0542704239487648
[2025-03-16 15:03:00,289][model][INFO] - Training step 28880 loss 0.014717726036906242
[2025-03-16 15:03:40,254][model][INFO] - Training step 29040 loss 0.0069252788089215755
[2025-03-16 15:04:19,584][model][INFO] - Training step 29200 loss 0.00584398303180933
[2025-03-16 15:04:59,917][model][INFO] - Training step 29360 loss 0.005417166277766228
[2025-03-16 15:05:40,082][model][INFO] - Training step 29520 loss 0.03199280425906181
[2025-03-16 15:06:21,294][model][INFO] - Training step 29680 loss 0.0265163816511631
[2025-03-16 15:07:02,089][model][INFO] - Training step 29840 loss 0.02717180922627449
[2025-03-16 15:07:41,955][model][INFO] - Training step 30000 loss 0.018006887286901474
[2025-03-16 15:08:22,233][model][INFO] - Training step 30160 loss 0.1471571922302246
[2025-03-16 15:09:01,801][model][INFO] - Training step 30320 loss 0.020015891641378403
[2025-03-16 15:09:42,744][model][INFO] - Training step 30480 loss 0.016315042972564697
[2025-03-16 15:10:21,762][model][INFO] - Training step 30640 loss 0.033135220408439636
[2025-03-16 15:11:00,980][model][INFO] - Training step 30800 loss 0.2596476972103119
[2025-03-16 15:11:42,013][model][INFO] - Training step 30960 loss 0.017270488664507866
[2025-03-16 15:12:20,862][model][INFO] - Training step 31120 loss 0.21826478838920593
[2025-03-16 15:13:01,386][model][INFO] - Training step 31280 loss 0.0358630046248436
[2025-03-16 15:13:41,514][model][INFO] - Training step 31440 loss 0.030596217140555382
[2025-03-16 15:14:23,787][model][INFO] - Training step 31600 loss 0.05096819996833801
[2025-03-16 15:15:04,050][model][INFO] - Training step 31760 loss 0.037095844745635986
[2025-03-16 15:15:43,674][model][INFO] - Training step 31920 loss 0.03612823039293289
[2025-03-16 15:16:24,408][model][INFO] - Training step 32080 loss 0.011341677978634834
[2025-03-16 15:17:04,260][model][INFO] - Training step 32240 loss 0.05166998505592346
[2025-03-16 15:17:43,073][model][INFO] - Training step 32400 loss 0.0050382232293486595
[2025-03-16 15:18:23,923][model][INFO] - Training step 32560 loss 0.026370912790298462
[2025-03-16 15:19:04,544][model][INFO] - Training step 32720 loss 0.03196708858013153
[2025-03-16 15:19:44,636][model][INFO] - Training step 32880 loss 0.00942324660718441
[2025-03-16 15:20:23,923][model][INFO] - Training step 33040 loss 0.001631369930692017
[2025-03-16 15:21:05,276][model][INFO] - Training step 33200 loss 0.245995432138443
[2025-03-16 15:21:47,377][model][INFO] - Training step 33360 loss 0.015173479914665222
[2025-03-16 15:22:27,325][model][INFO] - Training step 33520 loss 0.04354209452867508
[2025-03-16 15:23:07,311][model][INFO] - Training step 33680 loss 0.00524627510458231
[2025-03-16 15:23:47,506][model][INFO] - Training step 33840 loss 0.016822803765535355
[2025-03-16 15:24:26,989][model][INFO] - Training step 34000 loss 0.022187616676092148
[2025-03-16 15:25:07,032][model][INFO] - Training step 34160 loss 0.038387931883335114
[2025-03-16 15:25:48,652][model][INFO] - Training step 34320 loss 0.005991917569190264
[2025-03-16 15:26:31,217][model][INFO] - Training step 34480 loss 0.036958590149879456
[2025-03-16 15:27:11,061][model][INFO] - Training step 34640 loss 0.02728361077606678
[2025-03-16 15:27:50,622][model][INFO] - Training step 34800 loss 0.27473413944244385
[2025-03-16 15:28:32,416][model][INFO] - Training step 34960 loss 0.02765258029103279
[2025-03-16 15:29:11,820][model][INFO] - Training step 35120 loss 0.009234882891178131
[2025-03-16 15:29:52,672][model][INFO] - Training step 35280 loss 0.03535905480384827
[2025-03-16 15:30:34,828][model][INFO] - Training step 35440 loss 0.12330912053585052
[2025-03-16 15:31:15,043][model][INFO] - Training step 35600 loss 0.2543424963951111
[2025-03-16 15:31:55,473][model][INFO] - Training step 35760 loss 0.006096113473176956
[2025-03-16 15:32:35,087][model][INFO] - Training step 35920 loss 0.04211694002151489
[2025-03-16 15:33:16,905][model][INFO] - Training step 36080 loss 0.25909286737442017
[2025-03-16 15:33:56,762][model][INFO] - Training step 36240 loss 0.024162881076335907
[2025-03-16 15:34:37,480][model][INFO] - Training step 36400 loss 0.0935102105140686
[2025-03-16 15:35:17,349][model][INFO] - Training step 36560 loss 0.03321067988872528
[2025-03-16 15:35:57,899][model][INFO] - Training step 36720 loss 0.24962252378463745
[2025-03-16 15:36:38,276][model][INFO] - Training step 36880 loss 0.0529165118932724
[2025-03-16 15:37:17,922][model][INFO] - Training step 37040 loss 0.027092033997178078
[2025-03-16 15:37:58,789][model][INFO] - Training step 37200 loss 0.24401970207691193
[2025-03-16 15:38:38,523][model][INFO] - Training step 37360 loss 0.030035529285669327
[2025-03-16 15:39:18,640][model][INFO] - Training step 37520 loss 0.02252880111336708
[2025-03-16 15:39:59,552][model][INFO] - Training step 37680 loss 0.04085281118750572
[2025-03-16 15:40:38,434][model][INFO] - Training step 37840 loss 0.031432099640369415
[2025-03-16 15:41:18,503][model][INFO] - Training step 38000 loss 0.004984718281775713
[2025-03-16 15:41:58,888][model][INFO] - Training step 38160 loss 0.020543210208415985
[2025-03-16 15:42:41,245][model][INFO] - Training step 38320 loss 0.11771530658006668
[2025-03-16 15:43:20,229][model][INFO] - Training step 38480 loss 0.004849560093134642
[2025-03-16 15:44:00,321][model][INFO] - Training step 38640 loss 0.021919377148151398
[2025-03-16 15:44:39,896][model][INFO] - Training step 38800 loss 0.025938017293810844
[2025-03-16 15:45:19,826][model][INFO] - Training step 38960 loss 0.2585734724998474
[2025-03-16 15:45:58,929][model][INFO] - Training step 39120 loss 0.15186528861522675
[2025-03-16 15:46:39,236][model][INFO] - Training step 39280 loss 0.020675353705883026
[2025-03-16 15:47:18,028][model][INFO] - Training step 39440 loss 0.01690790057182312
[2025-03-16 15:47:59,263][model][INFO] - Training step 39600 loss 0.017872042953968048
[2025-03-16 15:48:39,994][model][INFO] - Training step 39760 loss 0.017488881945610046
[2025-03-16 15:49:21,595][model][INFO] - Training step 39920 loss 0.020183183252811432
[2025-03-16 15:50:01,717][model][INFO] - Training step 40080 loss 0.02548065409064293
[2025-03-16 15:50:41,533][model][INFO] - Training step 40240 loss 0.026681113988161087
[2025-03-16 15:51:20,162][model][INFO] - Training step 40400 loss 0.25415855646133423
[2025-03-16 15:52:00,079][model][INFO] - Training step 40560 loss 0.2603587806224823
[2025-03-16 15:52:39,641][model][INFO] - Training step 40720 loss 0.08558468520641327
[2025-03-16 15:53:19,629][model][INFO] - Training step 40880 loss 0.01411729771643877
[2025-03-16 15:53:57,789][model][INFO] - Training step 41040 loss 0.022133421152830124
[2025-03-16 15:54:38,759][model][INFO] - Training step 41200 loss 0.020579280331730843
[2025-03-16 15:55:21,215][model][INFO] - Training step 41360 loss 0.23683272302150726
[2025-03-16 15:56:00,271][model][INFO] - Training step 41520 loss 0.03268038481473923
[2025-03-16 15:56:41,466][model][INFO] - Training step 41680 loss 0.05398046597838402
[2025-03-16 15:57:21,842][model][INFO] - Training step 41840 loss 0.26320356130599976
[2025-03-16 15:58:00,637][model][INFO] - Training step 42000 loss 0.24627567827701569
[2025-03-16 15:58:40,535][model][INFO] - Training step 42160 loss 0.026111997663974762
[2025-03-16 15:59:20,321][model][INFO] - Training step 42320 loss 0.039492569863796234
[2025-03-16 16:00:01,834][model][INFO] - Training step 42480 loss 0.027357416227459908
[2025-03-16 16:00:42,005][model][INFO] - Training step 42640 loss 0.0061970967799425125
[2025-03-16 16:01:20,998][model][INFO] - Training step 42800 loss 0.05661828815937042
[2025-03-16 16:01:59,606][model][INFO] - Training step 42960 loss 0.01782769337296486
[2025-03-16 16:02:39,841][model][INFO] - Training step 43120 loss 0.06938785314559937
[2025-03-16 16:03:20,198][model][INFO] - Training step 43280 loss 0.03774324059486389
[2025-03-16 16:04:00,341][model][INFO] - Training step 43440 loss 0.00470375269651413
[2025-03-16 16:04:39,974][model][INFO] - Training step 43600 loss 0.015173682942986488
[2025-03-16 16:05:18,997][model][INFO] - Training step 43760 loss 0.02244698256254196
[2025-03-16 16:05:59,581][model][INFO] - Training step 43920 loss 0.09773682802915573
[2025-03-16 16:06:38,743][model][INFO] - Training step 44080 loss 0.028155211359262466
[2025-03-16 16:07:20,020][model][INFO] - Training step 44240 loss 0.09637364000082016
[2025-03-16 16:08:01,182][model][INFO] - Training step 44400 loss 0.0029904497787356377
[2025-03-16 16:08:39,131][model][INFO] - Training step 44560 loss 0.2595920264720917
[2025-03-16 16:09:19,288][model][INFO] - Training step 44720 loss 0.021844834089279175
[2025-03-16 16:09:59,008][model][INFO] - Training step 44880 loss 0.07428499311208725
[2025-03-16 16:10:37,913][model][INFO] - Training step 45040 loss 0.25149911642074585
[2025-03-16 16:11:15,914][model][INFO] - Training step 45200 loss 0.025597384199500084
[2025-03-16 16:11:55,975][model][INFO] - Training step 45360 loss 0.003878091461956501
[2025-03-16 16:12:36,125][model][INFO] - Training step 45520 loss 0.03434246778488159
[2025-03-16 16:13:17,652][model][INFO] - Training step 45680 loss 0.08075681328773499
[2025-03-16 16:13:56,912][model][INFO] - Training step 45840 loss 0.0837617814540863
[2025-03-16 16:14:36,905][model][INFO] - Training step 46000 loss 0.25885462760925293
[2025-03-16 16:15:19,200][model][INFO] - Training step 46160 loss 0.002878472674638033
[2025-03-16 16:15:58,204][model][INFO] - Training step 46320 loss 0.03033030405640602
[2025-03-16 16:16:38,227][model][INFO] - Training step 46480 loss 0.010900875553488731
[2025-03-16 16:17:16,714][model][INFO] - Training step 46640 loss 0.02751803770661354
[2025-03-16 16:17:57,462][model][INFO] - Training step 46800 loss 0.025312621146440506
[2025-03-16 16:18:36,737][model][INFO] - Training step 46960 loss 0.029198352247476578
[2025-03-16 16:19:16,158][model][INFO] - Training step 47120 loss 0.04450612887740135
[2025-03-16 16:19:55,776][model][INFO] - Training step 47280 loss 0.25551241636276245
[2025-03-16 16:20:35,147][model][INFO] - Training step 47440 loss 0.2536100745201111
[2025-03-16 16:21:15,551][model][INFO] - Training step 47600 loss 0.005447829607874155
[2025-03-16 16:21:55,820][model][INFO] - Training step 47760 loss 0.24480287730693817
[2025-03-16 16:22:36,820][model][INFO] - Training step 47920 loss 0.045500144362449646
[2025-03-16 16:23:16,117][model][INFO] - Training step 48080 loss 0.027817558497190475
[2025-03-16 16:23:55,287][model][INFO] - Training step 48240 loss 0.0027393358759582043
[2025-03-16 16:24:34,471][model][INFO] - Training step 48400 loss 0.04576694220304489
[2025-03-16 16:25:15,018][model][INFO] - Training step 48560 loss 0.00232141837477684
[2025-03-16 16:25:54,837][model][INFO] - Training step 48720 loss 0.10039573907852173
[2025-03-16 16:26:35,708][model][INFO] - Training step 48880 loss 0.014504057355225086
[2025-03-16 16:27:15,630][model][INFO] - Training step 49040 loss 0.018399782478809357
[2025-03-16 16:27:57,180][model][INFO] - Training step 49200 loss 0.014138488098978996
[2025-03-16 16:28:38,856][model][INFO] - Training step 49360 loss 0.02057773247361183
[2025-03-16 16:29:19,047][model][INFO] - Training step 49520 loss 0.23494212329387665
[2025-03-16 16:29:59,358][model][INFO] - Training step 49680 loss 0.03644784912467003
[2025-03-16 16:30:40,158][model][INFO] - Training step 49840 loss 0.03461524844169617
[2025-03-16 16:31:19,225][model][INFO] - Training step 50000 loss 0.03918306529521942
[2025-03-16 16:31:58,905][model][INFO] - Training step 50160 loss 0.010340433567762375
[2025-03-16 16:32:38,957][model][INFO] - Training step 50320 loss 0.01648753508925438
[2025-03-16 16:33:20,831][model][INFO] - Training step 50480 loss 0.014536229893565178
[2025-03-16 16:33:59,564][model][INFO] - Training step 50640 loss 0.011075041256844997
[2025-03-16 16:39:36,926][model][INFO] - Training step 0 loss 0.016500750556588173
[2025-03-16 16:40:15,833][model][INFO] - Training step 160 loss 0.013442634604871273
[2025-03-16 16:40:56,051][model][INFO] - Training step 320 loss 0.25278007984161377
[2025-03-16 16:41:36,010][model][INFO] - Training step 480 loss 0.021100349724292755
[2025-03-16 16:42:15,850][model][INFO] - Training step 640 loss 0.08101197332143784
[2025-03-16 16:42:54,475][model][INFO] - Training step 800 loss 0.2639390528202057
[2025-03-16 16:43:34,802][model][INFO] - Training step 960 loss 0.011800565756857395
[2025-03-16 16:44:13,048][model][INFO] - Training step 1120 loss 0.24212421476840973
[2025-03-16 16:44:52,342][model][INFO] - Training step 1280 loss 0.021302878856658936
[2025-03-16 16:45:31,452][model][INFO] - Training step 1440 loss 0.03095354326069355
[2025-03-16 16:46:10,155][model][INFO] - Training step 1600 loss 0.2597029209136963
[2025-03-16 16:46:49,835][model][INFO] - Training step 1760 loss 0.004472003784030676
[2025-03-16 16:47:29,705][model][INFO] - Training step 1920 loss 0.05922066420316696
[2025-03-16 16:48:11,974][model][INFO] - Training step 2080 loss 0.027788881212472916
[2025-03-16 16:48:52,399][model][INFO] - Training step 2240 loss 0.03054550476372242
[2025-03-16 16:49:29,923][model][INFO] - Training step 2400 loss 0.06525982916355133
[2025-03-16 16:50:10,729][model][INFO] - Training step 2560 loss 0.03978368267416954
[2025-03-16 16:50:51,627][model][INFO] - Training step 2720 loss 0.013865575194358826
[2025-03-16 16:51:32,081][model][INFO] - Training step 2880 loss 0.03566690534353256
[2025-03-16 16:52:12,273][model][INFO] - Training step 3040 loss 0.041470713913440704
[2025-03-16 16:52:52,090][model][INFO] - Training step 3200 loss 0.012209341861307621
[2025-03-16 16:53:32,836][model][INFO] - Training step 3360 loss 0.0030840947292745113
[2025-03-16 16:54:13,866][model][INFO] - Training step 3520 loss 0.026920143514871597
[2025-03-16 16:54:55,728][model][INFO] - Training step 3680 loss 0.026376258581876755
[2025-03-16 16:55:35,453][model][INFO] - Training step 3840 loss 0.022923694923520088
[2025-03-16 16:56:16,542][model][INFO] - Training step 4000 loss 0.034836575388908386
[2025-03-16 16:56:57,643][model][INFO] - Training step 4160 loss 0.013891679234802723
[2025-03-16 16:57:36,785][model][INFO] - Training step 4320 loss 0.02737906575202942
[2025-03-16 16:58:18,723][model][INFO] - Training step 4480 loss 0.004950499162077904
[2025-03-16 16:58:59,960][model][INFO] - Training step 4640 loss 0.0395379364490509
[2025-03-16 16:59:39,995][model][INFO] - Training step 4800 loss 0.0813303291797638
[2025-03-16 17:00:20,252][model][INFO] - Training step 4960 loss 0.24133816361427307
[2025-03-16 17:01:00,993][model][INFO] - Training step 5120 loss 0.11410297453403473
[2025-03-16 17:01:40,640][model][INFO] - Training step 5280 loss 0.0068575055338442326
[2025-03-16 17:02:20,531][model][INFO] - Training step 5440 loss 0.1598605364561081
[2025-03-16 17:02:59,269][model][INFO] - Training step 5600 loss 0.25458380579948425
[2025-03-16 17:03:38,950][model][INFO] - Training step 5760 loss 0.020240359008312225
[2025-03-16 17:04:19,038][model][INFO] - Training step 5920 loss 0.02377835288643837
[2025-03-16 17:04:58,109][model][INFO] - Training step 6080 loss 0.017739135771989822
[2025-03-16 17:05:37,178][model][INFO] - Training step 6240 loss 0.011431882157921791
[2025-03-16 17:06:17,121][model][INFO] - Training step 6400 loss 0.05627482384443283
[2025-03-16 17:06:56,625][model][INFO] - Training step 6560 loss 0.024592088535428047
[2025-03-16 17:07:37,611][model][INFO] - Training step 6720 loss 0.2501976191997528
[2025-03-16 17:08:17,819][model][INFO] - Training step 6880 loss 0.045659489929676056
[2025-03-16 17:08:57,143][model][INFO] - Training step 7040 loss 0.01067184004932642
[2025-03-16 17:09:37,378][model][INFO] - Training step 7200 loss 0.01693638414144516
[2025-03-16 17:10:18,188][model][INFO] - Training step 7360 loss 0.13043108582496643
[2025-03-16 17:10:58,158][model][INFO] - Training step 7520 loss 0.027816757559776306
[2025-03-16 17:11:38,273][model][INFO] - Training step 7680 loss 0.0051762317307293415
[2025-03-16 17:12:18,429][model][INFO] - Training step 7840 loss 0.0029169870540499687
[2025-03-16 17:12:59,240][model][INFO] - Training step 8000 loss 0.050068266689777374
[2025-03-16 17:13:39,747][model][INFO] - Training step 8160 loss 0.24594365060329437
[2025-03-16 17:14:19,756][model][INFO] - Training step 8320 loss 0.016588490456342697
[2025-03-16 17:14:58,856][model][INFO] - Training step 8480 loss 0.051851361989974976
[2025-03-16 17:15:38,575][model][INFO] - Training step 8640 loss 0.0039968956261873245
[2025-03-16 17:16:18,323][model][INFO] - Training step 8800 loss 0.04684455320239067
[2025-03-16 17:16:58,555][model][INFO] - Training step 8960 loss 0.3598593473434448
[2025-03-16 17:17:39,223][model][INFO] - Training step 9120 loss 0.2436361312866211
[2025-03-16 17:18:18,445][model][INFO] - Training step 9280 loss 0.037827543914318085
[2025-03-16 17:18:58,382][model][INFO] - Training step 9440 loss 0.011948048137128353
[2025-03-16 17:19:38,223][model][INFO] - Training step 9600 loss 0.2487739473581314
[2025-03-16 17:20:18,542][model][INFO] - Training step 9760 loss 0.01604316756129265
[2025-03-16 17:20:58,589][model][INFO] - Training step 9920 loss 0.0031777876429259777
[2025-03-16 17:21:38,806][model][INFO] - Training step 10080 loss 0.2542581558227539
[2025-03-16 17:22:18,090][model][INFO] - Training step 10240 loss 0.012994570657610893
[2025-03-16 17:22:58,455][model][INFO] - Training step 10400 loss 0.2207554578781128
[2025-03-16 17:23:39,585][model][INFO] - Training step 10560 loss 0.9182454347610474
[2025-03-16 17:24:20,904][model][INFO] - Training step 10720 loss 0.002760998671874404
[2025-03-16 17:25:00,388][model][INFO] - Training step 10880 loss 0.01944073662161827
[2025-03-16 17:25:40,407][model][INFO] - Training step 11040 loss 0.023250006139278412
[2025-03-16 17:26:21,600][model][INFO] - Training step 11200 loss 0.2499333918094635
[2025-03-16 17:27:01,151][model][INFO] - Training step 11360 loss 0.0197561327368021
[2025-03-16 17:27:41,896][model][INFO] - Training step 11520 loss 0.01792873814702034
[2025-03-16 17:28:22,460][model][INFO] - Training step 11680 loss 0.0355486199259758
[2025-03-16 17:29:03,697][model][INFO] - Training step 11840 loss 0.014698673039674759
[2025-03-16 17:29:44,991][model][INFO] - Training step 12000 loss 0.048822298645973206
[2025-03-16 17:30:25,161][model][INFO] - Training step 12160 loss 0.03843488544225693
[2025-03-16 17:31:02,711][model][INFO] - Training step 12320 loss 0.03103041648864746
[2025-03-16 17:31:43,571][model][INFO] - Training step 12480 loss 0.022235464304685593
[2025-03-16 17:32:23,393][model][INFO] - Training step 12640 loss 0.004607876762747765
[2025-03-16 17:33:03,230][model][INFO] - Training step 12800 loss 0.0186542309820652
[2025-03-16 17:33:43,014][model][INFO] - Training step 12960 loss 0.002964136190712452
[2025-03-16 17:34:23,322][model][INFO] - Training step 13120 loss 0.00592990405857563
[2025-03-16 17:35:04,029][model][INFO] - Training step 13280 loss 0.01057770662009716
[2025-03-16 17:35:44,523][model][INFO] - Training step 13440 loss 0.03408793732523918
[2025-03-16 17:36:25,427][model][INFO] - Training step 13600 loss 0.03354902192950249
[2025-03-16 17:37:04,920][model][INFO] - Training step 13760 loss 0.2507643699645996
[2025-03-16 17:37:44,424][model][INFO] - Training step 13920 loss 0.05783279985189438
[2025-03-16 17:38:25,833][model][INFO] - Training step 14080 loss 0.13715994358062744
[2025-03-16 17:39:05,798][model][INFO] - Training step 14240 loss 0.5755985975265503
[2025-03-16 17:39:45,897][model][INFO] - Training step 14400 loss 0.02993268519639969
[2025-03-16 17:40:25,611][model][INFO] - Training step 14560 loss 0.024073131382465363
[2025-03-16 17:41:06,736][model][INFO] - Training step 14720 loss 0.27247345447540283
[2025-03-16 17:41:47,028][model][INFO] - Training step 14880 loss 0.033509962260723114
[2025-03-16 17:42:28,357][model][INFO] - Training step 15040 loss 0.08461056649684906
[2025-03-16 17:43:08,823][model][INFO] - Training step 15200 loss 0.01651846617460251
[2025-03-16 17:43:48,780][model][INFO] - Training step 15360 loss 0.007226630579680204
[2025-03-16 17:44:29,514][model][INFO] - Training step 15520 loss 0.01574542745947838
[2025-03-16 17:45:10,229][model][INFO] - Training step 15680 loss 0.01416102983057499
[2025-03-16 17:45:50,597][model][INFO] - Training step 15840 loss 0.0810837373137474
[2025-03-16 17:46:30,828][model][INFO] - Training step 16000 loss 0.005126608535647392
[2025-03-16 17:47:12,077][model][INFO] - Training step 16160 loss 0.0206767451018095
[2025-03-16 17:47:51,412][model][INFO] - Training step 16320 loss 0.042579032480716705
[2025-03-16 17:48:32,393][model][INFO] - Training step 16480 loss 0.004460904747247696
[2025-03-16 17:49:11,921][model][INFO] - Training step 16640 loss 0.02570129558444023
[2025-03-16 17:49:50,490][model][INFO] - Training step 16800 loss 0.05515725165605545
[2025-03-16 17:50:30,720][model][INFO] - Training step 16960 loss 0.037100739777088165
[2025-03-16 17:51:09,773][model][INFO] - Training step 17120 loss 0.2534189224243164
[2025-03-16 17:51:51,565][model][INFO] - Training step 17280 loss 0.4766007363796234
[2025-03-16 17:52:32,550][model][INFO] - Training step 17440 loss 0.2458903044462204
[2025-03-16 17:53:13,500][model][INFO] - Training step 17600 loss 0.005284390412271023
[2025-03-16 17:53:55,091][model][INFO] - Training step 17760 loss 0.04965009167790413
[2025-03-16 17:54:34,910][model][INFO] - Training step 17920 loss 0.27116137742996216
[2025-03-16 17:55:17,811][model][INFO] - Training step 18080 loss 0.03064589574933052
[2025-03-16 17:55:57,514][model][INFO] - Training step 18240 loss 0.04886820912361145
[2025-03-16 17:56:38,157][model][INFO] - Training step 18400 loss 0.0045419116504490376
[2025-03-16 17:57:18,249][model][INFO] - Training step 18560 loss 0.018927348777651787
[2025-03-16 17:57:58,911][model][INFO] - Training step 18720 loss 0.01984350010752678
[2025-03-16 17:58:38,874][model][INFO] - Training step 18880 loss 0.01658080890774727
[2025-03-16 17:59:18,416][model][INFO] - Training step 19040 loss 0.02501560002565384
[2025-03-16 17:59:58,193][model][INFO] - Training step 19200 loss 0.03514727205038071
[2025-03-16 18:00:36,854][model][INFO] - Training step 19360 loss 0.07521700859069824
[2025-03-16 18:01:17,465][model][INFO] - Training step 19520 loss 0.023580174893140793
[2025-03-16 18:01:56,957][model][INFO] - Training step 19680 loss 0.2533467411994934
[2025-03-16 18:02:36,296][model][INFO] - Training step 19840 loss 0.020136136561632156
[2025-03-16 18:03:16,311][model][INFO] - Training step 20000 loss 0.054137323051691055
[2025-03-16 18:03:57,175][model][INFO] - Training step 20160 loss 0.24798637628555298
[2025-03-16 18:04:38,321][model][INFO] - Training step 20320 loss 0.18717503547668457
[2025-03-16 18:05:18,607][model][INFO] - Training step 20480 loss 0.2520599365234375
[2025-03-16 18:05:58,153][model][INFO] - Training step 20640 loss 0.023368533700704575
[2025-03-16 18:06:38,775][model][INFO] - Training step 20800 loss 0.03472195565700531
[2025-03-16 18:07:18,696][model][INFO] - Training step 20960 loss 0.018032994121313095
[2025-03-16 18:08:00,434][model][INFO] - Training step 21120 loss 0.12211200594902039
[2025-03-16 18:08:41,327][model][INFO] - Training step 21280 loss 0.2494019716978073
[2025-03-16 18:09:21,338][model][INFO] - Training step 21440 loss 0.006295380648225546
[2025-03-16 18:10:02,260][model][INFO] - Training step 21600 loss 0.07456540316343307
[2025-03-16 18:10:42,639][model][INFO] - Training step 21760 loss 0.03089660406112671
[2025-03-16 18:11:21,988][model][INFO] - Training step 21920 loss 0.01973695494234562
[2025-03-16 18:12:02,316][model][INFO] - Training step 22080 loss 0.01082129031419754
[2025-03-16 18:12:40,693][model][INFO] - Training step 22240 loss 0.005831767804920673
[2025-03-16 18:13:20,942][model][INFO] - Training step 22400 loss 0.024341365322470665
[2025-03-16 18:14:01,296][model][INFO] - Training step 22560 loss 0.030687076970934868
[2025-03-16 18:14:40,831][model][INFO] - Training step 22720 loss 0.010113416239619255
[2025-03-16 18:15:20,274][model][INFO] - Training step 22880 loss 0.012272495776414871
[2025-03-16 18:15:59,993][model][INFO] - Training step 23040 loss 0.05874507129192352
[2025-03-16 18:16:39,589][model][INFO] - Training step 23200 loss 0.0022269145119935274
[2025-03-16 18:17:19,678][model][INFO] - Training step 23360 loss 0.00452378811314702
[2025-03-16 18:17:59,874][model][INFO] - Training step 23520 loss 0.04671822115778923
[2025-03-16 18:18:40,095][model][INFO] - Training step 23680 loss 0.020982403308153152
[2025-03-16 18:19:20,695][model][INFO] - Training step 23840 loss 0.24517954885959625
[2025-03-16 18:20:00,131][model][INFO] - Training step 24000 loss 0.024496663361787796
[2025-03-16 18:20:40,003][model][INFO] - Training step 24160 loss 0.24650037288665771
[2025-03-16 18:21:20,161][model][INFO] - Training step 24320 loss 0.006903158500790596
[2025-03-16 18:21:59,500][model][INFO] - Training step 24480 loss 0.011120620183646679
[2025-03-16 18:22:38,927][model][INFO] - Training step 24640 loss 0.02993619441986084
[2025-03-16 18:23:18,612][model][INFO] - Training step 24800 loss 0.039139240980148315
[2025-03-16 18:23:58,923][model][INFO] - Training step 24960 loss 0.0262544397264719
[2025-03-16 18:24:40,547][model][INFO] - Training step 25120 loss 0.0044988710433244705
[2025-03-16 18:25:19,560][model][INFO] - Training step 25280 loss 0.01919487863779068
[2025-03-16 18:25:57,843][model][INFO] - Training step 25440 loss 0.01950836181640625
[2025-03-16 18:26:36,361][model][INFO] - Training step 25600 loss 0.1899229735136032
[2025-03-16 18:27:16,440][model][INFO] - Training step 25760 loss 0.11378201842308044
[2025-03-16 18:27:56,889][model][INFO] - Training step 25920 loss 0.24227677285671234
[2025-03-16 18:28:37,836][model][INFO] - Training step 26080 loss 0.026087012141942978
[2025-03-16 18:29:19,225][model][INFO] - Training step 26240 loss 0.002993859350681305
[2025-03-16 18:29:59,350][model][INFO] - Training step 26400 loss 0.051304854452610016
[2025-03-16 18:30:40,317][model][INFO] - Training step 26560 loss 0.020961828529834747
[2025-03-16 18:31:19,425][model][INFO] - Training step 26720 loss 0.0298677459359169
[2025-03-16 18:31:59,209][model][INFO] - Training step 26880 loss 0.24629870057106018
[2025-03-16 18:32:39,168][model][INFO] - Training step 27040 loss 0.06609858572483063
[2025-03-16 18:33:22,009][model][INFO] - Training step 27200 loss 0.12027596682310104
[2025-03-16 18:34:02,542][model][INFO] - Training step 27360 loss 0.0028999950736761093
[2025-03-16 18:34:43,056][model][INFO] - Training step 27520 loss 0.02607094869017601
[2025-03-16 18:35:24,933][model][INFO] - Training step 27680 loss 0.019854506477713585
[2025-03-16 18:36:04,728][model][INFO] - Training step 27840 loss 0.23938652873039246
[2025-03-16 18:36:45,185][model][INFO] - Training step 28000 loss 0.26145780086517334
[2025-03-16 18:37:26,097][model][INFO] - Training step 28160 loss 0.023136049509048462
[2025-03-16 18:38:05,409][model][INFO] - Training step 28320 loss 0.0216342993080616
[2025-03-16 18:38:45,903][model][INFO] - Training step 28480 loss 0.03717324137687683
[2025-03-16 18:39:27,527][model][INFO] - Training step 28640 loss 0.03753180801868439
[2025-03-16 18:40:08,322][model][INFO] - Training step 28800 loss 0.04229018837213516
[2025-03-16 18:40:48,460][model][INFO] - Training step 28960 loss 0.14186322689056396
[2025-03-16 18:41:29,469][model][INFO] - Training step 29120 loss 0.2571115493774414
[2025-03-16 18:42:10,351][model][INFO] - Training step 29280 loss 0.0188613161444664
[2025-03-16 18:42:50,620][model][INFO] - Training step 29440 loss 0.07115881890058517
[2025-03-16 18:43:30,527][model][INFO] - Training step 29600 loss 0.06752877682447433
[2025-03-16 18:44:11,675][model][INFO] - Training step 29760 loss 0.006163914687931538
[2025-03-16 18:44:51,488][model][INFO] - Training step 29920 loss 0.0234046820551157
[2025-03-16 18:45:33,997][model][INFO] - Training step 30080 loss 0.017090247943997383
[2025-03-16 18:46:12,853][model][INFO] - Training step 30240 loss 0.09000411629676819
[2025-03-16 18:46:52,982][model][INFO] - Training step 30400 loss 0.02804764360189438
[2025-03-16 18:47:32,909][model][INFO] - Training step 30560 loss 0.017164308577775955
[2025-03-16 18:48:12,032][model][INFO] - Training step 30720 loss 0.007282157428562641
[2025-03-16 18:48:51,463][model][INFO] - Training step 30880 loss 0.005175204016268253
[2025-03-16 18:49:31,971][model][INFO] - Training step 31040 loss 0.025361008942127228
[2025-03-16 18:50:11,360][model][INFO] - Training step 31200 loss 0.038694992661476135
[2025-03-16 18:50:51,608][model][INFO] - Training step 31360 loss 0.04167238622903824
[2025-03-16 18:51:30,315][model][INFO] - Training step 31520 loss 0.051815617829561234
[2025-03-16 18:52:10,868][model][INFO] - Training step 31680 loss 0.25189101696014404
[2025-03-16 18:52:51,442][model][INFO] - Training step 31840 loss 0.005005391780287027
[2025-03-16 18:53:30,984][model][INFO] - Training step 32000 loss 0.024821944534778595
[2025-03-16 18:54:11,034][model][INFO] - Training step 32160 loss 0.06992285698652267
[2025-03-16 18:54:50,448][model][INFO] - Training step 32320 loss 0.01976771280169487
[2025-03-16 18:55:30,046][model][INFO] - Training step 32480 loss 0.0347573384642601
[2025-03-16 18:56:11,133][model][INFO] - Training step 32640 loss 0.03735567256808281
[2025-03-16 18:56:51,197][model][INFO] - Training step 32800 loss 0.02854665368795395
[2025-03-16 18:57:31,766][model][INFO] - Training step 32960 loss 0.0038438159972429276
[2025-03-16 18:58:11,943][model][INFO] - Training step 33120 loss 0.24873411655426025
[2025-03-16 18:58:52,821][model][INFO] - Training step 33280 loss 0.004985463805496693
[2025-03-16 18:59:33,457][model][INFO] - Training step 33440 loss 0.052910223603248596
[2025-03-16 19:00:12,515][model][INFO] - Training step 33600 loss 0.02399400621652603
[2025-03-16 19:00:52,387][model][INFO] - Training step 33760 loss 0.023338954895734787
[2025-03-16 19:01:33,389][model][INFO] - Training step 33920 loss 0.038269683718681335
[2025-03-16 19:02:12,740][model][INFO] - Training step 34080 loss 0.01658306084573269
[2025-03-16 19:02:53,455][model][INFO] - Training step 34240 loss 0.023638658225536346
[2025-03-16 19:03:34,530][model][INFO] - Training step 34400 loss 0.005995459388941526
[2025-03-16 19:04:14,498][model][INFO] - Training step 34560 loss 0.03639010712504387
[2025-03-16 19:04:54,770][model][INFO] - Training step 34720 loss 0.1365838646888733
[2025-03-16 19:05:34,448][model][INFO] - Training step 34880 loss 0.042171359062194824
[2025-03-16 19:06:14,007][model][INFO] - Training step 35040 loss 0.02297261357307434
[2025-03-16 19:06:53,866][model][INFO] - Training step 35200 loss 0.016989514231681824
[2025-03-16 19:07:35,000][model][INFO] - Training step 35360 loss 0.0322713702917099
[2025-03-16 19:08:15,987][model][INFO] - Training step 35520 loss 0.02224365994334221
[2025-03-16 19:08:55,613][model][INFO] - Training step 35680 loss 0.2585459053516388
[2025-03-16 19:09:35,817][model][INFO] - Training step 35840 loss 0.027423400431871414
[2025-03-16 19:10:16,144][model][INFO] - Training step 36000 loss 0.03189539164304733
[2025-03-16 19:10:57,227][model][INFO] - Training step 36160 loss 0.0012968494556844234
[2025-03-16 19:11:37,955][model][INFO] - Training step 36320 loss 0.014004353433847427
[2025-03-16 19:12:17,254][model][INFO] - Training step 36480 loss 0.02212519757449627
[2025-03-16 19:12:56,836][model][INFO] - Training step 36640 loss 0.019578784704208374
[2025-03-16 19:13:36,366][model][INFO] - Training step 36800 loss 0.13281762599945068
[2025-03-16 19:14:16,635][model][INFO] - Training step 36960 loss 0.010706447064876556
[2025-03-16 19:14:57,140][model][INFO] - Training step 37120 loss 0.004324242006987333
[2025-03-16 19:15:37,032][model][INFO] - Training step 37280 loss 0.003789240727201104
[2025-03-16 19:16:16,110][model][INFO] - Training step 37440 loss 0.23813354969024658
[2025-03-16 19:16:55,512][model][INFO] - Training step 37600 loss 0.23636437952518463
[2025-03-16 19:17:36,845][model][INFO] - Training step 37760 loss 0.28732287883758545
[2025-03-16 19:18:17,923][model][INFO] - Training step 37920 loss 0.25198453664779663
[2025-03-16 19:18:57,605][model][INFO] - Training step 38080 loss 0.15144088864326477
[2025-03-16 19:19:38,617][model][INFO] - Training step 38240 loss 0.2433406412601471
[2025-03-16 19:20:18,428][model][INFO] - Training step 38400 loss 0.005518951918929815
[2025-03-16 19:20:57,687][model][INFO] - Training step 38560 loss 0.02162827178835869
[2025-03-16 19:21:37,903][model][INFO] - Training step 38720 loss 0.045653365552425385
[2025-03-16 19:22:17,618][model][INFO] - Training step 38880 loss 0.22214187681674957
[2025-03-16 19:22:56,823][model][INFO] - Training step 39040 loss 0.019981134682893753
[2025-03-16 19:23:36,881][model][INFO] - Training step 39200 loss 0.24050238728523254
[2025-03-16 19:24:18,174][model][INFO] - Training step 39360 loss 0.018445434048771858
[2025-03-16 19:24:58,415][model][INFO] - Training step 39520 loss 0.02261470817029476
[2025-03-16 19:25:38,408][model][INFO] - Training step 39680 loss 0.019616534933447838
[2025-03-16 19:26:17,910][model][INFO] - Training step 39840 loss 0.036633796989917755
[2025-03-16 19:27:00,084][model][INFO] - Training step 40000 loss 0.03184753656387329
[2025-03-16 19:27:39,418][model][INFO] - Training step 40160 loss 0.03647313266992569
[2025-03-16 19:28:19,671][model][INFO] - Training step 40320 loss 0.003371783532202244
[2025-03-16 19:29:01,443][model][INFO] - Training step 40480 loss 0.03651994466781616
[2025-03-16 19:29:41,707][model][INFO] - Training step 40640 loss 0.0053810840472579
[2025-03-16 19:30:21,103][model][INFO] - Training step 40800 loss 0.2341328114271164
[2025-03-16 19:31:02,117][model][INFO] - Training step 40960 loss 0.28853654861450195
[2025-03-16 19:31:41,429][model][INFO] - Training step 41120 loss 0.009155930951237679
[2025-03-16 19:32:22,256][model][INFO] - Training step 41280 loss 0.028915129601955414
[2025-03-16 19:33:03,002][model][INFO] - Training step 41440 loss 0.006951663643121719
[2025-03-16 19:33:43,484][model][INFO] - Training step 41600 loss 0.006251351907849312
[2025-03-16 19:34:24,549][model][INFO] - Training step 41760 loss 0.014302817173302174
[2025-03-16 19:35:04,234][model][INFO] - Training step 41920 loss 0.026156801730394363
[2025-03-16 19:35:43,892][model][INFO] - Training step 42080 loss 0.0072708940133452415
[2025-03-16 19:36:22,747][model][INFO] - Training step 42240 loss 0.018463842570781708
[2025-03-16 19:37:03,604][model][INFO] - Training step 42400 loss 0.2538904845714569
[2025-03-16 19:37:44,591][model][INFO] - Training step 42560 loss 0.010047674179077148
[2025-03-16 19:38:24,591][model][INFO] - Training step 42720 loss 0.020611416548490524
[2025-03-16 19:39:03,499][model][INFO] - Training step 42880 loss 0.030791152268648148
[2025-03-16 19:39:43,870][model][INFO] - Training step 43040 loss 0.05501782149076462
[2025-03-16 19:40:23,480][model][INFO] - Training step 43200 loss 0.32487550377845764
[2025-03-16 19:41:04,651][model][INFO] - Training step 43360 loss 0.03877038136124611
[2025-03-16 19:41:43,521][model][INFO] - Training step 43520 loss 0.03890138864517212
[2025-03-16 19:42:23,505][model][INFO] - Training step 43680 loss 0.028344426304101944
[2025-03-16 19:43:03,076][model][INFO] - Training step 43840 loss 0.02155599743127823
[2025-03-16 19:43:44,195][model][INFO] - Training step 44000 loss 0.026438722386956215
[2025-03-16 19:44:25,841][model][INFO] - Training step 44160 loss 0.003222026163712144
[2025-03-16 19:45:05,299][model][INFO] - Training step 44320 loss 0.002915048971772194
[2025-03-16 19:45:46,507][model][INFO] - Training step 44480 loss 0.007703603245317936
[2025-03-16 19:46:24,850][model][INFO] - Training step 44640 loss 0.06067463755607605
[2025-03-16 19:47:06,824][model][INFO] - Training step 44800 loss 0.017759937793016434
[2025-03-16 19:47:46,086][model][INFO] - Training step 44960 loss 0.034776557236909866
[2025-03-16 19:48:26,703][model][INFO] - Training step 45120 loss 0.0390925258398056
[2025-03-16 19:49:06,365][model][INFO] - Training step 45280 loss 0.24533194303512573
[2025-03-16 19:49:46,017][model][INFO] - Training step 45440 loss 0.009088141843676567
[2025-03-16 19:50:26,695][model][INFO] - Training step 45600 loss 0.23700785636901855
[2025-03-16 19:51:06,510][model][INFO] - Training step 45760 loss 0.05964091420173645
[2025-03-16 19:51:46,030][model][INFO] - Training step 45920 loss 0.2648315131664276
[2025-03-16 19:52:27,226][model][INFO] - Training step 46080 loss 0.052728574723005295
[2025-03-16 19:53:08,634][model][INFO] - Training step 46240 loss 0.01637156307697296
[2025-03-16 19:53:49,332][model][INFO] - Training step 46400 loss 0.009358486160635948
[2025-03-16 19:54:28,882][model][INFO] - Training step 46560 loss 0.01359593030065298
[2025-03-16 19:55:09,602][model][INFO] - Training step 46720 loss 0.02181079238653183
[2025-03-16 19:55:50,433][model][INFO] - Training step 46880 loss 0.025217872112989426
[2025-03-16 19:56:30,221][model][INFO] - Training step 47040 loss 0.19932088255882263
[2025-03-16 19:57:10,459][model][INFO] - Training step 47200 loss 0.01478932797908783
[2025-03-16 19:57:50,780][model][INFO] - Training step 47360 loss 0.007926716469228268
[2025-03-16 19:58:29,885][model][INFO] - Training step 47520 loss 0.020056091248989105
[2025-03-16 19:59:11,498][model][INFO] - Training step 47680 loss 0.04895765334367752
[2025-03-16 19:59:51,880][model][INFO] - Training step 47840 loss 0.020547473803162575
[2025-03-16 20:00:31,907][model][INFO] - Training step 48000 loss 0.03850974887609482
[2025-03-16 20:01:13,381][model][INFO] - Training step 48160 loss 0.032485924661159515
[2025-03-16 20:01:52,644][model][INFO] - Training step 48320 loss 0.2586834728717804
[2025-03-16 20:02:31,956][model][INFO] - Training step 48480 loss 0.0035899982322007418
[2025-03-16 20:03:12,693][model][INFO] - Training step 48640 loss 0.019903406500816345
[2025-03-16 20:03:53,950][model][INFO] - Training step 48800 loss 0.017398405820131302
[2025-03-16 20:04:32,729][model][INFO] - Training step 48960 loss 0.006917471997439861
[2025-03-16 20:05:13,455][model][INFO] - Training step 49120 loss 0.006754528731107712
[2025-03-16 20:05:53,503][model][INFO] - Training step 49280 loss 0.006224216893315315
[2025-03-16 20:06:32,533][model][INFO] - Training step 49440 loss 0.030947905033826828
[2025-03-16 20:07:12,956][model][INFO] - Training step 49600 loss 0.2598397731781006
[2025-03-16 20:07:54,179][model][INFO] - Training step 49760 loss 0.01291787438094616
[2025-03-16 20:08:34,255][model][INFO] - Training step 49920 loss 0.01666417345404625
[2025-03-16 20:09:15,133][model][INFO] - Training step 50080 loss 0.017240265384316444
[2025-03-16 20:09:54,753][model][INFO] - Training step 50240 loss 0.006085047032684088
[2025-03-16 20:10:34,331][model][INFO] - Training step 50400 loss 0.04004382714629173
[2025-03-16 20:11:13,472][model][INFO] - Training step 50560 loss 0.011673102155327797
[2025-03-16 20:11:53,556][model][INFO] - Training step 50720 loss 0.16689294576644897
[2025-03-16 20:17:32,775][model][INFO] - Training step 80 loss 0.07757467031478882
[2025-03-16 20:18:13,761][model][INFO] - Training step 240 loss 0.010103452950716019
[2025-03-16 20:18:53,818][model][INFO] - Training step 400 loss 0.0040174443274736404
[2025-03-16 20:19:34,964][model][INFO] - Training step 560 loss 0.005134747363626957
[2025-03-16 20:20:14,980][model][INFO] - Training step 720 loss 0.002227918477728963
[2025-03-16 20:20:55,813][model][INFO] - Training step 880 loss 0.022201262414455414
[2025-03-16 20:21:35,185][model][INFO] - Training step 1040 loss 0.01202009990811348
[2025-03-16 20:22:15,049][model][INFO] - Training step 1200 loss 0.005155239254236221
[2025-03-16 20:22:57,147][model][INFO] - Training step 1360 loss 0.06993623822927475
[2025-03-16 20:23:37,044][model][INFO] - Training step 1520 loss 0.03335363790392876
[2025-03-16 20:24:16,894][model][INFO] - Training step 1680 loss 0.031064357608556747
[2025-03-16 20:24:56,716][model][INFO] - Training step 1840 loss 0.007229892071336508
[2025-03-16 20:25:37,521][model][INFO] - Training step 2000 loss 0.24850212037563324
[2025-03-16 20:26:17,961][model][INFO] - Training step 2160 loss 0.006516134366393089
[2025-03-16 20:26:56,958][model][INFO] - Training step 2320 loss 0.01806248351931572
[2025-03-16 20:27:36,582][model][INFO] - Training step 2480 loss 0.26883578300476074
[2025-03-16 20:28:15,616][model][INFO] - Training step 2640 loss 0.01891721412539482
[2025-03-16 20:28:55,639][model][INFO] - Training step 2800 loss 0.07431966811418533
[2025-03-16 20:29:36,302][model][INFO] - Training step 2960 loss 0.23747585713863373
[2025-03-16 20:30:15,904][model][INFO] - Training step 3120 loss 0.20183604955673218
[2025-03-16 20:30:55,956][model][INFO] - Training step 3280 loss 0.09268967807292938
[2025-03-16 20:31:35,204][model][INFO] - Training step 3440 loss 0.05653824284672737
[2025-03-16 20:32:14,781][model][INFO] - Training step 3600 loss 0.04786234349012375
[2025-03-16 20:32:54,205][model][INFO] - Training step 3760 loss 0.018803544342517853
[2025-03-16 20:33:34,108][model][INFO] - Training step 3920 loss 0.06171250715851784
[2025-03-16 20:34:14,941][model][INFO] - Training step 4080 loss 0.03650598227977753
[2025-03-16 20:34:54,129][model][INFO] - Training step 4240 loss 0.03440301492810249
[2025-03-16 20:35:35,203][model][INFO] - Training step 4400 loss 0.014233444817364216
[2025-03-16 20:36:16,149][model][INFO] - Training step 4560 loss 0.24209122359752655
[2025-03-16 20:36:57,368][model][INFO] - Training step 4720 loss 0.01840987801551819
[2025-03-16 20:37:37,120][model][INFO] - Training step 4880 loss 0.013074791990220547
[2025-03-16 20:38:16,910][model][INFO] - Training step 5040 loss 0.27844417095184326
[2025-03-16 20:38:57,003][model][INFO] - Training step 5200 loss 0.015293776988983154
[2025-03-16 20:39:36,296][model][INFO] - Training step 5360 loss 0.05218289792537689
[2025-03-16 20:40:16,369][model][INFO] - Training step 5520 loss 0.07483136653900146
[2025-03-16 20:40:57,891][model][INFO] - Training step 5680 loss 0.021247409284114838
[2025-03-16 20:41:38,200][model][INFO] - Training step 5840 loss 0.01914975419640541
[2025-03-16 20:42:18,919][model][INFO] - Training step 6000 loss 0.018925189971923828
[2025-03-16 20:43:00,962][model][INFO] - Training step 6160 loss 0.029442250728607178
[2025-03-16 20:43:42,135][model][INFO] - Training step 6320 loss 0.027230028063058853
[2025-03-16 20:44:22,742][model][INFO] - Training step 6480 loss 0.026875995099544525
[2025-03-16 20:45:02,625][model][INFO] - Training step 6640 loss 0.01429079845547676
[2025-03-16 20:45:42,284][model][INFO] - Training step 6800 loss 0.005289684981107712
[2025-03-16 20:46:21,289][model][INFO] - Training step 6960 loss 0.02721998654305935
[2025-03-16 20:47:02,882][model][INFO] - Training step 7120 loss 0.03256417438387871
[2025-03-16 20:47:43,045][model][INFO] - Training step 7280 loss 0.031104523688554764
[2025-03-16 20:48:22,746][model][INFO] - Training step 7440 loss 0.014332087710499763
[2025-03-16 20:49:01,780][model][INFO] - Training step 7600 loss 0.0684443935751915
[2025-03-16 20:49:40,953][model][INFO] - Training step 7760 loss 0.03725419193506241
[2025-03-16 20:50:23,147][model][INFO] - Training step 7920 loss 0.024022210389375687
[2025-03-16 20:51:02,590][model][INFO] - Training step 8080 loss 0.08518685400485992
[2025-03-16 20:51:41,949][model][INFO] - Training step 8240 loss 0.017231550067663193
[2025-03-16 20:52:22,060][model][INFO] - Training step 8400 loss 0.02938806638121605
[2025-03-16 20:53:01,945][model][INFO] - Training step 8560 loss 0.007577904500067234
[2025-03-16 20:53:41,953][model][INFO] - Training step 8720 loss 0.0868806391954422
[2025-03-16 20:54:21,971][model][INFO] - Training step 8880 loss 0.03999911621212959
[2025-03-16 20:55:01,235][model][INFO] - Training step 9040 loss 0.05116657167673111
[2025-03-16 20:55:40,733][model][INFO] - Training step 9200 loss 0.007287012413144112
[2025-03-16 20:56:21,156][model][INFO] - Training step 9360 loss 0.03407104313373566
[2025-03-16 20:57:01,606][model][INFO] - Training step 9520 loss 0.004656385630369186
[2025-03-16 20:57:41,090][model][INFO] - Training step 9680 loss 0.2521231770515442
[2025-03-16 20:58:21,426][model][INFO] - Training step 9840 loss 0.038653649389743805
[2025-03-16 20:59:01,856][model][INFO] - Training step 10000 loss 0.014036111533641815
[2025-03-16 20:59:42,707][model][INFO] - Training step 10160 loss 0.008650865405797958
[2025-03-16 21:00:21,662][model][INFO] - Training step 10320 loss 0.036765843629837036
[2025-03-16 21:01:03,122][model][INFO] - Training step 10480 loss 0.002731684595346451
[2025-03-16 21:01:43,524][model][INFO] - Training step 10640 loss 0.1801125705242157
[2025-03-16 21:02:23,653][model][INFO] - Training step 10800 loss 0.030918430536985397
[2025-03-16 21:03:03,520][model][INFO] - Training step 10960 loss 0.048948634415864944
[2025-03-16 21:03:43,570][model][INFO] - Training step 11120 loss 0.01712716929614544
[2025-03-16 21:04:23,798][model][INFO] - Training step 11280 loss 0.052536509931087494
[2025-03-16 21:05:03,136][model][INFO] - Training step 11440 loss 0.04111555963754654
[2025-03-16 21:05:44,738][model][INFO] - Training step 11600 loss 0.004502970725297928
[2025-03-16 21:06:25,524][model][INFO] - Training step 11760 loss 0.030354663729667664
[2025-03-16 21:07:03,940][model][INFO] - Training step 11920 loss 0.046578485518693924
[2025-03-16 21:07:43,491][model][INFO] - Training step 12080 loss 0.0327833890914917
[2025-03-16 21:08:23,439][model][INFO] - Training step 12240 loss 0.03338691592216492
[2025-03-16 21:09:02,213][model][INFO] - Training step 12400 loss 0.16496452689170837
[2025-03-16 21:09:42,642][model][INFO] - Training step 12560 loss 0.0631321370601654
[2025-03-16 21:10:21,732][model][INFO] - Training step 12720 loss 0.02707277610898018
[2025-03-16 21:11:02,573][model][INFO] - Training step 12880 loss 0.0401143915951252
[2025-03-16 21:11:42,000][model][INFO] - Training step 13040 loss 0.02541767805814743
[2025-03-16 21:12:21,637][model][INFO] - Training step 13200 loss 0.06110255420207977
[2025-03-16 21:13:01,705][model][INFO] - Training step 13360 loss 0.04088790714740753
[2025-03-16 21:13:40,648][model][INFO] - Training step 13520 loss 0.019514795392751694
[2025-03-16 21:14:20,998][model][INFO] - Training step 13680 loss 0.015830062329769135
[2025-03-16 21:15:00,948][model][INFO] - Training step 13840 loss 0.01977408304810524
[2025-03-16 21:15:41,655][model][INFO] - Training step 14000 loss 0.017752736806869507
[2025-03-16 21:16:22,976][model][INFO] - Training step 14160 loss 0.2542268633842468
[2025-03-16 21:17:02,690][model][INFO] - Training step 14320 loss 0.0222226120531559
[2025-03-16 21:17:42,141][model][INFO] - Training step 14480 loss 0.017739754170179367
[2025-03-16 21:18:23,083][model][INFO] - Training step 14640 loss 0.005215749144554138
[2025-03-16 21:19:02,206][model][INFO] - Training step 14800 loss 0.029934167861938477
[2025-03-16 21:19:42,809][model][INFO] - Training step 14960 loss 0.038482651114463806
[2025-03-16 21:20:22,865][model][INFO] - Training step 15120 loss 0.2367510050535202
[2025-03-16 21:21:01,925][model][INFO] - Training step 15280 loss 0.023805636912584305
[2025-03-16 21:21:42,565][model][INFO] - Training step 15440 loss 0.020394811406731606
[2025-03-16 21:22:23,045][model][INFO] - Training step 15600 loss 0.2549416422843933
[2025-03-16 21:23:03,224][model][INFO] - Training step 15760 loss 0.06858041882514954
[2025-03-16 21:23:43,170][model][INFO] - Training step 15920 loss 0.21825926005840302
[2025-03-16 21:24:22,665][model][INFO] - Training step 16080 loss 0.07195382565259933
[2025-03-16 21:25:01,992][model][INFO] - Training step 16240 loss 0.0468515120446682
[2025-03-16 21:25:41,370][model][INFO] - Training step 16400 loss 0.026543669402599335
[2025-03-16 21:26:22,428][model][INFO] - Training step 16560 loss 0.23621207475662231
[2025-03-16 21:27:02,734][model][INFO] - Training step 16720 loss 0.022840138524770737
[2025-03-16 21:27:43,433][model][INFO] - Training step 16880 loss 0.019478503614664078
[2025-03-16 21:28:25,435][model][INFO] - Training step 17040 loss 0.24473707377910614
[2025-03-16 21:29:06,061][model][INFO] - Training step 17200 loss 0.03657049313187599
[2025-03-16 21:29:47,055][model][INFO] - Training step 17360 loss 0.011939072981476784
[2025-03-16 21:30:26,683][model][INFO] - Training step 17520 loss 0.026937471702694893
[2025-03-16 21:31:07,783][model][INFO] - Training step 17680 loss 0.06433813273906708
[2025-03-16 21:31:47,672][model][INFO] - Training step 17840 loss 0.07700757682323456
[2025-03-16 21:32:27,754][model][INFO] - Training step 18000 loss 0.003845544531941414
[2025-03-16 21:33:08,535][model][INFO] - Training step 18160 loss 0.26962727308273315
[2025-03-16 21:33:49,115][model][INFO] - Training step 18320 loss 0.005218997597694397
[2025-03-16 21:34:29,530][model][INFO] - Training step 18480 loss 0.037283964455127716
[2025-03-16 21:35:10,440][model][INFO] - Training step 18640 loss 0.006579776294529438
[2025-03-16 21:35:52,054][model][INFO] - Training step 18800 loss 0.00623355945572257
[2025-03-16 21:36:32,618][model][INFO] - Training step 18960 loss 0.03180348128080368
[2025-03-16 21:37:12,803][model][INFO] - Training step 19120 loss 0.019061416387557983
[2025-03-16 21:37:52,800][model][INFO] - Training step 19280 loss 0.0629778802394867
[2025-03-16 21:38:32,003][model][INFO] - Training step 19440 loss 0.026554644107818604
[2025-03-16 21:39:12,786][model][INFO] - Training step 19600 loss 0.03954695910215378
[2025-03-16 21:39:52,648][model][INFO] - Training step 19760 loss 0.012809759005904198
[2025-03-16 21:40:33,313][model][INFO] - Training step 19920 loss 0.11021603643894196
[2025-03-16 21:41:13,325][model][INFO] - Training step 20080 loss 0.006739846430718899
[2025-03-16 21:41:52,948][model][INFO] - Training step 20240 loss 0.019197937101125717
[2025-03-16 21:42:33,017][model][INFO] - Training step 20400 loss 0.05393686518073082
[2025-03-16 21:43:11,744][model][INFO] - Training step 20560 loss 0.01722745969891548
[2025-03-16 21:43:52,307][model][INFO] - Training step 20720 loss 0.06696640700101852
[2025-03-16 21:44:31,942][model][INFO] - Training step 20880 loss 0.02054538205265999
[2025-03-16 21:45:12,864][model][INFO] - Training step 21040 loss 0.25492244958877563
[2025-03-16 21:45:51,189][model][INFO] - Training step 21200 loss 0.023163247853517532
[2025-03-16 21:46:31,666][model][INFO] - Training step 21360 loss 0.004005748778581619
[2025-03-16 21:47:12,241][model][INFO] - Training step 21520 loss 0.023360002785921097
[2025-03-16 21:47:52,116][model][INFO] - Training step 21680 loss 0.24418608844280243
[2025-03-16 21:48:32,522][model][INFO] - Training step 21840 loss 0.27799931168556213
[2025-03-16 21:49:12,064][model][INFO] - Training step 22000 loss 0.2786450982093811
[2025-03-16 21:49:51,772][model][INFO] - Training step 22160 loss 0.025458430871367455
[2025-03-16 21:50:30,728][model][INFO] - Training step 22320 loss 0.027258479967713356
[2025-03-16 21:51:11,183][model][INFO] - Training step 22480 loss 0.04148738086223602
[2025-03-16 21:51:51,241][model][INFO] - Training step 22640 loss 0.25983646512031555
[2025-03-16 21:52:30,409][model][INFO] - Training step 22800 loss 0.2577783465385437
[2025-03-16 21:53:09,350][model][INFO] - Training step 22960 loss 0.016894102096557617
[2025-03-16 21:53:49,045][model][INFO] - Training step 23120 loss 0.2540929615497589
[2025-03-16 21:54:30,201][model][INFO] - Training step 23280 loss 0.01990756019949913
[2025-03-16 21:55:10,681][model][INFO] - Training step 23440 loss 0.09084588289260864
[2025-03-16 21:55:49,946][model][INFO] - Training step 23600 loss 0.002110731787979603
[2025-03-16 21:56:29,740][model][INFO] - Training step 23760 loss 0.03993330895900726
[2025-03-16 21:57:10,718][model][INFO] - Training step 23920 loss 0.24914123117923737
[2025-03-16 21:57:50,541][model][INFO] - Training step 24080 loss 0.20494931936264038
[2025-03-16 21:58:29,620][model][INFO] - Training step 24240 loss 0.01815255731344223
[2025-03-16 21:59:09,985][model][INFO] - Training step 24400 loss 0.0073697385378181934
[2025-03-16 21:59:49,725][model][INFO] - Training step 24560 loss 0.25192946195602417
[2025-03-16 22:00:28,850][model][INFO] - Training step 24720 loss 0.24880990386009216
[2025-03-16 22:01:08,992][model][INFO] - Training step 24880 loss 0.05000311881303787
[2025-03-16 22:01:49,166][model][INFO] - Training step 25040 loss 0.2268296778202057
[2025-03-16 22:02:29,557][model][INFO] - Training step 25200 loss 0.01832124963402748
[2025-03-16 22:03:09,628][model][INFO] - Training step 25360 loss 0.25318804383277893
[2025-03-16 22:03:49,271][model][INFO] - Training step 25520 loss 0.04379718750715256
[2025-03-16 22:04:27,946][model][INFO] - Training step 25680 loss 0.0860024094581604
[2025-03-16 22:05:07,819][model][INFO] - Training step 25840 loss 0.050642721354961395
[2025-03-16 22:05:47,494][model][INFO] - Training step 26000 loss 0.29519176483154297
[2025-03-16 22:06:27,069][model][INFO] - Training step 26160 loss 0.2571144700050354
[2025-03-16 22:07:05,851][model][INFO] - Training step 26320 loss 0.0362919345498085
[2025-03-16 22:07:45,707][model][INFO] - Training step 26480 loss 0.02026088535785675
[2025-03-16 22:08:24,960][model][INFO] - Training step 26640 loss 0.025963295251131058
[2025-03-16 22:09:06,142][model][INFO] - Training step 26800 loss 0.007467806339263916
[2025-03-16 22:09:45,652][model][INFO] - Training step 26960 loss 0.025978781282901764
[2025-03-16 22:10:26,209][model][INFO] - Training step 27120 loss 0.0037728133611381054
[2025-03-16 22:11:06,071][model][INFO] - Training step 27280 loss 0.0301804356276989
[2025-03-16 22:11:46,128][model][INFO] - Training step 27440 loss 0.041328854858875275
[2025-03-16 22:12:25,229][model][INFO] - Training step 27600 loss 0.04807144030928612
[2025-03-16 22:13:05,340][model][INFO] - Training step 27760 loss 0.003818970639258623
[2025-03-16 22:13:45,086][model][INFO] - Training step 27920 loss 0.012115079909563065
[2025-03-16 22:14:25,959][model][INFO] - Training step 28080 loss 0.025004703551530838
[2025-03-16 22:15:07,095][model][INFO] - Training step 28240 loss 0.04625658318400383
[2025-03-16 22:15:48,175][model][INFO] - Training step 28400 loss 0.04174606502056122
[2025-03-16 22:16:29,540][model][INFO] - Training step 28560 loss 0.01839183084666729
[2025-03-16 22:17:09,107][model][INFO] - Training step 28720 loss 0.25008854269981384
[2025-03-16 22:17:49,474][model][INFO] - Training step 28880 loss 0.009571035392582417
[2025-03-16 22:18:29,441][model][INFO] - Training step 29040 loss 0.03768569976091385
[2025-03-16 22:19:08,859][model][INFO] - Training step 29200 loss 0.0481114536523819
[2025-03-16 22:19:48,965][model][INFO] - Training step 29360 loss 0.007898541167378426
[2025-03-16 22:20:30,149][model][INFO] - Training step 29520 loss 0.2565600275993347
[2025-03-16 22:21:10,665][model][INFO] - Training step 29680 loss 0.030707281082868576
[2025-03-16 22:21:50,870][model][INFO] - Training step 29840 loss 0.04512116312980652
[2025-03-16 22:22:31,100][model][INFO] - Training step 30000 loss 0.011190501973032951
[2025-03-16 22:23:10,239][model][INFO] - Training step 30160 loss 0.03606986254453659
[2025-03-16 22:23:49,826][model][INFO] - Training step 30320 loss 0.20824646949768066
[2025-03-16 22:24:30,091][model][INFO] - Training step 30480 loss 0.26526978611946106
[2025-03-16 22:25:07,635][model][INFO] - Training step 30640 loss 0.0038286736235022545
[2025-03-16 22:25:47,308][model][INFO] - Training step 30800 loss 0.2861288785934448
[2025-03-16 22:26:27,061][model][INFO] - Training step 30960 loss 0.02135040983557701
[2025-03-16 22:27:06,892][model][INFO] - Training step 31120 loss 0.1439576894044876
[2025-03-16 22:27:46,372][model][INFO] - Training step 31280 loss 0.02848120406270027
[2025-03-16 22:28:27,056][model][INFO] - Training step 31440 loss 0.026152174919843674
[2025-03-16 22:29:07,959][model][INFO] - Training step 31600 loss 0.006978577468544245
[2025-03-16 22:29:48,945][model][INFO] - Training step 31760 loss 0.06219792366027832
[2025-03-16 22:30:28,381][model][INFO] - Training step 31920 loss 0.17183735966682434
[2025-03-16 22:31:08,516][model][INFO] - Training step 32080 loss 0.07219631969928741
[2025-03-16 22:31:49,650][model][INFO] - Training step 32240 loss 0.01673027127981186
[2025-03-16 22:32:30,142][model][INFO] - Training step 32400 loss 0.021671146154403687
[2025-03-16 22:33:10,552][model][INFO] - Training step 32560 loss 0.029947586357593536
[2025-03-16 22:33:53,225][model][INFO] - Training step 32720 loss 0.023098081350326538
[2025-03-16 22:34:35,141][model][INFO] - Training step 32880 loss 0.027324892580509186
[2025-03-16 22:35:15,769][model][INFO] - Training step 33040 loss 0.036724090576171875
[2025-03-16 22:35:56,197][model][INFO] - Training step 33200 loss 0.020259039476513863
[2025-03-16 22:36:35,924][model][INFO] - Training step 33360 loss 0.008251192048192024
[2025-03-16 22:37:14,941][model][INFO] - Training step 33520 loss 0.004836793057620525
[2025-03-16 22:37:55,248][model][INFO] - Training step 33680 loss 0.017344946041703224
[2025-03-16 22:38:35,508][model][INFO] - Training step 33840 loss 0.023806635290384293
[2025-03-16 22:39:14,794][model][INFO] - Training step 34000 loss 0.04367183893918991
[2025-03-16 22:39:55,809][model][INFO] - Training step 34160 loss 0.12887129187583923
[2025-03-16 22:40:35,802][model][INFO] - Training step 34320 loss 0.2536552846431732
[2025-03-16 22:41:16,316][model][INFO] - Training step 34480 loss 0.043647460639476776
[2025-03-16 22:41:56,770][model][INFO] - Training step 34640 loss 0.05146288871765137
[2025-03-16 22:42:36,812][model][INFO] - Training step 34800 loss 0.021379919722676277
[2025-03-16 22:43:17,637][model][INFO] - Training step 34960 loss 0.21456962823867798
[2025-03-16 22:43:57,909][model][INFO] - Training step 35120 loss 0.01674325205385685
[2025-03-16 22:44:38,156][model][INFO] - Training step 35280 loss 0.021371187642216682
[2025-03-16 22:45:18,667][model][INFO] - Training step 35440 loss 0.018002508208155632
[2025-03-16 22:45:58,210][model][INFO] - Training step 35600 loss 0.03004814311861992
[2025-03-16 22:46:39,434][model][INFO] - Training step 35760 loss 0.02238154038786888
[2025-03-16 22:47:19,484][model][INFO] - Training step 35920 loss 0.15581239759922028
[2025-03-16 22:48:01,508][model][INFO] - Training step 36080 loss 0.2488299310207367
[2025-03-16 22:48:40,533][model][INFO] - Training step 36240 loss 0.00529672484844923
[2025-03-16 22:49:20,746][model][INFO] - Training step 36400 loss 0.01788116991519928
[2025-03-16 22:50:01,909][model][INFO] - Training step 36560 loss 0.03218545764684677
[2025-03-16 22:50:42,966][model][INFO] - Training step 36720 loss 0.030683085322380066
[2025-03-16 22:51:22,967][model][INFO] - Training step 36880 loss 0.07742709666490555
[2025-03-16 22:52:03,051][model][INFO] - Training step 37040 loss 0.008623496629297733
[2025-03-16 22:52:42,688][model][INFO] - Training step 37200 loss 0.023677775636315346
[2025-03-16 22:53:23,349][model][INFO] - Training step 37360 loss 0.024033021181821823
[2025-03-16 22:54:02,646][model][INFO] - Training step 37520 loss 0.009269701316952705
[2025-03-16 22:54:43,431][model][INFO] - Training step 37680 loss 0.010536259040236473
[2025-03-16 22:55:26,519][model][INFO] - Training step 37840 loss 0.2574179172515869
[2025-03-16 22:56:06,636][model][INFO] - Training step 38000 loss 0.0360863134264946
[2025-03-16 22:56:47,681][model][INFO] - Training step 38160 loss 0.026869846507906914
[2025-03-16 22:57:29,133][model][INFO] - Training step 38320 loss 0.00476496759802103
[2025-03-16 22:58:08,705][model][INFO] - Training step 38480 loss 0.022499706596136093
[2025-03-16 22:58:47,778][model][INFO] - Training step 38640 loss 0.06341196596622467
[2025-03-16 22:59:25,766][model][INFO] - Training step 38800 loss 0.013346809893846512
[2025-03-16 23:00:06,866][model][INFO] - Training step 38960 loss 0.021921202540397644
[2025-03-16 23:00:46,817][model][INFO] - Training step 39120 loss 0.019196482375264168
[2025-03-16 23:01:28,030][model][INFO] - Training step 39280 loss 0.0021995166316628456
[2025-03-16 23:02:07,909][model][INFO] - Training step 39440 loss 0.01273767277598381
[2025-03-16 23:02:47,984][model][INFO] - Training step 39600 loss 0.019970372319221497
[2025-03-16 23:03:28,350][model][INFO] - Training step 39760 loss 0.03287697583436966
[2025-03-16 23:04:08,908][model][INFO] - Training step 39920 loss 0.01805567741394043
[2025-03-16 23:04:48,474][model][INFO] - Training step 40080 loss 0.004367458634078503
[2025-03-16 23:05:28,987][model][INFO] - Training step 40240 loss 0.003953723236918449
[2025-03-16 23:06:07,636][model][INFO] - Training step 40400 loss 0.022511113435029984
[2025-03-16 23:06:50,381][model][INFO] - Training step 40560 loss 0.003691723570227623
[2025-03-16 23:07:30,420][model][INFO] - Training step 40720 loss 0.002901682397350669
[2025-03-16 23:08:10,017][model][INFO] - Training step 40880 loss 0.05357503890991211
[2025-03-16 23:08:50,880][model][INFO] - Training step 41040 loss 0.03682846948504448
[2025-03-16 23:09:31,279][model][INFO] - Training step 41200 loss 0.01300177350640297
[2025-03-16 23:10:10,837][model][INFO] - Training step 41360 loss 0.008328583091497421
[2025-03-16 23:10:51,831][model][INFO] - Training step 41520 loss 0.004513842985033989
[2025-03-16 23:11:32,450][model][INFO] - Training step 41680 loss 0.053538642823696136
[2025-03-16 23:12:12,249][model][INFO] - Training step 41840 loss 0.25861644744873047
[2025-03-16 23:12:52,984][model][INFO] - Training step 42000 loss 0.06166483461856842
[2025-03-16 23:13:33,363][model][INFO] - Training step 42160 loss 0.018482286483049393
[2025-03-16 23:14:12,720][model][INFO] - Training step 42320 loss 0.012975753284990788
[2025-03-16 23:14:52,708][model][INFO] - Training step 42480 loss 0.019976096227765083
[2025-03-16 23:15:31,887][model][INFO] - Training step 42640 loss 0.01723572425544262
[2025-03-16 23:16:11,600][model][INFO] - Training step 42800 loss 0.022891737520694733
[2025-03-16 23:16:52,378][model][INFO] - Training step 42960 loss 0.017122458666563034
[2025-03-16 23:17:34,683][model][INFO] - Training step 43120 loss 0.0022581021767109632
[2025-03-16 23:18:14,763][model][INFO] - Training step 43280 loss 0.07348592579364777
[2025-03-16 23:18:56,899][model][INFO] - Training step 43440 loss 0.24848572909832
[2025-03-16 23:19:36,767][model][INFO] - Training step 43600 loss 0.2166525423526764
[2025-03-16 23:20:16,870][model][INFO] - Training step 43760 loss 0.019930988550186157
[2025-03-16 23:20:57,134][model][INFO] - Training step 43920 loss 0.03187517821788788
[2025-03-16 23:21:37,552][model][INFO] - Training step 44080 loss 0.006777206901460886
[2025-03-16 23:22:18,307][model][INFO] - Training step 44240 loss 0.03836727514863014
[2025-03-16 23:22:57,736][model][INFO] - Training step 44400 loss 0.035864800214767456
[2025-03-16 23:23:37,790][model][INFO] - Training step 44560 loss 0.2600971460342407
[2025-03-16 23:24:17,856][model][INFO] - Training step 44720 loss 0.02360963448882103
[2025-03-16 23:24:57,260][model][INFO] - Training step 44880 loss 0.042889855802059174
[2025-03-16 23:25:38,560][model][INFO] - Training step 45040 loss 0.002498780842870474
[2025-03-16 23:26:18,280][model][INFO] - Training step 45200 loss 0.012588050216436386
[2025-03-16 23:26:59,934][model][INFO] - Training step 45360 loss 0.034568995237350464
[2025-03-16 23:27:39,601][model][INFO] - Training step 45520 loss 0.02167663909494877
[2025-03-16 23:28:18,225][model][INFO] - Training step 45680 loss 0.01411527395248413
[2025-03-16 23:28:59,508][model][INFO] - Training step 45840 loss 0.002987063955515623
[2025-03-16 23:29:40,097][model][INFO] - Training step 46000 loss 0.06358601897954941
[2025-03-16 23:30:20,060][model][INFO] - Training step 46160 loss 0.24681678414344788
[2025-03-16 23:31:01,753][model][INFO] - Training step 46320 loss 0.02262982726097107
[2025-03-16 23:31:41,403][model][INFO] - Training step 46480 loss 0.013096718117594719
[2025-03-16 23:32:20,970][model][INFO] - Training step 46640 loss 0.05594869703054428
[2025-03-16 23:33:00,524][model][INFO] - Training step 46800 loss 0.23249828815460205
[2025-03-16 23:33:41,587][model][INFO] - Training step 46960 loss 0.24042317271232605
[2025-03-16 23:34:20,866][model][INFO] - Training step 47120 loss 0.050853319466114044
[2025-03-16 23:35:02,050][model][INFO] - Training step 47280 loss 0.005614493973553181
[2025-03-16 23:35:44,041][model][INFO] - Training step 47440 loss 0.012030666694045067
[2025-03-16 23:36:23,536][model][INFO] - Training step 47600 loss 0.03807854652404785
[2025-03-16 23:37:04,214][model][INFO] - Training step 47760 loss 0.05710451304912567
[2025-03-16 23:37:44,059][model][INFO] - Training step 47920 loss 0.1462760865688324
[2025-03-16 23:38:24,151][model][INFO] - Training step 48080 loss 0.2500959038734436
[2025-03-16 23:39:03,353][model][INFO] - Training step 48240 loss 0.019372690469026566
[2025-03-16 23:39:42,943][model][INFO] - Training step 48400 loss 0.03660063445568085
[2025-03-16 23:40:25,037][model][INFO] - Training step 48560 loss 0.03020990826189518
[2025-03-16 23:41:05,100][model][INFO] - Training step 48720 loss 0.24499136209487915
[2025-03-16 23:41:45,828][model][INFO] - Training step 48880 loss 0.01785687357187271
[2025-03-16 23:42:26,714][model][INFO] - Training step 49040 loss 0.25231778621673584
[2025-03-16 23:43:06,598][model][INFO] - Training step 49200 loss 0.011651163920760155
[2025-03-16 23:43:45,803][model][INFO] - Training step 49360 loss 0.021245647221803665
[2025-03-16 23:44:26,265][model][INFO] - Training step 49520 loss 0.03437693417072296
[2025-03-16 23:45:08,138][model][INFO] - Training step 49680 loss 0.060536716133356094
[2025-03-16 23:45:47,425][model][INFO] - Training step 49840 loss 0.05608012527227402
[2025-03-16 23:46:26,768][model][INFO] - Training step 50000 loss 0.0033491509966552258
[2025-03-16 23:47:06,977][model][INFO] - Training step 50160 loss 0.015805091708898544
[2025-03-16 23:47:46,909][model][INFO] - Training step 50320 loss 0.07465552538633347
[2025-03-16 23:48:26,737][model][INFO] - Training step 50480 loss 0.24848660826683044
[2025-03-16 23:49:05,868][model][INFO] - Training step 50640 loss 0.023119628429412842
[2025-03-16 23:54:45,363][model][INFO] - Training step 0 loss 0.004886690527200699
[2025-03-16 23:55:25,888][model][INFO] - Training step 160 loss 0.013021942228078842
[2025-03-16 23:56:08,110][model][INFO] - Training step 320 loss 0.02971300482749939
[2025-03-16 23:56:48,184][model][INFO] - Training step 480 loss 0.19594557583332062
[2025-03-16 23:57:26,978][model][INFO] - Training step 640 loss 0.020297158509492874
[2025-03-16 23:58:07,444][model][INFO] - Training step 800 loss 0.005106478463858366
[2025-03-16 23:58:47,923][model][INFO] - Training step 960 loss 0.01297593954950571
[2025-03-16 23:59:28,354][model][INFO] - Training step 1120 loss 0.06150038540363312
[2025-03-17 00:00:09,131][model][INFO] - Training step 1280 loss 0.013378775678575039
[2025-03-17 00:00:48,476][model][INFO] - Training step 1440 loss 0.1329674869775772
[2025-03-17 00:01:29,508][model][INFO] - Training step 1600 loss 0.042510636150836945
[2025-03-17 00:02:08,995][model][INFO] - Training step 1760 loss 0.02348669059574604
[2025-03-17 00:02:49,337][model][INFO] - Training step 1920 loss 0.04803415760397911
[2025-03-17 00:03:29,429][model][INFO] - Training step 2080 loss 0.05467391014099121
[2025-03-17 00:04:10,436][model][INFO] - Training step 2240 loss 0.2554490268230438
[2025-03-17 00:04:49,906][model][INFO] - Training step 2400 loss 0.02135995402932167
[2025-03-17 00:05:30,655][model][INFO] - Training step 2560 loss 0.05409121885895729
[2025-03-17 00:06:10,482][model][INFO] - Training step 2720 loss 0.020993195474147797
[2025-03-17 00:06:49,995][model][INFO] - Training step 2880 loss 0.017942139878869057
[2025-03-17 00:07:29,881][model][INFO] - Training step 3040 loss 0.004068730864673853
[2025-03-17 00:08:10,574][model][INFO] - Training step 3200 loss 0.26988232135772705
[2025-03-17 00:08:51,982][model][INFO] - Training step 3360 loss 0.013279653154313564
[2025-03-17 00:09:32,298][model][INFO] - Training step 3520 loss 0.0039521451108157635
[2025-03-17 00:10:11,803][model][INFO] - Training step 3680 loss 0.022524699568748474
[2025-03-17 00:10:50,498][model][INFO] - Training step 3840 loss 0.21856677532196045
[2025-03-17 00:11:31,486][model][INFO] - Training step 4000 loss 0.047014154493808746
[2025-03-17 00:12:12,508][model][INFO] - Training step 4160 loss 0.012976346537470818
[2025-03-17 00:12:55,051][model][INFO] - Training step 4320 loss 0.02491290494799614
[2025-03-17 00:13:34,869][model][INFO] - Training step 4480 loss 0.2539282441139221
[2025-03-17 00:14:16,631][model][INFO] - Training step 4640 loss 0.2470925748348236
[2025-03-17 00:14:56,904][model][INFO] - Training step 4800 loss 0.027227086946368217
[2025-03-17 00:15:37,620][model][INFO] - Training step 4960 loss 0.013499277643859386
[2025-03-17 00:16:19,818][model][INFO] - Training step 5120 loss 0.008489897474646568
[2025-03-17 00:17:01,091][model][INFO] - Training step 5280 loss 0.02117551490664482
[2025-03-17 00:17:41,451][model][INFO] - Training step 5440 loss 0.2445501685142517
[2025-03-17 00:18:20,610][model][INFO] - Training step 5600 loss 0.05691865086555481
[2025-03-17 00:18:59,780][model][INFO] - Training step 5760 loss 0.027114178985357285
[2025-03-17 00:19:39,208][model][INFO] - Training step 5920 loss 0.024865828454494476
[2025-03-17 00:20:17,400][model][INFO] - Training step 6080 loss 0.16498994827270508
[2025-03-17 00:20:56,990][model][INFO] - Training step 6240 loss 0.006250740960240364
[2025-03-17 00:21:38,029][model][INFO] - Training step 6400 loss 0.038559019565582275
[2025-03-17 00:22:18,083][model][INFO] - Training step 6560 loss 0.029272567480802536
[2025-03-17 00:22:59,383][model][INFO] - Training step 6720 loss 0.019414681941270828
[2025-03-17 00:23:40,734][model][INFO] - Training step 6880 loss 0.26132315397262573
[2025-03-17 00:24:20,766][model][INFO] - Training step 7040 loss 0.015860293060541153
[2025-03-17 00:25:03,374][model][INFO] - Training step 7200 loss 0.05885602906346321
[2025-03-17 00:25:42,821][model][INFO] - Training step 7360 loss 0.011930452659726143
[2025-03-17 00:26:23,621][model][INFO] - Training step 7520 loss 0.026889842003583908
[2025-03-17 00:27:04,602][model][INFO] - Training step 7680 loss 0.03369147330522537
[2025-03-17 00:27:44,903][model][INFO] - Training step 7840 loss 0.026279501616954803
[2025-03-17 00:28:25,292][model][INFO] - Training step 8000 loss 0.03209172189235687
[2025-03-17 00:29:04,988][model][INFO] - Training step 8160 loss 0.24494272470474243
[2025-03-17 00:29:45,831][model][INFO] - Training step 8320 loss 0.024194618687033653
[2025-03-17 00:30:25,748][model][INFO] - Training step 8480 loss 0.11277934908866882
[2025-03-17 00:31:04,938][model][INFO] - Training step 8640 loss 0.00563368946313858
[2025-03-17 00:31:44,764][model][INFO] - Training step 8800 loss 0.02915855683386326
[2025-03-17 00:32:24,684][model][INFO] - Training step 8960 loss 0.13651186227798462
[2025-03-17 00:33:03,168][model][INFO] - Training step 9120 loss 0.2524771988391876
[2025-03-17 00:33:42,742][model][INFO] - Training step 9280 loss 0.03925507143139839
[2025-03-17 00:34:24,412][model][INFO] - Training step 9440 loss 0.014096002094447613
[2025-03-17 00:35:04,094][model][INFO] - Training step 9600 loss 0.01881588250398636
[2025-03-17 00:35:44,265][model][INFO] - Training step 9760 loss 0.01677781529724598
[2025-03-17 00:36:24,335][model][INFO] - Training step 9920 loss 0.015651557594537735
[2025-03-17 00:37:05,685][model][INFO] - Training step 10080 loss 0.025996625423431396
[2025-03-17 00:37:45,263][model][INFO] - Training step 10240 loss 0.24029451608657837
[2025-03-17 00:38:26,635][model][INFO] - Training step 10400 loss 0.07344111800193787
[2025-03-17 00:39:06,956][model][INFO] - Training step 10560 loss 0.07926515489816666
[2025-03-17 00:39:46,910][model][INFO] - Training step 10720 loss 0.2625434398651123
[2025-03-17 00:40:26,526][model][INFO] - Training step 10880 loss 0.03451332077383995
[2025-03-17 00:41:06,189][model][INFO] - Training step 11040 loss 0.02481793239712715
[2025-03-17 00:41:46,095][model][INFO] - Training step 11200 loss 0.00721207819879055
[2025-03-17 00:42:25,857][model][INFO] - Training step 11360 loss 0.019938483834266663
[2025-03-17 00:43:06,432][model][INFO] - Training step 11520 loss 0.23488488793373108
[2025-03-17 00:43:47,266][model][INFO] - Training step 11680 loss 0.05461816489696503
[2025-03-17 00:44:28,076][model][INFO] - Training step 11840 loss 0.23791328072547913
[2025-03-17 00:45:07,197][model][INFO] - Training step 12000 loss 0.024319563060998917
[2025-03-17 00:45:48,976][model][INFO] - Training step 12160 loss 0.2390851378440857
[2025-03-17 00:46:27,778][model][INFO] - Training step 12320 loss 0.03429562970995903
[2025-03-17 00:47:09,236][model][INFO] - Training step 12480 loss 0.020193040370941162
[2025-03-17 00:47:48,430][model][INFO] - Training step 12640 loss 0.22641617059707642
[2025-03-17 00:48:27,438][model][INFO] - Training step 12800 loss 0.020144924521446228
[2025-03-17 00:49:07,256][model][INFO] - Training step 12960 loss 0.014221908524632454
[2025-03-17 00:49:47,735][model][INFO] - Training step 13120 loss 0.23065467178821564
[2025-03-17 00:50:28,516][model][INFO] - Training step 13280 loss 0.010798659175634384
[2025-03-17 00:51:08,892][model][INFO] - Training step 13440 loss 0.5118285417556763
[2025-03-17 00:51:49,031][model][INFO] - Training step 13600 loss 0.026810117065906525
[2025-03-17 00:52:30,393][model][INFO] - Training step 13760 loss 0.023172829300165176
[2025-03-17 00:53:09,975][model][INFO] - Training step 13920 loss 0.08274149894714355
[2025-03-17 00:53:50,082][model][INFO] - Training step 14080 loss 0.08319412171840668
[2025-03-17 00:54:29,602][model][INFO] - Training step 14240 loss 0.0579439140856266
[2025-03-17 00:55:09,343][model][INFO] - Training step 14400 loss 0.007759287022054195
[2025-03-17 00:55:49,681][model][INFO] - Training step 14560 loss 0.023911599069833755
[2025-03-17 00:56:29,262][model][INFO] - Training step 14720 loss 0.015539176762104034
[2025-03-17 00:57:08,944][model][INFO] - Training step 14880 loss 0.034672852605581284
[2025-03-17 00:57:49,119][model][INFO] - Training step 15040 loss 0.07075540721416473
[2025-03-17 00:58:27,472][model][INFO] - Training step 15200 loss 0.02842537686228752
[2025-03-17 00:59:07,084][model][INFO] - Training step 15360 loss 0.0037532595451921225
[2025-03-17 00:59:46,300][model][INFO] - Training step 15520 loss 0.26844969391822815
[2025-03-17 01:00:27,652][model][INFO] - Training step 15680 loss 0.015366552397608757
[2025-03-17 01:01:08,583][model][INFO] - Training step 15840 loss 0.06447718292474747
[2025-03-17 01:01:48,473][model][INFO] - Training step 16000 loss 0.25806576013565063
[2025-03-17 01:02:28,674][model][INFO] - Training step 16160 loss 0.26924076676368713
[2025-03-17 01:03:07,942][model][INFO] - Training step 16320 loss 0.024224979802966118
[2025-03-17 01:03:46,611][model][INFO] - Training step 16480 loss 0.016733799129724503
[2025-03-17 01:04:26,604][model][INFO] - Training step 16640 loss 0.37312060594558716
[2025-03-17 01:05:05,191][model][INFO] - Training step 16800 loss 0.030322013422846794
[2025-03-17 01:05:45,876][model][INFO] - Training step 16960 loss 0.034930646419525146
[2025-03-17 01:06:25,737][model][INFO] - Training step 17120 loss 0.023703821003437042
[2025-03-17 01:07:06,781][model][INFO] - Training step 17280 loss 0.011016497388482094
[2025-03-17 01:07:46,437][model][INFO] - Training step 17440 loss 0.0902789831161499
[2025-03-17 01:08:26,700][model][INFO] - Training step 17600 loss 0.021524295210838318
[2025-03-17 01:09:07,363][model][INFO] - Training step 17760 loss 0.036146849393844604
[2025-03-17 01:09:45,188][model][INFO] - Training step 17920 loss 0.2645496428012848
[2025-03-17 01:10:25,307][model][INFO] - Training step 18080 loss 0.004567553289234638
[2025-03-17 01:11:05,693][model][INFO] - Training step 18240 loss 0.035243578255176544
[2025-03-17 01:11:46,631][model][INFO] - Training step 18400 loss 0.08509461581707001
[2025-03-17 01:12:26,032][model][INFO] - Training step 18560 loss 0.0059098610654473305
[2025-03-17 01:13:05,041][model][INFO] - Training step 18720 loss 0.19189181923866272
[2025-03-17 01:13:47,184][model][INFO] - Training step 18880 loss 0.004288484342396259
[2025-03-17 01:14:25,546][model][INFO] - Training step 19040 loss 0.21336302161216736
[2025-03-17 01:15:05,499][model][INFO] - Training step 19200 loss 0.13668282330036163
[2025-03-17 01:15:44,891][model][INFO] - Training step 19360 loss 0.022914301604032516
[2025-03-17 01:16:24,526][model][INFO] - Training step 19520 loss 0.0037451053503900766
[2025-03-17 01:17:04,377][model][INFO] - Training step 19680 loss 0.25396743416786194
[2025-03-17 01:17:45,163][model][INFO] - Training step 19840 loss 0.06050710380077362
[2025-03-17 01:18:24,770][model][INFO] - Training step 20000 loss 0.034330662339925766
[2025-03-17 01:19:05,048][model][INFO] - Training step 20160 loss 0.003311020787805319
[2025-03-17 01:19:44,414][model][INFO] - Training step 20320 loss 0.036514051258563995
[2025-03-17 01:20:25,700][model][INFO] - Training step 20480 loss 0.031659215688705444
[2025-03-17 01:21:04,852][model][INFO] - Training step 20640 loss 0.021363144740462303
[2025-03-17 01:21:45,716][model][INFO] - Training step 20800 loss 0.2683306336402893
[2025-03-17 01:22:26,017][model][INFO] - Training step 20960 loss 0.016693858429789543
[2025-03-17 01:23:06,782][model][INFO] - Training step 21120 loss 0.04822687804698944
[2025-03-17 01:23:47,232][model][INFO] - Training step 21280 loss 0.04702942073345184
[2025-03-17 01:24:26,375][model][INFO] - Training step 21440 loss 0.01775679737329483
[2025-03-17 01:25:05,407][model][INFO] - Training step 21600 loss 0.25672900676727295
[2025-03-17 01:25:44,770][model][INFO] - Training step 21760 loss 0.2567518651485443
[2025-03-17 01:26:23,566][model][INFO] - Training step 21920 loss 0.017451703548431396
[2025-03-17 01:27:04,055][model][INFO] - Training step 22080 loss 0.05816849693655968
[2025-03-17 01:27:44,004][model][INFO] - Training step 22240 loss 0.02725262939929962
[2025-03-17 01:28:25,320][model][INFO] - Training step 22400 loss 0.005412546917796135
[2025-03-17 01:29:04,988][model][INFO] - Training step 22560 loss 0.02127748727798462
[2025-03-17 01:29:45,567][model][INFO] - Training step 22720 loss 0.011286438442766666
[2025-03-17 01:30:25,541][model][INFO] - Training step 22880 loss 0.01614414155483246
[2025-03-17 01:31:05,668][model][INFO] - Training step 23040 loss 0.03261144831776619
[2025-03-17 01:31:45,863][model][INFO] - Training step 23200 loss 0.055529944598674774
[2025-03-17 01:32:25,443][model][INFO] - Training step 23360 loss 0.255695104598999
[2025-03-17 01:33:05,032][model][INFO] - Training step 23520 loss 0.027474157512187958
[2025-03-17 01:33:44,557][model][INFO] - Training step 23680 loss 0.021076178178191185
[2025-03-17 01:34:24,408][model][INFO] - Training step 23840 loss 0.02404678799211979
[2025-03-17 01:35:04,035][model][INFO] - Training step 24000 loss 0.019028861075639725
[2025-03-17 01:35:42,815][model][INFO] - Training step 24160 loss 0.05110481381416321
[2025-03-17 01:36:22,234][model][INFO] - Training step 24320 loss 0.028184115886688232
[2025-03-17 01:37:02,670][model][INFO] - Training step 24480 loss 0.00772511912509799
[2025-03-17 01:37:41,809][model][INFO] - Training step 24640 loss 0.025862473994493484
[2025-03-17 01:38:22,959][model][INFO] - Training step 24800 loss 0.008760310709476471
[2025-03-17 01:39:04,439][model][INFO] - Training step 24960 loss 0.03888782113790512
[2025-03-17 01:39:45,599][model][INFO] - Training step 25120 loss 0.05659226328134537
[2025-03-17 01:40:24,643][model][INFO] - Training step 25280 loss 0.01874970830976963
[2025-03-17 01:41:04,917][model][INFO] - Training step 25440 loss 0.09212854504585266
[2025-03-17 01:41:44,237][model][INFO] - Training step 25600 loss 0.23364347219467163
[2025-03-17 01:42:23,257][model][INFO] - Training step 25760 loss 0.021118557080626488
[2025-03-17 01:43:03,623][model][INFO] - Training step 25920 loss 0.021357160061597824
[2025-03-17 01:43:42,786][model][INFO] - Training step 26080 loss 0.017523422837257385
[2025-03-17 01:44:22,979][model][INFO] - Training step 26240 loss 0.2452356517314911
[2025-03-17 01:45:01,930][model][INFO] - Training step 26400 loss 0.06644882261753082
[2025-03-17 01:45:42,543][model][INFO] - Training step 26560 loss 0.03632240369915962
[2025-03-17 01:46:23,203][model][INFO] - Training step 26720 loss 0.03150937706232071
[2025-03-17 01:47:03,604][model][INFO] - Training step 26880 loss 0.03895777091383934
[2025-03-17 01:47:43,338][model][INFO] - Training step 27040 loss 0.03595998138189316
[2025-03-17 01:48:24,369][model][INFO] - Training step 27200 loss 0.017483580857515335
[2025-03-17 01:49:04,469][model][INFO] - Training step 27360 loss 0.08071132749319077
[2025-03-17 01:49:44,892][model][INFO] - Training step 27520 loss 0.29561543464660645
[2025-03-17 01:50:26,204][model][INFO] - Training step 27680 loss 0.018468305468559265
[2025-03-17 01:51:05,674][model][INFO] - Training step 27840 loss 0.2432178556919098
[2025-03-17 01:51:46,210][model][INFO] - Training step 28000 loss 0.02807331271469593
[2025-03-17 01:52:25,690][model][INFO] - Training step 28160 loss 0.05288100242614746
[2025-03-17 01:53:06,273][model][INFO] - Training step 28320 loss 0.23194649815559387
[2025-03-17 01:53:47,581][model][INFO] - Training step 28480 loss 0.02831985242664814
[2025-03-17 01:54:27,105][model][INFO] - Training step 28640 loss 0.20633497834205627
[2025-03-17 01:55:06,691][model][INFO] - Training step 28800 loss 0.0028366628102958202
[2025-03-17 01:55:47,662][model][INFO] - Training step 28960 loss 0.030216095969080925
[2025-03-17 01:56:27,061][model][INFO] - Training step 29120 loss 0.08130031824111938
[2025-03-17 01:57:07,131][model][INFO] - Training step 29280 loss 0.054594431072473526
[2025-03-17 01:57:47,721][model][INFO] - Training step 29440 loss 0.028323080390691757
[2025-03-17 01:58:27,961][model][INFO] - Training step 29600 loss 0.051133379340171814
[2025-03-17 01:59:09,322][model][INFO] - Training step 29760 loss 0.04399173706769943
[2025-03-17 01:59:48,047][model][INFO] - Training step 29920 loss 0.06636437773704529
[2025-03-17 02:00:26,848][model][INFO] - Training step 30080 loss 0.004557773470878601
[2025-03-17 02:01:06,235][model][INFO] - Training step 30240 loss 0.027629772201180458
[2025-03-17 02:01:48,493][model][INFO] - Training step 30400 loss 0.04368305951356888
[2025-03-17 02:02:28,243][model][INFO] - Training step 30560 loss 0.02977355755865574
[2025-03-17 02:03:06,305][model][INFO] - Training step 30720 loss 0.009642986580729485
[2025-03-17 02:03:45,544][model][INFO] - Training step 30880 loss 0.018875885754823685
[2025-03-17 02:04:25,178][model][INFO] - Training step 31040 loss 0.02100260555744171
[2025-03-17 02:05:05,868][model][INFO] - Training step 31200 loss 0.26413694024086
[2025-03-17 02:05:45,367][model][INFO] - Training step 31360 loss 0.04415591061115265
[2025-03-17 02:06:24,814][model][INFO] - Training step 31520 loss 0.2538337707519531
[2025-03-17 02:07:05,482][model][INFO] - Training step 31680 loss 0.16279146075248718
[2025-03-17 02:07:44,452][model][INFO] - Training step 31840 loss 0.01172424852848053
[2025-03-17 02:08:23,988][model][INFO] - Training step 32000 loss 0.025456275790929794
[2025-03-17 02:09:05,542][model][INFO] - Training step 32160 loss 0.0496840737760067
[2025-03-17 02:09:45,710][model][INFO] - Training step 32320 loss 0.17665189504623413
[2025-03-17 02:10:25,866][model][INFO] - Training step 32480 loss 0.01632412150502205
[2025-03-17 02:11:07,481][model][INFO] - Training step 32640 loss 0.2644575238227844
[2025-03-17 02:11:46,887][model][INFO] - Training step 32800 loss 0.0741279274225235
[2025-03-17 02:12:26,224][model][INFO] - Training step 32960 loss 0.03435138240456581
[2025-03-17 02:13:06,576][model][INFO] - Training step 33120 loss 0.03960324823856354
[2025-03-17 02:13:47,637][model][INFO] - Training step 33280 loss 0.03696618229150772
[2025-03-17 02:14:28,309][model][INFO] - Training step 33440 loss 0.04238460212945938
[2025-03-17 02:15:09,547][model][INFO] - Training step 33600 loss 0.0758216455578804
[2025-03-17 02:15:51,748][model][INFO] - Training step 33760 loss 0.25507479906082153
[2025-03-17 02:16:31,718][model][INFO] - Training step 33920 loss 0.022927487269043922
[2025-03-17 02:17:11,773][model][INFO] - Training step 34080 loss 0.035825252532958984
[2025-03-17 02:17:53,630][model][INFO] - Training step 34240 loss 0.11204349994659424
[2025-03-17 02:18:36,333][model][INFO] - Training step 34400 loss 0.09479658305644989
[2025-03-17 02:19:16,744][model][INFO] - Training step 34560 loss 0.2236602008342743
[2025-03-17 02:19:56,819][model][INFO] - Training step 34720 loss 0.11697481572628021
[2025-03-17 02:20:37,464][model][INFO] - Training step 34880 loss 0.08507385849952698
[2025-03-17 02:21:17,480][model][INFO] - Training step 35040 loss 0.0022937338799238205
[2025-03-17 02:21:57,490][model][INFO] - Training step 35200 loss 0.24852830171585083
[2025-03-17 02:22:37,319][model][INFO] - Training step 35360 loss 0.0513165146112442
[2025-03-17 02:23:16,763][model][INFO] - Training step 35520 loss 0.02140682563185692
[2025-03-17 02:23:55,440][model][INFO] - Training step 35680 loss 0.027581270784139633
[2025-03-17 02:24:33,564][model][INFO] - Training step 35840 loss 0.01408546231687069
[2025-03-17 02:25:13,931][model][INFO] - Training step 36000 loss 0.001387599972076714
[2025-03-17 02:25:54,532][model][INFO] - Training step 36160 loss 0.024357285350561142
[2025-03-17 02:26:34,494][model][INFO] - Training step 36320 loss 0.012096095830202103
[2025-03-17 02:27:14,336][model][INFO] - Training step 36480 loss 0.023381400853395462
[2025-03-17 02:27:55,452][model][INFO] - Training step 36640 loss 0.022119544446468353
[2025-03-17 02:28:35,519][model][INFO] - Training step 36800 loss 0.0033655324950814247
[2025-03-17 02:29:16,596][model][INFO] - Training step 36960 loss 0.22044682502746582
[2025-03-17 02:29:55,861][model][INFO] - Training step 37120 loss 0.01636875420808792
[2025-03-17 02:30:37,482][model][INFO] - Training step 37280 loss 0.2549988031387329
[2025-03-17 02:31:18,051][model][INFO] - Training step 37440 loss 0.23812836408615112
[2025-03-17 02:31:59,336][model][INFO] - Training step 37600 loss 0.024089932441711426
[2025-03-17 02:32:37,666][model][INFO] - Training step 37760 loss 0.2684212923049927
[2025-03-17 02:33:16,765][model][INFO] - Training step 37920 loss 0.019128624349832535
[2025-03-17 02:33:55,816][model][INFO] - Training step 38080 loss 0.04740099608898163
[2025-03-17 02:34:36,542][model][INFO] - Training step 38240 loss 0.227923184633255
[2025-03-17 02:35:16,964][model][INFO] - Training step 38400 loss 0.236390620470047
[2025-03-17 02:35:57,380][model][INFO] - Training step 38560 loss 0.08246949315071106
[2025-03-17 02:36:36,523][model][INFO] - Training step 38720 loss 0.251813143491745
[2025-03-17 02:37:16,227][model][INFO] - Training step 38880 loss 0.02725827321410179
[2025-03-17 02:37:57,177][model][INFO] - Training step 39040 loss 0.09631143510341644
[2025-03-17 02:38:36,873][model][INFO] - Training step 39200 loss 0.0053351507522165775
[2025-03-17 02:39:17,427][model][INFO] - Training step 39360 loss 0.06048864126205444
[2025-03-17 02:39:57,211][model][INFO] - Training step 39520 loss 0.061490122228860855
[2025-03-17 02:40:36,763][model][INFO] - Training step 39680 loss 0.009592642076313496
[2025-03-17 02:41:15,665][model][INFO] - Training step 39840 loss 0.03266526013612747
[2025-03-17 02:41:54,752][model][INFO] - Training step 40000 loss 0.07293634116649628
[2025-03-17 02:42:35,529][model][INFO] - Training step 40160 loss 0.03138408064842224
[2025-03-17 02:43:15,966][model][INFO] - Training step 40320 loss 0.006183861754834652
[2025-03-17 02:43:55,247][model][INFO] - Training step 40480 loss 0.055997349321842194
[2025-03-17 02:44:35,259][model][INFO] - Training step 40640 loss 0.08055448532104492
[2025-03-17 02:45:15,758][model][INFO] - Training step 40800 loss 0.007219324819743633
[2025-03-17 02:45:56,011][model][INFO] - Training step 40960 loss 0.06348185986280441
[2025-03-17 02:46:37,810][model][INFO] - Training step 41120 loss 0.25017839670181274
[2025-03-17 02:47:19,131][model][INFO] - Training step 41280 loss 0.07551749050617218
[2025-03-17 02:47:59,249][model][INFO] - Training step 41440 loss 0.047488369047641754
[2025-03-17 02:48:38,715][model][INFO] - Training step 41600 loss 0.026372065767645836
[2025-03-17 02:49:18,905][model][INFO] - Training step 41760 loss 0.014933808706700802
[2025-03-17 02:49:57,843][model][INFO] - Training step 41920 loss 0.03369423747062683
[2025-03-17 02:50:39,404][model][INFO] - Training step 42080 loss 0.005941787734627724
[2025-03-17 02:51:18,876][model][INFO] - Training step 42240 loss 0.03521434962749481
[2025-03-17 02:51:58,037][model][INFO] - Training step 42400 loss 0.042841143906116486
[2025-03-17 02:52:41,012][model][INFO] - Training step 42560 loss 0.006869091652333736
[2025-03-17 02:53:21,118][model][INFO] - Training step 42720 loss 0.009345954284071922
[2025-03-17 02:53:58,666][model][INFO] - Training step 42880 loss 0.03776706010103226
[2025-03-17 02:54:38,899][model][INFO] - Training step 43040 loss 0.020434729754924774
[2025-03-17 02:55:19,544][model][INFO] - Training step 43200 loss 0.08285056054592133
[2025-03-17 02:56:00,420][model][INFO] - Training step 43360 loss 0.005511133465915918
[2025-03-17 02:56:42,334][model][INFO] - Training step 43520 loss 0.0391850471496582
[2025-03-17 02:57:22,939][model][INFO] - Training step 43680 loss 0.018707048147916794
[2025-03-17 02:58:03,306][model][INFO] - Training step 43840 loss 0.031060725450515747
[2025-03-17 02:58:43,884][model][INFO] - Training step 44000 loss 0.004249975085258484
[2025-03-17 02:59:24,287][model][INFO] - Training step 44160 loss 0.008610419929027557
[2025-03-17 03:00:04,818][model][INFO] - Training step 44320 loss 0.02320704609155655
[2025-03-17 03:00:45,966][model][INFO] - Training step 44480 loss 0.006631870754063129
[2025-03-17 03:01:25,511][model][INFO] - Training step 44640 loss 0.017866503447294235
[2025-03-17 03:02:04,390][model][INFO] - Training step 44800 loss 0.03552448749542236
[2025-03-17 03:02:44,245][model][INFO] - Training step 44960 loss 0.005448893643915653
[2025-03-17 03:03:23,288][model][INFO] - Training step 45120 loss 0.2514704465866089
[2025-03-17 03:04:03,004][model][INFO] - Training step 45280 loss 0.01963590271770954
[2025-03-17 03:04:42,281][model][INFO] - Training step 45440 loss 0.0063554816879332066
[2025-03-17 03:05:23,873][model][INFO] - Training step 45600 loss 0.031662628054618835
[2025-03-17 03:06:04,347][model][INFO] - Training step 45760 loss 0.0600191205739975
[2025-03-17 03:06:43,582][model][INFO] - Training step 45920 loss 0.022605642676353455
[2025-03-17 03:07:24,796][model][INFO] - Training step 46080 loss 0.04152364283800125
[2025-03-17 03:08:04,996][model][INFO] - Training step 46240 loss 0.016904406249523163
[2025-03-17 03:08:44,003][model][INFO] - Training step 46400 loss 0.027975432574748993
[2025-03-17 03:09:23,908][model][INFO] - Training step 46560 loss 0.2583041787147522
[2025-03-17 03:10:05,281][model][INFO] - Training step 46720 loss 0.01933194138109684
[2025-03-17 03:10:45,104][model][INFO] - Training step 46880 loss 0.02132706716656685
[2025-03-17 03:11:25,417][model][INFO] - Training step 47040 loss 0.26289427280426025
[2025-03-17 03:12:04,830][model][INFO] - Training step 47200 loss 0.012336216866970062
[2025-03-17 03:12:45,151][model][INFO] - Training step 47360 loss 0.08779224753379822
[2025-03-17 03:13:25,483][model][INFO] - Training step 47520 loss 0.011869225651025772
[2025-03-17 03:14:04,654][model][INFO] - Training step 47680 loss 0.03369338810443878
[2025-03-17 03:14:45,618][model][INFO] - Training step 47840 loss 0.021838435903191566
[2025-03-17 03:15:23,952][model][INFO] - Training step 48000 loss 0.2560139298439026
[2025-03-17 03:16:05,155][model][INFO] - Training step 48160 loss 0.0048774611204862595
[2025-03-17 03:16:44,861][model][INFO] - Training step 48320 loss 0.01894831284880638
[2025-03-17 03:17:25,959][model][INFO] - Training step 48480 loss 0.035023435950279236
[2025-03-17 03:18:05,080][model][INFO] - Training step 48640 loss 0.03925737738609314
[2025-03-17 03:18:45,351][model][INFO] - Training step 48800 loss 0.07690255343914032
[2025-03-17 03:19:24,753][model][INFO] - Training step 48960 loss 0.02617620676755905
[2025-03-17 03:20:04,842][model][INFO] - Training step 49120 loss 0.014394529163837433
[2025-03-17 03:20:45,319][model][INFO] - Training step 49280 loss 0.09762250632047653
[2025-03-17 03:21:26,077][model][INFO] - Training step 49440 loss 0.029335297644138336
[2025-03-17 03:22:06,538][model][INFO] - Training step 49600 loss 0.0519966259598732
[2025-03-17 03:22:47,228][model][INFO] - Training step 49760 loss 0.05689491331577301
[2025-03-17 03:23:26,678][model][INFO] - Training step 49920 loss 0.006709819659590721
[2025-03-17 03:24:05,983][model][INFO] - Training step 50080 loss 0.020856967195868492
[2025-03-17 03:24:47,533][model][INFO] - Training step 50240 loss 0.10779686272144318
[2025-03-17 03:25:27,134][model][INFO] - Training step 50400 loss 0.06280979514122009
[2025-03-17 03:26:07,991][model][INFO] - Training step 50560 loss 0.007174715865403414
[2025-03-17 03:26:47,052][model][INFO] - Training step 50720 loss 0.01921769231557846
[2025-03-17 03:32:22,232][model][INFO] - Training step 80 loss 0.005381939932703972
[2025-03-17 03:33:01,331][model][INFO] - Training step 240 loss 0.03590002655982971
[2025-03-17 03:33:41,505][model][INFO] - Training step 400 loss 0.026238419115543365
[2025-03-17 03:34:20,886][model][INFO] - Training step 560 loss 0.0051643941551446915
[2025-03-17 03:35:00,735][model][INFO] - Training step 720 loss 0.030937761068344116
[2025-03-17 03:35:42,004][model][INFO] - Training step 880 loss 0.02663291245698929
[2025-03-17 03:36:21,275][model][INFO] - Training step 1040 loss 0.028439275920391083
[2025-03-17 03:37:00,794][model][INFO] - Training step 1200 loss 0.44406813383102417
[2025-03-17 03:37:41,077][model][INFO] - Training step 1360 loss 0.03266975283622742
[2025-03-17 03:38:19,668][model][INFO] - Training step 1520 loss 0.029222270473837852
[2025-03-17 03:39:00,098][model][INFO] - Training step 1680 loss 0.002590743824839592
[2025-03-17 03:39:39,025][model][INFO] - Training step 1840 loss 0.03640730679035187
[2025-03-17 03:40:16,865][model][INFO] - Training step 2000 loss 0.037367381155490875
[2025-03-17 03:40:57,654][model][INFO] - Training step 2160 loss 0.013866627588868141
[2025-03-17 03:41:37,493][model][INFO] - Training step 2320 loss 0.022452784702181816
[2025-03-17 03:42:16,744][model][INFO] - Training step 2480 loss 0.03393280506134033
[2025-03-17 03:42:58,166][model][INFO] - Training step 2640 loss 0.25277814269065857
[2025-03-17 03:43:37,865][model][INFO] - Training step 2800 loss 0.031635358929634094
[2025-03-17 03:44:17,453][model][INFO] - Training step 2960 loss 0.24978739023208618
[2025-03-17 03:44:56,854][model][INFO] - Training step 3120 loss 0.07555530965328217
[2025-03-17 03:45:36,189][model][INFO] - Training step 3280 loss 0.34217578172683716
[2025-03-17 03:46:17,471][model][INFO] - Training step 3440 loss 0.049915481358766556
[2025-03-17 03:46:57,008][model][INFO] - Training step 3600 loss 0.018016807734966278
[2025-03-17 03:47:36,217][model][INFO] - Training step 3760 loss 0.03606025129556656
[2025-03-17 03:48:15,631][model][INFO] - Training step 3920 loss 0.019033871591091156
[2025-03-17 03:48:55,530][model][INFO] - Training step 4080 loss 0.03914869204163551
[2025-03-17 03:49:35,356][model][INFO] - Training step 4240 loss 0.005454580299556255
[2025-03-17 03:50:15,309][model][INFO] - Training step 4400 loss 0.022791976109147072
[2025-03-17 03:50:54,791][model][INFO] - Training step 4560 loss 0.004151355940848589
[2025-03-17 03:51:34,778][model][INFO] - Training step 4720 loss 0.049404576420784
[2025-03-17 03:52:14,132][model][INFO] - Training step 4880 loss 0.00851673074066639
[2025-03-17 03:52:53,137][model][INFO] - Training step 5040 loss 0.026819797232747078
[2025-03-17 03:53:33,501][model][INFO] - Training step 5200 loss 0.01544063538312912
[2025-03-17 03:54:14,343][model][INFO] - Training step 5360 loss 0.04342886060476303
[2025-03-17 03:54:55,222][model][INFO] - Training step 5520 loss 0.032481513917446136
[2025-03-17 03:55:35,741][model][INFO] - Training step 5680 loss 0.029625853523612022
[2025-03-17 03:56:16,551][model][INFO] - Training step 5840 loss 0.01863190159201622
[2025-03-17 03:56:55,348][model][INFO] - Training step 6000 loss 0.016026820987462997
[2025-03-17 03:57:34,493][model][INFO] - Training step 6160 loss 0.00687283743172884
[2025-03-17 03:58:13,798][model][INFO] - Training step 6320 loss 0.040531598031520844
[2025-03-17 03:58:53,065][model][INFO] - Training step 6480 loss 0.06228546053171158
[2025-03-17 03:59:34,541][model][INFO] - Training step 6640 loss 0.0041679274290800095
[2025-03-17 04:00:15,012][model][INFO] - Training step 6800 loss 0.030664939433336258
[2025-03-17 04:00:56,541][model][INFO] - Training step 6960 loss 0.25475597381591797
[2025-03-17 04:01:37,581][model][INFO] - Training step 7120 loss 0.006659271195530891
[2025-03-17 04:02:19,515][model][INFO] - Training step 7280 loss 0.2555868625640869
[2025-03-17 04:02:58,790][model][INFO] - Training step 7440 loss 0.01563783548772335
[2025-03-17 04:03:38,094][model][INFO] - Training step 7600 loss 0.04470417648553848
[2025-03-17 04:04:18,580][model][INFO] - Training step 7760 loss 0.033673323690891266
[2025-03-17 04:04:57,968][model][INFO] - Training step 7920 loss 0.04101908206939697
[2025-03-17 04:05:38,680][model][INFO] - Training step 8080 loss 0.023367667570710182
[2025-03-17 04:06:17,889][model][INFO] - Training step 8240 loss 0.017167240381240845
[2025-03-17 04:06:57,716][model][INFO] - Training step 8400 loss 0.001279499614611268
[2025-03-17 04:07:38,694][model][INFO] - Training step 8560 loss 0.017665982246398926
[2025-03-17 04:08:17,827][model][INFO] - Training step 8720 loss 0.01831396296620369
[2025-03-17 04:08:58,357][model][INFO] - Training step 8880 loss 0.016989167779684067
[2025-03-17 04:09:38,165][model][INFO] - Training step 9040 loss 0.011481193825602531
[2025-03-17 04:10:19,559][model][INFO] - Training step 9200 loss 0.2515643537044525
[2025-03-17 04:10:59,730][model][INFO] - Training step 9360 loss 0.024831077083945274
[2025-03-17 04:11:39,395][model][INFO] - Training step 9520 loss 0.012329176999628544
[2025-03-17 04:12:20,031][model][INFO] - Training step 9680 loss 0.2572932243347168
[2025-03-17 04:12:59,685][model][INFO] - Training step 9840 loss 0.036295220255851746
[2025-03-17 04:13:41,565][model][INFO] - Training step 10000 loss 0.009989559650421143
[2025-03-17 04:14:21,752][model][INFO] - Training step 10160 loss 0.0449315682053566
[2025-03-17 04:15:02,461][model][INFO] - Training step 10320 loss 0.01744728535413742
[2025-03-17 04:15:43,662][model][INFO] - Training step 10480 loss 0.023600125685334206
[2025-03-17 04:16:25,208][model][INFO] - Training step 10640 loss 0.02578147128224373
[2025-03-17 04:17:03,841][model][INFO] - Training step 10800 loss 0.21128574013710022
[2025-03-17 04:17:43,899][model][INFO] - Training step 10960 loss 0.04850974678993225
[2025-03-17 04:18:22,479][model][INFO] - Training step 11120 loss 0.015155910514295101
[2025-03-17 04:19:04,510][model][INFO] - Training step 11280 loss 0.02692870795726776
[2025-03-17 04:19:45,384][model][INFO] - Training step 11440 loss 0.02070300653576851
[2025-03-17 04:20:25,352][model][INFO] - Training step 11600 loss 0.021610748022794724
[2025-03-17 04:21:07,170][model][INFO] - Training step 11760 loss 0.027472935616970062
[2025-03-17 04:21:46,703][model][INFO] - Training step 11920 loss 0.24437233805656433
[2025-03-17 04:22:27,213][model][INFO] - Training step 12080 loss 0.09496058523654938
[2025-03-17 04:23:06,500][model][INFO] - Training step 12240 loss 0.033295247703790665
[2025-03-17 04:23:46,257][model][INFO] - Training step 12400 loss 0.005716582294553518
[2025-03-17 04:24:26,983][model][INFO] - Training step 12560 loss 0.04189934581518173
[2025-03-17 04:25:09,326][model][INFO] - Training step 12720 loss 0.2262941151857376
[2025-03-17 04:25:49,531][model][INFO] - Training step 12880 loss 0.23345652222633362
[2025-03-17 04:26:29,309][model][INFO] - Training step 13040 loss 0.026419024914503098
[2025-03-17 04:27:09,564][model][INFO] - Training step 13200 loss 0.025619056075811386
[2025-03-17 04:27:49,313][model][INFO] - Training step 13360 loss 0.06217407435178757
[2025-03-17 04:28:29,122][model][INFO] - Training step 13520 loss 0.03674972057342529
[2025-03-17 04:29:09,557][model][INFO] - Training step 13680 loss 0.016511663794517517
[2025-03-17 04:29:50,164][model][INFO] - Training step 13840 loss 0.015228193253278732
[2025-03-17 04:30:29,785][model][INFO] - Training step 14000 loss 0.0168013796210289
[2025-03-17 04:31:08,644][model][INFO] - Training step 14160 loss 0.017951607704162598
[2025-03-17 04:31:48,111][model][INFO] - Training step 14320 loss 0.03928591310977936
[2025-03-17 04:32:27,556][model][INFO] - Training step 14480 loss 0.016181662678718567
[2025-03-17 04:33:05,509][model][INFO] - Training step 14640 loss 0.03539634495973587
[2025-03-17 04:33:45,368][model][INFO] - Training step 14800 loss 0.006692220456898212
[2025-03-17 04:34:25,779][model][INFO] - Training step 14960 loss 0.017170172184705734
[2025-03-17 04:35:06,302][model][INFO] - Training step 15120 loss 0.013012003153562546
[2025-03-17 04:35:46,202][model][INFO] - Training step 15280 loss 0.04972407966852188
[2025-03-17 04:36:26,141][model][INFO] - Training step 15440 loss 0.24836841225624084
[2025-03-17 04:37:07,317][model][INFO] - Training step 15600 loss 0.07545533776283264
[2025-03-17 04:37:46,626][model][INFO] - Training step 15760 loss 0.30487459897994995
[2025-03-17 04:38:26,724][model][INFO] - Training step 15920 loss 0.24447226524353027
[2025-03-17 04:39:05,546][model][INFO] - Training step 16080 loss 0.24772265553474426
[2025-03-17 04:39:46,132][model][INFO] - Training step 16240 loss 0.026297636330127716
[2025-03-17 04:40:25,390][model][INFO] - Training step 16400 loss 0.1903214156627655
[2025-03-17 04:41:06,661][model][INFO] - Training step 16560 loss 0.032917365431785583
[2025-03-17 04:41:47,461][model][INFO] - Training step 16720 loss 0.032528772950172424
[2025-03-17 04:42:27,743][model][INFO] - Training step 16880 loss 0.023129548877477646
[2025-03-17 04:43:07,883][model][INFO] - Training step 17040 loss 0.05735663324594498
[2025-03-17 04:43:48,124][model][INFO] - Training step 17200 loss 0.036215364933013916
[2025-03-17 04:44:28,700][model][INFO] - Training step 17360 loss 0.01932172104716301
[2025-03-17 04:45:10,148][model][INFO] - Training step 17520 loss 0.033418137580156326
[2025-03-17 04:45:50,226][model][INFO] - Training step 17680 loss 0.01751646399497986
[2025-03-17 04:46:29,623][model][INFO] - Training step 17840 loss 0.2579609155654907
[2025-03-17 04:47:11,080][model][INFO] - Training step 18000 loss 0.004414070397615433
[2025-03-17 04:47:50,913][model][INFO] - Training step 18160 loss 0.07300055772066116
[2025-03-17 04:48:32,245][model][INFO] - Training step 18320 loss 0.006024093367159367
[2025-03-17 04:49:12,079][model][INFO] - Training step 18480 loss 0.01959974318742752
[2025-03-17 04:49:52,103][model][INFO] - Training step 18640 loss 0.03143848851323128
[2025-03-17 04:50:32,582][model][INFO] - Training step 18800 loss 0.012622518464922905
[2025-03-17 04:51:13,053][model][INFO] - Training step 18960 loss 0.05200701579451561
[2025-03-17 04:51:54,115][model][INFO] - Training step 19120 loss 0.02254263311624527
[2025-03-17 04:52:33,585][model][INFO] - Training step 19280 loss 0.025989025831222534
[2025-03-17 04:53:13,185][model][INFO] - Training step 19440 loss 0.026156485080718994
[2025-03-17 04:53:54,155][model][INFO] - Training step 19600 loss 0.0338367260992527
[2025-03-17 04:54:34,051][model][INFO] - Training step 19760 loss 0.02712569758296013
[2025-03-17 04:55:14,085][model][INFO] - Training step 19920 loss 0.041258424520492554
[2025-03-17 04:55:53,958][model][INFO] - Training step 20080 loss 0.03705248981714249
[2025-03-17 04:56:35,397][model][INFO] - Training step 20240 loss 0.031545743346214294
[2025-03-17 04:57:15,404][model][INFO] - Training step 20400 loss 0.08387462794780731
[2025-03-17 04:57:57,565][model][INFO] - Training step 20560 loss 0.01399100199341774
[2025-03-17 04:58:37,728][model][INFO] - Training step 20720 loss 0.037089891731739044
[2025-03-17 04:59:19,345][model][INFO] - Training step 20880 loss 0.2497422695159912
[2025-03-17 04:59:58,681][model][INFO] - Training step 21040 loss 0.005767361260950565
[2025-03-17 05:00:39,440][model][INFO] - Training step 21200 loss 0.005238236393779516
[2025-03-17 05:01:20,231][model][INFO] - Training step 21360 loss 0.07321198284626007
[2025-03-17 05:02:00,019][model][INFO] - Training step 21520 loss 0.05949252098798752
[2025-03-17 05:02:41,063][model][INFO] - Training step 21680 loss 0.004096736665815115
[2025-03-17 05:03:21,529][model][INFO] - Training step 21840 loss 0.0029079564847052097
[2025-03-17 05:04:01,235][model][INFO] - Training step 22000 loss 0.005593721754848957
[2025-03-17 05:04:40,578][model][INFO] - Training step 22160 loss 0.032364118844270706
[2025-03-17 05:05:21,096][model][INFO] - Training step 22320 loss 0.24548569321632385
[2025-03-17 05:06:00,966][model][INFO] - Training step 22480 loss 0.0054112267680466175
[2025-03-17 05:06:40,024][model][INFO] - Training step 22640 loss 0.026297301054000854
[2025-03-17 05:07:22,090][model][INFO] - Training step 22800 loss 0.2423226535320282
[2025-03-17 05:08:02,734][model][INFO] - Training step 22960 loss 0.016373705118894577
[2025-03-17 05:08:43,270][model][INFO] - Training step 23120 loss 0.020817311480641365
[2025-03-17 05:09:23,333][model][INFO] - Training step 23280 loss 0.02416672185063362
[2025-03-17 05:10:04,034][model][INFO] - Training step 23440 loss 0.006038323510438204
[2025-03-17 05:10:43,988][model][INFO] - Training step 23600 loss 0.034850992262363434
[2025-03-17 05:11:22,938][model][INFO] - Training step 23760 loss 0.02760329097509384
[2025-03-17 05:12:02,221][model][INFO] - Training step 23920 loss 0.006001520436257124
[2025-03-17 05:12:41,698][model][INFO] - Training step 24080 loss 0.042131055146455765
[2025-03-17 05:13:21,102][model][INFO] - Training step 24240 loss 0.014262303709983826
[2025-03-17 05:14:00,663][model][INFO] - Training step 24400 loss 0.01922995038330555
[2025-03-17 05:14:40,816][model][INFO] - Training step 24560 loss 0.02666257694363594
[2025-03-17 05:15:21,273][model][INFO] - Training step 24720 loss 0.0146370530128479
[2025-03-17 05:16:01,919][model][INFO] - Training step 24880 loss 0.03396490588784218
[2025-03-17 05:16:41,940][model][INFO] - Training step 25040 loss 0.029678858816623688
[2025-03-17 05:17:22,883][model][INFO] - Training step 25200 loss 0.02576809749007225
[2025-03-17 05:18:02,339][model][INFO] - Training step 25360 loss 0.07416781038045883
[2025-03-17 05:18:41,217][model][INFO] - Training step 25520 loss 0.12155237048864365
[2025-03-17 05:19:20,703][model][INFO] - Training step 25680 loss 0.08156532049179077
[2025-03-17 05:20:01,000][model][INFO] - Training step 25840 loss 0.04951731115579605
[2025-03-17 05:20:40,805][model][INFO] - Training step 26000 loss 0.08968353271484375
[2025-03-17 05:21:20,458][model][INFO] - Training step 26160 loss 0.033243462443351746
[2025-03-17 05:22:01,359][model][INFO] - Training step 26320 loss 0.09260323643684387
[2025-03-17 05:22:41,326][model][INFO] - Training step 26480 loss 0.007033343426883221
[2025-03-17 05:23:22,640][model][INFO] - Training step 26640 loss 0.021326225250959396
[2025-03-17 05:24:01,475][model][INFO] - Training step 26800 loss 0.009165789932012558
[2025-03-17 05:24:41,666][model][INFO] - Training step 26960 loss 0.0032969568856060505
[2025-03-17 05:25:21,617][model][INFO] - Training step 27120 loss 0.013061147183179855
[2025-03-17 05:26:01,471][model][INFO] - Training step 27280 loss 0.045926667749881744
[2025-03-17 05:26:42,977][model][INFO] - Training step 27440 loss 0.28283512592315674
[2025-03-17 05:27:23,300][model][INFO] - Training step 27600 loss 0.04456637427210808
[2025-03-17 05:28:02,303][model][INFO] - Training step 27760 loss 0.25330686569213867
[2025-03-17 05:28:41,922][model][INFO] - Training step 27920 loss 0.01344293262809515
[2025-03-17 05:29:23,963][model][INFO] - Training step 28080 loss 0.02609505131840706
[2025-03-17 05:30:03,257][model][INFO] - Training step 28240 loss 0.04185877740383148
[2025-03-17 05:30:41,802][model][INFO] - Training step 28400 loss 0.07938092947006226
[2025-03-17 05:31:22,742][model][INFO] - Training step 28560 loss 0.26360106468200684
[2025-03-17 05:32:03,830][model][INFO] - Training step 28720 loss 0.006545495707541704
[2025-03-17 05:32:43,934][model][INFO] - Training step 28880 loss 0.011965015903115273
[2025-03-17 05:33:23,883][model][INFO] - Training step 29040 loss 0.022068044170737267
[2025-03-17 05:34:04,230][model][INFO] - Training step 29200 loss 0.012287268415093422
[2025-03-17 05:34:43,575][model][INFO] - Training step 29360 loss 0.005632233805954456
[2025-03-17 05:35:23,215][model][INFO] - Training step 29520 loss 0.03853946179151535
[2025-03-17 05:36:04,877][model][INFO] - Training step 29680 loss 0.2383567988872528
[2025-03-17 05:36:45,776][model][INFO] - Training step 29840 loss 0.025386665016412735
[2025-03-17 05:37:26,569][model][INFO] - Training step 30000 loss 0.01224728487432003
[2025-03-17 05:38:07,355][model][INFO] - Training step 30160 loss 0.005640620365738869
[2025-03-17 05:38:46,737][model][INFO] - Training step 30320 loss 0.020748678594827652
[2025-03-17 05:39:26,749][model][INFO] - Training step 30480 loss 0.01482977531850338
[2025-03-17 05:40:05,255][model][INFO] - Training step 30640 loss 0.07623328268527985
[2025-03-17 05:40:43,076][model][INFO] - Training step 30800 loss 0.11125527322292328
[2025-03-17 05:41:23,988][model][INFO] - Training step 30960 loss 0.02546735480427742
[2025-03-17 05:42:04,815][model][INFO] - Training step 31120 loss 0.04152655601501465
[2025-03-17 05:42:45,262][model][INFO] - Training step 31280 loss 0.005729747004806995
[2025-03-17 05:43:24,058][model][INFO] - Training step 31440 loss 0.02656893990933895
[2025-03-17 05:44:04,858][model][INFO] - Training step 31600 loss 0.023958656936883926
[2025-03-17 05:44:44,021][model][INFO] - Training step 31760 loss 0.1148790568113327
[2025-03-17 05:45:24,009][model][INFO] - Training step 31920 loss 0.02769576385617256
[2025-03-17 05:46:04,769][model][INFO] - Training step 32080 loss 0.03920067101716995
[2025-03-17 05:46:45,377][model][INFO] - Training step 32240 loss 0.011775286868214607
[2025-03-17 05:47:26,517][model][INFO] - Training step 32400 loss 0.022464703768491745
[2025-03-17 05:48:07,334][model][INFO] - Training step 32560 loss 0.027031540870666504
[2025-03-17 05:48:46,807][model][INFO] - Training step 32720 loss 0.25311195850372314
[2025-03-17 05:49:27,510][model][INFO] - Training step 32880 loss 0.2694890797138214
[2025-03-17 05:50:07,520][model][INFO] - Training step 33040 loss 0.24385643005371094
[2025-03-17 05:50:48,496][model][INFO] - Training step 33200 loss 0.01927327550947666
[2025-03-17 05:51:29,560][model][INFO] - Training step 33360 loss 0.01793227344751358
[2025-03-17 05:52:09,947][model][INFO] - Training step 33520 loss 0.052389636635780334
[2025-03-17 05:52:50,016][model][INFO] - Training step 33680 loss 0.2531649172306061
[2025-03-17 05:53:32,548][model][INFO] - Training step 33840 loss 0.005737101659178734
[2025-03-17 05:54:11,769][model][INFO] - Training step 34000 loss 0.0042912461794912815
[2025-03-17 05:54:52,382][model][INFO] - Training step 34160 loss 0.2589237689971924
[2025-03-17 05:55:33,839][model][INFO] - Training step 34320 loss 0.014494549483060837
[2025-03-17 05:56:12,747][model][INFO] - Training step 34480 loss 0.06545592844486237
[2025-03-17 05:56:53,414][model][INFO] - Training step 34640 loss 0.24079230427742004
[2025-03-17 05:57:34,165][model][INFO] - Training step 34800 loss 0.019008366391062737
[2025-03-17 05:58:17,226][model][INFO] - Training step 34960 loss 0.024874873459339142
[2025-03-17 05:58:57,099][model][INFO] - Training step 35120 loss 0.0056961216032505035
[2025-03-17 05:59:36,331][model][INFO] - Training step 35280 loss 0.08097776770591736
[2025-03-17 06:00:16,336][model][INFO] - Training step 35440 loss 0.0044870199635624886
[2025-03-17 06:00:57,082][model][INFO] - Training step 35600 loss 0.2557460069656372
[2025-03-17 06:01:37,280][model][INFO] - Training step 35760 loss 0.02075236663222313
[2025-03-17 06:02:17,064][model][INFO] - Training step 35920 loss 0.004878094419836998
[2025-03-17 06:02:57,151][model][INFO] - Training step 36080 loss 0.033710453659296036
[2025-03-17 06:03:37,186][model][INFO] - Training step 36240 loss 0.019787466153502464
[2025-03-17 06:04:16,727][model][INFO] - Training step 36400 loss 0.017201021313667297
[2025-03-17 06:04:56,319][model][INFO] - Training step 36560 loss 0.016600266098976135
[2025-03-17 06:05:36,921][model][INFO] - Training step 36720 loss 0.009241925552487373
[2025-03-17 06:06:18,010][model][INFO] - Training step 36880 loss 0.003969524521380663
[2025-03-17 06:06:58,888][model][INFO] - Training step 37040 loss 0.018297698348760605
[2025-03-17 06:07:37,598][model][INFO] - Training step 37200 loss 0.0635836198925972
[2025-03-17 06:08:18,221][model][INFO] - Training step 37360 loss 0.006527206860482693
[2025-03-17 06:08:58,346][model][INFO] - Training step 37520 loss 0.029746316373348236
[2025-03-17 06:09:39,127][model][INFO] - Training step 37680 loss 0.02242131531238556
[2025-03-17 06:10:18,151][model][INFO] - Training step 37840 loss 0.031073372811079025
[2025-03-17 06:10:59,516][model][INFO] - Training step 38000 loss 0.020264487713575363
[2025-03-17 06:11:39,759][model][INFO] - Training step 38160 loss 0.054415829479694366
[2025-03-17 06:12:21,924][model][INFO] - Training step 38320 loss 0.031152799725532532
[2025-03-17 06:13:01,641][model][INFO] - Training step 38480 loss 0.029192112386226654
[2025-03-17 06:13:42,231][model][INFO] - Training step 38640 loss 0.030760902911424637
[2025-03-17 06:14:21,139][model][INFO] - Training step 38800 loss 0.03659261763095856
[2025-03-17 06:15:02,820][model][INFO] - Training step 38960 loss 0.02002529986202717
[2025-03-17 06:15:41,002][model][INFO] - Training step 39120 loss 0.024055318906903267
[2025-03-17 06:16:20,838][model][INFO] - Training step 39280 loss 0.0028683491982519627
[2025-03-17 06:17:00,778][model][INFO] - Training step 39440 loss 0.019174322485923767
[2025-03-17 06:17:41,692][model][INFO] - Training step 39600 loss 0.0074136629700660706
[2025-03-17 06:18:21,505][model][INFO] - Training step 39760 loss 0.017656777054071426
[2025-03-17 06:19:01,820][model][INFO] - Training step 39920 loss 0.015445476397871971
[2025-03-17 06:19:41,539][model][INFO] - Training step 40080 loss 0.2549746632575989
[2025-03-17 06:20:22,123][model][INFO] - Training step 40240 loss 0.018993869423866272
[2025-03-17 06:21:01,139][model][INFO] - Training step 40400 loss 0.02346561849117279
[2025-03-17 06:21:42,815][model][INFO] - Training step 40560 loss 0.025077586993575096
[2025-03-17 06:22:23,673][model][INFO] - Training step 40720 loss 0.09338002651929855
[2025-03-17 06:23:04,920][model][INFO] - Training step 40880 loss 0.0016710003837943077
[2025-03-17 06:23:46,018][model][INFO] - Training step 41040 loss 0.09847833216190338
[2025-03-17 06:24:26,648][model][INFO] - Training step 41200 loss 0.015467245131731033
[2025-03-17 06:25:07,813][model][INFO] - Training step 41360 loss 0.054356202483177185
[2025-03-17 06:25:47,519][model][INFO] - Training step 41520 loss 0.005559002049267292
[2025-03-17 06:26:29,172][model][INFO] - Training step 41680 loss 0.08271421492099762
[2025-03-17 06:27:08,693][model][INFO] - Training step 41840 loss 0.018022429198026657
[2025-03-17 06:27:48,533][model][INFO] - Training step 42000 loss 0.035022467374801636
[2025-03-17 06:28:29,149][model][INFO] - Training step 42160 loss 0.24892646074295044
[2025-03-17 06:29:09,089][model][INFO] - Training step 42320 loss 0.014655651524662971
[2025-03-17 06:29:49,705][model][INFO] - Training step 42480 loss 0.12568140029907227
[2025-03-17 06:30:30,534][model][INFO] - Training step 42640 loss 0.017221538349986076
[2025-03-17 06:31:10,548][model][INFO] - Training step 42800 loss 0.013302361592650414
[2025-03-17 06:31:50,352][model][INFO] - Training step 42960 loss 0.015070421621203423
[2025-03-17 06:32:31,991][model][INFO] - Training step 43120 loss 0.04126252979040146
[2025-03-17 06:33:10,790][model][INFO] - Training step 43280 loss 0.11469437181949615
[2025-03-17 06:33:52,275][model][INFO] - Training step 43440 loss 0.24834591150283813
[2025-03-17 06:34:32,179][model][INFO] - Training step 43600 loss 0.011698530986905098
[2025-03-17 06:35:13,070][model][INFO] - Training step 43760 loss 0.02288808301091194
[2025-03-17 06:35:52,199][model][INFO] - Training step 43920 loss 0.24573354423046112
[2025-03-17 06:36:32,363][model][INFO] - Training step 44080 loss 0.027044659480452538
[2025-03-17 06:37:12,348][model][INFO] - Training step 44240 loss 0.03320903703570366
[2025-03-17 06:37:52,758][model][INFO] - Training step 44400 loss 0.03740190714597702
[2025-03-17 06:38:32,191][model][INFO] - Training step 44560 loss 0.2571142613887787
[2025-03-17 06:39:11,874][model][INFO] - Training step 44720 loss 0.03761757165193558
[2025-03-17 06:39:51,814][model][INFO] - Training step 44880 loss 0.05146906152367592
[2025-03-17 06:40:31,483][model][INFO] - Training step 45040 loss 0.023053251206874847
[2025-03-17 06:41:10,042][model][INFO] - Training step 45200 loss 0.01394647266715765
[2025-03-17 06:41:52,692][model][INFO] - Training step 45360 loss 0.2565402388572693
[2025-03-17 06:42:33,279][model][INFO] - Training step 45520 loss 0.03053952381014824
[2025-03-17 06:43:13,515][model][INFO] - Training step 45680 loss 0.02087709866464138
[2025-03-17 06:43:54,744][model][INFO] - Training step 45840 loss 0.10258950293064117
[2025-03-17 06:44:34,103][model][INFO] - Training step 46000 loss 0.044054120779037476
[2025-03-17 06:45:13,459][model][INFO] - Training step 46160 loss 0.028923189267516136
[2025-03-17 06:45:55,104][model][INFO] - Training step 46320 loss 0.030002903193235397
[2025-03-17 06:46:36,623][model][INFO] - Training step 46480 loss 0.022489026188850403
[2025-03-17 06:47:16,246][model][INFO] - Training step 46640 loss 0.050349075347185135
[2025-03-17 06:47:57,375][model][INFO] - Training step 46800 loss 0.23465126752853394
[2025-03-17 06:48:38,125][model][INFO] - Training step 46960 loss 0.02945343405008316
[2025-03-17 06:49:17,638][model][INFO] - Training step 47120 loss 0.0014091584598645568
[2025-03-17 06:49:57,743][model][INFO] - Training step 47280 loss 0.012925924733281136
[2025-03-17 06:50:38,397][model][INFO] - Training step 47440 loss 0.017009470611810684
[2025-03-17 06:51:18,541][model][INFO] - Training step 47600 loss 0.1243937760591507
[2025-03-17 06:51:58,034][model][INFO] - Training step 47760 loss 0.03848176449537277
[2025-03-17 06:52:37,937][model][INFO] - Training step 47920 loss 0.043056219816207886
[2025-03-17 06:53:18,931][model][INFO] - Training step 48080 loss 0.2494368851184845
[2025-03-17 06:53:57,567][model][INFO] - Training step 48240 loss 0.046192049980163574
[2025-03-17 06:54:37,201][model][INFO] - Training step 48400 loss 0.11471264064311981
[2025-03-17 06:55:17,180][model][INFO] - Training step 48560 loss 0.042073801159858704
[2025-03-17 06:55:56,757][model][INFO] - Training step 48720 loss 0.014892727136611938
[2025-03-17 06:56:35,763][model][INFO] - Training step 48880 loss 0.01592729054391384
[2025-03-17 06:57:17,041][model][INFO] - Training step 49040 loss 0.022442296147346497
[2025-03-17 06:57:57,309][model][INFO] - Training step 49200 loss 0.023602789267897606
[2025-03-17 06:58:36,580][model][INFO] - Training step 49360 loss 0.03395853191614151
[2025-03-17 06:59:16,229][model][INFO] - Training step 49520 loss 0.06469738483428955
[2025-03-17 06:59:54,599][model][INFO] - Training step 49680 loss 0.01316661573946476
[2025-03-17 07:00:34,867][model][INFO] - Training step 49840 loss 0.08587077260017395
[2025-03-17 07:01:14,259][model][INFO] - Training step 50000 loss 0.06403781473636627
[2025-03-17 07:01:53,719][model][INFO] - Training step 50160 loss 0.01600821688771248
[2025-03-17 07:02:33,154][model][INFO] - Training step 50320 loss 0.01909594237804413
[2025-03-17 07:03:12,651][model][INFO] - Training step 50480 loss 0.02107360027730465
[2025-03-17 07:03:52,307][model][INFO] - Training step 50640 loss 0.010800446383655071
[2025-03-17 07:09:30,376][model][INFO] - Training step 0 loss 0.015112161636352539
[2025-03-17 07:10:10,720][model][INFO] - Training step 160 loss 0.017280109226703644
[2025-03-17 07:10:53,317][model][INFO] - Training step 320 loss 0.020953303202986717
[2025-03-17 07:11:35,144][model][INFO] - Training step 480 loss 0.018666788935661316
[2025-03-17 07:12:13,480][model][INFO] - Training step 640 loss 0.08169235289096832
[2025-03-17 07:12:53,996][model][INFO] - Training step 800 loss 0.002525020856410265
[2025-03-17 07:13:34,214][model][INFO] - Training step 960 loss 0.015562045387923717
[2025-03-17 07:14:14,899][model][INFO] - Training step 1120 loss 0.24539488554000854
[2025-03-17 07:14:54,555][model][INFO] - Training step 1280 loss 0.24919220805168152
[2025-03-17 07:15:34,171][model][INFO] - Training step 1440 loss 0.2644103467464447
[2025-03-17 07:16:13,568][model][INFO] - Training step 1600 loss 0.04911243915557861
[2025-03-17 07:16:53,432][model][INFO] - Training step 1760 loss 0.24763551354408264
[2025-03-17 07:17:32,770][model][INFO] - Training step 1920 loss 0.015713892877101898
[2025-03-17 07:18:13,452][model][INFO] - Training step 2080 loss 0.02206362597644329
[2025-03-17 07:18:52,241][model][INFO] - Training step 2240 loss 0.027268506586551666
[2025-03-17 07:19:32,257][model][INFO] - Training step 2400 loss 0.020269742235541344
[2025-03-17 07:20:11,612][model][INFO] - Training step 2560 loss 0.04463064670562744
[2025-03-17 07:20:52,419][model][INFO] - Training step 2720 loss 0.013236124068498611
[2025-03-17 07:21:32,139][model][INFO] - Training step 2880 loss 0.014480672776699066
[2025-03-17 07:22:11,624][model][INFO] - Training step 3040 loss 0.02152561955153942
[2025-03-17 07:22:51,220][model][INFO] - Training step 3200 loss 0.010387914255261421
[2025-03-17 07:23:30,834][model][INFO] - Training step 3360 loss 0.005810040980577469
[2025-03-17 07:24:11,396][model][INFO] - Training step 3520 loss 0.0329209640622139
[2025-03-17 07:24:52,201][model][INFO] - Training step 3680 loss 0.2451801300048828
[2025-03-17 07:25:31,964][model][INFO] - Training step 3840 loss 0.03043113462626934
[2025-03-17 07:26:12,289][model][INFO] - Training step 4000 loss 0.25635790824890137
[2025-03-17 07:26:53,252][model][INFO] - Training step 4160 loss 0.2633576989173889
[2025-03-17 07:27:33,565][model][INFO] - Training step 4320 loss 0.03608788177371025
[2025-03-17 07:28:13,026][model][INFO] - Training step 4480 loss 0.02685828134417534
[2025-03-17 07:28:54,221][model][INFO] - Training step 4640 loss 0.03382045030593872
[2025-03-17 07:29:35,443][model][INFO] - Training step 4800 loss 0.07370637357234955
[2025-03-17 07:30:15,496][model][INFO] - Training step 4960 loss 0.008718762546777725
[2025-03-17 07:30:53,598][model][INFO] - Training step 5120 loss 0.045047298073768616
[2025-03-17 07:31:33,668][model][INFO] - Training step 5280 loss 0.24149373173713684
[2025-03-17 07:32:13,209][model][INFO] - Training step 5440 loss 0.006061377935111523
[2025-03-17 07:32:53,119][model][INFO] - Training step 5600 loss 0.020754696801304817
[2025-03-17 07:33:31,656][model][INFO] - Training step 5760 loss 0.26202237606048584
[2025-03-17 07:34:12,479][model][INFO] - Training step 5920 loss 0.0265454463660717
[2025-03-17 07:34:51,475][model][INFO] - Training step 6080 loss 0.0053052036091685295
[2025-03-17 07:35:32,318][model][INFO] - Training step 6240 loss 0.008372319862246513
[2025-03-17 07:36:12,805][model][INFO] - Training step 6400 loss 0.018702421337366104
[2025-03-17 07:36:51,982][model][INFO] - Training step 6560 loss 0.02701537311077118
[2025-03-17 07:37:32,390][model][INFO] - Training step 6720 loss 0.0629170760512352
[2025-03-17 07:38:13,023][model][INFO] - Training step 6880 loss 0.0051817819476127625
[2025-03-17 07:38:53,350][model][INFO] - Training step 7040 loss 0.01751061901450157
[2025-03-17 07:39:34,614][model][INFO] - Training step 7200 loss 0.004804907366633415
[2025-03-17 07:40:15,074][model][INFO] - Training step 7360 loss 0.02362518012523651
[2025-03-17 07:40:53,795][model][INFO] - Training step 7520 loss 0.025276951491832733
[2025-03-17 07:41:32,972][model][INFO] - Training step 7680 loss 0.03550529107451439
[2025-03-17 07:42:12,660][model][INFO] - Training step 7840 loss 0.022246450185775757
[2025-03-17 07:42:52,997][model][INFO] - Training step 8000 loss 0.17173629999160767
[2025-03-17 07:43:32,414][model][INFO] - Training step 8160 loss 0.09098923206329346
[2025-03-17 07:44:12,255][model][INFO] - Training step 8320 loss 0.007597821764647961
[2025-03-17 07:44:51,517][model][INFO] - Training step 8480 loss 0.06726149469614029
[2025-03-17 07:45:30,958][model][INFO] - Training step 8640 loss 0.01848309487104416
[2025-03-17 07:46:09,901][model][INFO] - Training step 8800 loss 0.032149363309144974
[2025-03-17 07:46:49,545][model][INFO] - Training step 8960 loss 0.04190658777952194
[2025-03-17 07:47:28,871][model][INFO] - Training step 9120 loss 0.04000091925263405
[2025-03-17 07:48:08,800][model][INFO] - Training step 9280 loss 0.06542781740427017
[2025-03-17 07:48:48,814][model][INFO] - Training step 9440 loss 0.017028197646141052
[2025-03-17 07:49:29,612][model][INFO] - Training step 9600 loss 0.0032860897481441498
[2025-03-17 07:50:10,379][model][INFO] - Training step 9760 loss 0.22959795594215393
[2025-03-17 07:50:51,462][model][INFO] - Training step 9920 loss 0.026519984006881714
[2025-03-17 07:51:31,628][model][INFO] - Training step 10080 loss 0.020523637533187866
[2025-03-17 07:52:10,391][model][INFO] - Training step 10240 loss 0.24731703102588654
[2025-03-17 07:52:50,233][model][INFO] - Training step 10400 loss 0.029384028166532516
[2025-03-17 07:53:30,053][model][INFO] - Training step 10560 loss 0.001933980267494917
[2025-03-17 07:54:08,617][model][INFO] - Training step 10720 loss 0.011734728701412678
[2025-03-17 07:54:47,155][model][INFO] - Training step 10880 loss 0.03269239515066147
[2025-03-17 07:55:26,114][model][INFO] - Training step 11040 loss 0.024421166628599167
[2025-03-17 07:56:05,505][model][INFO] - Training step 11200 loss 0.01918889954686165
[2025-03-17 07:56:44,586][model][INFO] - Training step 11360 loss 0.01955132745206356
[2025-03-17 07:57:24,369][model][INFO] - Training step 11520 loss 0.1493784636259079
[2025-03-17 07:58:04,081][model][INFO] - Training step 11680 loss 0.06397809088230133
[2025-03-17 07:58:45,432][model][INFO] - Training step 11840 loss 0.016258161514997482
[2025-03-17 07:59:25,826][model][INFO] - Training step 12000 loss 0.0022695481311529875
[2025-03-17 08:00:06,089][model][INFO] - Training step 12160 loss 0.030819501727819443
[2025-03-17 08:00:46,471][model][INFO] - Training step 12320 loss 0.2631121277809143
[2025-03-17 08:01:28,069][model][INFO] - Training step 12480 loss 0.021381698548793793
[2025-03-17 08:02:08,837][model][INFO] - Training step 12640 loss 0.02972840890288353
[2025-03-17 08:02:48,050][model][INFO] - Training step 12800 loss 0.23762476444244385
[2025-03-17 08:03:28,112][model][INFO] - Training step 12960 loss 0.023859675973653793
[2025-03-17 08:04:07,312][model][INFO] - Training step 13120 loss 0.24809132516384125
[2025-03-17 08:04:47,390][model][INFO] - Training step 13280 loss 0.01798946037888527
[2025-03-17 08:05:28,614][model][INFO] - Training step 13440 loss 0.03360773250460625
[2025-03-17 08:06:09,169][model][INFO] - Training step 13600 loss 0.029734816402196884
[2025-03-17 08:06:51,416][model][INFO] - Training step 13760 loss 0.022956693544983864
[2025-03-17 08:07:29,901][model][INFO] - Training step 13920 loss 0.2258947789669037
[2025-03-17 08:08:10,126][model][INFO] - Training step 14080 loss 0.017039593309164047
[2025-03-17 08:08:49,560][model][INFO] - Training step 14240 loss 0.004548653494566679
[2025-03-17 08:09:28,489][model][INFO] - Training step 14400 loss 0.006745903752744198
[2025-03-17 08:10:07,842][model][INFO] - Training step 14560 loss 0.1603700816631317
[2025-03-17 08:10:47,558][model][INFO] - Training step 14720 loss 0.026265934109687805
[2025-03-17 08:11:27,542][model][INFO] - Training step 14880 loss 0.005167517811059952
[2025-03-17 08:12:07,397][model][INFO] - Training step 15040 loss 0.034397706389427185
[2025-03-17 08:12:47,400][model][INFO] - Training step 15200 loss 0.020307807251811028
[2025-03-17 08:13:26,924][model][INFO] - Training step 15360 loss 0.010118365287780762
[2025-03-17 08:14:05,961][model][INFO] - Training step 15520 loss 0.01265272218734026
[2025-03-17 08:14:45,815][model][INFO] - Training step 15680 loss 0.0048815165646374226
[2025-03-17 08:15:25,134][model][INFO] - Training step 15840 loss 0.03086082637310028
[2025-03-17 08:16:05,555][model][INFO] - Training step 16000 loss 0.004150136839598417
[2025-03-17 08:16:45,723][model][INFO] - Training step 16160 loss 0.01419101282954216
[2025-03-17 08:17:25,879][model][INFO] - Training step 16320 loss 0.024816719815135002
[2025-03-17 08:18:06,218][model][INFO] - Training step 16480 loss 0.004111819434911013
[2025-03-17 08:18:45,422][model][INFO] - Training step 16640 loss 0.01717790588736534
[2025-03-17 08:19:25,932][model][INFO] - Training step 16800 loss 0.025920916348695755
[2025-03-17 08:20:08,632][model][INFO] - Training step 16960 loss 0.02572820708155632
[2025-03-17 08:20:49,064][model][INFO] - Training step 17120 loss 0.03441733494400978
[2025-03-17 08:21:30,171][model][INFO] - Training step 17280 loss 0.05427682399749756
[2025-03-17 08:22:09,699][model][INFO] - Training step 17440 loss 0.1165865808725357
[2025-03-17 08:22:50,233][model][INFO] - Training step 17600 loss 0.2735750377178192
[2025-03-17 08:23:29,797][model][INFO] - Training step 17760 loss 0.0010545587865635753
[2025-03-17 08:24:08,024][model][INFO] - Training step 17920 loss 0.07157611846923828
[2025-03-17 08:24:47,700][model][INFO] - Training step 18080 loss 0.005023520439863205
[2025-03-17 08:25:27,779][model][INFO] - Training step 18240 loss 0.034347519278526306
[2025-03-17 08:26:08,265][model][INFO] - Training step 18400 loss 0.2567194104194641
[2025-03-17 08:26:49,279][model][INFO] - Training step 18560 loss 0.017273394390940666
[2025-03-17 08:27:30,199][model][INFO] - Training step 18720 loss 0.057155199348926544
[2025-03-17 08:28:09,248][model][INFO] - Training step 18880 loss 0.0172633845359087
[2025-03-17 08:28:48,569][model][INFO] - Training step 19040 loss 0.08480139076709747
[2025-03-17 08:29:28,711][model][INFO] - Training step 19200 loss 0.0262281633913517
[2025-03-17 08:30:08,108][model][INFO] - Training step 19360 loss 0.025125112384557724
[2025-03-17 08:30:49,054][model][INFO] - Training step 19520 loss 0.04133892059326172
[2025-03-17 08:31:29,763][model][INFO] - Training step 19680 loss 0.2562323212623596
[2025-03-17 08:32:09,489][model][INFO] - Training step 19840 loss 0.02025042101740837
[2025-03-17 08:32:48,844][model][INFO] - Training step 20000 loss 0.23990432918071747
[2025-03-17 08:33:30,409][model][INFO] - Training step 20160 loss 0.2516287565231323
[2025-03-17 08:34:10,730][model][INFO] - Training step 20320 loss 0.003035642672330141
[2025-03-17 08:34:49,988][model][INFO] - Training step 20480 loss 0.029611557722091675
[2025-03-17 08:35:29,838][model][INFO] - Training step 20640 loss 0.05224069207906723
[2025-03-17 08:36:09,852][model][INFO] - Training step 20800 loss 0.03190039470791817
[2025-03-17 08:36:50,274][model][INFO] - Training step 20960 loss 0.005026441067457199
[2025-03-17 08:37:30,605][model][INFO] - Training step 21120 loss 0.3170962929725647
[2025-03-17 08:38:10,019][model][INFO] - Training step 21280 loss 0.2453896403312683
[2025-03-17 08:38:50,322][model][INFO] - Training step 21440 loss 0.01739298366010189
[2025-03-17 08:39:30,477][model][INFO] - Training step 21600 loss 0.034032367169857025
[2025-03-17 08:40:10,232][model][INFO] - Training step 21760 loss 0.029128164052963257
[2025-03-17 08:40:50,392][model][INFO] - Training step 21920 loss 0.06613190472126007
[2025-03-17 08:41:29,493][model][INFO] - Training step 22080 loss 0.25799864530563354
[2025-03-17 08:42:07,601][model][INFO] - Training step 22240 loss 0.023196998983621597
[2025-03-17 08:42:47,912][model][INFO] - Training step 22400 loss 0.04744578152894974
[2025-03-17 08:43:28,707][model][INFO] - Training step 22560 loss 0.002082057297229767
[2025-03-17 08:44:07,571][model][INFO] - Training step 22720 loss 0.006581505760550499
[2025-03-17 08:44:47,365][model][INFO] - Training step 22880 loss 0.011740347370505333
[2025-03-17 08:45:27,348][model][INFO] - Training step 23040 loss 0.00445307232439518
[2025-03-17 08:46:06,210][model][INFO] - Training step 23200 loss 0.15196886658668518
[2025-03-17 08:46:45,929][model][INFO] - Training step 23360 loss 0.254410982131958
[2025-03-17 08:47:25,871][model][INFO] - Training step 23520 loss 0.02675318717956543
[2025-03-17 08:48:06,595][model][INFO] - Training step 23680 loss 0.052093882113695145
[2025-03-17 08:48:45,825][model][INFO] - Training step 23840 loss 0.029579084366559982
[2025-03-17 08:49:24,576][model][INFO] - Training step 24000 loss 0.2480212152004242
[2025-03-17 08:50:06,603][model][INFO] - Training step 24160 loss 0.006292284931987524
[2025-03-17 08:50:46,459][model][INFO] - Training step 24320 loss 0.032298121601343155
[2025-03-17 08:51:26,470][model][INFO] - Training step 24480 loss 0.242204949259758
[2025-03-17 08:52:06,423][model][INFO] - Training step 24640 loss 0.0025514215230941772
[2025-03-17 08:52:46,822][model][INFO] - Training step 24800 loss 0.02990233711898327
[2025-03-17 08:53:27,465][model][INFO] - Training step 24960 loss 0.020569603890180588
[2025-03-17 08:54:08,501][model][INFO] - Training step 25120 loss 0.12208326160907745
[2025-03-17 08:54:48,575][model][INFO] - Training step 25280 loss 0.013653161004185677
[2025-03-17 08:55:29,309][model][INFO] - Training step 25440 loss 0.013050762936472893
[2025-03-17 08:56:08,718][model][INFO] - Training step 25600 loss 0.0345652773976326
[2025-03-17 08:56:47,437][model][INFO] - Training step 25760 loss 0.024391504004597664
[2025-03-17 08:57:28,773][model][INFO] - Training step 25920 loss 0.02155054733157158
[2025-03-17 08:58:08,732][model][INFO] - Training step 26080 loss 0.04408669471740723
[2025-03-17 08:58:48,969][model][INFO] - Training step 26240 loss 0.016911394894123077
[2025-03-17 08:59:28,719][model][INFO] - Training step 26400 loss 0.0638774037361145
[2025-03-17 09:00:08,950][model][INFO] - Training step 26560 loss 0.013760759495198727
[2025-03-17 09:00:48,804][model][INFO] - Training step 26720 loss 0.020043134689331055
[2025-03-17 09:01:27,923][model][INFO] - Training step 26880 loss 0.0029903799295425415
[2025-03-17 09:02:08,255][model][INFO] - Training step 27040 loss 0.01243051327764988
[2025-03-17 09:02:49,098][model][INFO] - Training step 27200 loss 0.020515799522399902
[2025-03-17 09:03:29,081][model][INFO] - Training step 27360 loss 0.059721339493989944
[2025-03-17 09:04:07,286][model][INFO] - Training step 27520 loss 0.0800442323088646
[2025-03-17 09:04:46,113][model][INFO] - Training step 27680 loss 0.016002725809812546
[2025-03-17 09:05:26,745][model][INFO] - Training step 27840 loss 0.23690906167030334
[2025-03-17 09:06:07,595][model][INFO] - Training step 28000 loss 0.016732078045606613
[2025-03-17 09:06:47,922][model][INFO] - Training step 28160 loss 0.013943364843726158
[2025-03-17 09:07:27,815][model][INFO] - Training step 28320 loss 0.01764804497361183
[2025-03-17 09:08:06,959][model][INFO] - Training step 28480 loss 0.03739991784095764
[2025-03-17 09:08:47,264][model][INFO] - Training step 28640 loss 0.04574296623468399
[2025-03-17 09:09:26,139][model][INFO] - Training step 28800 loss 0.0032114796340465546
[2025-03-17 09:10:06,364][model][INFO] - Training step 28960 loss 0.033953577280044556
[2025-03-17 09:10:46,270][model][INFO] - Training step 29120 loss 0.03152366727590561
[2025-03-17 09:11:27,343][model][INFO] - Training step 29280 loss 0.046580970287323
[2025-03-17 09:12:07,181][model][INFO] - Training step 29440 loss 0.08629775047302246
[2025-03-17 09:12:47,707][model][INFO] - Training step 29600 loss 0.030276186764240265
[2025-03-17 09:13:27,397][model][INFO] - Training step 29760 loss 0.25094541907310486
[2025-03-17 09:14:06,864][model][INFO] - Training step 29920 loss 0.24325546622276306
[2025-03-17 09:14:46,048][model][INFO] - Training step 30080 loss 0.24943330883979797
[2025-03-17 09:15:26,135][model][INFO] - Training step 30240 loss 0.004809147212654352
[2025-03-17 09:16:06,006][model][INFO] - Training step 30400 loss 0.006427971180528402
[2025-03-17 09:16:47,110][model][INFO] - Training step 30560 loss 0.02351328544318676
[2025-03-17 09:17:27,441][model][INFO] - Training step 30720 loss 0.0165533609688282
[2025-03-17 09:18:05,827][model][INFO] - Training step 30880 loss 0.05257640779018402
[2025-03-17 09:18:48,079][model][INFO] - Training step 31040 loss 0.06447288393974304
[2025-03-17 09:19:26,967][model][INFO] - Training step 31200 loss 0.016701506450772285
[2025-03-17 09:20:07,334][model][INFO] - Training step 31360 loss 0.24055156111717224
[2025-03-17 09:20:47,916][model][INFO] - Training step 31520 loss 0.006772493943572044
[2025-03-17 09:21:29,860][model][INFO] - Training step 31680 loss 0.27192962169647217
[2025-03-17 09:22:09,175][model][INFO] - Training step 31840 loss 0.011302599683403969
[2025-03-17 09:22:48,349][model][INFO] - Training step 32000 loss 0.005861617624759674
[2025-03-17 09:23:28,686][model][INFO] - Training step 32160 loss 0.03680039197206497
[2025-03-17 09:24:10,040][model][INFO] - Training step 32320 loss 0.0026641280855983496
[2025-03-17 09:24:49,791][model][INFO] - Training step 32480 loss 0.06113547831773758
[2025-03-17 09:25:29,618][model][INFO] - Training step 32640 loss 0.07093070447444916
[2025-03-17 09:26:10,529][model][INFO] - Training step 32800 loss 0.008659173734486103
[2025-03-17 09:26:50,621][model][INFO] - Training step 32960 loss 0.022185416892170906
[2025-03-17 09:27:30,285][model][INFO] - Training step 33120 loss 0.027989037334918976
[2025-03-17 09:28:09,991][model][INFO] - Training step 33280 loss 0.03477974981069565
[2025-03-17 09:28:50,400][model][INFO] - Training step 33440 loss 0.02395603433251381
[2025-03-17 09:29:29,773][model][INFO] - Training step 33600 loss 0.021228719502687454
[2025-03-17 09:30:10,647][model][INFO] - Training step 33760 loss 0.02283235639333725
[2025-03-17 09:30:51,370][model][INFO] - Training step 33920 loss 0.2530880570411682
[2025-03-17 09:31:30,800][model][INFO] - Training step 34080 loss 0.018028058111667633
[2025-03-17 09:32:12,540][model][INFO] - Training step 34240 loss 0.2501595616340637
[2025-03-17 09:32:54,675][model][INFO] - Training step 34400 loss 0.24766121804714203
[2025-03-17 09:33:34,582][model][INFO] - Training step 34560 loss 0.024798143655061722
[2025-03-17 09:34:15,501][model][INFO] - Training step 34720 loss 0.016722727566957474
[2025-03-17 09:34:56,732][model][INFO] - Training step 34880 loss 0.03934639319777489
[2025-03-17 09:35:37,488][model][INFO] - Training step 35040 loss 0.2471422255039215
[2025-03-17 09:36:17,683][model][INFO] - Training step 35200 loss 0.012363306246697903
[2025-03-17 09:36:57,975][model][INFO] - Training step 35360 loss 0.013188013806939125
[2025-03-17 09:37:40,423][model][INFO] - Training step 35520 loss 0.07086876034736633
[2025-03-17 09:38:20,675][model][INFO] - Training step 35680 loss 0.03203248977661133
[2025-03-17 09:38:58,892][model][INFO] - Training step 35840 loss 0.007956279441714287
[2025-03-17 09:39:38,712][model][INFO] - Training step 36000 loss 0.2466355562210083
[2025-03-17 09:40:19,197][model][INFO] - Training step 36160 loss 0.024289578199386597
[2025-03-17 09:41:00,481][model][INFO] - Training step 36320 loss 0.014333139173686504
[2025-03-17 09:41:41,748][model][INFO] - Training step 36480 loss 0.02623927593231201
[2025-03-17 09:42:22,782][model][INFO] - Training step 36640 loss 0.01918167993426323
[2025-03-17 09:43:02,124][model][INFO] - Training step 36800 loss 0.2596575617790222
[2025-03-17 09:43:43,134][model][INFO] - Training step 36960 loss 0.0023943204432725906
[2025-03-17 09:44:22,349][model][INFO] - Training step 37120 loss 0.2520703077316284
[2025-03-17 09:45:01,347][model][INFO] - Training step 37280 loss 0.023817673325538635
[2025-03-17 09:45:41,440][model][INFO] - Training step 37440 loss 0.0307653546333313
[2025-03-17 09:46:22,360][model][INFO] - Training step 37600 loss 0.24195805191993713
[2025-03-17 09:47:03,813][model][INFO] - Training step 37760 loss 0.0047881766222417355
[2025-03-17 09:47:43,912][model][INFO] - Training step 37920 loss 0.01019933633506298
[2025-03-17 09:48:22,707][model][INFO] - Training step 38080 loss 0.06124964728951454
[2025-03-17 09:49:03,637][model][INFO] - Training step 38240 loss 0.024073153734207153
[2025-03-17 09:49:44,582][model][INFO] - Training step 38400 loss 0.022616613656282425
[2025-03-17 09:50:24,232][model][INFO] - Training step 38560 loss 0.005866745486855507
[2025-03-17 09:51:04,202][model][INFO] - Training step 38720 loss 0.025612186640501022
[2025-03-17 09:51:43,718][model][INFO] - Training step 38880 loss 0.029391523450613022
[2025-03-17 09:52:24,538][model][INFO] - Training step 39040 loss 0.026147738099098206
[2025-03-17 09:53:03,008][model][INFO] - Training step 39200 loss 0.004019365645945072
[2025-03-17 09:53:41,009][model][INFO] - Training step 39360 loss 0.017525644972920418
[2025-03-17 09:54:20,185][model][INFO] - Training step 39520 loss 0.02230912260711193
[2025-03-17 09:55:00,414][model][INFO] - Training step 39680 loss 0.014161061495542526
[2025-03-17 09:55:41,498][model][INFO] - Training step 39840 loss 0.027319302782416344
[2025-03-17 09:56:22,336][model][INFO] - Training step 40000 loss 0.15334108471870422
[2025-03-17 09:57:04,617][model][INFO] - Training step 40160 loss 0.0034493738785386086
[2025-03-17 09:57:44,783][model][INFO] - Training step 40320 loss 0.021944426000118256
[2025-03-17 09:58:24,756][model][INFO] - Training step 40480 loss 0.008338361978530884
[2025-03-17 09:59:06,205][model][INFO] - Training step 40640 loss 0.026569191366434097
[2025-03-17 09:59:46,711][model][INFO] - Training step 40800 loss 0.011974111199378967
[2025-03-17 10:00:27,382][model][INFO] - Training step 40960 loss 0.07892781496047974
[2025-03-17 10:01:06,405][model][INFO] - Training step 41120 loss 0.011759735643863678
[2025-03-17 10:01:48,364][model][INFO] - Training step 41280 loss 0.024362947791814804
[2025-03-17 10:02:27,538][model][INFO] - Training step 41440 loss 0.14224031567573547
[2025-03-17 10:03:09,553][model][INFO] - Training step 41600 loss 0.006893746089190245
[2025-03-17 10:03:50,623][model][INFO] - Training step 41760 loss 0.015187490731477737
[2025-03-17 10:04:31,065][model][INFO] - Training step 41920 loss 0.08705537021160126
[2025-03-17 10:05:11,891][model][INFO] - Training step 42080 loss 0.013084303587675095
[2025-03-17 10:05:53,108][model][INFO] - Training step 42240 loss 0.2646191120147705
[2025-03-17 10:06:32,687][model][INFO] - Training step 42400 loss 0.031819120049476624
[2025-03-17 10:07:15,009][model][INFO] - Training step 42560 loss 0.003883530618622899
[2025-03-17 10:07:55,230][model][INFO] - Training step 42720 loss 0.25136011838912964
[2025-03-17 10:08:35,266][model][INFO] - Training step 42880 loss 0.027589287608861923
[2025-03-17 10:09:15,812][model][INFO] - Training step 43040 loss 0.018221989274024963
[2025-03-17 10:09:55,402][model][INFO] - Training step 43200 loss 0.02389824017882347
[2025-03-17 10:10:36,436][model][INFO] - Training step 43360 loss 0.00434440141543746
[2025-03-17 10:11:16,483][model][INFO] - Training step 43520 loss 0.003849923610687256
[2025-03-17 10:11:54,895][model][INFO] - Training step 43680 loss 0.026167334988713264
[2025-03-17 10:12:35,507][model][INFO] - Training step 43840 loss 0.022392962127923965
[2025-03-17 10:13:16,645][model][INFO] - Training step 44000 loss 0.02532048523426056
[2025-03-17 10:13:57,739][model][INFO] - Training step 44160 loss 0.009668064303696156
[2025-03-17 10:14:36,776][model][INFO] - Training step 44320 loss 0.013052723370492458
[2025-03-17 10:15:16,719][model][INFO] - Training step 44480 loss 0.035939089953899384
[2025-03-17 10:15:54,943][model][INFO] - Training step 44640 loss 0.018649976700544357
[2025-03-17 10:16:35,842][model][INFO] - Training step 44800 loss 0.01767941191792488
[2025-03-17 10:17:16,126][model][INFO] - Training step 44960 loss 0.23042969405651093
[2025-03-17 10:17:56,159][model][INFO] - Training step 45120 loss 0.04014822095632553
[2025-03-17 10:18:36,556][model][INFO] - Training step 45280 loss 0.002260314766317606
[2025-03-17 10:19:17,253][model][INFO] - Training step 45440 loss 0.005834081210196018
[2025-03-17 10:19:58,989][model][INFO] - Training step 45600 loss 0.24401730298995972
[2025-03-17 10:20:39,759][model][INFO] - Training step 45760 loss 0.027800410985946655
[2025-03-17 10:21:18,634][model][INFO] - Training step 45920 loss 0.020525293424725533
[2025-03-17 10:22:00,301][model][INFO] - Training step 46080 loss 0.023371737450361252
[2025-03-17 10:22:40,834][model][INFO] - Training step 46240 loss 0.02898601070046425
[2025-03-17 10:23:23,312][model][INFO] - Training step 46400 loss 0.24979674816131592
[2025-03-17 10:24:04,190][model][INFO] - Training step 46560 loss 0.021532375365495682
[2025-03-17 10:24:44,631][model][INFO] - Training step 46720 loss 0.24742525815963745
[2025-03-17 10:25:24,710][model][INFO] - Training step 46880 loss 0.028352685272693634
[2025-03-17 10:26:03,930][model][INFO] - Training step 47040 loss 0.03522733971476555
[2025-03-17 10:26:43,898][model][INFO] - Training step 47200 loss 0.2766662538051605
[2025-03-17 10:27:24,384][model][INFO] - Training step 47360 loss 0.25139111280441284
[2025-03-17 10:28:04,283][model][INFO] - Training step 47520 loss 0.013883762992918491
[2025-03-17 10:28:45,195][model][INFO] - Training step 47680 loss 0.02494695968925953
[2025-03-17 10:29:24,573][model][INFO] - Training step 47840 loss 0.014766120351850986
[2025-03-17 10:30:05,065][model][INFO] - Training step 48000 loss 0.05403001233935356
[2025-03-17 10:30:45,889][model][INFO] - Training step 48160 loss 0.0015246713301166892
[2025-03-17 10:31:26,737][model][INFO] - Training step 48320 loss 0.032145045697689056
[2025-03-17 10:32:06,845][model][INFO] - Training step 48480 loss 0.24673527479171753
[2025-03-17 10:32:46,595][model][INFO] - Training step 48640 loss 0.03187541291117668
[2025-03-17 10:33:25,758][model][INFO] - Training step 48800 loss 0.021035613492131233
[2025-03-17 10:34:05,319][model][INFO] - Training step 48960 loss 0.27644187211990356
[2025-03-17 10:34:45,089][model][INFO] - Training step 49120 loss 0.017278756946325302
[2025-03-17 10:35:25,394][model][INFO] - Training step 49280 loss 0.24572668969631195
[2025-03-17 10:36:06,271][model][INFO] - Training step 49440 loss 0.03657243028283119
[2025-03-17 10:36:47,145][model][INFO] - Training step 49600 loss 0.04545438289642334
[2025-03-17 10:37:26,238][model][INFO] - Training step 49760 loss 0.05045885592699051
[2025-03-17 10:38:07,862][model][INFO] - Training step 49920 loss 0.07589180767536163
[2025-03-17 10:38:48,468][model][INFO] - Training step 50080 loss 0.017229240387678146
[2025-03-17 10:39:29,297][model][INFO] - Training step 50240 loss 0.015112746506929398
[2025-03-17 10:40:09,578][model][INFO] - Training step 50400 loss 0.03783595561981201
[2025-03-17 10:40:48,848][model][INFO] - Training step 50560 loss 0.017183996737003326
[2025-03-17 10:41:27,712][model][INFO] - Training step 50720 loss 0.038984429091215134
[2025-03-17 10:47:05,619][model][INFO] - Training step 80 loss 0.04291193187236786
[2025-03-17 10:47:46,135][model][INFO] - Training step 240 loss 0.008477197960019112
[2025-03-17 10:48:26,228][model][INFO] - Training step 400 loss 0.026287946850061417
[2025-03-17 10:49:07,127][model][INFO] - Training step 560 loss 0.020695248618721962
[2025-03-17 10:49:48,780][model][INFO] - Training step 720 loss 0.025189880281686783
[2025-03-17 10:50:28,541][model][INFO] - Training step 880 loss 0.004251979757100344
[2025-03-17 10:51:07,226][model][INFO] - Training step 1040 loss 0.013256597332656384
[2025-03-17 10:51:46,115][model][INFO] - Training step 1200 loss 0.02533641830086708
[2025-03-17 10:52:26,014][model][INFO] - Training step 1360 loss 0.10494845360517502
[2025-03-17 10:53:06,274][model][INFO] - Training step 1520 loss 0.027627170085906982
[2025-03-17 10:53:46,558][model][INFO] - Training step 1680 loss 0.09829430282115936
[2025-03-17 10:54:27,018][model][INFO] - Training step 1840 loss 0.006489802151918411
[2025-03-17 10:55:07,284][model][INFO] - Training step 2000 loss 0.03271762281656265
[2025-03-17 10:55:46,635][model][INFO] - Training step 2160 loss 0.03431783244013786
[2025-03-17 10:56:26,780][model][INFO] - Training step 2320 loss 0.02768789976835251
[2025-03-17 10:57:06,205][model][INFO] - Training step 2480 loss 0.014935148879885674
[2025-03-17 10:57:46,595][model][INFO] - Training step 2640 loss 0.09312492609024048
[2025-03-17 10:58:26,953][model][INFO] - Training step 2800 loss 0.025657709687948227
[2025-03-17 10:59:06,270][model][INFO] - Training step 2960 loss 0.2565268874168396
[2025-03-17 10:59:46,950][model][INFO] - Training step 3120 loss 0.09362467378377914
[2025-03-17 11:00:27,193][model][INFO] - Training step 3280 loss 0.12249656766653061
[2025-03-17 11:01:07,432][model][INFO] - Training step 3440 loss 0.03758911415934563
[2025-03-17 11:01:46,684][model][INFO] - Training step 3600 loss 0.2474830150604248
[2025-03-17 11:02:25,770][model][INFO] - Training step 3760 loss 0.005484967026859522
[2025-03-17 11:03:06,467][model][INFO] - Training step 3920 loss 0.015263242647051811
[2025-03-17 11:03:46,443][model][INFO] - Training step 4080 loss 0.02237561345100403
[2025-03-17 11:04:25,881][model][INFO] - Training step 4240 loss 0.043881192803382874
[2025-03-17 11:05:07,255][model][INFO] - Training step 4400 loss 0.01256486400961876
[2025-03-17 11:05:47,773][model][INFO] - Training step 4560 loss 0.23132097721099854
[2025-03-17 11:06:28,838][model][INFO] - Training step 4720 loss 0.24311622977256775
[2025-03-17 11:07:09,182][model][INFO] - Training step 4880 loss 0.010239599272608757
[2025-03-17 11:07:48,891][model][INFO] - Training step 5040 loss 0.2755599617958069
[2025-03-17 11:08:29,310][model][INFO] - Training step 5200 loss 0.007397918496280909
[2025-03-17 11:09:08,317][model][INFO] - Training step 5360 loss 0.007144764997065067
[2025-03-17 11:09:49,050][model][INFO] - Training step 5520 loss 0.008580774068832397
[2025-03-17 11:10:28,596][model][INFO] - Training step 5680 loss 0.01419272180646658
[2025-03-17 11:11:08,552][model][INFO] - Training step 5840 loss 0.04576842486858368
[2025-03-17 11:11:49,331][model][INFO] - Training step 6000 loss 0.01223247405141592
[2025-03-17 11:12:29,394][model][INFO] - Training step 6160 loss 0.0037540614139288664
[2025-03-17 11:13:09,666][model][INFO] - Training step 6320 loss 0.0033411988988518715
[2025-03-17 11:13:50,365][model][INFO] - Training step 6480 loss 0.022946499288082123
[2025-03-17 11:14:29,811][model][INFO] - Training step 6640 loss 0.007632615976035595
[2025-03-17 11:15:10,821][model][INFO] - Training step 6800 loss 0.017192387953400612
[2025-03-17 11:15:49,337][model][INFO] - Training step 6960 loss 0.03482383117079735
[2025-03-17 11:16:29,284][model][INFO] - Training step 7120 loss 0.038048721849918365
[2025-03-17 11:17:09,392][model][INFO] - Training step 7280 loss 0.00882586557418108
[2025-03-17 11:17:48,720][model][INFO] - Training step 7440 loss 0.25586840510368347
[2025-03-17 11:18:28,161][model][INFO] - Training step 7600 loss 0.058123573660850525
[2025-03-17 11:19:08,803][model][INFO] - Training step 7760 loss 0.030115682631731033
[2025-03-17 11:19:48,068][model][INFO] - Training step 7920 loss 0.022399628534913063
[2025-03-17 11:20:27,608][model][INFO] - Training step 8080 loss 0.029546400532126427
[2025-03-17 11:21:08,156][model][INFO] - Training step 8240 loss 0.016938960179686546
[2025-03-17 11:21:47,440][model][INFO] - Training step 8400 loss 0.030166350305080414
[2025-03-17 11:22:28,285][model][INFO] - Training step 8560 loss 0.02528015524148941
[2025-03-17 11:23:08,092][model][INFO] - Training step 8720 loss 0.02255205065011978
[2025-03-17 11:23:49,355][model][INFO] - Training step 8880 loss 0.03039667382836342
[2025-03-17 11:24:29,687][model][INFO] - Training step 9040 loss 0.04003090411424637
[2025-03-17 11:25:09,327][model][INFO] - Training step 9200 loss 0.11314613372087479
[2025-03-17 11:25:48,082][model][INFO] - Training step 9360 loss 0.02316949889063835
[2025-03-17 11:26:28,282][model][INFO] - Training step 9520 loss 0.023594310507178307
[2025-03-17 11:27:07,611][model][INFO] - Training step 9680 loss 0.0325717031955719
[2025-03-17 11:27:47,590][model][INFO] - Training step 9840 loss 0.3271748721599579
[2025-03-17 11:28:27,897][model][INFO] - Training step 10000 loss 0.2657279670238495
[2025-03-17 11:29:09,238][model][INFO] - Training step 10160 loss 0.016949616372585297
[2025-03-17 11:29:48,116][model][INFO] - Training step 10320 loss 0.02491096220910549
[2025-03-17 11:30:28,825][model][INFO] - Training step 10480 loss 0.01833776757121086
[2025-03-17 11:31:09,725][model][INFO] - Training step 10640 loss 0.07046008110046387
[2025-03-17 11:31:50,072][model][INFO] - Training step 10800 loss 0.0485968291759491
[2025-03-17 11:32:30,826][model][INFO] - Training step 10960 loss 0.12092505395412445
[2025-03-17 11:33:11,619][model][INFO] - Training step 11120 loss 0.2520417869091034
[2025-03-17 11:33:49,817][model][INFO] - Training step 11280 loss 0.007481694221496582
[2025-03-17 11:34:30,520][model][INFO] - Training step 11440 loss 0.021758155897259712
[2025-03-17 11:35:10,818][model][INFO] - Training step 11600 loss 0.022121639922261238
[2025-03-17 11:35:51,224][model][INFO] - Training step 11760 loss 0.0365382619202137
[2025-03-17 11:36:30,916][model][INFO] - Training step 11920 loss 0.12032999098300934
[2025-03-17 11:37:11,794][model][INFO] - Training step 12080 loss 0.033152930438518524
[2025-03-17 11:37:52,610][model][INFO] - Training step 12240 loss 0.24890688061714172
[2025-03-17 11:38:31,428][model][INFO] - Training step 12400 loss 0.010495172813534737
[2025-03-17 11:39:12,034][model][INFO] - Training step 12560 loss 0.022555215284228325
[2025-03-17 11:39:51,536][model][INFO] - Training step 12720 loss 0.02851022407412529
[2025-03-17 11:40:32,478][model][INFO] - Training step 12880 loss 0.017068035900592804
[2025-03-17 11:41:12,471][model][INFO] - Training step 13040 loss 0.025735389441251755
[2025-03-17 11:41:52,442][model][INFO] - Training step 13200 loss 0.23936676979064941
[2025-03-17 11:42:33,339][model][INFO] - Training step 13360 loss 0.04198620468378067
[2025-03-17 11:43:14,293][model][INFO] - Training step 13520 loss 0.025001343339681625
[2025-03-17 11:43:54,943][model][INFO] - Training step 13680 loss 0.3029685616493225
[2025-03-17 11:44:35,283][model][INFO] - Training step 13840 loss 0.014870209619402885
[2025-03-17 11:45:15,752][model][INFO] - Training step 14000 loss 0.02429291233420372
[2025-03-17 11:45:55,270][model][INFO] - Training step 14160 loss 0.2516384720802307
[2025-03-17 11:46:35,811][model][INFO] - Training step 14320 loss 0.022041596472263336
[2025-03-17 11:47:15,571][model][INFO] - Training step 14480 loss 0.015331525355577469
[2025-03-17 11:47:55,688][model][INFO] - Training step 14640 loss 0.016837356612086296
[2025-03-17 11:48:35,966][model][INFO] - Training step 14800 loss 0.010772071778774261
[2025-03-17 11:49:15,878][model][INFO] - Training step 14960 loss 0.016471777111291885
[2025-03-17 11:49:56,910][model][INFO] - Training step 15120 loss 0.06909671425819397
[2025-03-17 11:50:37,806][model][INFO] - Training step 15280 loss 0.08258411288261414
[2025-03-17 11:51:18,621][model][INFO] - Training step 15440 loss 0.013640956953167915
[2025-03-17 11:51:57,933][model][INFO] - Training step 15600 loss 0.0967860072851181
[2025-03-17 11:52:38,269][model][INFO] - Training step 15760 loss 0.11563223600387573
[2025-03-17 11:53:19,566][model][INFO] - Training step 15920 loss 0.004285052884370089
[2025-03-17 11:53:59,787][model][INFO] - Training step 16080 loss 0.007113751024007797
[2025-03-17 11:54:38,068][model][INFO] - Training step 16240 loss 0.006739109754562378
[2025-03-17 11:55:16,891][model][INFO] - Training step 16400 loss 0.030580097809433937
[2025-03-17 11:55:56,960][model][INFO] - Training step 16560 loss 0.02970183454453945
[2025-03-17 11:56:36,657][model][INFO] - Training step 16720 loss 0.0230554286390543
[2025-03-17 11:57:17,440][model][INFO] - Training step 16880 loss 0.02480541542172432
[2025-03-17 11:57:56,623][model][INFO] - Training step 17040 loss 0.01229886244982481
[2025-03-17 11:58:37,377][model][INFO] - Training step 17200 loss 0.08047005534172058
[2025-03-17 11:59:16,972][model][INFO] - Training step 17360 loss 0.015229699201881886
[2025-03-17 11:59:56,222][model][INFO] - Training step 17520 loss 0.024701103568077087
[2025-03-17 12:00:38,507][model][INFO] - Training step 17680 loss 0.020537488162517548
[2025-03-17 12:01:17,477][model][INFO] - Training step 17840 loss 0.029968608170747757
[2025-03-17 12:01:56,096][model][INFO] - Training step 18000 loss 0.026669833809137344
[2025-03-17 12:02:37,493][model][INFO] - Training step 18160 loss 0.027943940833210945
[2025-03-17 12:03:19,130][model][INFO] - Training step 18320 loss 0.07179917395114899
[2025-03-17 12:03:59,700][model][INFO] - Training step 18480 loss 0.007119419053196907
[2025-03-17 12:04:40,419][model][INFO] - Training step 18640 loss 0.02625577338039875
[2025-03-17 12:05:19,980][model][INFO] - Training step 18800 loss 0.011881502345204353
[2025-03-17 12:05:59,354][model][INFO] - Training step 18960 loss 0.03342161700129509
[2025-03-17 12:06:41,591][model][INFO] - Training step 19120 loss 0.023417530581355095
[2025-03-17 12:07:21,124][model][INFO] - Training step 19280 loss 0.06314252316951752
[2025-03-17 12:07:59,553][model][INFO] - Training step 19440 loss 0.02999686263501644
[2025-03-17 12:08:41,518][model][INFO] - Training step 19600 loss 0.09710795432329178
[2025-03-17 12:09:21,507][model][INFO] - Training step 19760 loss 0.021614395081996918
[2025-03-17 12:10:01,616][model][INFO] - Training step 19920 loss 0.005848345346748829
[2025-03-17 12:10:40,230][model][INFO] - Training step 20080 loss 0.125884547829628
[2025-03-17 12:11:20,313][model][INFO] - Training step 20240 loss 0.15510989725589752
[2025-03-17 12:11:58,306][model][INFO] - Training step 20400 loss 0.03923220932483673
[2025-03-17 12:12:38,226][model][INFO] - Training step 20560 loss 0.014860051684081554
[2025-03-17 12:13:19,020][model][INFO] - Training step 20720 loss 0.07493078708648682
[2025-03-17 12:13:59,301][model][INFO] - Training step 20880 loss 0.019709572196006775
[2025-03-17 12:14:39,241][model][INFO] - Training step 21040 loss 0.25851741433143616
[2025-03-17 12:15:18,996][model][INFO] - Training step 21200 loss 0.020995020866394043
[2025-03-17 12:15:58,545][model][INFO] - Training step 21360 loss 0.05170027166604996
[2025-03-17 12:16:39,315][model][INFO] - Training step 21520 loss 0.029635947197675705
[2025-03-17 12:17:20,052][model][INFO] - Training step 21680 loss 0.028154924511909485
[2025-03-17 12:18:01,643][model][INFO] - Training step 21840 loss 0.0457172691822052
[2025-03-17 12:18:40,154][model][INFO] - Training step 22000 loss 0.03255394101142883
[2025-03-17 12:19:20,171][model][INFO] - Training step 22160 loss 0.06664711236953735
[2025-03-17 12:20:01,593][model][INFO] - Training step 22320 loss 0.030055705457925797
[2025-03-17 12:20:42,522][model][INFO] - Training step 22480 loss 0.009531768038868904
[2025-03-17 12:21:23,217][model][INFO] - Training step 22640 loss 0.013447936624288559
[2025-03-17 12:22:04,294][model][INFO] - Training step 22800 loss 0.02346387505531311
[2025-03-17 12:22:45,440][model][INFO] - Training step 22960 loss 0.02086847648024559
[2025-03-17 12:23:24,974][model][INFO] - Training step 23120 loss 0.021726232022047043
[2025-03-17 12:24:04,746][model][INFO] - Training step 23280 loss 0.05376431345939636
[2025-03-17 12:24:45,208][model][INFO] - Training step 23440 loss 0.01779402606189251
[2025-03-17 12:25:24,904][model][INFO] - Training step 23600 loss 0.033018700778484344
[2025-03-17 12:26:03,716][model][INFO] - Training step 23760 loss 0.007060077972710133
[2025-03-17 12:26:43,853][model][INFO] - Training step 23920 loss 0.026010029017925262
[2025-03-17 12:27:22,858][model][INFO] - Training step 24080 loss 0.005128463730216026
[2025-03-17 12:28:02,839][model][INFO] - Training step 24240 loss 0.012195618823170662
[2025-03-17 12:28:42,819][model][INFO] - Training step 24400 loss 0.0338824987411499
[2025-03-17 12:29:23,107][model][INFO] - Training step 24560 loss 0.003333080094307661
[2025-03-17 12:30:03,680][model][INFO] - Training step 24720 loss 0.01740981638431549
[2025-03-17 12:30:43,428][model][INFO] - Training step 24880 loss 0.04301558434963226
[2025-03-17 12:31:22,332][model][INFO] - Training step 25040 loss 0.026375623419880867
[2025-03-17 12:32:01,188][model][INFO] - Training step 25200 loss 0.24527592957019806
[2025-03-17 12:32:40,323][model][INFO] - Training step 25360 loss 0.2512320280075073
[2025-03-17 12:33:20,405][model][INFO] - Training step 25520 loss 0.24687686562538147
[2025-03-17 12:34:01,088][model][INFO] - Training step 25680 loss 0.003974065184593201
[2025-03-17 12:34:40,754][model][INFO] - Training step 25840 loss 0.009247451089322567
[2025-03-17 12:35:21,541][model][INFO] - Training step 26000 loss 0.1505899429321289
[2025-03-17 12:36:00,814][model][INFO] - Training step 26160 loss 0.01960577443242073
[2025-03-17 12:36:41,201][model][INFO] - Training step 26320 loss 0.07158336043357849
[2025-03-17 12:37:22,114][model][INFO] - Training step 26480 loss 0.24869874119758606
[2025-03-17 12:38:01,902][model][INFO] - Training step 26640 loss 0.011250630021095276
[2025-03-17 12:38:41,034][model][INFO] - Training step 26800 loss 0.03335636854171753
[2025-03-17 12:39:22,290][model][INFO] - Training step 26960 loss 0.03082934394478798
[2025-03-17 12:40:01,167][model][INFO] - Training step 27120 loss 0.017218662425875664
[2025-03-17 12:40:41,040][model][INFO] - Training step 27280 loss 0.07902386784553528
[2025-03-17 12:41:19,573][model][INFO] - Training step 27440 loss 0.031600434333086014
[2025-03-17 12:42:00,025][model][INFO] - Training step 27600 loss 0.05284486711025238
[2025-03-17 12:42:39,596][model][INFO] - Training step 27760 loss 0.02702619880437851
[2025-03-17 12:43:18,005][model][INFO] - Training step 27920 loss 0.013238226063549519
[2025-03-17 12:43:58,137][model][INFO] - Training step 28080 loss 0.02609071135520935
[2025-03-17 12:44:37,979][model][INFO] - Training step 28240 loss 0.24508342146873474
[2025-03-17 12:45:18,453][model][INFO] - Training step 28400 loss 0.052106112241744995
[2025-03-17 12:46:00,240][model][INFO] - Training step 28560 loss 0.019831646233797073
[2025-03-17 12:46:39,811][model][INFO] - Training step 28720 loss 0.010943137109279633
[2025-03-17 12:47:18,644][model][INFO] - Training step 28880 loss 0.01731691136956215
[2025-03-17 12:48:00,305][model][INFO] - Training step 29040 loss 0.021134907379746437
[2025-03-17 12:48:39,849][model][INFO] - Training step 29200 loss 0.015198898501694202
[2025-03-17 12:49:19,526][model][INFO] - Training step 29360 loss 0.023063642904162407
[2025-03-17 12:50:00,443][model][INFO] - Training step 29520 loss 0.00456303171813488
[2025-03-17 12:50:42,009][model][INFO] - Training step 29680 loss 0.02808523178100586
[2025-03-17 12:51:20,775][model][INFO] - Training step 29840 loss 0.02568913996219635
[2025-03-17 12:52:01,606][model][INFO] - Training step 30000 loss 0.10384586453437805
[2025-03-17 12:52:39,876][model][INFO] - Training step 30160 loss 0.039643578231334686
[2025-03-17 12:53:19,995][model][INFO] - Training step 30320 loss 0.017062487080693245
[2025-03-17 12:53:59,466][model][INFO] - Training step 30480 loss 0.032685503363609314
[2025-03-17 12:54:37,792][model][INFO] - Training step 30640 loss 0.026826772838830948
[2025-03-17 12:55:15,388][model][INFO] - Training step 30800 loss 0.04439523071050644
[2025-03-17 12:55:57,529][model][INFO] - Training step 30960 loss 0.045647285878658295
[2025-03-17 12:56:37,725][model][INFO] - Training step 31120 loss 0.14477208256721497
[2025-03-17 12:57:17,592][model][INFO] - Training step 31280 loss 0.045088592916727066
[2025-03-17 12:57:58,826][model][INFO] - Training step 31440 loss 0.0034470059908926487
[2025-03-17 12:58:39,283][model][INFO] - Training step 31600 loss 0.023908039554953575
[2025-03-17 12:59:20,457][model][INFO] - Training step 31760 loss 0.2601896822452545
[2025-03-17 13:00:00,929][model][INFO] - Training step 31920 loss 0.027677953243255615
[2025-03-17 13:00:39,626][model][INFO] - Training step 32080 loss 0.0207417830824852
[2025-03-17 13:01:20,159][model][INFO] - Training step 32240 loss 0.021887153387069702
[2025-03-17 13:02:00,379][model][INFO] - Training step 32400 loss 0.043169714510440826
[2025-03-17 13:02:41,088][model][INFO] - Training step 32560 loss 0.02845947816967964
[2025-03-17 13:03:22,812][model][INFO] - Training step 32720 loss 0.016953878104686737
[2025-03-17 13:04:03,950][model][INFO] - Training step 32880 loss 0.14204096794128418
[2025-03-17 13:04:43,775][model][INFO] - Training step 33040 loss 0.02473122626543045
[2025-03-17 13:05:24,468][model][INFO] - Training step 33200 loss 0.033281899988651276
[2025-03-17 13:06:03,812][model][INFO] - Training step 33360 loss 0.014468781650066376
[2025-03-17 13:06:43,775][model][INFO] - Training step 33520 loss 0.02898714691400528
[2025-03-17 13:07:23,593][model][INFO] - Training step 33680 loss 0.004254605621099472
[2025-03-17 13:08:03,519][model][INFO] - Training step 33840 loss 0.044512294232845306
[2025-03-17 13:08:43,103][model][INFO] - Training step 34000 loss 0.004830504301935434
[2025-03-17 13:09:24,369][model][INFO] - Training step 34160 loss 0.25925907492637634
[2025-03-17 13:10:03,992][model][INFO] - Training step 34320 loss 0.08647281676530838
[2025-03-17 13:10:45,082][model][INFO] - Training step 34480 loss 0.26013338565826416
[2025-03-17 13:11:25,416][model][INFO] - Training step 34640 loss 0.23219652473926544
[2025-03-17 13:12:03,865][model][INFO] - Training step 34800 loss 0.030614640563726425
[2025-03-17 13:12:45,185][model][INFO] - Training step 34960 loss 0.022185055539011955
[2025-03-17 13:13:26,119][model][INFO] - Training step 35120 loss 0.007693191524595022
[2025-03-17 13:14:06,100][model][INFO] - Training step 35280 loss 0.02295791357755661
[2025-03-17 13:14:46,075][model][INFO] - Training step 35440 loss 0.2422286570072174
[2025-03-17 13:15:26,584][model][INFO] - Training step 35600 loss 0.06415532529354095
[2025-03-17 13:16:06,475][model][INFO] - Training step 35760 loss 0.020583324134349823
[2025-03-17 13:16:46,989][model][INFO] - Training step 35920 loss 0.1527385413646698
[2025-03-17 13:17:27,708][model][INFO] - Training step 36080 loss 0.26022273302078247
[2025-03-17 13:18:07,376][model][INFO] - Training step 36240 loss 0.04089551419019699
[2025-03-17 13:18:47,860][model][INFO] - Training step 36400 loss 0.06959137320518494
[2025-03-17 13:19:28,195][model][INFO] - Training step 36560 loss 0.00594644621014595
[2025-03-17 13:20:07,813][model][INFO] - Training step 36720 loss 0.24346724152565002
[2025-03-17 13:20:48,245][model][INFO] - Training step 36880 loss 0.34032297134399414
[2025-03-17 13:21:28,367][model][INFO] - Training step 37040 loss 0.014627223834395409
[2025-03-17 13:22:10,290][model][INFO] - Training step 37200 loss 0.022252777591347694
[2025-03-17 13:22:50,188][model][INFO] - Training step 37360 loss 0.003671701531857252
[2025-03-17 13:23:30,373][model][INFO] - Training step 37520 loss 0.009512168355286121
[2025-03-17 13:24:10,584][model][INFO] - Training step 37680 loss 0.03233005106449127
[2025-03-17 13:24:50,027][model][INFO] - Training step 37840 loss 0.03164583444595337
[2025-03-17 13:25:28,512][model][INFO] - Training step 38000 loss 0.0025126885157078505
[2025-03-17 13:26:07,594][model][INFO] - Training step 38160 loss 0.017576050013303757
[2025-03-17 13:26:48,331][model][INFO] - Training step 38320 loss 0.030819199979305267
[2025-03-17 13:27:28,105][model][INFO] - Training step 38480 loss 0.03400377929210663
[2025-03-17 13:28:07,763][model][INFO] - Training step 38640 loss 0.0197267048060894
[2025-03-17 13:28:47,197][model][INFO] - Training step 38800 loss 0.028369959443807602
[2025-03-17 13:29:28,483][model][INFO] - Training step 38960 loss 0.02320936694741249
[2025-03-17 13:30:08,613][model][INFO] - Training step 39120 loss 0.020995020866394043
[2025-03-17 13:30:48,208][model][INFO] - Training step 39280 loss 0.02264213189482689
[2025-03-17 13:31:29,184][model][INFO] - Training step 39440 loss 0.08154842257499695
[2025-03-17 13:32:08,960][model][INFO] - Training step 39600 loss 0.017450425773859024
[2025-03-17 13:32:49,949][model][INFO] - Training step 39760 loss 0.022014010697603226
[2025-03-17 13:33:29,655][model][INFO] - Training step 39920 loss 0.0026061551179736853
[2025-03-17 13:34:11,701][model][INFO] - Training step 40080 loss 0.033771347254514694
[2025-03-17 13:34:51,791][model][INFO] - Training step 40240 loss 0.02219220995903015
[2025-03-17 13:35:30,376][model][INFO] - Training step 40400 loss 0.06342554092407227
[2025-03-17 13:36:10,779][model][INFO] - Training step 40560 loss 0.02868840843439102
[2025-03-17 13:36:52,104][model][INFO] - Training step 40720 loss 0.035480186343193054
[2025-03-17 13:37:31,431][model][INFO] - Training step 40880 loss 0.01249062642455101
[2025-03-17 13:38:10,945][model][INFO] - Training step 41040 loss 0.005243499763309956
[2025-03-17 13:38:50,991][model][INFO] - Training step 41200 loss 0.012061063200235367
[2025-03-17 13:39:32,739][model][INFO] - Training step 41360 loss 0.010449872352182865
[2025-03-17 13:40:13,821][model][INFO] - Training step 41520 loss 0.03262603282928467
[2025-03-17 13:40:54,153][model][INFO] - Training step 41680 loss 0.20776401460170746
[2025-03-17 13:41:34,103][model][INFO] - Training step 41840 loss 0.009879184886813164
[2025-03-17 13:42:14,168][model][INFO] - Training step 42000 loss 0.03430226817727089
[2025-03-17 13:42:55,115][model][INFO] - Training step 42160 loss 0.0369681678712368
[2025-03-17 13:43:34,512][model][INFO] - Training step 42320 loss 0.012010972946882248
[2025-03-17 13:44:16,204][model][INFO] - Training step 42480 loss 0.018322555348277092
[2025-03-17 13:44:57,099][model][INFO] - Training step 42640 loss 0.24266743659973145
[2025-03-17 13:45:38,660][model][INFO] - Training step 42800 loss 0.0467657744884491
[2025-03-17 13:46:20,057][model][INFO] - Training step 42960 loss 0.008441139943897724
[2025-03-17 13:47:00,848][model][INFO] - Training step 43120 loss 0.0015562388580292463
[2025-03-17 13:47:41,027][model][INFO] - Training step 43280 loss 0.037430837750434875
[2025-03-17 13:48:21,850][model][INFO] - Training step 43440 loss 0.049544934183359146
[2025-03-17 13:49:03,586][model][INFO] - Training step 43600 loss 0.01228599064052105
[2025-03-17 13:49:44,806][model][INFO] - Training step 43760 loss 0.05989806354045868
[2025-03-17 13:50:24,971][model][INFO] - Training step 43920 loss 0.2501054108142853
[2025-03-17 13:51:05,256][model][INFO] - Training step 44080 loss 0.026082508265972137
[2025-03-17 13:51:45,133][model][INFO] - Training step 44240 loss 0.025980379432439804
[2025-03-17 13:52:27,016][model][INFO] - Training step 44400 loss 0.04273367300629616
[2025-03-17 13:53:06,535][model][INFO] - Training step 44560 loss 0.13475783169269562
[2025-03-17 13:53:46,566][model][INFO] - Training step 44720 loss 0.019989728927612305
[2025-03-17 13:54:28,424][model][INFO] - Training step 44880 loss 0.005872621666640043
[2025-03-17 13:55:09,066][model][INFO] - Training step 45040 loss 0.271848201751709
[2025-03-17 13:55:50,426][model][INFO] - Training step 45200 loss 0.00948910042643547
[2025-03-17 13:56:32,080][model][INFO] - Training step 45360 loss 0.0202937088906765
[2025-03-17 13:57:12,267][model][INFO] - Training step 45520 loss 0.02417624555528164
[2025-03-17 13:57:53,058][model][INFO] - Training step 45680 loss 0.01017453521490097
[2025-03-17 13:58:33,333][model][INFO] - Training step 45840 loss 0.13490723073482513
[2025-03-17 13:59:12,808][model][INFO] - Training step 46000 loss 0.2635655105113983
[2025-03-17 13:59:53,586][model][INFO] - Training step 46160 loss 0.005066266283392906
[2025-03-17 14:00:34,659][model][INFO] - Training step 46320 loss 0.025090273469686508
[2025-03-17 14:01:15,999][model][INFO] - Training step 46480 loss 0.24807915091514587
[2025-03-17 14:01:54,901][model][INFO] - Training step 46640 loss 0.28134286403656006
[2025-03-17 14:02:35,724][model][INFO] - Training step 46800 loss 0.025024287402629852
[2025-03-17 14:03:16,706][model][INFO] - Training step 46960 loss 0.04034210368990898
[2025-03-17 14:03:55,060][model][INFO] - Training step 47120 loss 0.058566682040691376
[2025-03-17 14:04:36,812][model][INFO] - Training step 47280 loss 0.014956897124648094
[2025-03-17 14:05:16,973][model][INFO] - Training step 47440 loss 0.2305748164653778
[2025-03-17 14:05:55,716][model][INFO] - Training step 47600 loss 0.2548564076423645
[2025-03-17 14:06:36,017][model][INFO] - Training step 47760 loss 0.10397084057331085
[2025-03-17 14:07:16,063][model][INFO] - Training step 47920 loss 0.037930190563201904
[2025-03-17 14:07:56,644][model][INFO] - Training step 48080 loss 0.09913579374551773
[2025-03-17 14:08:36,229][model][INFO] - Training step 48240 loss 0.04397297278046608
[2025-03-17 14:09:17,448][model][INFO] - Training step 48400 loss 0.08156690001487732
[2025-03-17 14:09:56,686][model][INFO] - Training step 48560 loss 0.003958457615226507
[2025-03-17 14:10:37,139][model][INFO] - Training step 48720 loss 0.2430378794670105
[2025-03-17 14:11:17,174][model][INFO] - Training step 48880 loss 0.23548904061317444
[2025-03-17 14:11:54,974][model][INFO] - Training step 49040 loss 0.0316200815141201
[2025-03-17 14:12:35,223][model][INFO] - Training step 49200 loss 0.02148604206740856
[2025-03-17 14:13:16,061][model][INFO] - Training step 49360 loss 0.005399396643042564
[2025-03-17 14:13:55,989][model][INFO] - Training step 49520 loss 0.006091493181884289
[2025-03-17 14:14:36,085][model][INFO] - Training step 49680 loss 0.01165205892175436
[2025-03-17 14:15:16,257][model][INFO] - Training step 49840 loss 0.28019481897354126
[2025-03-17 14:15:56,829][model][INFO] - Training step 50000 loss 0.008160917088389397
[2025-03-17 14:16:36,712][model][INFO] - Training step 50160 loss 0.07985579967498779
[2025-03-17 14:17:17,693][model][INFO] - Training step 50320 loss 0.07302531599998474
[2025-03-17 14:17:57,168][model][INFO] - Training step 50480 loss 0.028796061873435974
[2025-03-17 14:18:37,215][model][INFO] - Training step 50640 loss 0.02181580290198326
[2025-03-17 14:24:13,834][model][INFO] - Training step 0 loss 0.014809437096118927
[2025-03-17 14:24:56,032][model][INFO] - Training step 160 loss 0.003973985090851784
[2025-03-17 14:25:35,606][model][INFO] - Training step 320 loss 0.050889045000076294
[2025-03-17 14:26:16,228][model][INFO] - Training step 480 loss 0.021570492535829544
[2025-03-17 14:26:56,046][model][INFO] - Training step 640 loss 0.1777847409248352
[2025-03-17 14:27:36,936][model][INFO] - Training step 800 loss 0.005318301264196634
[2025-03-17 14:28:17,378][model][INFO] - Training step 960 loss 0.03533041849732399
[2025-03-17 14:28:57,103][model][INFO] - Training step 1120 loss 0.04174903780221939
[2025-03-17 14:29:37,565][model][INFO] - Training step 1280 loss 0.0303802490234375
[2025-03-17 14:30:17,008][model][INFO] - Training step 1440 loss 0.022627554833889008
[2025-03-17 14:30:57,271][model][INFO] - Training step 1600 loss 0.005116589367389679
[2025-03-17 14:31:36,833][model][INFO] - Training step 1760 loss 0.024266177788376808
[2025-03-17 14:32:17,622][model][INFO] - Training step 1920 loss 0.04861007258296013
[2025-03-17 14:32:57,225][model][INFO] - Training step 2080 loss 0.23944894969463348
[2025-03-17 14:33:36,554][model][INFO] - Training step 2240 loss 0.01843402534723282
[2025-03-17 14:34:15,372][model][INFO] - Training step 2400 loss 0.23669996857643127
[2025-03-17 14:34:55,026][model][INFO] - Training step 2560 loss 0.05036493390798569
[2025-03-17 14:35:34,407][model][INFO] - Training step 2720 loss 0.2436743974685669
[2025-03-17 14:36:13,899][model][INFO] - Training step 2880 loss 0.24743618071079254
[2025-03-17 14:36:53,484][model][INFO] - Training step 3040 loss 0.0195660050958395
[2025-03-17 14:37:32,536][model][INFO] - Training step 3200 loss 0.014346234500408173
[2025-03-17 14:38:13,277][model][INFO] - Training step 3360 loss 0.03018926829099655
[2025-03-17 14:38:52,997][model][INFO] - Training step 3520 loss 0.06963557004928589
[2025-03-17 14:39:34,815][model][INFO] - Training step 3680 loss 0.00134191638790071
[2025-03-17 14:40:14,837][model][INFO] - Training step 3840 loss 0.024806421250104904
[2025-03-17 14:40:55,596][model][INFO] - Training step 4000 loss 0.25728166103363037
[2025-03-17 14:41:36,165][model][INFO] - Training step 4160 loss 0.030497202649712563
[2025-03-17 14:42:16,070][model][INFO] - Training step 4320 loss 0.025048809126019478
[2025-03-17 14:42:56,043][model][INFO] - Training step 4480 loss 0.026759956032037735
[2025-03-17 14:43:37,340][model][INFO] - Training step 4640 loss 0.12030147016048431
[2025-03-17 14:44:17,725][model][INFO] - Training step 4800 loss 0.002457633148878813
[2025-03-17 14:44:58,059][model][INFO] - Training step 4960 loss 0.081118643283844
[2025-03-17 14:45:38,330][model][INFO] - Training step 5120 loss 0.6557850241661072
[2025-03-17 14:46:17,973][model][INFO] - Training step 5280 loss 0.010428661480545998
[2025-03-17 14:46:58,795][model][INFO] - Training step 5440 loss 0.03942194581031799
[2025-03-17 14:47:37,307][model][INFO] - Training step 5600 loss 0.01618153229355812
[2025-03-17 14:48:16,394][model][INFO] - Training step 5760 loss 0.024324525147676468
[2025-03-17 14:48:58,763][model][INFO] - Training step 5920 loss 0.0038664157036691904
[2025-03-17 14:49:38,059][model][INFO] - Training step 6080 loss 0.005486188922077417
[2025-03-17 14:50:19,182][model][INFO] - Training step 6240 loss 0.04384859278798103
[2025-03-17 14:50:59,866][model][INFO] - Training step 6400 loss 0.08653340488672256
[2025-03-17 14:51:40,585][model][INFO] - Training step 6560 loss 0.02240046113729477
[2025-03-17 14:52:21,169][model][INFO] - Training step 6720 loss 0.006345098372548819
[2025-03-17 14:53:02,687][model][INFO] - Training step 6880 loss 0.12031854689121246
[2025-03-17 14:53:42,380][model][INFO] - Training step 7040 loss 0.08134021610021591
[2025-03-17 14:54:21,218][model][INFO] - Training step 7200 loss 0.013614227995276451
[2025-03-17 14:55:00,426][model][INFO] - Training step 7360 loss 0.2531396150588989
[2025-03-17 14:55:40,758][model][INFO] - Training step 7520 loss 0.04388277977705002
[2025-03-17 14:56:21,237][model][INFO] - Training step 7680 loss 0.05078352242708206
[2025-03-17 14:57:01,301][model][INFO] - Training step 7840 loss 0.24996614456176758
[2025-03-17 14:57:40,801][model][INFO] - Training step 8000 loss 0.007069506216794252
[2025-03-17 14:58:20,037][model][INFO] - Training step 8160 loss 0.014814293012022972
[2025-03-17 14:58:58,305][model][INFO] - Training step 8320 loss 0.03822806477546692
[2025-03-17 14:59:37,100][model][INFO] - Training step 8480 loss 0.10040339827537537
[2025-03-17 15:00:18,641][model][INFO] - Training step 8640 loss 0.025194328278303146
[2025-03-17 15:01:00,070][model][INFO] - Training step 8800 loss 0.03573880344629288
[2025-03-17 15:01:40,950][model][INFO] - Training step 8960 loss 0.029859211295843124
[2025-03-17 15:02:20,596][model][INFO] - Training step 9120 loss 0.04473312944173813
[2025-03-17 15:03:01,012][model][INFO] - Training step 9280 loss 0.030110884457826614
[2025-03-17 15:03:41,702][model][INFO] - Training step 9440 loss 0.02117200382053852
[2025-03-17 15:04:21,459][model][INFO] - Training step 9600 loss 0.037439025938510895
[2025-03-17 15:05:01,590][model][INFO] - Training step 9760 loss 0.017025593668222427
[2025-03-17 15:05:41,335][model][INFO] - Training step 9920 loss 0.24355489015579224
[2025-03-17 15:06:21,569][model][INFO] - Training step 10080 loss 0.018984094262123108
[2025-03-17 15:07:01,354][model][INFO] - Training step 10240 loss 0.023317404091358185
[2025-03-17 15:07:42,380][model][INFO] - Training step 10400 loss 0.2592608332633972
[2025-03-17 15:08:23,569][model][INFO] - Training step 10560 loss 0.005030784755945206
[2025-03-17 15:09:03,895][model][INFO] - Training step 10720 loss 0.02894875779747963
[2025-03-17 15:09:44,717][model][INFO] - Training step 10880 loss 0.03212028741836548
[2025-03-17 15:10:23,885][model][INFO] - Training step 11040 loss 0.028444839641451836
[2025-03-17 15:11:02,465][model][INFO] - Training step 11200 loss 0.24765121936798096
[2025-03-17 15:11:42,952][model][INFO] - Training step 11360 loss 0.24456915259361267
[2025-03-17 15:12:22,079][model][INFO] - Training step 11520 loss 0.028086762875318527
[2025-03-17 15:13:01,288][model][INFO] - Training step 11680 loss 0.07648590207099915
[2025-03-17 15:13:40,559][model][INFO] - Training step 11840 loss 0.023968487977981567
[2025-03-17 15:14:20,740][model][INFO] - Training step 12000 loss 0.055850427597761154
[2025-03-17 15:15:01,802][model][INFO] - Training step 12160 loss 0.05372759699821472
[2025-03-17 15:15:40,587][model][INFO] - Training step 12320 loss 0.029705949127674103
[2025-03-17 15:16:21,162][model][INFO] - Training step 12480 loss 0.06554854661226273
[2025-03-17 15:17:00,833][model][INFO] - Training step 12640 loss 0.2428988516330719
[2025-03-17 15:17:40,534][model][INFO] - Training step 12800 loss 0.023479465395212173
[2025-03-17 15:18:21,674][model][INFO] - Training step 12960 loss 0.02746519446372986
[2025-03-17 15:19:02,198][model][INFO] - Training step 13120 loss 0.060389451682567596
[2025-03-17 15:19:42,724][model][INFO] - Training step 13280 loss 0.00978005863726139
[2025-03-17 15:20:22,998][model][INFO] - Training step 13440 loss 0.033039771020412445
[2025-03-17 15:21:03,074][model][INFO] - Training step 13600 loss 0.018263202160596848
[2025-03-17 15:21:43,266][model][INFO] - Training step 13760 loss 0.029614601284265518
[2025-03-17 15:22:23,054][model][INFO] - Training step 13920 loss 0.1350981742143631
[2025-03-17 15:23:03,512][model][INFO] - Training step 14080 loss 0.0030917373951524496
[2025-03-17 15:23:43,420][model][INFO] - Training step 14240 loss 0.042032867670059204
[2025-03-17 15:24:23,070][model][INFO] - Training step 14400 loss 0.006829556077718735
[2025-03-17 15:25:03,187][model][INFO] - Training step 14560 loss 0.07814813405275345
[2025-03-17 15:25:42,910][model][INFO] - Training step 14720 loss 0.006282293237745762
[2025-03-17 15:26:21,787][model][INFO] - Training step 14880 loss 0.028743697330355644
[2025-03-17 15:27:01,753][model][INFO] - Training step 15040 loss 0.051465053111314774
[2025-03-17 15:27:41,397][model][INFO] - Training step 15200 loss 0.02507447823882103
[2025-03-17 15:28:20,651][model][INFO] - Training step 15360 loss 0.06617480516433716
[2025-03-17 15:29:00,691][model][INFO] - Training step 15520 loss 0.06277967989444733
[2025-03-17 15:29:40,663][model][INFO] - Training step 15680 loss 0.01995520293712616
[2025-03-17 15:30:21,040][model][INFO] - Training step 15840 loss 0.07135862112045288
[2025-03-17 15:31:00,563][model][INFO] - Training step 16000 loss 0.25942105054855347
[2025-03-17 15:31:40,880][model][INFO] - Training step 16160 loss 0.005405499134212732
[2025-03-17 15:32:22,319][model][INFO] - Training step 16320 loss 0.03708602488040924
[2025-03-17 15:33:02,259][model][INFO] - Training step 16480 loss 0.014583384618163109
[2025-03-17 15:33:41,281][model][INFO] - Training step 16640 loss 0.03810041397809982
[2025-03-17 15:34:22,608][model][INFO] - Training step 16800 loss 0.27237626910209656
[2025-03-17 15:35:02,832][model][INFO] - Training step 16960 loss 0.026926575228571892
[2025-03-17 15:35:43,387][model][INFO] - Training step 17120 loss 0.025511346757411957
[2025-03-17 15:36:24,586][model][INFO] - Training step 17280 loss 0.0031227825675159693
[2025-03-17 15:37:06,001][model][INFO] - Training step 17440 loss 0.021174322813749313
[2025-03-17 15:37:46,095][model][INFO] - Training step 17600 loss 0.024357082322239876
[2025-03-17 15:38:26,052][model][INFO] - Training step 17760 loss 0.05498924106359482
[2025-03-17 15:39:05,973][model][INFO] - Training step 17920 loss 0.056254178285598755
[2025-03-17 15:39:48,055][model][INFO] - Training step 18080 loss 0.022566981613636017
[2025-03-17 15:40:31,437][model][INFO] - Training step 18240 loss 0.02861757017672062
[2025-03-17 15:41:11,860][model][INFO] - Training step 18400 loss 0.03085261583328247
[2025-03-17 15:41:51,271][model][INFO] - Training step 18560 loss 0.2857113182544708
[2025-03-17 15:42:32,518][model][INFO] - Training step 18720 loss 0.024811647832393646
[2025-03-17 15:43:12,573][model][INFO] - Training step 18880 loss 0.016326241195201874
[2025-03-17 15:43:50,362][model][INFO] - Training step 19040 loss 0.02753143385052681
[2025-03-17 15:44:31,505][model][INFO] - Training step 19200 loss 0.02586488425731659
[2025-03-17 15:45:11,044][model][INFO] - Training step 19360 loss 0.003746600355952978
[2025-03-17 15:45:50,891][model][INFO] - Training step 19520 loss 0.03059902787208557
[2025-03-17 15:46:33,784][model][INFO] - Training step 19680 loss 0.003959469497203827
[2025-03-17 15:47:13,182][model][INFO] - Training step 19840 loss 0.2623208463191986
[2025-03-17 15:47:53,566][model][INFO] - Training step 20000 loss 0.05024518072605133
[2025-03-17 15:48:34,560][model][INFO] - Training step 20160 loss 0.0034448630176484585
[2025-03-17 15:49:14,837][model][INFO] - Training step 20320 loss 0.02694181352853775
[2025-03-17 15:49:54,500][model][INFO] - Training step 20480 loss 0.042219433933496475
[2025-03-17 15:50:35,681][model][INFO] - Training step 20640 loss 0.0054380702786147594
[2025-03-17 15:51:16,691][model][INFO] - Training step 20800 loss 0.2213762253522873
[2025-03-17 15:51:56,983][model][INFO] - Training step 20960 loss 0.01757991686463356
[2025-03-17 15:52:39,264][model][INFO] - Training step 21120 loss 0.05195590853691101
[2025-03-17 15:53:19,527][model][INFO] - Training step 21280 loss 0.016056226566433907
[2025-03-17 15:53:58,326][model][INFO] - Training step 21440 loss 0.019582349807024002
[2025-03-17 15:54:38,949][model][INFO] - Training step 21600 loss 0.06567490845918655
[2025-03-17 15:55:18,683][model][INFO] - Training step 21760 loss 0.035350948572158813
[2025-03-17 15:55:58,622][model][INFO] - Training step 21920 loss 0.024766892194747925
[2025-03-17 15:56:39,232][model][INFO] - Training step 22080 loss 0.006940098945051432
[2025-03-17 15:57:19,968][model][INFO] - Training step 22240 loss 0.24593354761600494
[2025-03-17 15:57:59,367][model][INFO] - Training step 22400 loss 0.09695683419704437
[2025-03-17 15:58:39,719][model][INFO] - Training step 22560 loss 0.023416319862008095
[2025-03-17 15:59:20,196][model][INFO] - Training step 22720 loss 0.26037296652793884
[2025-03-17 15:59:58,686][model][INFO] - Training step 22880 loss 0.011806005612015724
[2025-03-17 16:00:37,402][model][INFO] - Training step 23040 loss 0.2575053572654724
[2025-03-17 16:01:18,191][model][INFO] - Training step 23200 loss 0.039191920310258865
[2025-03-17 16:01:58,646][model][INFO] - Training step 23360 loss 0.2630290389060974
[2025-03-17 16:02:39,126][model][INFO] - Training step 23520 loss 0.019539613276720047
[2025-03-17 16:03:19,829][model][INFO] - Training step 23680 loss 0.020029354840517044
[2025-03-17 16:04:00,030][model][INFO] - Training step 23840 loss 0.02335251122713089
[2025-03-17 16:04:40,440][model][INFO] - Training step 24000 loss 0.00657037366181612
[2025-03-17 16:05:19,634][model][INFO] - Training step 24160 loss 0.025782253593206406
[2025-03-17 16:06:00,851][model][INFO] - Training step 24320 loss 0.022823181003332138
[2025-03-17 16:06:39,765][model][INFO] - Training step 24480 loss 0.23476463556289673
[2025-03-17 16:07:18,885][model][INFO] - Training step 24640 loss 0.04089783877134323
[2025-03-17 16:07:58,376][model][INFO] - Training step 24800 loss 0.2618865370750427
[2025-03-17 16:08:39,634][model][INFO] - Training step 24960 loss 0.043943002820014954
[2025-03-17 16:09:20,252][model][INFO] - Training step 25120 loss 0.2513687014579773
[2025-03-17 16:09:58,316][model][INFO] - Training step 25280 loss 0.01720144785940647
[2025-03-17 16:10:37,879][model][INFO] - Training step 25440 loss 0.0036553642712533474
[2025-03-17 16:11:17,642][model][INFO] - Training step 25600 loss 0.24092355370521545
[2025-03-17 16:11:56,874][model][INFO] - Training step 25760 loss 0.03134598955512047
[2025-03-17 16:12:36,662][model][INFO] - Training step 25920 loss 0.18753662705421448
[2025-03-17 16:13:17,347][model][INFO] - Training step 26080 loss 0.007997154258191586
[2025-03-17 16:13:57,488][model][INFO] - Training step 26240 loss 0.02543700486421585
[2025-03-17 16:14:38,159][model][INFO] - Training step 26400 loss 0.2543364465236664
[2025-03-17 16:15:19,662][model][INFO] - Training step 26560 loss 0.01995312049984932
[2025-03-17 16:15:59,575][model][INFO] - Training step 26720 loss 0.030878674238920212
[2025-03-17 16:16:41,001][model][INFO] - Training step 26880 loss 0.005940606817603111
[2025-03-17 16:17:21,088][model][INFO] - Training step 27040 loss 0.007975044660270214
[2025-03-17 16:18:02,108][model][INFO] - Training step 27200 loss 0.03948498144745827
[2025-03-17 16:18:41,410][model][INFO] - Training step 27360 loss 0.26588213443756104
[2025-03-17 16:19:21,838][model][INFO] - Training step 27520 loss 0.27017736434936523
[2025-03-17 16:20:01,814][model][INFO] - Training step 27680 loss 0.25305142998695374
[2025-03-17 16:20:40,646][model][INFO] - Training step 27840 loss 0.028663523495197296
[2025-03-17 16:21:19,099][model][INFO] - Training step 28000 loss 0.01750935986638069
[2025-03-17 16:22:00,084][model][INFO] - Training step 28160 loss 0.01683012768626213
[2025-03-17 16:22:40,554][model][INFO] - Training step 28320 loss 0.08966326713562012
[2025-03-17 16:23:21,410][model][INFO] - Training step 28480 loss 0.0739363431930542
[2025-03-17 16:24:02,251][model][INFO] - Training step 28640 loss 0.10260038077831268
[2025-03-17 16:24:42,486][model][INFO] - Training step 28800 loss 0.03562045842409134
[2025-03-17 16:25:21,810][model][INFO] - Training step 28960 loss 0.1602475941181183
[2025-03-17 16:26:01,671][model][INFO] - Training step 29120 loss 0.03240927308797836
[2025-03-17 16:26:42,651][model][INFO] - Training step 29280 loss 0.019640326499938965
[2025-03-17 16:27:21,754][model][INFO] - Training step 29440 loss 0.017811335623264313
[2025-03-17 16:28:00,720][model][INFO] - Training step 29600 loss 0.28512004017829895
[2025-03-17 16:28:41,463][model][INFO] - Training step 29760 loss 0.03379721939563751
[2025-03-17 16:29:20,974][model][INFO] - Training step 29920 loss 0.024733735248446465
[2025-03-17 16:30:00,097][model][INFO] - Training step 30080 loss 0.0021517761051654816
[2025-03-17 16:30:39,811][model][INFO] - Training step 30240 loss 0.004661759827286005
[2025-03-17 16:31:19,818][model][INFO] - Training step 30400 loss 0.0344683974981308
[2025-03-17 16:32:00,687][model][INFO] - Training step 30560 loss 0.03304542601108551
[2025-03-17 16:32:40,192][model][INFO] - Training step 30720 loss 0.008999461308121681
[2025-03-17 16:33:19,923][model][INFO] - Training step 30880 loss 0.2555088996887207
[2025-03-17 16:34:00,309][model][INFO] - Training step 31040 loss 0.0433289110660553
[2025-03-17 16:34:39,356][model][INFO] - Training step 31200 loss 0.06235833838582039
[2025-03-17 16:35:18,309][model][INFO] - Training step 31360 loss 0.2462296038866043
[2025-03-17 16:35:58,354][model][INFO] - Training step 31520 loss 0.05391829088330269
[2025-03-17 16:36:39,481][model][INFO] - Training step 31680 loss 0.2547135055065155
[2025-03-17 16:37:19,026][model][INFO] - Training step 31840 loss 0.009465975686907768
[2025-03-17 16:38:00,392][model][INFO] - Training step 32000 loss 0.2480514645576477
[2025-03-17 16:38:40,883][model][INFO] - Training step 32160 loss 0.28311386704444885
[2025-03-17 16:39:22,288][model][INFO] - Training step 32320 loss 0.021146230399608612
[2025-03-17 16:40:03,451][model][INFO] - Training step 32480 loss 0.031460952013731
[2025-03-17 16:40:43,882][model][INFO] - Training step 32640 loss 0.029240302741527557
[2025-03-17 16:41:24,082][model][INFO] - Training step 32800 loss 0.02284727245569229
[2025-03-17 16:42:04,122][model][INFO] - Training step 32960 loss 0.06893616914749146
[2025-03-17 16:42:43,542][model][INFO] - Training step 33120 loss 0.027607552707195282
[2025-03-17 16:43:25,105][model][INFO] - Training step 33280 loss 0.07159401476383209
[2025-03-17 16:44:05,330][model][INFO] - Training step 33440 loss 0.030833885073661804
[2025-03-17 16:44:45,390][model][INFO] - Training step 33600 loss 0.2624039649963379
[2025-03-17 16:45:25,914][model][INFO] - Training step 33760 loss 0.03666938841342926
[2025-03-17 16:46:05,825][model][INFO] - Training step 33920 loss 0.018892284482717514
[2025-03-17 16:46:45,453][model][INFO] - Training step 34080 loss 0.02940230816602707
[2025-03-17 16:47:24,642][model][INFO] - Training step 34240 loss 0.02579972892999649
[2025-03-17 16:48:04,924][model][INFO] - Training step 34400 loss 0.0701351910829544
[2025-03-17 16:48:45,005][model][INFO] - Training step 34560 loss 0.2188359797000885
[2025-03-17 16:49:27,067][model][INFO] - Training step 34720 loss 0.02135782316327095
[2025-03-17 16:50:08,179][model][INFO] - Training step 34880 loss 0.05451766401529312
[2025-03-17 16:50:50,185][model][INFO] - Training step 35040 loss 0.0027720797806978226
[2025-03-17 16:51:29,593][model][INFO] - Training step 35200 loss 0.01505856029689312
[2025-03-17 16:52:08,976][model][INFO] - Training step 35360 loss 0.005312736611813307
[2025-03-17 16:52:48,171][model][INFO] - Training step 35520 loss 0.025878360494971275
[2025-03-17 16:53:27,803][model][INFO] - Training step 35680 loss 0.04245225340127945
[2025-03-17 16:54:08,080][model][INFO] - Training step 35840 loss 0.05675388127565384
[2025-03-17 16:54:47,999][model][INFO] - Training step 36000 loss 0.201008141040802
[2025-03-17 16:55:27,755][model][INFO] - Training step 36160 loss 0.29973968863487244
[2025-03-17 16:56:07,867][model][INFO] - Training step 36320 loss 0.011828426271677017
[2025-03-17 16:56:48,724][model][INFO] - Training step 36480 loss 0.24937009811401367
[2025-03-17 16:57:30,486][model][INFO] - Training step 36640 loss 0.02405041642487049
[2025-03-17 16:58:08,943][model][INFO] - Training step 36800 loss 0.022680940106511116
[2025-03-17 16:58:48,939][model][INFO] - Training step 36960 loss 0.2333807349205017
[2025-03-17 16:59:29,184][model][INFO] - Training step 37120 loss 0.03954169154167175
[2025-03-17 17:00:10,275][model][INFO] - Training step 37280 loss 0.1757344901561737
[2025-03-17 17:00:50,260][model][INFO] - Training step 37440 loss 0.05512847751379013
[2025-03-17 17:01:31,582][model][INFO] - Training step 37600 loss 0.018857216462492943
[2025-03-17 17:02:11,459][model][INFO] - Training step 37760 loss 0.26895755529403687
[2025-03-17 17:02:51,106][model][INFO] - Training step 37920 loss 0.012556146830320358
[2025-03-17 17:03:31,446][model][INFO] - Training step 38080 loss 0.023076556622982025
[2025-03-17 17:04:11,048][model][INFO] - Training step 38240 loss 0.01747787371277809
[2025-03-17 17:04:51,603][model][INFO] - Training step 38400 loss 0.0038654182571917772
[2025-03-17 17:05:30,402][model][INFO] - Training step 38560 loss 0.020662318915128708
[2025-03-17 17:06:10,452][model][INFO] - Training step 38720 loss 0.024038180708885193
[2025-03-17 17:06:50,994][model][INFO] - Training step 38880 loss 0.025029711425304413
[2025-03-17 17:07:30,261][model][INFO] - Training step 39040 loss 0.017569340765476227
[2025-03-17 17:08:10,620][model][INFO] - Training step 39200 loss 0.2461281418800354
[2025-03-17 17:08:51,693][model][INFO] - Training step 39360 loss 0.07393889129161835
[2025-03-17 17:09:31,797][model][INFO] - Training step 39520 loss 0.008719021454453468
[2025-03-17 17:10:10,842][model][INFO] - Training step 39680 loss 0.012993695214390755
[2025-03-17 17:10:50,489][model][INFO] - Training step 39840 loss 0.02464989945292473
[2025-03-17 17:11:30,675][model][INFO] - Training step 40000 loss 0.026824960485100746
[2025-03-17 17:12:14,247][model][INFO] - Training step 40160 loss 0.05080912634730339
[2025-03-17 17:12:54,479][model][INFO] - Training step 40320 loss 0.039088331162929535
[2025-03-17 17:13:34,829][model][INFO] - Training step 40480 loss 0.04924068599939346
[2025-03-17 17:14:16,005][model][INFO] - Training step 40640 loss 0.039867859333753586
[2025-03-17 17:14:54,987][model][INFO] - Training step 40800 loss 0.010864151641726494
[2025-03-17 17:15:34,802][model][INFO] - Training step 40960 loss 0.03999962657690048
[2025-03-17 17:16:14,843][model][INFO] - Training step 41120 loss 0.009212581440806389
[2025-03-17 17:16:56,309][model][INFO] - Training step 41280 loss 0.02364450879395008
[2025-03-17 17:17:36,411][model][INFO] - Training step 41440 loss 0.035806700587272644
[2025-03-17 17:18:17,457][model][INFO] - Training step 41600 loss 0.02501433901488781
[2025-03-17 17:18:57,790][model][INFO] - Training step 41760 loss 0.2574813663959503
[2025-03-17 17:19:38,272][model][INFO] - Training step 41920 loss 0.25588566064834595
[2025-03-17 17:20:19,381][model][INFO] - Training step 42080 loss 0.010385092347860336
[2025-03-17 17:20:59,024][model][INFO] - Training step 42240 loss 0.04520431160926819
[2025-03-17 17:21:37,803][model][INFO] - Training step 42400 loss 0.25260961055755615
[2025-03-17 17:22:17,774][model][INFO] - Training step 42560 loss 0.24743089079856873
[2025-03-17 17:22:58,388][model][INFO] - Training step 42720 loss 0.05861987546086311
[2025-03-17 17:23:39,074][model][INFO] - Training step 42880 loss 0.2639346718788147
[2025-03-17 17:24:18,697][model][INFO] - Training step 43040 loss 0.015850145369768143
[2025-03-17 17:24:58,165][model][INFO] - Training step 43200 loss 0.05329374596476555
[2025-03-17 17:25:37,869][model][INFO] - Training step 43360 loss 0.03370236977934837
[2025-03-17 17:26:18,170][model][INFO] - Training step 43520 loss 0.0023211869411170483
[2025-03-17 17:27:00,813][model][INFO] - Training step 43680 loss 0.24739116430282593
[2025-03-17 17:27:40,618][model][INFO] - Training step 43840 loss 0.26399943232536316
[2025-03-17 17:28:21,053][model][INFO] - Training step 44000 loss 0.02969398722052574
[2025-03-17 17:29:01,920][model][INFO] - Training step 44160 loss 0.26466792821884155
[2025-03-17 17:29:42,347][model][INFO] - Training step 44320 loss 0.004390586167573929
[2025-03-17 17:30:23,658][model][INFO] - Training step 44480 loss 0.25219833850860596
[2025-03-17 17:31:02,409][model][INFO] - Training step 44640 loss 0.01696292869746685
[2025-03-17 17:31:42,260][model][INFO] - Training step 44800 loss 0.01770951971411705
[2025-03-17 17:32:22,294][model][INFO] - Training step 44960 loss 0.023118965327739716
[2025-03-17 17:33:01,557][model][INFO] - Training step 45120 loss 0.029136311262845993
[2025-03-17 17:33:42,328][model][INFO] - Training step 45280 loss 0.0022290607448667288
[2025-03-17 17:34:22,548][model][INFO] - Training step 45440 loss 0.2515464723110199
[2025-03-17 17:35:01,480][model][INFO] - Training step 45600 loss 0.055836036801338196
[2025-03-17 17:35:42,958][model][INFO] - Training step 45760 loss 0.256600946187973
[2025-03-17 17:36:22,726][model][INFO] - Training step 45920 loss 0.008043704554438591
[2025-03-17 17:37:03,315][model][INFO] - Training step 46080 loss 0.01992759481072426
[2025-03-17 17:37:43,795][model][INFO] - Training step 46240 loss 0.042152032256126404
[2025-03-17 17:38:25,755][model][INFO] - Training step 46400 loss 0.008297504857182503
[2025-03-17 17:39:05,485][model][INFO] - Training step 46560 loss 0.03717975318431854
[2025-03-17 17:39:46,866][model][INFO] - Training step 46720 loss 0.021769583225250244
[2025-03-17 17:40:27,257][model][INFO] - Training step 46880 loss 0.03951366990804672
[2025-03-17 17:41:05,668][model][INFO] - Training step 47040 loss 0.03499484807252884
[2025-03-17 17:41:46,463][model][INFO] - Training step 47200 loss 0.012278994545340538
[2025-03-17 17:42:26,300][model][INFO] - Training step 47360 loss 0.17376631498336792
[2025-03-17 17:43:05,978][model][INFO] - Training step 47520 loss 0.006749583873897791
[2025-03-17 17:43:47,098][model][INFO] - Training step 47680 loss 0.2744382619857788
[2025-03-17 17:44:26,437][model][INFO] - Training step 47840 loss 0.01905617117881775
[2025-03-17 17:45:05,996][model][INFO] - Training step 48000 loss 0.04174394905567169
[2025-03-17 17:45:47,000][model][INFO] - Training step 48160 loss 0.10926090180873871
[2025-03-17 17:46:25,269][model][INFO] - Training step 48320 loss 0.028649479150772095
[2025-03-17 17:47:05,949][model][INFO] - Training step 48480 loss 0.01766200363636017
[2025-03-17 17:47:46,247][model][INFO] - Training step 48640 loss 0.031785886734724045
[2025-03-17 17:48:25,513][model][INFO] - Training step 48800 loss 0.07542149722576141
[2025-03-17 17:49:04,835][model][INFO] - Training step 48960 loss 0.015767378732562065
[2025-03-17 17:49:45,023][model][INFO] - Training step 49120 loss 0.01630103401839733
[2025-03-17 17:50:24,721][model][INFO] - Training step 49280 loss 0.01734018325805664
[2025-03-17 17:51:05,891][model][INFO] - Training step 49440 loss 0.25617867708206177
[2025-03-17 17:51:46,810][model][INFO] - Training step 49600 loss 0.024165533483028412
[2025-03-17 17:52:27,321][model][INFO] - Training step 49760 loss 0.038089342415332794
[2025-03-17 17:53:08,668][model][INFO] - Training step 49920 loss 0.012555129826068878
[2025-03-17 17:53:48,167][model][INFO] - Training step 50080 loss 0.015635086223483086
[2025-03-17 17:54:29,187][model][INFO] - Training step 50240 loss 0.008749989792704582
[2025-03-17 17:55:08,317][model][INFO] - Training step 50400 loss 0.01933078095316887
[2025-03-17 17:55:47,371][model][INFO] - Training step 50560 loss 0.01270105130970478
[2025-03-17 17:56:26,615][model][INFO] - Training step 50720 loss 0.01968466304242611
[2025-03-17 18:02:05,044][model][INFO] - Training step 80 loss 0.055649980902671814
[2025-03-17 18:02:45,152][model][INFO] - Training step 240 loss 0.10535770654678345
[2025-03-17 18:03:24,903][model][INFO] - Training step 400 loss 0.034292612224817276
[2025-03-17 18:04:04,950][model][INFO] - Training step 560 loss 0.24845543503761292
[2025-03-17 18:04:45,550][model][INFO] - Training step 720 loss 0.058468032628297806
[2025-03-17 18:05:26,027][model][INFO] - Training step 880 loss 0.02267793007194996
[2025-03-17 18:06:05,156][model][INFO] - Training step 1040 loss 0.008473791182041168
[2025-03-17 18:06:45,547][model][INFO] - Training step 1200 loss 0.030951056629419327
[2025-03-17 18:07:26,174][model][INFO] - Training step 1360 loss 0.02172381430864334
[2025-03-17 18:08:06,638][model][INFO] - Training step 1520 loss 0.029737969860434532
[2025-03-17 18:08:46,996][model][INFO] - Training step 1680 loss 0.016832198947668076
[2025-03-17 18:09:27,272][model][INFO] - Training step 1840 loss 0.03579564392566681
[2025-03-17 18:10:08,344][model][INFO] - Training step 2000 loss 0.03278644382953644
[2025-03-17 18:10:47,556][model][INFO] - Training step 2160 loss 0.019183102995157242
[2025-03-17 18:11:27,276][model][INFO] - Training step 2320 loss 0.023802269250154495
[2025-03-17 18:12:07,809][model][INFO] - Training step 2480 loss 0.013499511405825615
[2025-03-17 18:12:46,682][model][INFO] - Training step 2640 loss 0.03363568335771561
[2025-03-17 18:13:27,360][model][INFO] - Training step 2800 loss 0.0629473552107811
[2025-03-17 18:14:08,625][model][INFO] - Training step 2960 loss 0.013721603900194168
[2025-03-17 18:14:48,398][model][INFO] - Training step 3120 loss 0.05810807645320892
[2025-03-17 18:15:28,935][model][INFO] - Training step 3280 loss 0.03004493936896324
[2025-03-17 18:16:09,107][model][INFO] - Training step 3440 loss 0.027233414351940155
[2025-03-17 18:16:48,014][model][INFO] - Training step 3600 loss 0.003892215434461832
[2025-03-17 18:17:26,568][model][INFO] - Training step 3760 loss 0.027081720530986786
[2025-03-17 18:18:07,815][model][INFO] - Training step 3920 loss 0.26174086332321167
[2025-03-17 18:18:48,887][model][INFO] - Training step 4080 loss 0.25617796182632446
[2025-03-17 18:19:27,991][model][INFO] - Training step 4240 loss 0.24834607541561127
[2025-03-17 18:20:07,894][model][INFO] - Training step 4400 loss 0.011336775496602058
[2025-03-17 18:20:48,535][model][INFO] - Training step 4560 loss 0.019885335117578506
[2025-03-17 18:21:31,275][model][INFO] - Training step 4720 loss 0.07423467189073563
[2025-03-17 18:22:09,841][model][INFO] - Training step 4880 loss 0.01948002725839615
[2025-03-17 18:22:49,978][model][INFO] - Training step 5040 loss 0.13378354907035828
[2025-03-17 18:23:29,109][model][INFO] - Training step 5200 loss 0.17771510779857635
[2025-03-17 18:24:09,120][model][INFO] - Training step 5360 loss 0.03709453344345093
[2025-03-17 18:24:49,286][model][INFO] - Training step 5520 loss 0.057927973568439484
[2025-03-17 18:25:29,800][model][INFO] - Training step 5680 loss 0.016426555812358856
[2025-03-17 18:26:09,867][model][INFO] - Training step 5840 loss 0.01996855065226555
[2025-03-17 18:26:51,664][model][INFO] - Training step 6000 loss 0.024722494184970856
[2025-03-17 18:27:30,947][model][INFO] - Training step 6160 loss 0.01803530752658844
[2025-03-17 18:28:13,076][model][INFO] - Training step 6320 loss 0.03619635850191116
[2025-03-17 18:28:53,804][model][INFO] - Training step 6480 loss 0.05309585854411125
[2025-03-17 18:29:33,680][model][INFO] - Training step 6640 loss 0.006212363950908184
[2025-03-17 18:30:14,566][model][INFO] - Training step 6800 loss 0.25020432472229004
[2025-03-17 18:30:53,399][model][INFO] - Training step 6960 loss 0.04334717243909836
[2025-03-17 18:31:34,193][model][INFO] - Training step 7120 loss 0.02974843978881836
[2025-03-17 18:32:13,891][model][INFO] - Training step 7280 loss 0.013257009908556938
[2025-03-17 18:32:53,812][model][INFO] - Training step 7440 loss 0.033683113753795624
[2025-03-17 18:33:34,501][model][INFO] - Training step 7600 loss 0.044525254517793655
[2025-03-17 18:34:14,466][model][INFO] - Training step 7760 loss 0.02428499609231949
[2025-03-17 18:34:55,645][model][INFO] - Training step 7920 loss 0.24305176734924316
[2025-03-17 18:35:36,547][model][INFO] - Training step 8080 loss 0.005805235356092453
[2025-03-17 18:36:15,707][model][INFO] - Training step 8240 loss 0.017162863165140152
[2025-03-17 18:36:54,346][model][INFO] - Training step 8400 loss 0.02905106544494629
[2025-03-17 18:37:32,958][model][INFO] - Training step 8560 loss 0.018772128969430923
[2025-03-17 18:38:13,709][model][INFO] - Training step 8720 loss 0.019317667931318283
[2025-03-17 18:38:52,726][model][INFO] - Training step 8880 loss 0.021301928907632828
[2025-03-17 18:39:34,515][model][INFO] - Training step 9040 loss 0.01059064269065857
[2025-03-17 18:40:14,013][model][INFO] - Training step 9200 loss 0.003982793539762497
[2025-03-17 18:40:54,711][model][INFO] - Training step 9360 loss 0.04400032013654709
[2025-03-17 18:41:34,575][model][INFO] - Training step 9520 loss 0.26192986965179443
[2025-03-17 18:42:13,494][model][INFO] - Training step 9680 loss 0.0701383426785469
[2025-03-17 18:42:54,409][model][INFO] - Training step 9840 loss 0.24718475341796875
[2025-03-17 18:43:34,642][model][INFO] - Training step 10000 loss 0.03847411274909973
[2025-03-17 18:44:15,631][model][INFO] - Training step 10160 loss 0.025877486914396286
[2025-03-17 18:44:55,483][model][INFO] - Training step 10320 loss 0.018102426081895828
[2025-03-17 18:45:36,169][model][INFO] - Training step 10480 loss 0.05383303388953209
[2025-03-17 18:46:15,965][model][INFO] - Training step 10640 loss 0.025530967861413956
[2025-03-17 18:46:55,201][model][INFO] - Training step 10800 loss 0.04157228022813797
[2025-03-17 18:47:36,052][model][INFO] - Training step 10960 loss 0.25659188628196716
[2025-03-17 18:48:16,493][model][INFO] - Training step 11120 loss 0.018481183797121048
[2025-03-17 18:48:56,632][model][INFO] - Training step 11280 loss 0.02262086421251297
[2025-03-17 18:49:37,906][model][INFO] - Training step 11440 loss 0.2730877995491028
[2025-03-17 18:50:19,456][model][INFO] - Training step 11600 loss 0.03290657326579094
[2025-03-17 18:50:58,980][model][INFO] - Training step 11760 loss 0.04589862376451492
[2025-03-17 18:51:38,189][model][INFO] - Training step 11920 loss 0.06426727026700974
[2025-03-17 18:52:19,210][model][INFO] - Training step 12080 loss 0.03151601552963257
[2025-03-17 18:52:59,580][model][INFO] - Training step 12240 loss 0.04040418565273285
[2025-03-17 18:53:39,093][model][INFO] - Training step 12400 loss 0.018006689846515656
[2025-03-17 18:54:19,561][model][INFO] - Training step 12560 loss 0.0596991628408432
[2025-03-17 18:54:59,550][model][INFO] - Training step 12720 loss 0.02956574410200119
[2025-03-17 18:55:40,404][model][INFO] - Training step 12880 loss 0.017680294811725616
[2025-03-17 18:56:19,472][model][INFO] - Training step 13040 loss 0.04002763330936432
[2025-03-17 18:57:01,579][model][INFO] - Training step 13200 loss 0.031684521585702896
[2025-03-17 18:57:41,492][model][INFO] - Training step 13360 loss 0.08395064622163773
[2025-03-17 18:58:21,202][model][INFO] - Training step 13520 loss 0.25997158885002136
[2025-03-17 18:59:02,228][model][INFO] - Training step 13680 loss 0.01322892028838396
[2025-03-17 18:59:43,665][model][INFO] - Training step 13840 loss 0.014315875247120857
[2025-03-17 19:00:23,804][model][INFO] - Training step 14000 loss 0.01860634982585907
[2025-03-17 19:01:03,760][model][INFO] - Training step 14160 loss 0.018081046640872955
[2025-03-17 19:01:44,231][model][INFO] - Training step 14320 loss 0.033028729259967804
[2025-03-17 19:02:25,042][model][INFO] - Training step 14480 loss 0.0185561440885067
[2025-03-17 19:03:05,603][model][INFO] - Training step 14640 loss 0.2512775659561157
[2025-03-17 19:03:45,655][model][INFO] - Training step 14800 loss 0.003563652280718088
[2025-03-17 19:04:25,726][model][INFO] - Training step 14960 loss 0.01690599136054516
[2025-03-17 19:05:07,225][model][INFO] - Training step 15120 loss 0.017197713255882263
[2025-03-17 19:05:46,830][model][INFO] - Training step 15280 loss 0.02141932025551796
[2025-03-17 19:06:26,520][model][INFO] - Training step 15440 loss 0.023548904806375504
[2025-03-17 19:07:07,858][model][INFO] - Training step 15600 loss 0.046290040016174316
[2025-03-17 19:07:48,193][model][INFO] - Training step 15760 loss 0.0757811963558197
[2025-03-17 19:08:26,551][model][INFO] - Training step 15920 loss 0.25159403681755066
[2025-03-17 19:09:05,366][model][INFO] - Training step 16080 loss 0.24883157014846802
[2025-03-17 19:09:44,603][model][INFO] - Training step 16240 loss 0.04212689399719238
[2025-03-17 19:10:24,145][model][INFO] - Training step 16400 loss 0.2497280389070511
[2025-03-17 19:11:02,991][model][INFO] - Training step 16560 loss 0.056220829486846924
[2025-03-17 19:11:42,246][model][INFO] - Training step 16720 loss 0.0013446048833429813
[2025-03-17 19:12:21,654][model][INFO] - Training step 16880 loss 0.022682856768369675
[2025-03-17 19:13:02,436][model][INFO] - Training step 17040 loss 0.016274679452180862
[2025-03-17 19:13:43,871][model][INFO] - Training step 17200 loss 0.04154186695814133
[2025-03-17 19:14:24,709][model][INFO] - Training step 17360 loss 0.010997312143445015
[2025-03-17 19:15:03,190][model][INFO] - Training step 17520 loss 0.02632097899913788
[2025-03-17 19:15:43,156][model][INFO] - Training step 17680 loss 0.021384820342063904
[2025-03-17 19:16:22,717][model][INFO] - Training step 17840 loss 0.027595024555921555
[2025-03-17 19:17:02,414][model][INFO] - Training step 18000 loss 0.006844420917332172
[2025-03-17 19:17:41,282][model][INFO] - Training step 18160 loss 0.037959352135658264
[2025-03-17 19:18:21,982][model][INFO] - Training step 18320 loss 0.006022998131811619
[2025-03-17 19:19:02,934][model][INFO] - Training step 18480 loss 0.023304402828216553
[2025-03-17 19:19:42,392][model][INFO] - Training step 18640 loss 0.027991896495223045
[2025-03-17 19:20:22,337][model][INFO] - Training step 18800 loss 0.01738518476486206
[2025-03-17 19:21:00,711][model][INFO] - Training step 18960 loss 0.05768405273556709
[2025-03-17 19:21:41,375][model][INFO] - Training step 19120 loss 0.0521823987364769
[2025-03-17 19:22:21,754][model][INFO] - Training step 19280 loss 0.024589000269770622
[2025-03-17 19:23:01,535][model][INFO] - Training step 19440 loss 0.022549539804458618
[2025-03-17 19:23:40,337][model][INFO] - Training step 19600 loss 0.030389299616217613
[2025-03-17 19:24:20,529][model][INFO] - Training step 19760 loss 0.013214973732829094
[2025-03-17 19:25:00,261][model][INFO] - Training step 19920 loss 0.03986547142267227
[2025-03-17 19:25:42,454][model][INFO] - Training step 20080 loss 0.2743806540966034
[2025-03-17 19:26:22,978][model][INFO] - Training step 20240 loss 0.017925478518009186
[2025-03-17 19:27:03,624][model][INFO] - Training step 20400 loss 0.27062705159187317
[2025-03-17 19:27:42,442][model][INFO] - Training step 20560 loss 0.02374066784977913
[2025-03-17 19:28:22,220][model][INFO] - Training step 20720 loss 0.182022362947464
[2025-03-17 19:29:02,106][model][INFO] - Training step 20880 loss 0.018476411700248718
[2025-03-17 19:29:41,749][model][INFO] - Training step 21040 loss 0.03486856818199158
[2025-03-17 19:30:22,462][model][INFO] - Training step 21200 loss 0.23823955655097961
[2025-03-17 19:31:01,950][model][INFO] - Training step 21360 loss 0.036539606750011444
[2025-03-17 19:31:43,031][model][INFO] - Training step 21520 loss 0.04551001638174057
[2025-03-17 19:32:22,946][model][INFO] - Training step 21680 loss 0.003964773379266262
[2025-03-17 19:33:03,049][model][INFO] - Training step 21840 loss 0.09169153869152069
[2025-03-17 19:33:42,410][model][INFO] - Training step 22000 loss 0.028610507026314735
[2025-03-17 19:34:21,669][model][INFO] - Training step 22160 loss 0.030773762613534927
[2025-03-17 19:35:01,537][model][INFO] - Training step 22320 loss 0.02205844223499298
[2025-03-17 19:35:42,807][model][INFO] - Training step 22480 loss 0.27774447202682495
[2025-03-17 19:36:22,525][model][INFO] - Training step 22640 loss 0.006665242835879326
[2025-03-17 19:37:02,318][model][INFO] - Training step 22800 loss 0.0041628931649029255
[2025-03-17 19:37:43,328][model][INFO] - Training step 22960 loss 0.015980960801243782
[2025-03-17 19:38:23,533][model][INFO] - Training step 23120 loss 0.033546194434165955
[2025-03-17 19:39:04,672][model][INFO] - Training step 23280 loss 0.1231505274772644
[2025-03-17 19:39:45,260][model][INFO] - Training step 23440 loss 0.01727452129125595
[2025-03-17 19:40:26,575][model][INFO] - Training step 23600 loss 0.036349885165691376
[2025-03-17 19:41:06,279][model][INFO] - Training step 23760 loss 0.03912760317325592
[2025-03-17 19:41:47,528][model][INFO] - Training step 23920 loss 0.24725341796875
[2025-03-17 19:42:27,778][model][INFO] - Training step 24080 loss 0.24224576354026794
[2025-03-17 19:43:07,286][model][INFO] - Training step 24240 loss 0.05913184583187103
[2025-03-17 19:43:46,557][model][INFO] - Training step 24400 loss 0.24238932132720947
[2025-03-17 19:44:25,662][model][INFO] - Training step 24560 loss 0.11942057311534882
[2025-03-17 19:45:05,698][model][INFO] - Training step 24720 loss 0.19170503318309784
[2025-03-17 19:45:46,958][model][INFO] - Training step 24880 loss 0.04992864280939102
[2025-03-17 19:46:25,104][model][INFO] - Training step 25040 loss 0.09565437585115433
[2025-03-17 19:47:04,848][model][INFO] - Training step 25200 loss 0.02405467815697193
[2025-03-17 19:47:45,794][model][INFO] - Training step 25360 loss 0.0043868934735655785
[2025-03-17 19:48:28,420][model][INFO] - Training step 25520 loss 0.03173412010073662
[2025-03-17 19:49:07,500][model][INFO] - Training step 25680 loss 0.24861161410808563
[2025-03-17 19:49:46,157][model][INFO] - Training step 25840 loss 0.2550033628940582
[2025-03-17 19:50:27,449][model][INFO] - Training step 26000 loss 0.2540598511695862
[2025-03-17 19:51:06,751][model][INFO] - Training step 26160 loss 0.023187115788459778
[2025-03-17 19:51:47,952][model][INFO] - Training step 26320 loss 0.07221178710460663
[2025-03-17 19:52:27,705][model][INFO] - Training step 26480 loss 0.2486911118030548
[2025-03-17 19:53:08,010][model][INFO] - Training step 26640 loss 0.02385757490992546
[2025-03-17 19:53:47,346][model][INFO] - Training step 26800 loss 0.008092429488897324
[2025-03-17 19:54:28,028][model][INFO] - Training step 26960 loss 0.04021860286593437
[2025-03-17 19:55:08,087][model][INFO] - Training step 27120 loss 0.06762267649173737
[2025-03-17 19:55:49,164][model][INFO] - Training step 27280 loss 0.038267217576503754
[2025-03-17 19:56:30,494][model][INFO] - Training step 27440 loss 0.030391301959753036
[2025-03-17 19:57:12,124][model][INFO] - Training step 27600 loss 0.007465943228453398
[2025-03-17 19:57:52,444][model][INFO] - Training step 27760 loss 0.027521256357431412
[2025-03-17 19:58:32,186][model][INFO] - Training step 27920 loss 0.016330938786268234
[2025-03-17 19:59:12,647][model][INFO] - Training step 28080 loss 0.250936359167099
[2025-03-17 19:59:54,224][model][INFO] - Training step 28240 loss 0.03850488364696503
[2025-03-17 20:00:34,177][model][INFO] - Training step 28400 loss 0.07128250598907471
[2025-03-17 20:01:14,855][model][INFO] - Training step 28560 loss 0.07741089910268784
[2025-03-17 20:01:54,229][model][INFO] - Training step 28720 loss 0.24924926459789276
[2025-03-17 20:02:33,811][model][INFO] - Training step 28880 loss 0.006351800635457039
[2025-03-17 20:03:14,140][model][INFO] - Training step 29040 loss 0.028427109122276306
[2025-03-17 20:03:54,827][model][INFO] - Training step 29200 loss 0.0025538781192153692
[2025-03-17 20:04:35,029][model][INFO] - Training step 29360 loss 0.007155256345868111
[2025-03-17 20:05:16,578][model][INFO] - Training step 29520 loss 0.2576896846294403
[2025-03-17 20:05:57,711][model][INFO] - Training step 29680 loss 0.0042167347855865955
[2025-03-17 20:06:36,490][model][INFO] - Training step 29840 loss 0.0037273645866662264
[2025-03-17 20:07:17,443][model][INFO] - Training step 30000 loss 0.25649911165237427
[2025-03-17 20:07:57,032][model][INFO] - Training step 30160 loss 0.0068274009972810745
[2025-03-17 20:08:36,992][model][INFO] - Training step 30320 loss 0.08459416031837463
[2025-03-17 20:09:18,922][model][INFO] - Training step 30480 loss 0.014650763012468815
[2025-03-17 20:09:58,998][model][INFO] - Training step 30640 loss 0.020252009853720665
[2025-03-17 20:10:38,357][model][INFO] - Training step 30800 loss 0.004745326470583677
[2025-03-17 20:11:20,103][model][INFO] - Training step 30960 loss 0.012668388895690441
[2025-03-17 20:12:00,512][model][INFO] - Training step 31120 loss 0.24802736937999725
[2025-03-17 20:12:40,402][model][INFO] - Training step 31280 loss 0.28242984414100647
[2025-03-17 20:13:21,220][model][INFO] - Training step 31440 loss 0.026200177147984505
[2025-03-17 20:14:01,082][model][INFO] - Training step 31600 loss 0.02408236637711525
[2025-03-17 20:14:40,512][model][INFO] - Training step 31760 loss 0.07273929566144943
[2025-03-17 20:15:20,780][model][INFO] - Training step 31920 loss 0.02445077896118164
[2025-03-17 20:16:00,508][model][INFO] - Training step 32080 loss 0.25153058767318726
[2025-03-17 20:16:40,819][model][INFO] - Training step 32240 loss 0.014428472146391869
[2025-03-17 20:17:21,810][model][INFO] - Training step 32400 loss 0.0822160616517067
[2025-03-17 20:18:02,608][model][INFO] - Training step 32560 loss 0.02395033836364746
[2025-03-17 20:18:42,386][model][INFO] - Training step 32720 loss 0.09302423149347305
[2025-03-17 20:19:23,890][model][INFO] - Training step 32880 loss 0.024306010454893112
[2025-03-17 20:20:02,051][model][INFO] - Training step 33040 loss 0.2473960816860199
[2025-03-17 20:20:42,178][model][INFO] - Training step 33200 loss 0.2535685896873474
[2025-03-17 20:21:21,667][model][INFO] - Training step 33360 loss 0.2549418807029724
[2025-03-17 20:22:01,020][model][INFO] - Training step 33520 loss 0.027503227815032005
[2025-03-17 20:22:41,744][model][INFO] - Training step 33680 loss 0.012084638699889183
[2025-03-17 20:23:22,587][model][INFO] - Training step 33840 loss 0.2506865859031677
[2025-03-17 20:24:02,597][model][INFO] - Training step 34000 loss 0.010859690606594086
[2025-03-17 20:24:43,014][model][INFO] - Training step 34160 loss 0.255310595035553
[2025-03-17 20:25:23,619][model][INFO] - Training step 34320 loss 0.05077899247407913
[2025-03-17 20:26:04,330][model][INFO] - Training step 34480 loss 0.03504905104637146
[2025-03-17 20:26:44,671][model][INFO] - Training step 34640 loss 0.037732891738414764
[2025-03-17 20:27:23,838][model][INFO] - Training step 34800 loss 0.26332101225852966
[2025-03-17 20:28:03,298][model][INFO] - Training step 34960 loss 0.026614544913172722
[2025-03-17 20:28:42,155][model][INFO] - Training step 35120 loss 0.011540118604898453
[2025-03-17 20:29:22,153][model][INFO] - Training step 35280 loss 0.25622254610061646
[2025-03-17 20:30:03,103][model][INFO] - Training step 35440 loss 0.01804952323436737
[2025-03-17 20:30:43,191][model][INFO] - Training step 35600 loss 0.0035294662229716778
[2025-03-17 20:31:22,954][model][INFO] - Training step 35760 loss 0.04532072693109512
[2025-03-17 20:32:02,804][model][INFO] - Training step 35920 loss 0.15338435769081116
[2025-03-17 20:32:42,935][model][INFO] - Training step 36080 loss 0.005867763888090849
[2025-03-17 20:33:23,409][model][INFO] - Training step 36240 loss 0.2568622827529907
[2025-03-17 20:34:04,332][model][INFO] - Training step 36400 loss 0.007186466827988625
[2025-03-17 20:34:44,788][model][INFO] - Training step 36560 loss 0.01990065909922123
[2025-03-17 20:35:25,227][model][INFO] - Training step 36720 loss 0.006471038796007633
[2025-03-17 20:36:05,755][model][INFO] - Training step 36880 loss 0.017393454909324646
[2025-03-17 20:36:44,681][model][INFO] - Training step 37040 loss 0.016352467238903046
[2025-03-17 20:37:25,313][model][INFO] - Training step 37200 loss 0.02548966370522976
[2025-03-17 20:38:04,921][model][INFO] - Training step 37360 loss 0.06445968151092529
[2025-03-17 20:38:45,493][model][INFO] - Training step 37520 loss 0.011846158653497696
[2025-03-17 20:39:25,494][model][INFO] - Training step 37680 loss 0.020121067762374878
[2025-03-17 20:40:05,523][model][INFO] - Training step 37840 loss 0.077121801674366
[2025-03-17 20:40:44,585][model][INFO] - Training step 38000 loss 0.007802330888807774
[2025-03-17 20:41:24,197][model][INFO] - Training step 38160 loss 0.019237644970417023
[2025-03-17 20:42:03,803][model][INFO] - Training step 38320 loss 0.02915135771036148
[2025-03-17 20:42:44,897][model][INFO] - Training step 38480 loss 0.26254189014434814
[2025-03-17 20:43:24,147][model][INFO] - Training step 38640 loss 0.035172976553440094
[2025-03-17 20:44:03,683][model][INFO] - Training step 38800 loss 0.24834856390953064
[2025-03-17 20:44:44,687][model][INFO] - Training step 38960 loss 0.24505332112312317
[2025-03-17 20:45:24,769][model][INFO] - Training step 39120 loss 0.02165907621383667
[2025-03-17 20:46:04,908][model][INFO] - Training step 39280 loss 0.004646847024559975
[2025-03-17 20:46:45,699][model][INFO] - Training step 39440 loss 0.01429065503180027
[2025-03-17 20:47:25,799][model][INFO] - Training step 39600 loss 0.02210594341158867
[2025-03-17 20:48:05,632][model][INFO] - Training step 39760 loss 0.04411720484495163
[2025-03-17 20:48:45,164][model][INFO] - Training step 39920 loss 0.0040853205136954784
[2025-03-17 20:49:24,545][model][INFO] - Training step 40080 loss 0.013115286827087402
[2025-03-17 20:50:06,489][model][INFO] - Training step 40240 loss 0.02218666300177574
[2025-03-17 20:50:46,742][model][INFO] - Training step 40400 loss 0.25177615880966187
[2025-03-17 20:51:27,170][model][INFO] - Training step 40560 loss 0.027164213359355927
[2025-03-17 20:52:07,347][model][INFO] - Training step 40720 loss 0.026713822036981583
[2025-03-17 20:52:47,381][model][INFO] - Training step 40880 loss 0.01812846213579178
[2025-03-17 20:53:27,324][model][INFO] - Training step 41040 loss 0.02490532025694847
[2025-03-17 20:54:06,728][model][INFO] - Training step 41200 loss 0.24193622171878815
[2025-03-17 20:54:47,961][model][INFO] - Training step 41360 loss 0.020397774875164032
[2025-03-17 20:55:28,513][model][INFO] - Training step 41520 loss 0.036840882152318954
[2025-03-17 20:56:10,237][model][INFO] - Training step 41680 loss 0.2651279866695404
[2025-03-17 20:56:49,707][model][INFO] - Training step 41840 loss 0.04391377419233322
[2025-03-17 20:57:29,449][model][INFO] - Training step 42000 loss 0.052017077803611755
[2025-03-17 20:58:09,919][model][INFO] - Training step 42160 loss 0.022745266556739807
[2025-03-17 20:58:48,465][model][INFO] - Training step 42320 loss 0.015195852145552635
[2025-03-17 20:59:30,469][model][INFO] - Training step 42480 loss 0.2716444134712219
[2025-03-17 21:00:10,040][model][INFO] - Training step 42640 loss 0.026193693280220032
[2025-03-17 21:00:49,830][model][INFO] - Training step 42800 loss 0.2271612137556076
[2025-03-17 21:01:31,222][model][INFO] - Training step 42960 loss 0.021166011691093445
[2025-03-17 21:02:13,523][model][INFO] - Training step 43120 loss 0.06573091447353363
[2025-03-17 21:02:53,529][model][INFO] - Training step 43280 loss 0.04017727077007294
[2025-03-17 21:03:38,382][model][INFO] - Training step 43440 loss 0.03873683884739876
[2025-03-17 21:04:18,392][model][INFO] - Training step 43600 loss 0.22627820074558258
[2025-03-17 21:04:58,369][model][INFO] - Training step 43760 loss 0.062250345945358276
[2025-03-17 21:05:40,797][model][INFO] - Training step 43920 loss 0.25017911195755005
[2025-03-17 21:06:22,232][model][INFO] - Training step 44080 loss 0.2493480145931244
[2025-03-17 21:07:03,953][model][INFO] - Training step 44240 loss 0.04878609627485275
[2025-03-17 21:07:45,841][model][INFO] - Training step 44400 loss 0.005388438701629639
[2025-03-17 21:08:25,638][model][INFO] - Training step 44560 loss 0.0363440066576004
[2025-03-17 21:09:06,283][model][INFO] - Training step 44720 loss 0.05819676071405411
[2025-03-17 21:09:45,119][model][INFO] - Training step 44880 loss 0.1406407654285431
[2025-03-17 21:10:25,433][model][INFO] - Training step 45040 loss 0.028512656688690186
[2025-03-17 21:11:05,598][model][INFO] - Training step 45200 loss 0.2599712610244751
[2025-03-17 21:11:45,011][model][INFO] - Training step 45360 loss 0.0037486706860363483
[2025-03-17 21:12:25,888][model][INFO] - Training step 45520 loss 0.03516063839197159
[2025-03-17 21:13:05,410][model][INFO] - Training step 45680 loss 0.010346904397010803
[2025-03-17 21:13:45,534][model][INFO] - Training step 45840 loss 0.0030967770144343376
[2025-03-17 21:14:25,954][model][INFO] - Training step 46000 loss 0.002143657999113202
[2025-03-17 21:15:06,979][model][INFO] - Training step 46160 loss 0.005198903847485781
[2025-03-17 21:15:46,695][model][INFO] - Training step 46320 loss 0.023511618375778198
[2025-03-17 21:16:26,798][model][INFO] - Training step 46480 loss 0.01967036724090576
[2025-03-17 21:17:09,076][model][INFO] - Training step 46640 loss 0.25128549337387085
[2025-03-17 21:17:48,543][model][INFO] - Training step 46800 loss 0.00484408438205719
[2025-03-17 21:18:28,775][model][INFO] - Training step 46960 loss 0.031961433589458466
[2025-03-17 21:19:08,442][model][INFO] - Training step 47120 loss 0.2555050849914551
[2025-03-17 21:19:48,965][model][INFO] - Training step 47280 loss 0.25462639331817627
[2025-03-17 21:20:29,976][model][INFO] - Training step 47440 loss 0.013741610571742058
[2025-03-17 21:21:08,933][model][INFO] - Training step 47600 loss 0.03705466538667679
[2025-03-17 21:21:48,536][model][INFO] - Training step 47760 loss 0.0550839863717556
[2025-03-17 21:22:29,730][model][INFO] - Training step 47920 loss 0.026132451370358467
[2025-03-17 21:23:10,069][model][INFO] - Training step 48080 loss 0.18519845604896545
[2025-03-17 21:23:48,931][model][INFO] - Training step 48240 loss 0.01767832785844803
[2025-03-17 21:24:29,272][model][INFO] - Training step 48400 loss 0.036173440515995026
[2025-03-17 21:25:08,493][model][INFO] - Training step 48560 loss 0.003794303396716714
[2025-03-17 21:25:49,524][model][INFO] - Training step 48720 loss 0.004407163709402084
[2025-03-17 21:26:30,107][model][INFO] - Training step 48880 loss 0.01852552406489849
[2025-03-17 21:27:09,186][model][INFO] - Training step 49040 loss 0.013378763571381569
[2025-03-17 21:27:49,319][model][INFO] - Training step 49200 loss 0.022520486265420914
[2025-03-17 21:28:29,580][model][INFO] - Training step 49360 loss 0.002849757904186845
[2025-03-17 21:29:08,668][model][INFO] - Training step 49520 loss 0.0526704266667366
[2025-03-17 21:29:47,033][model][INFO] - Training step 49680 loss 0.010101089254021645
[2025-03-17 21:30:26,431][model][INFO] - Training step 49840 loss 0.08560794591903687
[2025-03-17 21:31:06,572][model][INFO] - Training step 50000 loss 0.019099608063697815
[2025-03-17 21:31:47,144][model][INFO] - Training step 50160 loss 0.014311201870441437
[2025-03-17 21:32:27,161][model][INFO] - Training step 50320 loss 0.0972793698310852
[2025-03-17 21:33:06,592][model][INFO] - Training step 50480 loss 0.2524595856666565
[2025-03-17 21:33:47,387][model][INFO] - Training step 50640 loss 0.016693398356437683
[2025-03-17 21:39:26,167][model][INFO] - Training step 0 loss 0.015729663893580437
[2025-03-17 21:40:05,750][model][INFO] - Training step 160 loss 0.017309166491031647
[2025-03-17 21:40:45,126][model][INFO] - Training step 320 loss 0.02597566694021225
[2025-03-17 21:41:25,520][model][INFO] - Training step 480 loss 0.01908009871840477
[2025-03-17 21:42:04,538][model][INFO] - Training step 640 loss 0.01961256004869938
[2025-03-17 21:42:44,735][model][INFO] - Training step 800 loss 0.02282658964395523
[2025-03-17 21:43:25,743][model][INFO] - Training step 960 loss 0.012993627227842808
[2025-03-17 21:44:03,840][model][INFO] - Training step 1120 loss 0.03975015878677368
[2025-03-17 21:44:44,504][model][INFO] - Training step 1280 loss 0.028076861053705215
[2025-03-17 21:45:23,754][model][INFO] - Training step 1440 loss 0.2730352282524109
[2025-03-17 21:46:04,705][model][INFO] - Training step 1600 loss 0.04202853888273239
[2025-03-17 21:46:46,289][model][INFO] - Training step 1760 loss 0.033942535519599915
[2025-03-17 21:47:25,747][model][INFO] - Training step 1920 loss 0.0178217813372612
[2025-03-17 21:48:05,846][model][INFO] - Training step 2080 loss 0.01806279458105564
[2025-03-17 21:48:45,272][model][INFO] - Training step 2240 loss 0.03065151534974575
[2025-03-17 21:49:23,743][model][INFO] - Training step 2400 loss 0.0538751482963562
[2025-03-17 21:50:04,431][model][INFO] - Training step 2560 loss 0.040224380791187286
[2025-03-17 21:50:45,237][model][INFO] - Training step 2720 loss 0.014344875700771809
[2025-03-17 21:51:24,997][model][INFO] - Training step 2880 loss 0.01406276784837246
[2025-03-17 21:52:04,719][model][INFO] - Training step 3040 loss 0.09441667795181274
[2025-03-17 21:52:46,673][model][INFO] - Training step 3200 loss 0.010660197585821152
[2025-03-17 21:53:26,480][model][INFO] - Training step 3360 loss 0.005745681002736092
[2025-03-17 21:54:05,118][model][INFO] - Training step 3520 loss 0.025805700570344925
[2025-03-17 21:54:45,229][model][INFO] - Training step 3680 loss 0.021931994706392288
[2025-03-17 21:55:24,561][model][INFO] - Training step 3840 loss 0.2492593675851822
[2025-03-17 21:56:05,400][model][INFO] - Training step 4000 loss 0.11109086871147156
[2025-03-17 21:56:45,628][model][INFO] - Training step 4160 loss 0.012068325653672218
[2025-03-17 21:57:25,848][model][INFO] - Training step 4320 loss 0.026809364557266235
[2025-03-17 21:58:07,597][model][INFO] - Training step 4480 loss 0.029203161597251892
[2025-03-17 21:58:47,888][model][INFO] - Training step 4640 loss 0.02813507243990898
[2025-03-17 21:59:28,004][model][INFO] - Training step 4800 loss 0.028756752610206604
[2025-03-17 22:00:07,783][model][INFO] - Training step 4960 loss 0.009627042338252068
[2025-03-17 22:00:48,586][model][INFO] - Training step 5120 loss 0.13284261524677277
[2025-03-17 22:01:29,329][model][INFO] - Training step 5280 loss 0.20950469374656677
[2025-03-17 22:02:09,701][model][INFO] - Training step 5440 loss 0.043310895562171936
[2025-03-17 22:02:49,417][model][INFO] - Training step 5600 loss 0.26891249418258667
[2025-03-17 22:03:29,282][model][INFO] - Training step 5760 loss 0.03708793967962265
[2025-03-17 22:04:10,574][model][INFO] - Training step 5920 loss 0.07076290249824524
[2025-03-17 22:04:49,921][model][INFO] - Training step 6080 loss 0.015858620405197144
[2025-03-17 22:05:30,762][model][INFO] - Training step 6240 loss 0.07356425374746323
[2025-03-17 22:06:11,297][model][INFO] - Training step 6400 loss 0.01824825257062912
[2025-03-17 22:06:51,205][model][INFO] - Training step 6560 loss 0.02174454554915428
[2025-03-17 22:07:32,051][model][INFO] - Training step 6720 loss 0.006453089416027069
[2025-03-17 22:08:12,060][model][INFO] - Training step 6880 loss 0.005484716966748238
[2025-03-17 22:08:53,068][model][INFO] - Training step 7040 loss 0.010912317782640457
[2025-03-17 22:09:32,953][model][INFO] - Training step 7200 loss 0.002994774840772152
[2025-03-17 22:10:12,407][model][INFO] - Training step 7360 loss 0.24354572594165802
[2025-03-17 22:10:52,176][model][INFO] - Training step 7520 loss 0.25322628021240234
[2025-03-17 22:11:32,607][model][INFO] - Training step 7680 loss 0.10092717409133911
[2025-03-17 22:12:12,525][model][INFO] - Training step 7840 loss 0.02110784500837326
[2025-03-17 22:12:52,952][model][INFO] - Training step 8000 loss 0.03346482664346695
[2025-03-17 22:13:33,852][model][INFO] - Training step 8160 loss 0.012995028868317604
[2025-03-17 22:14:13,289][model][INFO] - Training step 8320 loss 0.24656569957733154
[2025-03-17 22:14:53,665][model][INFO] - Training step 8480 loss 0.10293398052453995
[2025-03-17 22:15:34,872][model][INFO] - Training step 8640 loss 0.025245781987905502
[2025-03-17 22:16:15,797][model][INFO] - Training step 8800 loss 0.2525142431259155
[2025-03-17 22:16:57,512][model][INFO] - Training step 8960 loss 0.6555541753768921
[2025-03-17 22:17:37,324][model][INFO] - Training step 9120 loss 0.03281627595424652
[2025-03-17 22:18:17,249][model][INFO] - Training step 9280 loss 0.024199072271585464
[2025-03-17 22:18:55,865][model][INFO] - Training step 9440 loss 0.016390394419431686
[2025-03-17 22:19:35,619][model][INFO] - Training step 9600 loss 0.015050657093524933
[2025-03-17 22:20:15,990][model][INFO] - Training step 9760 loss 0.23692671954631805
[2025-03-17 22:20:56,951][model][INFO] - Training step 9920 loss 0.018019653856754303
[2025-03-17 22:21:35,834][model][INFO] - Training step 10080 loss 0.04316585510969162
[2025-03-17 22:22:16,411][model][INFO] - Training step 10240 loss 0.013035712763667107
[2025-03-17 22:22:56,705][model][INFO] - Training step 10400 loss 0.019613251090049744
[2025-03-17 22:23:35,662][model][INFO] - Training step 10560 loss 0.6877772212028503
[2025-03-17 22:24:15,189][model][INFO] - Training step 10720 loss 0.005543394945561886
[2025-03-17 22:24:56,099][model][INFO] - Training step 10880 loss 0.03739381581544876
[2025-03-17 22:25:35,574][model][INFO] - Training step 11040 loss 0.23928788304328918
[2025-03-17 22:26:15,873][model][INFO] - Training step 11200 loss 0.02230963297188282
[2025-03-17 22:26:56,161][model][INFO] - Training step 11360 loss 0.039892636239528656
[2025-03-17 22:27:35,136][model][INFO] - Training step 11520 loss 0.019909681752324104
[2025-03-17 22:28:15,755][model][INFO] - Training step 11680 loss 0.033778127282857895
[2025-03-17 22:28:56,276][model][INFO] - Training step 11840 loss 0.03369079530239105
[2025-03-17 22:29:35,373][model][INFO] - Training step 12000 loss 0.023134924471378326
[2025-03-17 22:30:15,469][model][INFO] - Training step 12160 loss 0.23997436463832855
[2025-03-17 22:30:55,330][model][INFO] - Training step 12320 loss 0.10110203176736832
[2025-03-17 22:31:35,594][model][INFO] - Training step 12480 loss 0.020300626754760742
[2025-03-17 22:32:15,288][model][INFO] - Training step 12640 loss 0.003199657890945673
[2025-03-17 22:32:55,204][model][INFO] - Training step 12800 loss 0.02118399739265442
[2025-03-17 22:33:35,171][model][INFO] - Training step 12960 loss 0.012854731641709805
[2025-03-17 22:34:14,548][model][INFO] - Training step 13120 loss 0.24502289295196533
[2025-03-17 22:34:54,643][model][INFO] - Training step 13280 loss 0.01257092971354723
[2025-03-17 22:35:33,656][model][INFO] - Training step 13440 loss 0.504667341709137
[2025-03-17 22:36:12,952][model][INFO] - Training step 13600 loss 0.03697482869029045
[2025-03-17 22:36:52,799][model][INFO] - Training step 13760 loss 0.024218423292040825
[2025-03-17 22:37:32,906][model][INFO] - Training step 13920 loss 0.041223254054784775
[2025-03-17 22:38:12,194][model][INFO] - Training step 14080 loss 0.0021262066438794136
[2025-03-17 22:38:52,066][model][INFO] - Training step 14240 loss 0.10885158181190491
[2025-03-17 22:39:31,168][model][INFO] - Training step 14400 loss 0.0063679413869977
[2025-03-17 22:40:11,853][model][INFO] - Training step 14560 loss 0.027058854699134827
[2025-03-17 22:40:52,516][model][INFO] - Training step 14720 loss 0.2584230899810791
[2025-03-17 22:41:32,493][model][INFO] - Training step 14880 loss 0.02791494131088257
[2025-03-17 22:42:12,173][model][INFO] - Training step 15040 loss 0.3342178463935852
[2025-03-17 22:42:52,211][model][INFO] - Training step 15200 loss 0.015950791537761688
[2025-03-17 22:43:31,326][model][INFO] - Training step 15360 loss 0.008841291069984436
[2025-03-17 22:44:10,376][model][INFO] - Training step 15520 loss 0.01359221525490284
[2025-03-17 22:44:49,660][model][INFO] - Training step 15680 loss 0.01943109557032585
[2025-03-17 22:45:30,153][model][INFO] - Training step 15840 loss 0.06351959705352783
[2025-03-17 22:46:09,483][model][INFO] - Training step 16000 loss 0.01100863330066204
[2025-03-17 22:46:48,548][model][INFO] - Training step 16160 loss 0.014406360685825348
[2025-03-17 22:47:28,324][model][INFO] - Training step 16320 loss 0.24820685386657715
[2025-03-17 22:48:06,089][model][INFO] - Training step 16480 loss 0.027551501989364624
[2025-03-17 22:48:47,295][model][INFO] - Training step 16640 loss 0.017649801447987556
[2025-03-17 22:49:26,118][model][INFO] - Training step 16800 loss 0.027560081332921982
[2025-03-17 22:50:07,673][model][INFO] - Training step 16960 loss 0.03498561680316925
[2025-03-17 22:50:45,935][model][INFO] - Training step 17120 loss 0.002747428137809038
[2025-03-17 22:51:27,079][model][INFO] - Training step 17280 loss 0.02224833145737648
[2025-03-17 22:52:06,176][model][INFO] - Training step 17440 loss 0.27930110692977905
[2025-03-17 22:52:45,204][model][INFO] - Training step 17600 loss 0.028921127319335938
[2025-03-17 22:53:24,999][model][INFO] - Training step 17760 loss 0.031407613307237625
[2025-03-17 22:54:04,792][model][INFO] - Training step 17920 loss 0.04696004092693329
[2025-03-17 22:54:45,200][model][INFO] - Training step 18080 loss 0.02455640770494938
[2025-03-17 22:55:24,324][model][INFO] - Training step 18240 loss 0.05957716703414917
[2025-03-17 22:56:06,637][model][INFO] - Training step 18400 loss 0.006717561278492212
[2025-03-17 22:56:44,804][model][INFO] - Training step 18560 loss 0.031288664788007736
[2025-03-17 22:57:25,289][model][INFO] - Training step 18720 loss 0.2560100555419922
[2025-03-17 22:58:05,448][model][INFO] - Training step 18880 loss 0.08457879722118378
[2025-03-17 22:58:45,574][model][INFO] - Training step 19040 loss 0.027693260461091995
[2025-03-17 22:59:26,104][model][INFO] - Training step 19200 loss 0.06196296960115433
[2025-03-17 23:00:05,090][model][INFO] - Training step 19360 loss 0.021736707538366318
[2025-03-17 23:00:44,792][model][INFO] - Training step 19520 loss 0.023451287299394608
[2025-03-17 23:01:25,965][model][INFO] - Training step 19680 loss 0.001806536689400673
[2025-03-17 23:02:05,224][model][INFO] - Training step 19840 loss 0.2766374945640564
[2025-03-17 23:02:45,945][model][INFO] - Training step 20000 loss 0.005814677104353905
[2025-03-17 23:03:25,537][model][INFO] - Training step 20160 loss 0.02163558267056942
[2025-03-17 23:04:04,973][model][INFO] - Training step 20320 loss 0.072634756565094
[2025-03-17 23:04:44,293][model][INFO] - Training step 20480 loss 0.2523505687713623
[2025-03-17 23:05:25,450][model][INFO] - Training step 20640 loss 0.04155372828245163
[2025-03-17 23:06:06,417][model][INFO] - Training step 20800 loss 0.25842511653900146
[2025-03-17 23:06:47,878][model][INFO] - Training step 20960 loss 0.020834997296333313
[2025-03-17 23:07:28,728][model][INFO] - Training step 21120 loss 0.1048383116722107
[2025-03-17 23:08:10,307][model][INFO] - Training step 21280 loss 0.008589789271354675
[2025-03-17 23:08:51,553][model][INFO] - Training step 21440 loss 0.012204937636852264
[2025-03-17 23:09:33,088][model][INFO] - Training step 21600 loss 0.25341102480888367
[2025-03-17 23:10:13,450][model][INFO] - Training step 21760 loss 0.007077020592987537
[2025-03-17 23:10:54,433][model][INFO] - Training step 21920 loss 0.003026887308806181
[2025-03-17 23:11:33,741][model][INFO] - Training step 22080 loss 0.05785570666193962
[2025-03-17 23:12:13,632][model][INFO] - Training step 22240 loss 0.02870873361825943
[2025-03-17 23:12:53,668][model][INFO] - Training step 22400 loss 0.02750876359641552
[2025-03-17 23:13:34,476][model][INFO] - Training step 22560 loss 0.021719131618738174
[2025-03-17 23:14:16,447][model][INFO] - Training step 22720 loss 0.011178100481629372
[2025-03-17 23:14:56,770][model][INFO] - Training step 22880 loss 0.011863930150866508
[2025-03-17 23:15:36,677][model][INFO] - Training step 23040 loss 0.03311102092266083
[2025-03-17 23:16:16,507][model][INFO] - Training step 23200 loss 0.07782718539237976
[2025-03-17 23:16:55,478][model][INFO] - Training step 23360 loss 0.053611911833286285
[2025-03-17 23:17:35,454][model][INFO] - Training step 23520 loss 0.02371230721473694
[2025-03-17 23:18:14,719][model][INFO] - Training step 23680 loss 0.2517663836479187
[2025-03-17 23:18:56,464][model][INFO] - Training step 23840 loss 0.022238872945308685
[2025-03-17 23:19:35,585][model][INFO] - Training step 24000 loss 0.01997608318924904
[2025-03-17 23:20:14,759][model][INFO] - Training step 24160 loss 0.02492509037256241
[2025-03-17 23:20:55,336][model][INFO] - Training step 24320 loss 0.02271154709160328
[2025-03-17 23:21:36,213][model][INFO] - Training step 24480 loss 0.007853029295802116
[2025-03-17 23:22:15,002][model][INFO] - Training step 24640 loss 0.07535037398338318
[2025-03-17 23:22:54,377][model][INFO] - Training step 24800 loss 0.17634263634681702
[2025-03-17 23:23:35,389][model][INFO] - Training step 24960 loss 0.006368035450577736
[2025-03-17 23:24:36,188][model][INFO] - Training step 25120 loss 0.2535001039505005
[2025-03-17 23:25:59,827][model][INFO] - Training step 25280 loss 0.019220884889364243
[2025-03-17 23:27:22,514][model][INFO] - Training step 25440 loss 0.020878169685602188
[2025-03-17 23:28:47,719][model][INFO] - Training step 25600 loss 0.24376676976680756
[2025-03-17 23:30:13,281][model][INFO] - Training step 25760 loss 0.02710391953587532
[2025-03-17 23:31:37,586][model][INFO] - Training step 25920 loss 0.06191027909517288
[2025-03-17 23:33:04,411][model][INFO] - Training step 26080 loss 0.020180508494377136
[2025-03-17 23:34:32,141][model][INFO] - Training step 26240 loss 0.018671400845050812
[2025-03-17 23:35:55,987][model][INFO] - Training step 26400 loss 0.04703352600336075
[2025-03-17 23:37:23,069][model][INFO] - Training step 26560 loss 0.2599073648452759
[2025-03-17 23:38:49,541][model][INFO] - Training step 26720 loss 0.04911892116069794
[2025-03-17 23:40:15,587][model][INFO] - Training step 26880 loss 0.006232164800167084
[2025-03-17 23:41:39,874][model][INFO] - Training step 27040 loss 0.045491307973861694
[2025-03-17 23:43:06,694][model][INFO] - Training step 27200 loss 0.02145637571811676
[2025-03-17 23:44:32,218][model][INFO] - Training step 27360 loss 0.05021126940846443
[2025-03-17 23:45:55,540][model][INFO] - Training step 27520 loss 0.026744864881038666
[2025-03-17 23:47:20,380][model][INFO] - Training step 27680 loss 0.025039048865437508
[2025-03-17 23:48:45,110][model][INFO] - Training step 27840 loss 0.030001487582921982
[2025-03-17 23:50:12,056][model][INFO] - Training step 28000 loss 0.051383960992097855
[2025-03-17 23:51:40,619][model][INFO] - Training step 28160 loss 0.26930201053619385
[2025-03-17 23:53:05,871][model][INFO] - Training step 28320 loss 0.23996806144714355
[2025-03-17 23:54:30,628][model][INFO] - Training step 28480 loss 0.02944505587220192
[2025-03-17 23:55:57,587][model][INFO] - Training step 28640 loss 0.03722171485424042
[2025-03-17 23:57:20,466][model][INFO] - Training step 28800 loss 0.047462962567806244
[2025-03-17 23:58:45,901][model][INFO] - Training step 28960 loss 0.03325406834483147
[2025-03-18 00:00:11,578][model][INFO] - Training step 29120 loss 0.2601815462112427
[2025-03-18 00:01:37,766][model][INFO] - Training step 29280 loss 0.0492631159722805
[2025-03-18 00:03:04,045][model][INFO] - Training step 29440 loss 0.13192804157733917
[2025-03-18 00:04:28,340][model][INFO] - Training step 29600 loss 0.04536373168230057
[2025-03-18 00:05:51,508][model][INFO] - Training step 29760 loss 0.005922136828303337
[2025-03-18 00:07:18,101][model][INFO] - Training step 29920 loss 0.025485536083579063
[2025-03-18 00:08:43,102][model][INFO] - Training step 30080 loss 0.023091182112693787
[2025-03-18 00:10:08,339][model][INFO] - Training step 30240 loss 0.029163092374801636
[2025-03-18 00:11:35,251][model][INFO] - Training step 30400 loss 0.0037690475583076477
[2025-03-18 00:12:58,380][model][INFO] - Training step 30560 loss 0.0188119038939476
[2025-03-18 00:14:21,703][model][INFO] - Training step 30720 loss 0.24322205781936646
[2025-03-18 00:15:45,100][model][INFO] - Training step 30880 loss 0.024334590882062912
[2025-03-18 00:17:09,315][model][INFO] - Training step 31040 loss 0.03189537674188614
[2025-03-18 00:18:34,613][model][INFO] - Training step 31200 loss 0.0014102094573900104
[2025-03-18 00:19:58,155][model][INFO] - Training step 31360 loss 0.24675831198692322
[2025-03-18 00:21:18,964][model][INFO] - Training step 31520 loss 0.058167919516563416
[2025-03-18 00:22:44,144][model][INFO] - Training step 31680 loss 0.02763880044221878
[2025-03-18 00:24:06,948][model][INFO] - Training step 31840 loss 0.005663515068590641
[2025-03-18 00:25:33,588][model][INFO] - Training step 32000 loss 0.24523696303367615
[2025-03-18 00:26:55,105][model][INFO] - Training step 32160 loss 0.2507399320602417
[2025-03-18 00:28:18,168][model][INFO] - Training step 32320 loss 0.167263001203537
[2025-03-18 00:29:41,718][model][INFO] - Training step 32480 loss 0.005185619927942753
[2025-03-18 00:31:09,298][model][INFO] - Training step 32640 loss 0.2625352144241333
[2025-03-18 00:32:35,052][model][INFO] - Training step 32800 loss 0.0029303862247616053
[2025-03-18 00:34:02,584][model][INFO] - Training step 32960 loss 0.03019959107041359
[2025-03-18 00:35:25,150][model][INFO] - Training step 33120 loss 0.021619323641061783
[2025-03-18 00:36:48,936][model][INFO] - Training step 33280 loss 0.4018748998641968
[2025-03-18 00:38:14,288][model][INFO] - Training step 33440 loss 0.05759907886385918
[2025-03-18 00:39:37,867][model][INFO] - Training step 33600 loss 0.10393022000789642
[2025-03-18 00:41:02,787][model][INFO] - Training step 33760 loss 0.023843109607696533
[2025-03-18 00:42:31,009][model][INFO] - Training step 33920 loss 0.004832553211599588
[2025-03-18 00:43:58,584][model][INFO] - Training step 34080 loss 0.06924603879451752
[2025-03-18 00:45:24,052][model][INFO] - Training step 34240 loss 0.23615704476833344
[2025-03-18 00:46:50,005][model][INFO] - Training step 34400 loss 0.23288455605506897
[2025-03-18 00:48:17,450][model][INFO] - Training step 34560 loss 0.04105084016919136
[2025-03-18 00:49:40,444][model][INFO] - Training step 34720 loss 0.01790018379688263
[2025-03-18 00:51:01,966][model][INFO] - Training step 34880 loss 0.016857482492923737
[2025-03-18 00:52:27,243][model][INFO] - Training step 35040 loss 0.02675335295498371
[2025-03-18 00:53:54,409][model][INFO] - Training step 35200 loss 0.020819474011659622
[2025-03-18 00:55:15,923][model][INFO] - Training step 35360 loss 0.015253214165568352
[2025-03-18 00:56:46,643][model][INFO] - Training step 35520 loss 0.02031736448407173
[2025-03-18 00:58:06,759][model][INFO] - Training step 35680 loss 0.03487035632133484
[2025-03-18 00:59:32,176][model][INFO] - Training step 35840 loss 0.03511245176196098
[2025-03-18 01:01:00,790][model][INFO] - Training step 36000 loss 0.19530947506427765
[2025-03-18 01:02:28,616][model][INFO] - Training step 36160 loss 0.04963415861129761
[2025-03-18 01:03:53,552][model][INFO] - Training step 36320 loss 0.2423475980758667
[2025-03-18 01:05:22,266][model][INFO] - Training step 36480 loss 0.016273997724056244
[2025-03-18 01:06:48,128][model][INFO] - Training step 36640 loss 0.020422667264938354
[2025-03-18 01:08:16,680][model][INFO] - Training step 36800 loss 0.02156253159046173
[2025-03-18 01:09:42,422][model][INFO] - Training step 36960 loss 0.01264533307403326
[2025-03-18 01:11:05,171][model][INFO] - Training step 37120 loss 0.016191432252526283
[2025-03-18 01:12:30,826][model][INFO] - Training step 37280 loss 0.0772775337100029
[2025-03-18 01:13:54,479][model][INFO] - Training step 37440 loss 0.2252124547958374
[2025-03-18 01:15:16,189][model][INFO] - Training step 37600 loss 0.06702415645122528
[2025-03-18 01:16:39,905][model][INFO] - Training step 37760 loss 0.023234330117702484
[2025-03-18 01:18:06,310][model][INFO] - Training step 37920 loss 0.010432109236717224
[2025-03-18 01:19:29,778][model][INFO] - Training step 38080 loss 0.27338486909866333
[2025-03-18 01:20:57,072][model][INFO] - Training step 38240 loss 0.017009347677230835
[2025-03-18 01:22:21,773][model][INFO] - Training step 38400 loss 0.020585209131240845
[2025-03-18 01:23:48,159][model][INFO] - Training step 38560 loss 0.019553853198885918
[2025-03-18 01:25:14,679][model][INFO] - Training step 38720 loss 0.036925509572029114
[2025-03-18 01:26:38,486][model][INFO] - Training step 38880 loss 0.021639816462993622
[2025-03-18 01:28:02,512][model][INFO] - Training step 39040 loss 0.033322785049676895
[2025-03-18 01:29:28,523][model][INFO] - Training step 39200 loss 0.2316461205482483
[2025-03-18 01:30:52,875][model][INFO] - Training step 39360 loss 0.0061307065188884735
[2025-03-18 01:32:14,841][model][INFO] - Training step 39520 loss 0.024583831429481506
[2025-03-18 01:33:38,565][model][INFO] - Training step 39680 loss 0.02474762499332428
[2025-03-18 01:35:00,974][model][INFO] - Training step 39840 loss 0.004638028796762228
[2025-03-18 01:36:25,039][model][INFO] - Training step 40000 loss 0.03559236228466034
[2025-03-18 01:37:50,329][model][INFO] - Training step 40160 loss 0.02425101026892662
[2025-03-18 01:39:17,464][model][INFO] - Training step 40320 loss 0.03356150537729263
[2025-03-18 01:40:40,426][model][INFO] - Training step 40480 loss 0.2321358621120453
[2025-03-18 01:42:07,428][model][INFO] - Training step 40640 loss 0.029714487493038177
[2025-03-18 01:43:31,473][model][INFO] - Training step 40800 loss 0.006992173381149769
[2025-03-18 01:44:55,930][model][INFO] - Training step 40960 loss 0.024401649832725525
[2025-03-18 01:46:20,572][model][INFO] - Training step 41120 loss 0.24865755438804626
[2025-03-18 01:47:47,719][model][INFO] - Training step 41280 loss 0.03691042214632034
[2025-03-18 01:49:11,617][model][INFO] - Training step 41440 loss 0.25554847717285156
[2025-03-18 01:50:38,081][model][INFO] - Training step 41600 loss 0.05684516578912735
[2025-03-18 01:52:03,980][model][INFO] - Training step 41760 loss 0.009763125330209732
[2025-03-18 01:53:29,705][model][INFO] - Training step 41920 loss 0.018996354192495346
[2025-03-18 01:54:55,846][model][INFO] - Training step 42080 loss 0.0074576991610229015
[2025-03-18 01:56:16,114][model][INFO] - Training step 42240 loss 0.02067810669541359
[2025-03-18 01:57:40,714][model][INFO] - Training step 42400 loss 0.03106769733130932
[2025-03-18 01:59:04,541][model][INFO] - Training step 42560 loss 0.23986884951591492
[2025-03-18 02:00:28,983][model][INFO] - Training step 42720 loss 0.02586570382118225
[2025-03-18 02:01:48,961][model][INFO] - Training step 42880 loss 0.03297204524278641
[2025-03-18 02:03:11,589][model][INFO] - Training step 43040 loss 0.009458974935114384
[2025-03-18 02:04:38,247][model][INFO] - Training step 43200 loss 0.3354949653148651
[2025-03-18 02:06:03,954][model][INFO] - Training step 43360 loss 0.08708171546459198
[2025-03-18 02:07:28,842][model][INFO] - Training step 43520 loss 0.003061566734686494
[2025-03-18 02:08:51,812][model][INFO] - Training step 43680 loss 0.029640918597579002
[2025-03-18 02:10:15,001][model][INFO] - Training step 43840 loss 0.021908573806285858
[2025-03-18 02:11:39,748][model][INFO] - Training step 44000 loss 0.25205039978027344
[2025-03-18 02:13:07,176][model][INFO] - Training step 44160 loss 0.03701511025428772
[2025-03-18 02:14:32,697][model][INFO] - Training step 44320 loss 0.01602702960371971
[2025-03-18 02:15:57,753][model][INFO] - Training step 44480 loss 0.01018444448709488
[2025-03-18 02:17:20,241][model][INFO] - Training step 44640 loss 0.023802220821380615
[2025-03-18 02:18:46,181][model][INFO] - Training step 44800 loss 0.25734347105026245
[2025-03-18 02:20:11,898][model][INFO] - Training step 44960 loss 0.022491898387670517
[2025-03-18 02:21:36,733][model][INFO] - Training step 45120 loss 0.047724463045597076
[2025-03-18 02:22:59,212][model][INFO] - Training step 45280 loss 0.019172303378582
[2025-03-18 02:24:21,678][model][INFO] - Training step 45440 loss 0.00518688652664423
[2025-03-18 02:25:48,745][model][INFO] - Training step 45600 loss 0.007719570770859718
[2025-03-18 02:27:11,308][model][INFO] - Training step 45760 loss 0.03538265824317932
[2025-03-18 02:28:38,696][model][INFO] - Training step 45920 loss 0.020464329048991203
[2025-03-18 02:30:04,766][model][INFO] - Training step 46080 loss 0.023232685402035713
[2025-03-18 02:31:26,420][model][INFO] - Training step 46240 loss 0.015930652618408203
[2025-03-18 02:32:51,255][model][INFO] - Training step 46400 loss 0.019540593028068542
[2025-03-18 02:34:12,198][model][INFO] - Training step 46560 loss 0.013527856208384037
[2025-03-18 02:35:39,046][model][INFO] - Training step 46720 loss 0.021059207618236542
[2025-03-18 02:37:03,421][model][INFO] - Training step 46880 loss 0.024269528687000275
[2025-03-18 02:38:25,140][model][INFO] - Training step 47040 loss 0.03521368280053139
[2025-03-18 02:39:51,909][model][INFO] - Training step 47200 loss 0.003582798643037677
[2025-03-18 02:41:13,189][model][INFO] - Training step 47360 loss 0.01682622916996479
[2025-03-18 02:42:38,871][model][INFO] - Training step 47520 loss 0.06954219937324524
[2025-03-18 02:44:04,777][model][INFO] - Training step 47680 loss 0.09921681135892868
[2025-03-18 02:45:32,194][model][INFO] - Training step 47840 loss 0.015894878655672073
[2025-03-18 02:46:56,793][model][INFO] - Training step 48000 loss 0.03993299603462219
[2025-03-18 02:48:20,873][model][INFO] - Training step 48160 loss 0.018109071999788284
[2025-03-18 02:49:42,679][model][INFO] - Training step 48320 loss 0.2652329206466675
[2025-03-18 02:51:04,862][model][INFO] - Training step 48480 loss 0.017285317182540894
[2025-03-18 02:52:27,369][model][INFO] - Training step 48640 loss 0.023382000625133514
[2025-03-18 02:53:52,422][model][INFO] - Training step 48800 loss 0.07823833078145981
[2025-03-18 02:55:16,745][model][INFO] - Training step 48960 loss 0.011311713606119156
[2025-03-18 02:56:42,603][model][INFO] - Training step 49120 loss 0.01470709778368473
[2025-03-18 02:58:06,139][model][INFO] - Training step 49280 loss 0.06872270256280899
[2025-03-18 02:59:28,262][model][INFO] - Training step 49440 loss 0.021008919924497604
[2025-03-18 03:00:52,200][model][INFO] - Training step 49600 loss 0.025346865877509117
[2025-03-18 03:02:15,045][model][INFO] - Training step 49760 loss 0.2554040551185608
[2025-03-18 03:03:38,582][model][INFO] - Training step 49920 loss 0.01983492821455002
[2025-03-18 03:05:05,902][model][INFO] - Training step 50080 loss 0.11018068343400955
[2025-03-18 03:06:35,310][model][INFO] - Training step 50240 loss 0.011470513418316841
[2025-03-18 03:08:00,587][model][INFO] - Training step 50400 loss 0.023489192128181458
[2025-03-18 03:09:21,748][model][INFO] - Training step 50560 loss 0.014633756130933762
[2025-03-18 03:10:45,666][model][INFO] - Training step 50720 loss 0.0031171280425041914
[2025-03-18 03:23:46,460][model][INFO] - Training step 80 loss 0.1474701464176178
[2025-03-18 03:25:10,078][model][INFO] - Training step 240 loss 0.02062084712088108
[2025-03-18 03:26:34,190][model][INFO] - Training step 400 loss 0.023101208731532097
[2025-03-18 03:27:55,679][model][INFO] - Training step 560 loss 0.04832009971141815
[2025-03-18 03:29:22,269][model][INFO] - Training step 720 loss 0.03273431211709976
[2025-03-18 03:30:45,970][model][INFO] - Training step 880 loss 0.023389996960759163
[2025-03-18 03:32:09,359][model][INFO] - Training step 1040 loss 0.014426185749471188
[2025-03-18 03:33:34,275][model][INFO] - Training step 1200 loss 0.0029728757217526436
[2025-03-18 03:34:59,056][model][INFO] - Training step 1360 loss 0.034545235335826874
[2025-03-18 03:36:22,934][model][INFO] - Training step 1520 loss 0.04254401475191116
[2025-03-18 03:37:48,138][model][INFO] - Training step 1680 loss 0.029299918562173843
[2025-03-18 03:39:15,081][model][INFO] - Training step 1840 loss 0.030536197125911713
[2025-03-18 03:40:39,777][model][INFO] - Training step 2000 loss 0.03954188525676727
[2025-03-18 03:42:00,950][model][INFO] - Training step 2160 loss 0.015103930607438087
[2025-03-18 03:43:24,369][model][INFO] - Training step 2320 loss 0.006359659601002932
[2025-03-18 03:44:47,788][model][INFO] - Training step 2480 loss 0.14041851460933685
[2025-03-18 03:46:11,471][model][INFO] - Training step 2640 loss 0.02575674280524254
[2025-03-18 03:47:32,919][model][INFO] - Training step 2800 loss 0.08193197846412659
[2025-03-18 03:48:54,741][model][INFO] - Training step 2960 loss 0.29803943634033203
[2025-03-18 03:50:18,043][model][INFO] - Training step 3120 loss 0.015920812264084816
[2025-03-18 03:51:43,348][model][INFO] - Training step 3280 loss 0.02823619171977043
[2025-03-18 03:53:03,513][model][INFO] - Training step 3440 loss 0.04870627075433731
[2025-03-18 03:54:27,750][model][INFO] - Training step 3600 loss 0.012673832476139069
[2025-03-18 03:55:51,881][model][INFO] - Training step 3760 loss 0.018236715346574783
[2025-03-18 03:57:15,739][model][INFO] - Training step 3920 loss 0.03989037126302719
[2025-03-18 03:58:42,319][model][INFO] - Training step 4080 loss 0.02643526718020439
[2025-03-18 04:00:02,347][model][INFO] - Training step 4240 loss 0.06322862207889557
[2025-03-18 04:01:24,329][model][INFO] - Training step 4400 loss 0.013517715968191624
[2025-03-18 04:02:50,719][model][INFO] - Training step 4560 loss 0.02005724236369133
[2025-03-18 04:04:14,764][model][INFO] - Training step 4720 loss 0.2698778510093689
[2025-03-18 04:05:36,113][model][INFO] - Training step 4880 loss 0.013503558933734894
[2025-03-18 04:06:59,108][model][INFO] - Training step 5040 loss 0.02857562154531479
[2025-03-18 04:08:21,630][model][INFO] - Training step 5200 loss 0.25557947158813477
[2025-03-18 04:09:45,185][model][INFO] - Training step 5360 loss 0.08836366981267929
[2025-03-18 04:11:08,970][model][INFO] - Training step 5520 loss 0.029869064688682556
[2025-03-18 04:12:33,328][model][INFO] - Training step 5680 loss 0.09354111552238464
[2025-03-18 04:14:00,127][model][INFO] - Training step 5840 loss 0.03561969846487045
[2025-03-18 04:15:26,306][model][INFO] - Training step 6000 loss 0.010978665202856064
[2025-03-18 04:16:49,012][model][INFO] - Training step 6160 loss 0.005098432302474976
[2025-03-18 04:18:14,582][model][INFO] - Training step 6320 loss 0.038925059139728546
[2025-03-18 04:19:38,325][model][INFO] - Training step 6480 loss 0.24316231906414032
[2025-03-18 04:21:00,960][model][INFO] - Training step 6640 loss 0.007243527099490166
[2025-03-18 04:22:24,736][model][INFO] - Training step 6800 loss 0.03610287606716156
[2025-03-18 04:23:47,919][model][INFO] - Training step 6960 loss 0.02834298461675644
[2025-03-18 04:25:07,841][model][INFO] - Training step 7120 loss 0.044879645109176636
[2025-03-18 04:26:32,990][model][INFO] - Training step 7280 loss 0.012129001319408417
[2025-03-18 04:27:56,826][model][INFO] - Training step 7440 loss 0.2450333684682846
[2025-03-18 04:29:19,114][model][INFO] - Training step 7600 loss 0.037292033433914185
[2025-03-18 04:30:41,661][model][INFO] - Training step 7760 loss 0.030942920595407486
[2025-03-18 04:32:08,853][model][INFO] - Training step 7920 loss 0.006006220355629921
[2025-03-18 04:33:31,264][model][INFO] - Training step 8080 loss 0.02523988112807274
[2025-03-18 04:34:53,150][model][INFO] - Training step 8240 loss 0.02100614830851555
[2025-03-18 04:36:14,069][model][INFO] - Training step 8400 loss 0.2493375539779663
[2025-03-18 04:37:36,585][model][INFO] - Training step 8560 loss 0.017666315659880638
[2025-03-18 04:39:00,340][model][INFO] - Training step 8720 loss 0.03503458946943283
[2025-03-18 04:40:23,386][model][INFO] - Training step 8880 loss 0.09471321851015091
[2025-03-18 04:41:47,179][model][INFO] - Training step 9040 loss 0.013849964365363121
[2025-03-18 04:43:09,733][model][INFO] - Training step 9200 loss 0.2614063620567322
[2025-03-18 04:44:33,743][model][INFO] - Training step 9360 loss 0.005127481184899807
[2025-03-18 04:45:54,705][model][INFO] - Training step 9520 loss 0.08174048364162445
[2025-03-18 04:47:19,059][model][INFO] - Training step 9680 loss 0.31875336170196533
[2025-03-18 04:48:43,144][model][INFO] - Training step 9840 loss 0.0359349399805069
[2025-03-18 04:50:07,523][model][INFO] - Training step 10000 loss 0.004917892627418041
[2025-03-18 04:51:30,509][model][INFO] - Training step 10160 loss 0.08219112455844879
[2025-03-18 04:52:52,954][model][INFO] - Training step 10320 loss 0.032882481813430786
[2025-03-18 04:54:17,059][model][INFO] - Training step 10480 loss 0.09373369812965393
[2025-03-18 04:55:40,385][model][INFO] - Training step 10640 loss 0.2517699897289276
[2025-03-18 04:57:00,608][model][INFO] - Training step 10800 loss 0.26030197739601135
[2025-03-18 04:58:21,650][model][INFO] - Training step 10960 loss 0.0037915240973234177
[2025-03-18 04:59:41,232][model][INFO] - Training step 11120 loss 0.018294857814908028
[2025-03-18 05:01:02,487][model][INFO] - Training step 11280 loss 0.02158668264746666
[2025-03-18 05:02:23,723][model][INFO] - Training step 11440 loss 0.2638978958129883
[2025-03-18 05:03:45,020][model][INFO] - Training step 11600 loss 0.014971252530813217
[2025-03-18 05:05:10,259][model][INFO] - Training step 11760 loss 0.029658598825335503
[2025-03-18 05:06:30,578][model][INFO] - Training step 11920 loss 0.10395138710737228
[2025-03-18 05:07:55,002][model][INFO] - Training step 12080 loss 0.24404773116111755
[2025-03-18 05:09:16,570][model][INFO] - Training step 12240 loss 0.2696842551231384
[2025-03-18 05:10:37,147][model][INFO] - Training step 12400 loss 0.24432489275932312
[2025-03-18 05:11:59,500][model][INFO] - Training step 12560 loss 0.023379594087600708
[2025-03-18 05:13:23,889][model][INFO] - Training step 12720 loss 0.20790717005729675
[2025-03-18 05:14:46,792][model][INFO] - Training step 12880 loss 0.01753847301006317
[2025-03-18 05:16:11,435][model][INFO] - Training step 13040 loss 0.24822017550468445
[2025-03-18 05:17:31,550][model][INFO] - Training step 13200 loss 0.026737451553344727
[2025-03-18 05:18:53,419][model][INFO] - Training step 13360 loss 0.09286710619926453
[2025-03-18 05:20:19,734][model][INFO] - Training step 13520 loss 0.009337315335869789
[2025-03-18 05:21:46,466][model][INFO] - Training step 13680 loss 0.01676766201853752
[2025-03-18 05:23:07,890][model][INFO] - Training step 13840 loss 0.019660789519548416
[2025-03-18 05:24:33,615][model][INFO] - Training step 14000 loss 0.017304521054029465
[2025-03-18 05:25:56,069][model][INFO] - Training step 14160 loss 0.025674903765320778
[2025-03-18 05:27:18,902][model][INFO] - Training step 14320 loss 0.2519102692604065
[2025-03-18 05:28:42,911][model][INFO] - Training step 14480 loss 0.04936608672142029
[2025-03-18 05:30:07,972][model][INFO] - Training step 14640 loss 0.045360393822193146
[2025-03-18 05:31:29,105][model][INFO] - Training step 14800 loss 0.24514126777648926
[2025-03-18 05:32:54,555][model][INFO] - Training step 14960 loss 0.01385760959237814
[2025-03-18 05:34:18,943][model][INFO] - Training step 15120 loss 0.03221037983894348
[2025-03-18 05:35:43,834][model][INFO] - Training step 15280 loss 0.0562303401529789
[2025-03-18 05:37:09,163][model][INFO] - Training step 15440 loss 0.246961772441864
[2025-03-18 05:38:32,917][model][INFO] - Training step 15600 loss 0.046418409794569016
[2025-03-18 05:39:54,544][model][INFO] - Training step 15760 loss 0.3071545958518982
[2025-03-18 05:41:17,551][model][INFO] - Training step 15920 loss 0.2463051974773407
[2025-03-18 05:42:39,315][model][INFO] - Training step 16080 loss 0.012416666373610497
[2025-03-18 05:43:58,584][model][INFO] - Training step 16240 loss 0.03024452179670334
[2025-03-18 05:45:21,859][model][INFO] - Training step 16400 loss 0.024553831666707993
[2025-03-18 05:46:41,070][model][INFO] - Training step 16560 loss 0.03998900204896927
[2025-03-18 05:48:02,193][model][INFO] - Training step 16720 loss 0.019327286630868912
[2025-03-18 05:49:26,828][model][INFO] - Training step 16880 loss 0.017630942165851593
[2025-03-18 05:50:51,839][model][INFO] - Training step 17040 loss 2.442408800125122
[2025-03-18 05:52:14,472][model][INFO] - Training step 17200 loss 0.09123096615076065
[2025-03-18 05:53:34,919][model][INFO] - Training step 17360 loss 0.028106842190027237
[2025-03-18 05:54:57,612][model][INFO] - Training step 17520 loss 0.045688696205616
[2025-03-18 05:56:26,032][model][INFO] - Training step 17680 loss 0.23288780450820923
[2025-03-18 05:57:47,885][model][INFO] - Training step 17840 loss 0.06834985315799713
[2025-03-18 05:59:11,507][model][INFO] - Training step 18000 loss 0.02932441607117653
[2025-03-18 06:00:36,703][model][INFO] - Training step 18160 loss 0.02082279697060585
[2025-03-18 06:02:02,140][model][INFO] - Training step 18320 loss 0.0202320609241724
[2025-03-18 06:03:29,009][model][INFO] - Training step 18480 loss 0.29255157709121704
[2025-03-18 06:04:52,559][model][INFO] - Training step 18640 loss 0.04053300619125366
[2025-03-18 06:06:16,255][model][INFO] - Training step 18800 loss 0.014833042398095131
[2025-03-18 06:07:41,553][model][INFO] - Training step 18960 loss 0.05743694305419922
[2025-03-18 06:09:06,568][model][INFO] - Training step 19120 loss 0.025915145874023438
[2025-03-18 06:10:28,752][model][INFO] - Training step 19280 loss 0.02606845088303089
[2025-03-18 06:11:49,311][model][INFO] - Training step 19440 loss 0.14346906542778015
[2025-03-18 06:13:13,016][model][INFO] - Training step 19600 loss 0.027400534600019455
[2025-03-18 06:14:32,842][model][INFO] - Training step 19760 loss 0.01475323736667633
[2025-03-18 06:15:55,959][model][INFO] - Training step 19920 loss 0.08739744871854782
[2025-03-18 06:17:18,056][model][INFO] - Training step 20080 loss 0.0399378277361393
[2025-03-18 06:18:39,898][model][INFO] - Training step 20240 loss 0.07877744734287262
[2025-03-18 06:20:05,239][model][INFO] - Training step 20400 loss 0.06052209809422493
[2025-03-18 06:21:25,112][model][INFO] - Training step 20560 loss 0.2530389726161957
[2025-03-18 06:22:50,325][model][INFO] - Training step 20720 loss 0.048279400914907455
[2025-03-18 06:24:14,801][model][INFO] - Training step 20880 loss 0.023837193846702576
[2025-03-18 06:25:38,892][model][INFO] - Training step 21040 loss 0.24663046002388
[2025-03-18 06:26:58,873][model][INFO] - Training step 21200 loss 0.027645539492368698
[2025-03-18 06:28:20,711][model][INFO] - Training step 21360 loss 0.2429998517036438
[2025-03-18 06:29:42,076][model][INFO] - Training step 21520 loss 0.04300171509385109
[2025-03-18 06:31:04,737][model][INFO] - Training step 21680 loss 0.027340099215507507
[2025-03-18 06:32:27,761][model][INFO] - Training step 21840 loss 0.030605753883719444
[2025-03-18 06:33:47,255][model][INFO] - Training step 22000 loss 0.033209215849637985
[2025-03-18 06:35:06,485][model][INFO] - Training step 22160 loss 0.10770302265882492
[2025-03-18 06:36:32,031][model][INFO] - Training step 22320 loss 0.23752950131893158
[2025-03-18 06:37:53,097][model][INFO] - Training step 22480 loss 0.004134771414101124
[2025-03-18 06:39:14,588][model][INFO] - Training step 22640 loss 0.24102666974067688
[2025-03-18 06:40:38,243][model][INFO] - Training step 22800 loss 0.028667910024523735
[2025-03-18 06:41:59,532][model][INFO] - Training step 22960 loss 0.004739983007311821
[2025-03-18 06:43:20,716][model][INFO] - Training step 23120 loss 0.0250120647251606
[2025-03-18 06:44:42,893][model][INFO] - Training step 23280 loss 0.038114406168460846
[2025-03-18 06:46:02,798][model][INFO] - Training step 23440 loss 0.02405726909637451
[2025-03-18 06:47:26,515][model][INFO] - Training step 23600 loss 0.12022195011377335
[2025-03-18 06:48:47,963][model][INFO] - Training step 23760 loss 0.02997264638543129
[2025-03-18 06:50:09,224][model][INFO] - Training step 23920 loss 0.024569634348154068
[2025-03-18 06:51:33,481][model][INFO] - Training step 24080 loss 0.042581431567668915
[2025-03-18 06:52:54,693][model][INFO] - Training step 24240 loss 0.24699902534484863
[2025-03-18 06:54:15,681][model][INFO] - Training step 24400 loss 0.018846964463591576
[2025-03-18 06:55:39,563][model][INFO] - Training step 24560 loss 0.25547686219215393
[2025-03-18 06:57:01,894][model][INFO] - Training step 24720 loss 0.3181029260158539
[2025-03-18 06:58:22,522][model][INFO] - Training step 24880 loss 0.02455383911728859
[2025-03-18 06:59:46,965][model][INFO] - Training step 25040 loss 0.25344318151474
[2025-03-18 07:01:05,296][model][INFO] - Training step 25200 loss 0.01709621585905552
[2025-03-18 07:02:24,210][model][INFO] - Training step 25360 loss 0.04550807178020477
[2025-03-18 07:03:45,588][model][INFO] - Training step 25520 loss 0.24350759387016296
[2025-03-18 07:05:09,083][model][INFO] - Training step 25680 loss 0.14455440640449524
[2025-03-18 07:06:27,281][model][INFO] - Training step 25840 loss 0.25457850098609924
[2025-03-18 07:07:51,379][model][INFO] - Training step 26000 loss 0.05034710466861725
[2025-03-18 07:09:12,547][model][INFO] - Training step 26160 loss 0.020497914403676987
[2025-03-18 07:10:33,252][model][INFO] - Training step 26320 loss 0.07511797547340393
[2025-03-18 07:11:54,652][model][INFO] - Training step 26480 loss 0.2372361123561859
[2025-03-18 07:13:18,732][model][INFO] - Training step 26640 loss 0.02296307496726513
[2025-03-18 07:14:39,718][model][INFO] - Training step 26800 loss 0.010520349256694317
[2025-03-18 07:16:01,517][model][INFO] - Training step 26960 loss 0.2643415033817291
[2025-03-18 07:17:26,381][model][INFO] - Training step 27120 loss 0.22595517337322235
[2025-03-18 07:18:50,906][model][INFO] - Training step 27280 loss 0.2629544138908386
[2025-03-18 07:20:15,265][model][INFO] - Training step 27440 loss 0.2704896330833435
[2025-03-18 07:21:34,614][model][INFO] - Training step 27600 loss 0.09614522010087967
[2025-03-18 07:22:59,085][model][INFO] - Training step 27760 loss 0.25129109621047974
[2025-03-18 07:24:21,938][model][INFO] - Training step 27920 loss 0.2554684281349182
[2025-03-18 07:25:43,774][model][INFO] - Training step 28080 loss 0.025838136672973633
[2025-03-18 07:27:03,696][model][INFO] - Training step 28240 loss 0.24628427624702454
[2025-03-18 07:28:27,021][model][INFO] - Training step 28400 loss 0.05263776332139969
[2025-03-18 07:29:52,818][model][INFO] - Training step 28560 loss 0.022471603006124496
[2025-03-18 07:31:15,505][model][INFO] - Training step 28720 loss 0.005986511707305908
[2025-03-18 07:32:37,225][model][INFO] - Training step 28880 loss 0.007532108575105667
[2025-03-18 07:33:59,914][model][INFO] - Training step 29040 loss 0.026391107589006424
[2025-03-18 07:35:21,546][model][INFO] - Training step 29200 loss 0.0019420788157731295
[2025-03-18 07:36:44,548][model][INFO] - Training step 29360 loss 0.005177240818738937
[2025-03-18 07:38:05,196][model][INFO] - Training step 29520 loss 0.03489360958337784
[2025-03-18 07:39:27,579][model][INFO] - Training step 29680 loss 0.02453734539449215
[2025-03-18 07:40:49,670][model][INFO] - Training step 29840 loss 0.004993067122995853
[2025-03-18 07:42:11,758][model][INFO] - Training step 30000 loss 0.020659901201725006
[2025-03-18 07:43:34,462][model][INFO] - Training step 30160 loss 0.03384672850370407
[2025-03-18 07:44:54,686][model][INFO] - Training step 30320 loss 0.020649803802371025
[2025-03-18 07:46:17,472][model][INFO] - Training step 30480 loss 0.015895556658506393
[2025-03-18 07:47:37,351][model][INFO] - Training step 30640 loss 0.00631775613874197
[2025-03-18 07:48:58,440][model][INFO] - Training step 30800 loss 0.005515143275260925
[2025-03-18 07:50:22,296][model][INFO] - Training step 30960 loss 0.02500699646770954
[2025-03-18 07:51:44,956][model][INFO] - Training step 31120 loss 0.029079187661409378
[2025-03-18 07:53:04,489][model][INFO] - Training step 31280 loss 0.031169021502137184
[2025-03-18 07:54:27,750][model][INFO] - Training step 31440 loss 0.25536295771598816
[2025-03-18 07:55:48,171][model][INFO] - Training step 31600 loss 0.26187700033187866
[2025-03-18 07:57:08,021][model][INFO] - Training step 31760 loss 0.03538774698972702
[2025-03-18 07:58:29,934][model][INFO] - Training step 31920 loss 0.17116005718708038
[2025-03-18 07:59:53,254][model][INFO] - Training step 32080 loss 0.03739403188228607
[2025-03-18 08:01:16,694][model][INFO] - Training step 32240 loss 0.001643652911297977
[2025-03-18 08:02:39,285][model][INFO] - Training step 32400 loss 0.10792374610900879
[2025-03-18 08:04:02,854][model][INFO] - Training step 32560 loss 0.10484300553798676
[2025-03-18 08:05:31,187][model][INFO] - Training step 32720 loss 0.017368659377098083
[2025-03-18 08:06:53,076][model][INFO] - Training step 32880 loss 0.02770073711872101
[2025-03-18 08:08:10,826][model][INFO] - Training step 33040 loss 0.021593229845166206
[2025-03-18 08:09:31,968][model][INFO] - Training step 33200 loss 0.0032179823610931635
[2025-03-18 08:10:53,578][model][INFO] - Training step 33360 loss 0.04898947477340698
[2025-03-18 08:12:14,224][model][INFO] - Training step 33520 loss 0.03240356966853142
[2025-03-18 08:13:37,115][model][INFO] - Training step 33680 loss 0.007682421710342169
[2025-03-18 08:15:04,632][model][INFO] - Training step 33840 loss 0.018689189106225967
[2025-03-18 08:16:26,101][model][INFO] - Training step 34000 loss 0.011487402021884918
[2025-03-18 08:17:47,496][model][INFO] - Training step 34160 loss 0.043543435633182526
[2025-03-18 08:19:10,594][model][INFO] - Training step 34320 loss 0.03048902377486229
[2025-03-18 08:20:35,496][model][INFO] - Training step 34480 loss 0.05195809155702591
[2025-03-18 08:21:18,375][model][INFO] - Training step 34640 loss 0.024402379989624023
[2025-03-18 08:21:57,406][model][INFO] - Training step 34800 loss 0.015230106189846992
[2025-03-18 08:22:37,583][model][INFO] - Training step 34960 loss 0.025137562304735184
[2025-03-18 08:23:19,347][model][INFO] - Training step 35120 loss 0.012282333336770535
[2025-03-18 08:23:59,928][model][INFO] - Training step 35280 loss 0.02125520259141922
[2025-03-18 08:24:40,713][model][INFO] - Training step 35440 loss 0.06938394904136658
[2025-03-18 08:25:21,201][model][INFO] - Training step 35600 loss 0.0971488282084465
[2025-03-18 08:26:02,088][model][INFO] - Training step 35760 loss 0.01761683076620102
[2025-03-18 08:26:40,672][model][INFO] - Training step 35920 loss 0.009340455755591393
[2025-03-18 08:27:22,331][model][INFO] - Training step 36080 loss 0.04128769785165787
[2025-03-18 08:28:02,828][model][INFO] - Training step 36240 loss 0.0026822383515536785
[2025-03-18 08:28:43,287][model][INFO] - Training step 36400 loss 0.06656832993030548
[2025-03-18 08:29:25,018][model][INFO] - Training step 36560 loss 0.039158739149570465
[2025-03-18 08:30:05,048][model][INFO] - Training step 36720 loss 0.008275545202195644
[2025-03-18 08:30:45,854][model][INFO] - Training step 36880 loss 0.030652226880192757
[2025-03-18 08:31:26,228][model][INFO] - Training step 37040 loss 0.24198828637599945
[2025-03-18 08:32:05,587][model][INFO] - Training step 37200 loss 0.030378611758351326
[2025-03-18 08:32:46,008][model][INFO] - Training step 37360 loss 0.23773439228534698
[2025-03-18 08:33:26,204][model][INFO] - Training step 37520 loss 0.008101100102066994
[2025-03-18 08:34:06,132][model][INFO] - Training step 37680 loss 0.0197310633957386
[2025-03-18 08:34:46,485][model][INFO] - Training step 37840 loss 0.025712985545396805
[2025-03-18 08:35:25,694][model][INFO] - Training step 38000 loss 0.0035528282169252634
[2025-03-18 08:36:06,502][model][INFO] - Training step 38160 loss 0.006307384464889765
[2025-03-18 08:36:46,820][model][INFO] - Training step 38320 loss 0.02686590887606144
[2025-03-18 08:37:26,617][model][INFO] - Training step 38480 loss 0.09421058744192123
[2025-03-18 08:38:06,286][model][INFO] - Training step 38640 loss 0.01978786289691925
[2025-03-18 08:38:44,962][model][INFO] - Training step 38800 loss 0.02371915802359581
[2025-03-18 08:39:25,553][model][INFO] - Training step 38960 loss 0.2741098403930664
[2025-03-18 08:40:30,582][model][INFO] - Training step 39120 loss 0.006630112882703543
[2025-03-18 08:41:58,463][model][INFO] - Training step 39280 loss 0.24281388521194458
[2025-03-18 08:43:22,586][model][INFO] - Training step 39440 loss 0.026747141033411026
[2025-03-18 08:44:45,736][model][INFO] - Training step 39600 loss 0.26559510827064514
[2025-03-18 08:46:13,242][model][INFO] - Training step 39760 loss 0.01551271602511406
[2025-03-18 08:47:38,699][model][INFO] - Training step 39920 loss 0.003209044225513935
[2025-03-18 08:49:06,278][model][INFO] - Training step 40080 loss 0.24877937138080597
[2025-03-18 08:50:30,922][model][INFO] - Training step 40240 loss 0.017648980021476746
[2025-03-18 08:51:56,864][model][INFO] - Training step 40400 loss 0.022291304543614388
[2025-03-18 08:53:25,893][model][INFO] - Training step 40560 loss 0.0258602574467659
[2025-03-18 08:54:50,198][model][INFO] - Training step 40720 loss 0.04768943041563034
[2025-03-18 08:56:15,583][model][INFO] - Training step 40880 loss 0.01468010526150465
[2025-03-18 08:57:41,317][model][INFO] - Training step 41040 loss 0.023207394406199455
[2025-03-18 08:59:05,541][model][INFO] - Training step 41200 loss 0.01565474644303322
[2025-03-18 09:00:35,748][model][INFO] - Training step 41360 loss 0.013293180614709854
[2025-03-18 09:01:58,702][model][INFO] - Training step 41520 loss 0.031629037111997604
[2025-03-18 09:03:23,141][model][INFO] - Training step 41680 loss 0.11007682234048843
[2025-03-18 09:04:48,914][model][INFO] - Training step 41840 loss 0.016194283962249756
[2025-03-18 09:06:12,933][model][INFO] - Training step 42000 loss 0.146065354347229
[2025-03-18 09:07:41,067][model][INFO] - Training step 42160 loss 0.007098154630511999
[2025-03-18 09:09:09,639][model][INFO] - Training step 42320 loss 0.013595562428236008
[2025-03-18 09:10:40,293][model][INFO] - Training step 42480 loss 0.02510097622871399
[2025-03-18 09:12:06,537][model][INFO] - Training step 42640 loss 0.017459727823734283
[2025-03-18 09:13:29,602][model][INFO] - Training step 42800 loss 0.32288914918899536
[2025-03-18 09:14:54,179][model][INFO] - Training step 42960 loss 0.04294862970709801
[2025-03-18 09:16:20,836][model][INFO] - Training step 43120 loss 0.09805560111999512
[2025-03-18 09:17:47,795][model][INFO] - Training step 43280 loss 0.24503111839294434
[2025-03-18 09:19:17,515][model][INFO] - Training step 43440 loss 0.24685944616794586
[2025-03-18 09:20:42,388][model][INFO] - Training step 43600 loss 0.03460324555635452
[2025-03-18 09:22:05,720][model][INFO] - Training step 43760 loss 0.019543085247278214
[2025-03-18 09:23:32,321][model][INFO] - Training step 43920 loss 0.04275863245129585
[2025-03-18 09:24:59,404][model][INFO] - Training step 44080 loss 0.009800253435969353
[2025-03-18 09:26:25,399][model][INFO] - Training step 44240 loss 0.02737479656934738
[2025-03-18 09:27:53,595][model][INFO] - Training step 44400 loss 0.0339973047375679
[2025-03-18 09:29:20,077][model][INFO] - Training step 44560 loss 0.09048953652381897
[2025-03-18 09:30:45,350][model][INFO] - Training step 44720 loss 0.03013020008802414
[2025-03-18 09:32:13,284][model][INFO] - Training step 44880 loss 0.2521013021469116
[2025-03-18 09:33:39,494][model][INFO] - Training step 45040 loss 0.25326383113861084
[2025-03-18 09:35:02,803][model][INFO] - Training step 45200 loss 0.01057585421949625
[2025-03-18 09:36:27,824][model][INFO] - Training step 45360 loss 0.004647443071007729
[2025-03-18 09:37:56,126][model][INFO] - Training step 45520 loss 0.028257962316274643
[2025-03-18 09:39:22,286][model][INFO] - Training step 45680 loss 0.2572581470012665
[2025-03-18 09:40:50,130][model][INFO] - Training step 45840 loss 0.05776718258857727
[2025-03-18 09:42:15,691][model][INFO] - Training step 46000 loss 0.007518145255744457
[2025-03-18 09:43:43,917][model][INFO] - Training step 46160 loss 0.06741316616535187
[2025-03-18 09:45:09,755][model][INFO] - Training step 46320 loss 0.2547134757041931
[2025-03-18 09:46:40,381][model][INFO] - Training step 46480 loss 0.24817025661468506
[2025-03-18 09:48:03,455][model][INFO] - Training step 46640 loss 0.041730910539627075
[2025-03-18 09:49:30,799][model][INFO] - Training step 46800 loss 0.006765048019587994
[2025-03-18 09:50:55,959][model][INFO] - Training step 46960 loss 0.06721877306699753
[2025-03-18 09:52:19,794][model][INFO] - Training step 47120 loss 0.03784333914518356
[2025-03-18 09:53:48,167][model][INFO] - Training step 47280 loss 0.017084702849388123
[2025-03-18 09:55:18,122][model][INFO] - Training step 47440 loss 0.005620255134999752
[2025-03-18 09:56:44,502][model][INFO] - Training step 47600 loss 0.03696521744132042
[2025-03-18 09:58:08,901][model][INFO] - Training step 47760 loss 0.25874441862106323
[2025-03-18 09:59:34,354][model][INFO] - Training step 47920 loss 0.025690987706184387
[2025-03-18 10:01:01,129][model][INFO] - Training step 48080 loss 0.02807936817407608
[2025-03-18 10:02:22,361][model][INFO] - Training step 48240 loss 0.018822740763425827
[2025-03-18 10:03:47,201][model][INFO] - Training step 48400 loss 0.24904680252075195
[2025-03-18 10:05:13,424][model][INFO] - Training step 48560 loss 0.1446252465248108
[2025-03-18 10:06:38,191][model][INFO] - Training step 48720 loss 0.020537693053483963
[2025-03-18 10:08:04,956][model][INFO] - Training step 48880 loss 0.24695608019828796
[2025-03-18 10:09:32,741][model][INFO] - Training step 49040 loss 0.029113050550222397
[2025-03-18 10:10:58,273][model][INFO] - Training step 49200 loss 0.004779560957103968
[2025-03-18 10:12:26,922][model][INFO] - Training step 49360 loss 0.16341254115104675
[2025-03-18 10:13:57,845][model][INFO] - Training step 49520 loss 0.07060874998569489
[2025-03-18 10:15:26,726][model][INFO] - Training step 49680 loss 0.009683758020401001
[2025-03-18 10:16:49,383][model][INFO] - Training step 49840 loss 0.0359906330704689
[2025-03-18 10:18:17,001][model][INFO] - Training step 50000 loss 0.019872622564435005
[2025-03-18 10:19:43,648][model][INFO] - Training step 50160 loss 0.013529729098081589
[2025-03-18 10:21:11,648][model][INFO] - Training step 50320 loss 0.013878818601369858
[2025-03-18 10:22:38,240][model][INFO] - Training step 50480 loss 0.019092343747615814
[2025-03-18 10:24:01,320][model][INFO] - Training step 50640 loss 0.011936377733945847
[2025-03-18 10:37:31,324][model][INFO] - Training step 0 loss 0.01541977096349001
[2025-03-18 10:38:58,730][model][INFO] - Training step 160 loss 0.01634090393781662
[2025-03-18 10:40:25,473][model][INFO] - Training step 320 loss 0.2588048577308655
[2025-03-18 10:41:52,096][model][INFO] - Training step 480 loss 0.03656180948019028
[2025-03-18 10:43:18,358][model][INFO] - Training step 640 loss 0.018826093524694443
[2025-03-18 10:44:45,801][model][INFO] - Training step 800 loss 0.003442392684519291
[2025-03-18 10:46:13,042][model][INFO] - Training step 960 loss 0.023329414427280426
[2025-03-18 10:47:38,527][model][INFO] - Training step 1120 loss 0.03769419342279434
[2025-03-18 10:49:04,195][model][INFO] - Training step 1280 loss 0.24504047632217407
[2025-03-18 10:50:28,847][model][INFO] - Training step 1440 loss 0.06179686263203621
[2025-03-18 10:51:54,018][model][INFO] - Training step 1600 loss 0.041622407734394073
[2025-03-18 10:53:19,869][model][INFO] - Training step 1760 loss 0.029732858762145042
[2025-03-18 10:54:45,658][model][INFO] - Training step 1920 loss 0.25404971837997437
[2025-03-18 10:56:13,892][model][INFO] - Training step 2080 loss 0.021017877385020256
[2025-03-18 10:57:39,307][model][INFO] - Training step 2240 loss 0.0058252569288015366
[2025-03-18 10:59:04,163][model][INFO] - Training step 2400 loss 0.005533186253160238
[2025-03-18 11:00:27,498][model][INFO] - Training step 2560 loss 0.007087660953402519
[2025-03-18 11:01:53,063][model][INFO] - Training step 2720 loss 0.25377243757247925
[2025-03-18 11:03:20,067][model][INFO] - Training step 2880 loss 0.017225582152605057
[2025-03-18 11:04:42,638][model][INFO] - Training step 3040 loss 0.02388807386159897
[2025-03-18 11:06:09,896][model][INFO] - Training step 3200 loss 0.010432787239551544
[2025-03-18 11:07:38,377][model][INFO] - Training step 3360 loss 0.0066039105877280235
[2025-03-18 11:09:03,636][model][INFO] - Training step 3520 loss 0.10489970445632935
[2025-03-18 11:10:31,608][model][INFO] - Training step 3680 loss 0.24312584102153778
[2025-03-18 11:11:58,923][model][INFO] - Training step 3840 loss 0.004377366974949837
[2025-03-18 11:13:23,288][model][INFO] - Training step 4000 loss 0.05501940846443176
[2025-03-18 11:14:55,048][model][INFO] - Training step 4160 loss 0.25417861342430115
[2025-03-18 11:16:22,855][model][INFO] - Training step 4320 loss 0.019847923889756203
[2025-03-18 11:17:49,456][model][INFO] - Training step 4480 loss 0.02180967852473259
[2025-03-18 11:19:14,637][model][INFO] - Training step 4640 loss 0.08065368980169296
[2025-03-18 11:20:39,717][model][INFO] - Training step 4800 loss 0.02595270797610283
[2025-03-18 11:22:03,237][model][INFO] - Training step 4960 loss 0.008549774065613747
[2025-03-18 11:23:29,118][model][INFO] - Training step 5120 loss 0.07575726509094238
[2025-03-18 11:24:53,465][model][INFO] - Training step 5280 loss 0.00837398786097765
[2025-03-18 11:26:19,774][model][INFO] - Training step 5440 loss 0.10185730457305908
[2025-03-18 11:27:46,002][model][INFO] - Training step 5600 loss 0.05463326722383499
[2025-03-18 11:29:10,651][model][INFO] - Training step 5760 loss 0.039909396320581436
[2025-03-18 11:30:39,094][model][INFO] - Training step 5920 loss 0.028332103043794632
[2025-03-18 11:32:05,072][model][INFO] - Training step 6080 loss 0.018778305500745773
[2025-03-18 11:33:32,029][model][INFO] - Training step 6240 loss 0.23705217242240906
[2025-03-18 11:35:03,489][model][INFO] - Training step 6400 loss 0.01819598861038685
[2025-03-18 11:36:28,200][model][INFO] - Training step 6560 loss 0.026800397783517838
[2025-03-18 11:37:55,262][model][INFO] - Training step 6720 loss 0.24465380609035492
[2025-03-18 11:39:20,785][model][INFO] - Training step 6880 loss 0.04429874196648598
[2025-03-18 11:40:47,592][model][INFO] - Training step 7040 loss 0.009061498567461967
[2025-03-18 11:42:14,450][model][INFO] - Training step 7200 loss 0.01692955009639263
[2025-03-18 11:43:42,285][model][INFO] - Training step 7360 loss 0.2534494996070862
[2025-03-18 11:45:11,011][model][INFO] - Training step 7520 loss 0.03141440078616142
[2025-03-18 11:46:40,207][model][INFO] - Training step 7680 loss 0.021965323016047478
[2025-03-18 11:48:04,832][model][INFO] - Training step 7840 loss 0.2667081952095032
[2025-03-18 11:49:31,090][model][INFO] - Training step 8000 loss 0.23776346445083618
[2025-03-18 11:51:00,557][model][INFO] - Training step 8160 loss 0.03796052560210228
[2025-03-18 11:52:24,808][model][INFO] - Training step 8320 loss 0.025176066905260086
[2025-03-18 11:53:52,688][model][INFO] - Training step 8480 loss 0.0529671385884285
[2025-03-18 11:55:20,462][model][INFO] - Training step 8640 loss 0.005539810284972191
[2025-03-18 11:56:48,180][model][INFO] - Training step 8800 loss 0.11091238260269165
[2025-03-18 11:58:11,927][model][INFO] - Training step 8960 loss 0.00633765384554863
[2025-03-18 11:59:38,066][model][INFO] - Training step 9120 loss 0.25183165073394775
[2025-03-18 12:00:58,232][model][INFO] - Training step 9280 loss 0.2450418621301651
[2025-03-18 12:02:21,523][model][INFO] - Training step 9440 loss 0.01763489656150341
[2025-03-18 12:03:44,891][model][INFO] - Training step 9600 loss 0.020319126546382904
[2025-03-18 12:05:07,319][model][INFO] - Training step 9760 loss 0.23190684616565704
[2025-03-18 12:06:35,458][model][INFO] - Training step 9920 loss 0.003571443259716034
[2025-03-18 12:08:03,990][model][INFO] - Training step 10080 loss 0.25473952293395996
[2025-03-18 12:09:27,874][model][INFO] - Training step 10240 loss 0.012189235538244247
[2025-03-18 12:10:56,119][model][INFO] - Training step 10400 loss 0.21988078951835632
[2025-03-18 12:12:21,302][model][INFO] - Training step 10560 loss 0.006267878692597151
[2025-03-18 12:13:46,018][model][INFO] - Training step 10720 loss 0.27753937244415283
[2025-03-18 12:15:11,599][model][INFO] - Training step 10880 loss 0.036162517964839935
[2025-03-18 12:16:41,049][model][INFO] - Training step 11040 loss 0.023336296901106834
[2025-03-18 12:18:03,913][model][INFO] - Training step 11200 loss 0.10404691100120544
[2025-03-18 12:19:28,676][model][INFO] - Training step 11360 loss 0.23875552415847778
[2025-03-18 12:20:52,561][model][INFO] - Training step 11520 loss 0.018343450501561165
[2025-03-18 12:22:17,416][model][INFO] - Training step 11680 loss 0.22579076886177063
[2025-03-18 12:23:42,944][model][INFO] - Training step 11840 loss 0.0056652105413377285
[2025-03-18 12:25:06,825][model][INFO] - Training step 12000 loss 0.24899426102638245
[2025-03-18 12:26:34,621][model][INFO] - Training step 12160 loss 0.025966305285692215
[2025-03-18 12:27:58,278][model][INFO] - Training step 12320 loss 0.003398511093109846
[2025-03-18 12:29:24,643][model][INFO] - Training step 12480 loss 0.02764951065182686
[2025-03-18 12:30:47,718][model][INFO] - Training step 12640 loss 0.23313015699386597
[2025-03-18 12:32:13,322][model][INFO] - Training step 12800 loss 0.019168173894286156
[2025-03-18 12:33:41,173][model][INFO] - Training step 12960 loss 0.030632425099611282
[2025-03-18 12:35:07,643][model][INFO] - Training step 13120 loss 0.01114090345799923
[2025-03-18 12:36:28,253][model][INFO] - Training step 13280 loss 0.028284016996622086
[2025-03-18 12:37:54,839][model][INFO] - Training step 13440 loss 0.03193243592977524
[2025-03-18 12:39:19,190][model][INFO] - Training step 13600 loss 0.1663084775209427
[2025-03-18 12:40:44,953][model][INFO] - Training step 13760 loss 0.022587081417441368
[2025-03-18 12:42:10,038][model][INFO] - Training step 13920 loss 0.13678237795829773
[2025-03-18 12:43:40,996][model][INFO] - Training step 14080 loss 0.0027279325295239687
[2025-03-18 12:45:09,162][model][INFO] - Training step 14240 loss 0.06766857206821442
[2025-03-18 12:46:34,911][model][INFO] - Training step 14400 loss 0.007478731218725443
[2025-03-18 12:47:59,532][model][INFO] - Training step 14560 loss 0.0792955681681633
[2025-03-18 12:49:28,215][model][INFO] - Training step 14720 loss 0.019721318036317825
[2025-03-18 12:50:51,530][model][INFO] - Training step 14880 loss 0.031782444566488266
[2025-03-18 12:52:21,076][model][INFO] - Training step 15040 loss 0.04325290024280548
[2025-03-18 12:53:46,287][model][INFO] - Training step 15200 loss 0.01672551780939102
[2025-03-18 12:55:14,663][model][INFO] - Training step 15360 loss 0.006903721485286951
[2025-03-18 12:56:37,760][model][INFO] - Training step 15520 loss 0.018357031047344208
[2025-03-18 12:58:01,382][model][INFO] - Training step 15680 loss 0.06877575814723969
[2025-03-18 12:59:28,165][model][INFO] - Training step 15840 loss 0.0340498648583889
[2025-03-18 13:00:53,410][model][INFO] - Training step 16000 loss 0.009393688291311264
[2025-03-18 13:02:20,155][model][INFO] - Training step 16160 loss 0.005857392214238644
[2025-03-18 13:03:45,609][model][INFO] - Training step 16320 loss 0.02312960848212242
[2025-03-18 13:05:11,614][model][INFO] - Training step 16480 loss 0.06406097114086151
[2025-03-18 13:06:35,346][model][INFO] - Training step 16640 loss 0.04235732555389404
[2025-03-18 13:07:59,686][model][INFO] - Training step 16800 loss 0.012704113498330116
[2025-03-18 13:09:26,957][model][INFO] - Training step 16960 loss 0.027902178466320038
[2025-03-18 13:10:48,671][model][INFO] - Training step 17120 loss 0.24887774884700775
[2025-03-18 13:12:15,112][model][INFO] - Training step 17280 loss 0.031621161848306656
[2025-03-18 13:13:39,713][model][INFO] - Training step 17440 loss 0.020193545147776604
[2025-03-18 13:15:03,137][model][INFO] - Training step 17600 loss 0.2481198012828827
[2025-03-18 13:16:29,466][model][INFO] - Training step 17760 loss 0.047212567180395126
